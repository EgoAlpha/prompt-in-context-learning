{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ğŸ‡ LangChain\n",
    "\n",
    "\\[[English Version](./LangChainTutorial_en.ipynb)\\]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "å¦‚ä½•æ‰“é€ æˆ‘ä»¬è‡ªå·±ä¸“å±çš„èŠå¤©æœºå™¨äººï¼Ÿå¦‚ä½•é€šè¿‡ç®€å•çš„æ–¹å¼æ“æ§å¤§è¯­è¨€æ¨¡å‹(LLMs)ä»è€Œå­¦ä¹ åˆ°ç‰¹å®šé¢†åŸŸå†…çš„çŸ¥è¯†ï¼Ÿå¦‚ä½•åœ¨æ—¥å¸¸çš„å·¥ä½œæµå¼ä¸­ä½¿ç”¨å¤§æ¨¡å‹æ¿€å‘æ›´å¤šçš„æ½œåŠ›ï¼Ÿ\n",
    ">è¯·è®¾æƒ³ä¸‹é¢è¿™å‡ ç§åœºæ™¯ï¼šä½ æ‹¥æœ‰å‡ æœ¬ç”µå­ä¹¦ï¼Œæˆ–å‡ åä¸ªæ–‡æœ¬æ–‡ä»¶ï¼ŒæŠ‘æˆ–æ˜¯åˆ©ç”¨æ•°æ®åº“å®Œæˆç‰¹å®šä»»åŠ¡,æˆ‘ä»¬æƒ³è¦LLMsæ¨¡å‹å­¦ä¹ ç”¨æˆ·ç»™å®šçš„æ•°æ®ï¼Œå¹¶ä¸”åªå›ç­”ç»™å®šæ•°æ®èŒƒå›´å†…çš„ç›¸å…³é—®é¢˜,å¦‚æœé—®é¢˜è¶…å‡ºèŒƒå›´,ä¸€å¾‹å‘ŠçŸ¥ç”¨æˆ·é—®é¢˜è¶…å‡ºèŒƒå›´æ— æ³•å›ç­”,ä¹Ÿå°±æ˜¯æˆ‘ä»¬è¦é™åˆ¶LLMsæ¨¡å‹è‡ªç”±å‘æŒ¥ï¼Œä¸èƒ½è®©å®ƒéšä¾¿ä¹±è¯´ã€‚å¦‚ä½•åŸºäºå¤§æ¨¡å‹å®Œæˆä¸Šè¿°ä»»åŠ¡ï¼ŸLangChainå¯ä»¥å¸®ä½ å®ç°ã€‚ç‚¹å‡»ğŸ‘‰[è¿™é‡Œ](https://python.langchain.com/en/latest/index.html)ğŸ‘ˆå¯ä»¥ç›´æ¥è·³è½¬åˆ°LangChainçš„å®˜æ–¹æ–‡æ¡£è¯´æ˜ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LangChainæ˜¯ä¸€ä¸ªå¤§æ¨¡å‹ä¸Šå±‚å·¥å…·é“¾ï¼Œä¸€ä¸ªåŸºäºLLMsçš„åº”ç”¨ç¨‹åºå¼€å‘æ¡†æ¶, é€šè¿‡å¯ç»„åˆæ€§æ¥ä½¿ç”¨LLMæ„å»ºåº”ç”¨ç¨‹åº. å…¶é‡ç‚¹åœ¨äº\"å¯ç»„åˆæ€§\"ã€‚è®¾è®¡ä¸€ç³»åˆ—ä¾¿äºé›†æˆåˆ°å®é™…åº”ç”¨ä¸­çš„æ¥å£ï¼Œé™ä½äº†åœ¨å®é™…åœºæ™¯ä¸­éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹çš„éš¾åº¦ã€‚LangChainå¯ç”¨äºèŠå¤©æœºå™¨äººã€ç”Ÿæˆå¼é—®ç­”(GQA)ã€æ–‡æœ¬æ‘˜è¦æå–ç­‰ã€‚\n",
    "LangChainçš„ç›®æ ‡åœ¨äºï¼š\n",
    " - å…è®¸å¤§è¯­è¨€æ¨¡å‹å¤„ç†ä¸åŒæ¥æºçš„æ•°æ®\n",
    " - è®©å¤§è¯­è¨€æ¨¡å‹èƒ½å’Œå¸ƒç½®å®ƒçš„ç¯å¢ƒä¹‹é—´è¿›è¡Œäº¤äº’\n",
    "\n",
    "<img src=\"./langchain.png\" align=center width=100% />\n",
    "\n",
    "å¦‚ä¸Šå›¾æ‰€ç¤ºï¼ŒLangChainåº“ä¸»è¦åŒ…å«å…­ä¸ªéƒ¨åˆ†:\n",
    "- **Models**: æä¾›åŸºäºOpenAI APIå°è£…å¥½çš„å¤§æ¨¡å‹ï¼ŒåŒ…å«å¸¸è§çš„OpenAIå¤§æ¨¡å‹ï¼Œä¹Ÿæ”¯æŒè‡ªå®šä¹‰å¤§æ¨¡å‹çš„å°è£…ã€‚\n",
    "- **Prompt**: æ”¯æŒè‡ªå®šä¹‰Promptå·¥ç¨‹çš„å¿«é€Ÿå®ç°ä»¥åŠå’ŒLLMsçš„å¯¹æ¥ã€‚\n",
    "- **Index** æ¥å—ç”¨æˆ·æŸ¥è¯¢ï¼Œç´¢å¼•æœ€ç›¸å…³å†…å®¹è¿”å›ã€‚\n",
    "- **Memory**: æ ‡å‡†çš„æ¥å£, åœ¨chains/callä¹‹é—´ä¿å­˜çŠ¶æ€ã€‚\n",
    "- **Chains**: ä¸€ç³»åˆ—çš„è°ƒç”¨(LLMsæˆ–è€…å…¶ä»–, å¦‚ç½‘ç»œ, æ“ä½œç³»ç»Ÿ), Chainsæä¾›äº†æ ‡å‡†çš„æ¥å£å’Œè®¾ç½®æ¥ç»„åˆè¿™äº›è°ƒç”¨ã€‚ å…ˆä»å¤–éƒ¨çš„æºè·å–ä¿¡æ¯, ç„¶åå–‚ç»™LLMsã€‚å¤§æ¨¡å‹é’ˆå¯¹ä¸€ç³»åˆ—ä»»åŠ¡çš„é¡ºåºæ‰§è¡Œé€»è¾‘é“¾ã€‚\n",
    "- **Agents**: ä»£ç†, éå¸¸é‡è¦çš„ä¸€ç¯, å…³äºå¯¹LLMsåšä½•ç§action, å¦‚ä½•åšã€‚é€šå¸¸Utilsä¸­çš„èƒ½åŠ›ã€Chainsä¸­çš„å„ç§é€»è¾‘é“¾éƒ½ä¼šå°è£…æˆä¸€ä¸ªä¸ªå·¥å…·ï¼ˆToolsï¼‰ä¾›Agentsè¿›è¡Œæ™ºèƒ½åŒ–è°ƒç”¨ã€‚\n",
    "\n",
    "ğŸŒŸ æˆ‘ä»¬å°†ä¸»è¦åŸºäºOpenAIæä¾›å•†è¿›è¡Œä»£ç çš„è¯´æ˜ä¸è®²è§£ï¼Œé‚£ä¹ˆï¼Œæˆ‘ä»¬å°±å¼€å§‹è¿™ä¸ªæ—…ç¨‹å§ï¼ï¼ï¼âœŠ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“œ æ–‡æ¡£ç›®å½•ç»“æ„\n",
    "\n",
    "- [Before Start](#before-start)\n",
    "- [Models](#models)\n",
    "- [Prompt](#prompt)\n",
    "- [Index](#index)\n",
    "- [Memory](#memory)\n",
    "- [Chains](#chains)\n",
    "- [Agents](#agents)\n",
    "- [Coding Examples](#coding-exampls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Before Start\n",
    "\n",
    "ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥,è®¾ç½®ä»£ç†æ˜¯é’ˆå¯¹å›½å†…ç”¨æˆ·ï¼ˆåªé’ˆå¯¹å¤§é™†ï¼Œä¸æ¶‰åŠé¦™æ¸¯ã€æ¾³é—¨å’Œå°æ¹¾åœ°åŒºï¼‰ä½¿ç”¨OpenAIéœ€è¦æŒ‚è½½VPNçš„é—®é¢˜ï¼Œå› æ­¤éœ€è¦æœ¬åœ°è¿è¡Œç¨‹åºè¿›è¡Œä»£ç†è®¾ç½®ï¼Œä»è€Œé¿å…ç½‘ç»œåŸå› å¯¼è‡´çš„è®¿é—®å’Œè°ƒç”¨é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# è®¾ç½®HTTPä»£ç†ï¼Œæœ¬åœ°IPåœ°å€ä»¥åŠç«¯å£å·ï¼ŒæŸ¥çœ‹IPå¯ä»¥é€šè¿‡Win/Linuxä¸‹çš„IPCONFIG/IFCONFIGå‘½ä»¤æŸ¥çœ‹ï¼Œä¹Ÿå¯ä»¥ç›´æ¥é»˜è®¤è®¾ç½®ä¸º127.0.0.1,ç«¯å£è¦å†™æŒ‚è½½VPNçš„ç«¯å£å·ã€‚\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:XXX'\n",
    "# è®¾ç½®HTTPSä»£ç†ï¼ŒåŒä¸Š\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:XXX'\n",
    "\n",
    "#æ£€æŸ¥ä»£ç†æ˜¯å¦æœ‰ç”¨\n",
    "def check_proxy():\n",
    "    import urllib.request\n",
    "    url = \"https://www.google.com\"\n",
    "    # url = \"https://www.baidu.com\"\n",
    "    filename = \"google.html\"\n",
    "    urllib.request.urlretrieve(url, filename)#ä¿å­˜åœ¨å½“å‰æ–‡ä»¶å¤¹ä¸‹\n",
    "\n",
    "check_proxy()\n",
    "\n",
    "# openaiçš„key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"å¡«ä¸Šä½ è‡ªå·±çš„openai api  key\"\n",
    "\n",
    "#æœç´¢apiçš„key,ä»…åœ¨agentä¸­ä½¿ç”¨ï¼Œè¿™æ­¥ä¸æ˜¯å¿…è¦çš„\n",
    "os.environ['SERPAPI_API_KEY']='å¡«ä¸Šä½ è‡ªå·±çš„serpapi api key'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æ£€æŸ¥è°·æ­Œæœç´¢APIæ˜¯å¦èƒ½ç”¨ï¼Œè¿™ä¸€æ­¥æ˜¯éå¿…è¦çš„å¯é€‰æ­¥éª¤ï¼Œå¦‚æœä½ åœ¨ä¸‹æ–‡çš„ç¤ºä¾‹ä¸­æœ‰ç”¨åˆ°è°·æ­Œæœç´¢APIçš„ï¼Œé‚£å°±éœ€è¦è¿›è¡Œç›¸åº”çš„æ³¨å†Œæ‰å¯ä»¥è°ƒç”¨è®¿é—®ï¼Œæ³¨å†Œç½‘å€ç‚¹å‡»ğŸ‘‰[è¿™é‡Œ](https://serpapi.com/dashboard)ğŸ‘ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'search_metadata': {'id': '643802169d158690e4963190', 'status': 'Success', 'json_endpoint': 'https://serpapi.com/searches/11aa25012aaee788/643802169d158690e4963190.json', 'created_at': '2023-04-13 13:22:30 UTC', 'processed_at': '2023-04-13 13:22:30 UTC', 'google_url': 'https://www.google.com/search?q=coffee&oq=coffee&uule=w+CAIQICIdQXVzdGluLFRYLFRleGFzLFVuaXRlZCBTdGF0ZXM&sourceid=chrome&ie=UTF-8', 'raw_html_file': 'https://serpapi.com/searches/11aa25012aaee788/643802169d158690e4963190.html', 'total_time_taken': 6.54}, 'search_parameters': {'engine': 'google', 'q': 'coffee', 'location_requested': 'Austin,Texas', 'location_used': 'Austin,TX,Texas,United States', 'google_domain': 'google.com', 'device': 'desktop'}, 'search_information': {'organic_results_state': 'Results for exact spelling', 'query_displayed': 'coffee', 'total_results': 4660000000, 'time_taken_displayed': 0.68, 'menu_items': [{'position': 1, 'title': 'Images', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAC', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&tbm=isch'}, {'position': 2, 'title': 'Maps', 'link': 'https://maps.google.com/maps?q=coffee&uule=w+CAIQICIdQXVzdGluLFRYLFRleGFzLFVuaXRlZCBTdGF0ZXM&um=1&ie=UTF-8&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAE'}, {'position': 3, 'title': 'Shopping', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=shop&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAG', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&tbm=shop'}, {'position': 4, 'title': 'Videos', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=vid&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAI', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&tbm=vid'}, {'position': 5, 'title': 'News', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=nws&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAK', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&tbm=nws'}, {'position': 6, 'title': 'Books', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=bks&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAM'}, {'position': 7, 'title': 'Flights', 'link': 'https://www.google.com/flights?q=coffee&source=lnms&tbm=flm&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAO'}, {'position': 8, 'title': 'Finance', 'link': 'https://www.google.com/finance?sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAQ'}]}, 'local_map': {'link': 'https://www.google.com/search?q=coffee&npsic=0&rflfq=1&rldoc=1&rllag=32070028,-99860352,38230&tbm=lcl&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQtgN6BAggEAE', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/2ceeb353df0a2b7dbacfb30245d6b608.png', 'gps_coordinates': {'latitude': 32.070028, 'longitude': -99.860352, 'altitude': 38230}}, 'local_results': {'places': [{'position': 1, 'title': 'Cup of Joe', 'rating': 4.6, 'reviews_original': '(28)', 'reviews': 28, 'type': 'Cafe', 'address': 'Winters, TX', 'description': '\"Great coffee at a good value\"', 'place_id': '6645020494937232090', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&ludocid=6645020494937232090&q=coffee', 'lsig': 'AB86z5WMhEZFuTAJ4GDnJFa6q6QI', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/0705f5877861a41dca5d37ea99dd97ef89f977fc0b365c8cf27ec04d7e618086c09b1b2ed1363660.jpeg', 'gps_coordinates': {'latitude': 31.957932, 'longitude': -99.96268}}, {'position': 2, 'title': 'The Coffee Haus on Main', 'rating': 4.8, 'reviews_original': '(36)', 'reviews': 36, 'type': 'Coffee shop', 'address': 'Ballinger, TX', 'place_id': '7920778704432590090', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&ludocid=7920778704432590090&q=coffee', 'lsig': 'AB86z5UZD5xj713sXU0khIy4IiH8', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/0705f5877861a41dca5d37ea99dd97ef0a78d9eb720337ce35a1440d44674901de89cb271256be32.jpeg', 'gps_coordinates': {'latitude': 31.737326, 'longitude': -99.94827}, 'service_options': {'dine_in': True, 'takeout': True, 'no_delivery': True}}, {'position': 3, 'title': 'Starbucks', 'rating': 4.1, 'reviews_original': '(899)', 'reviews': 899, 'price': '$$', 'type': 'Coffee shop', 'address': 'Abilene, TX', 'description': 'Iconic Seattle-based coffeehouse chain', 'place_id': '12667355487137518257', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&ludocid=12667355487137518257&q=coffee', 'lsig': 'AB86z5UP_UZ7Xmy5pKn1KyEN_jln', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/0705f5877861a41dca5d37ea99dd97efa22f666b4763d1bb8847ef0f5b7d937e6e1dbdec5b00b43d.jpeg', 'gps_coordinates': {'latitude': 32.40273, 'longitude': -99.75803}}], 'more_locations_link': 'https://www.google.com/search?tbs=lf:1,lf_ui:9&tbm=lcl&q=coffee&rflfq=1&num=10&uule=w+CAIQICIdQXVzdGluLFRYLFRleGFzLFVuaXRlZCBTdGF0ZXM&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQjGp6BAgjEAI'}, 'knowledge_graph': {'title': 'Coffee', 'type': 'Beverage', 'kgmid': '/m/02vqfm', 'knowledge_graph_search_link': 'https://www.google.com/search?kgmid=/m/02vqfm&hl=en-US&q=Coffee&kgs=b20ee92310a81805&shndl=0&source=sh/x/kp/1', 'serpapi_knowledge_graph_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&hl=en-US&kgmid=%2Fm%2F02vqfm&location=Austin%2CTexas&q=Coffee', 'header_images': [{'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199679b67c7e38cfee5d269be063747a036a99fba652bbfbf7afe.jpeg', 'source': 'https://en.wikipedia.org/wiki/Coffee'}, {'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199679b67c7e38cfee5d2494a19d1b8b89f6366a3aec97ea21ede.jpeg', 'source': 'https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/'}, {'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199679b67c7e38cfee5d2c856230e8a98377b70dca233c2119e9d.jpeg', 'source': 'https://www.rush.edu/news/health-benefits-coffee'}, {'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199679b67c7e38cfee5d255d27c8f4046047c96132e92d1c347c3.jpeg', 'source': 'https://www.healthline.com/nutrition/top-evidence-based-health-benefits-of-coffee'}, {'image': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTfWpPUDBL9AWrANOJSorna-dMqhtYRtK8VhPYgoFfF3g&s', 'source': 'https://www.tastingtable.com/794355/different-types-of-coffee-explained/'}], 'description': 'Coffee is a beverage prepared from roasted coffee beans. Darkly colored, bitter, and slightly acidic, coffee has a stimulating effect on humans, primarily due to its caffeine content. It has the highest sales in the world market for hot drinks.', 'source': {'name': 'Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Coffee'}, 'acidity_level': '4.85 to 5.10', 'acidity_level_links': [{'text': 'Acidity level', 'link': 'https://www.google.com/search?q=coffee+acidity+level&stick=H4sIAAAAAAAAAOPgE-LUz9U3MCorTMvVksjPttIvzsgvKklLTC6xSkzOTInPSS1LzVnEKpKcn5aWmqoAEsssqVQACwMA6FvyLz4AAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ6BMoAHoFCI8BEAI'}, {'text': 'healthline.com', 'link': 'https://www.healthline.com/nutrition/is-coffee-acidic'}], 'buttons': [{'text': 'Price', 'subtitle': 'Price Of Coffee', 'title': 'Two tablespoons', 'link': 'https://twochimpscoffee.com/guides/how-to-use-coffee-syrup/#:~:text=Two%20tablespoons%20(30ml%20or%20one,for%20a%20regular%20coffee%20cup.', 'displayed_link': 'https://twochimpscoffee.com â€º guides â€º how-to-use-coff...', 'snippet': \"Two tablespoons (30ml or one ounce) of syrup is a good go-to if you're wondering how much coffee syrup to put in coffee. This is for a regular coffee cup.\", 'snippet_highlighted_words': ['Two tablespoons (30ml or one ounce)'], 'answer': 'Two tablespoons', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199675fd122d14c827c9e3e8fed4a470f851e3e84adff4a23eb4f.png', 'search_link': 'https://www.google.com/search?q=price+of+coffee&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQrooIegUIjAEQBA', 'serpapi_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=price+of+coffee'}, {'text': 'Energy Amount', 'subtitle': 'How Many Calories In Coffee', 'table': [['Amount Per 1 fl oz (29.6 g)100 grams6 fl oz (178 g)1 cup (8 fl oz) (237 g)1 cup (8 fl oz) (237 g)'], ['Calories 1']], 'search_link': 'https://www.google.com/search?q=how+many+calories+in+coffee&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQrooIegUIjAEQCA', 'serpapi_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=how+many+calories+in+coffee'}, {'text': 'Protein Amount', 'subtitle': 'How Much Protein Is In Coffee', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQixTzjUfKnje6rtTLWUrleiMFyY4UusMCuTGsIgABnHjJ3&s', 'title': 'Protein Coffee: How it works & 8 benefits you should be aware of', 'link': 'https://healthcareweekly.com/protein-coffee-benefits/#:~:text=Is%20Coffee%20On%20Its%20Own,meaningful%2C%20to%20say%20the%20least.', 'displayed_link': 'https://healthcareweekly.com â€º protein-coffee-benefits', 'snippet': 'Is Coffee On Its Own a Good Source of Protein? The short answer: no, coffee is not a good source of protein. However, protein content depends on the type of coffee. For instance, one cup (about 6 fluid ounces) of black coffee contains approximately 0.21 grams of protein, which is not meaningful, to say the least.', 'snippet_highlighted_words': ['no, coffee is not a good source of protein'], 'search_link': 'https://www.google.com/search?q=how+much+protein+is+in+coffee&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQrooIegUIjAEQDg', 'serpapi_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=how+much+protein+is+in+coffee'}, {'text': 'Ph level', 'subtitle': 'Ph Of Coffee', 'title': 'about 5', 'link': 'https://byjus.com/question-answer/ph-of-black-coffee/#:~:text=Black%20coffee%20typically%20has%20a,beans%2C%20roasting%2C%20and%20brewing.', 'displayed_link': 'https://byjus.com â€º question-answer â€º ph-of-black-coffee', 'snippet': 'Black coffee typically has a pH of about 5 and is thus slightly acidic. It is acidic, with pH between 4 and 5, depending on the beans, roasting, and brewing.', 'snippet_highlighted_words': ['about 5'], 'answer': 'about 5', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199675fd122d14c827c9ec36fd87acab3f7ae25c98ca17a4aace0.png', 'search_link': 'https://www.google.com/search?q=ph+of+coffee&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQrooIegUIjAEQEg', 'serpapi_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=ph+of+coffee'}], 'compounds_in_coffee': [{'name': 'Chlorogenic acid', 'link': 'https://www.google.com/search?q=Chlorogenic+acid&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwL87IiddiWMQq4JyRk1-Un56al5mskJicmbKDlREA-TI5fCcAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiIARAF', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Chlorogenic+acid&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwL87IiddiWMQq4JyRk1-Un56al5mskJicmbKDlREA-TI5fCcAAAA', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967401e973bf2272dfc16e2c8cfafa7c4cc39c553489d2631b66274c812e7446727.png'}, {'name': 'Quinic acid', 'link': 'https://www.google.com/search?q=Quinic+acid&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwL042tdBiWMTKHViamZeZrJCYnJmyg5URAI7HIvkiAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiIARAH', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Quinic+acid&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwL042tdBiWMTKHViamZeZrJCYnJmyg5URAI7HIvkiAAAA', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967401e973bf2272dfc16e2c8cfafa7c4cc2362001c04c2f1d2044b09e83d185675.png'}, {'name': 'Trigonelline', 'link': 'https://www.google.com/search?q=Trigonelline&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwrTKojNdiWMTKE1KUmZ6fl5qTk5mXuoOVEQBGl_DeIwAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiIARAJ', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Trigonelline&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwrTKojNdiWMTKE1KUmZ6fl5qTk5mXuoOVEQBGl_DeIwAAAA', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967401e973bf2272dfc16e2c8cfafa7c4cc8a99acca8218dd6ae69d6e62b343a898.png'}, {'name': 'Melanoidin', 'link': 'https://www.google.com/search?q=Melanoidin&stick=H4sIAAAAAAAAAONgFmJQ4tLP1TcwKso2M8zQYljEyuWbmpOYl5-Zkpm3g5URAEiv4kMiAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiIARAL', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Melanoidin&stick=H4sIAAAAAAAAAONgFmJQ4tLP1TcwKso2M8zQYljEyuWbmpOYl5-Zkpm3g5URAEiv4kMiAAAA', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967401e973bf2272dfc16e2c8cfafa7c4ccfcc2b1e8a30cf831eff946b2458c1940.png'}], 'compounds_in_coffee_link': 'https://www.google.com/search?q=compounds+in+coffee&stick=H4sIAAAAAAAAAONgFuLUz9U3MCorTMtVQjC1RLKTrfST83Nz8_OsUvLL88oTi1KKVzEKOmek5mYmJ-Y45-cW5JfmpRQvYhVOhrEVMvMUkvPT0lJTd7AyAgA94efZWwAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQMSgAegUIiAEQAQ', 'compounds_in_coffee_stick': 'H4sIAAAAAAAAAONgFuLUz9U3MCorTMtVQjC1RLKTrfST83Nz8_OsUvLL88oTi1KKVzEKOmek5mYmJ-Y45-cW5JfmpRQvYhVOhrEVMvMUkvPT0lJTd7AyAgA94efZWwAAAA', 'people_also_search_for': [{'name': 'Tea', 'link': 'https://www.google.com/search?q=Tea&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMgjPPDr-bVSwS7IwMGJZrTdb97oset9qkWSGGc8Wrx0cWPU0xfD2y8UwLcWHQST1bjafkmRjiQwYRe_3Itgz9qVSCKdZzbGbuLy9QXEb0Z8fNkExbIqMPt_n-TOdD4t0ZhyGHDkRXkCD3stHPYlkI9F6NqruSkOP8q19qSCJwA-F-iIzZCw4sk6NwHFknXQGz29sgmuriUCUg3JKKEr9yO6rD_j0gO7sFpA_vyMkVnlD2E-eVQ%3D%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiJARAF', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Tea&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMgjPPDr-bVSwS7IwMGJZrTdb97oset9qkWSGGc8Wrx0cWPU0xfD2y8UwLcWHQST1bjafkmRjiQwYRe_3Itgz9qVSCKdZzbGbuLy9QXEb0Z8fNkExbIqMPt_n-TOdD4t0ZhyGHDkRXkCD3stHPYlkI9F6NqruSkOP8q19qSCJwA-F-iIzZCw4sk6NwHFknXQGz29sgmuriUCUg3JKKEr9yO6rD_j0gO7sFpA_vyMkVnlD2E-eVQ%3D%3D', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967e72d5e765855f08c845d5d1bff276fdeeaa0922bc08dd464936d4e065df28d61.jpeg'}, {'name': 'Espresso', 'link': 'https://www.google.com/search?q=Espresso&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMjyaN62njrr4Y2vVD-0W98vYZcIInyX3v-g5zZZpHjjG-Poxv3XLD0drTfOgpVcCf-zFRIPvsy9oT9UP_w35iIRi9Dl7PJ4-ldCIJDe667xhyIl72gjAFfOKZBu3XGinHDe096zuvjykLeb_xXU3DhU-1QmnhQUqLZaEFgHJmWWQuA0wE2cEjLHtjh10JWDgzqQv2KOWtaNv-dvOLwEiFloEH3I1N1rrm0NY4CZcMZcqugn660gEsBi5JGVH9mmfP4wv-CI%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiJARAH', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Espresso&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMjyaN62njrr4Y2vVD-0W98vYZcIInyX3v-g5zZZpHjjG-Poxv3XLD0drTfOgpVcCf-zFRIPvsy9oT9UP_w35iIRi9Dl7PJ4-ldCIJDe667xhyIl72gjAFfOKZBu3XGinHDe096zuvjykLeb_xXU3DhU-1QmnhQUqLZaEFgHJmWWQuA0wE2cEjLHtjh10JWDgzqQv2KOWtaNv-dvOLwEiFloEH3I1N1rrm0NY4CZcMZcqugn660gEsBi5JGVH9mmfP4wv-CI%3D', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967e72d5e765855f08c845d5d1bff276fde5336e38b7da39c82f50576790ba2d2e1.jpeg'}, {'name': 'Cappuccino', 'link': 'https://www.google.com/search?q=Cappuccino&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMklZ6vtN6-8AY4RsUb9j1aMcn5_Fx0RVtguKTSjYOzJGH7WEnPl_82g6G4ZmQ47a0aQn5OaDfWitFqB1UyoD-3DPX9OrIzCD9nADAxnBhkOFxJrA8pSHWbkRwBQLlUjMBh218i1GQwoy1lyiRUKtITtVX99LqKB4Vnw74JG_9e88ZJr1WoMkOQoqE67xGs1BZHT4Q8YggMDNYAvtEZClZcNRxN3i715e-oP_ZO0WK7VtSx7RbP8PO9dSe9qaWJAVAfAFW7k%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiJARAJ', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Cappuccino&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMklZ6vtN6-8AY4RsUb9j1aMcn5_Fx0RVtguKTSjYOzJGH7WEnPl_82g6G4ZmQ47a0aQn5OaDfWitFqB1UyoD-3DPX9OrIzCD9nADAxnBhkOFxJrA8pSHWbkRwBQLlUjMBh218i1GQwoy1lyiRUKtITtVX99LqKB4Vnw74JG_9e88ZJr1WoMkOQoqE67xGs1BZHT4Q8YggMDNYAvtEZClZcNRxN3i715e-oP_ZO0WK7VtSx7RbP8PO9dSe9qaWJAVAfAFW7k%3D', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967e72d5e765855f08c845d5d1bff276fde30bbff2f88cf8f3a124c859ded15a3a2.jpeg'}, {'name': 'Latte', 'link': 'https://www.google.com/search?q=Latte&si=AMnBZoEofOODruSEFWFjdccePwMH96ZlZt3bOiKSR9t4pqlu2E2Y95jVypGw5nHfEGbzdy_B-mJrk7TV3R0_l7ZUBiUkk1BiloRi17mH8ufqGqbkUhe0c8_KO5vzQNZ-nrEeAaA8my_qJpcAz8qE92rIWhWLdi2-Y-wRjvz59t6q5db5z6-tVBvk31oUge5WvKN_KY-abBJwuAmRcDVTFFkzJExr2ij50aEqL8xoQy48LtRLUoNcARf8G9RPDtEL8wYJDyK5-OlqfXP74-MHX3KmEH_oT5JEeAsCl9zNCisFeyvLawCXTaY%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiJARAL', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Latte&si=AMnBZoEofOODruSEFWFjdccePwMH96ZlZt3bOiKSR9t4pqlu2E2Y95jVypGw5nHfEGbzdy_B-mJrk7TV3R0_l7ZUBiUkk1BiloRi17mH8ufqGqbkUhe0c8_KO5vzQNZ-nrEeAaA8my_qJpcAz8qE92rIWhWLdi2-Y-wRjvz59t6q5db5z6-tVBvk31oUge5WvKN_KY-abBJwuAmRcDVTFFkzJExr2ij50aEqL8xoQy48LtRLUoNcARf8G9RPDtEL8wYJDyK5-OlqfXP74-MHX3KmEH_oT5JEeAsCl9zNCisFeyvLawCXTaY%3D', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967e72d5e765855f08c845d5d1bff276fde3abe05036e61cb692c62b7db1ef7bd3f.jpeg'}], 'people_also_search_for_link': 'https://www.google.com/search?q=Coffee&stick=H4sIAAAAAAAAAONgFuLUz9U3MCorTMtVQjC1BIMzU1LLEyuL_VIrSoJLUguKF7GyOeenpaWm7mBlBABkIv_mNwAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQMSgAegUIiQEQAQ', 'people_also_search_for_stick': 'H4sIAAAAAAAAAONgFuLUz9U3MCorTMtVQjC1BIMzU1LLEyuL_VIrSoJLUguKF7GyOeenpaWm7mBlBABkIv_mNwAAAA', 'see_results_about': [{'name': 'Coffee bean', 'extensions': ['A coffee bean is a seed of the Coffea plant and the source for ...'], 'link': 'https://www.google.com/search?q=Coffee+bean&si=AMnBZoGn39e0tI_t2dCPKQ2j8QBKDHso0GZnCtfIMxO7bEcZSZ7sNGHzwtf8qdnwn3tXQ0AGsm2Ng73UcXfebGimZRXPLuphz7aw2b9GplBsHHhxGd0xEKJ8XvF1_wM5SNp0hs8oNfrzJQdeFjaOKy4f1Y1HsVo-vZbsVBt1pibEO5fKPf-Urjg%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ6RN6BAhlEAE', 'image': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQlwgD-6s3Vk872C9OaOBm_9QUtkchzWBoJWCdLswp_BSHUV8pNHndshQ&s=0'}], 'list': {'total_fat': ['0 g', '0%'], 'saturated_fat': ['0 g', '0%'], 'trans_fat_regulation': ['0 g'], 'cholesterol': ['0 mg', '0%'], 'sodium': ['5 mg', '0%'], 'potassium': ['116 mg', '3%'], 'total_carbohydrate': ['0 g', '0%'], 'dietary_fiber': ['0 g', '0%'], 'sugar': ['0 g'], 'protein': ['0.3 g', '0%'], 'caffeine': ['95 mg'], 'vitamin_c': ['0%'], 'calcium': ['0%'], 'iron': ['0%'], 'vitamin_d': ['0%'], 'vitamin_b6': ['0%'], 'cobalamin': ['0%'], 'magnesium': ['1%']}}, 'inline_images': [{'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C%252Fm%252F02vqfm%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kSeRZX4tRmBDC5WzqJ72knpK80xKw&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_B16BQiGARAB#imgrc=cHhAmJrw8EtbWM', 'source': 'https://en.wikipedia.org/wiki/Coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/9965b78b2d80b21d3f5db41f337bfeec902227f017d9dd1735e3765fd889c51e.jpeg', 'original': 'https://upload.wikimedia.org/wikipedia/commons/e/e4/Latte_and_dark_coffee.jpg', 'title': 'upload.wikimedia.org/wikipedia/commons/e/e4/Latte_...', 'source_name': 'en.wikipedia.org'}, {'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C_%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kQVRu5edShja3G23xcn5YB3AJ_0Lg&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_h16BQiHARAB#imgrc=9M1X2EDxsYNTZM', 'source': 'https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/9965b78b2d80b21d094f8ec1d3c2855e858ac1ef5bb628283bdffe67e0109546.jpeg', 'original': 'https://www.tastingtable.com/img/gallery/coffee-brands-ranked-from-worst-to-best/l-intro-1645231221.jpg', 'title': '31 Coffee Brands, Ranked From Worst To Best', 'source_name': 'Tasting Table'}, {'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C_%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kQVRu5edShja3G23xcn5YB3AJ_0Lg&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_h16BQiFARAB#imgrc=35LBrLe6iLMgNM', 'source': 'https://www.rush.edu/news/health-benefits-coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/9965b78b2d80b21d295a96d9e9320dc43b3ec3c1d728d8e2afa4eb919701e379.jpeg', 'original': 'https://www.rush.edu/sites/default/files/styles/386x217/public/media-images/Coffee_WebFeature.png?itok=gxteJ01c', 'title': 'Health Benefits of Coffee | Rush System', 'source_name': 'Rush University Medical Center'}, {'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C_%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kQVRu5edShja3G23xcn5YB3AJ_0Lg&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_h16BQiEARAB#imgrc=Ye55hwurmsyIDM', 'source': 'https://www.healthline.com/nutrition/top-evidence-based-health-benefits-of-coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/9965b78b2d80b21dc4a259fd912f9bcc346c5506f77fea62694c644a3ab00fa5.jpeg', 'original': 'https://post.healthline.com/wp-content/uploads/2020/08/coffee-worlds-biggest-source-of-antioxidants-1296x728-feature_0-732x549.jpg', 'title': '9 Health Benefits of Coffee, Based on Science', 'source_name': 'Healthline'}, {'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C_%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kQVRu5edShja3G23xcn5YB3AJ_0Lg&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_h16BQiDARAB#imgrc=e1xARNWS4v0NdM', 'source': 'https://www.tastingtable.com/794355/different-types-of-coffee-explained/', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTfWpPUDBL9AWrANOJSorna-dMqhtYRtK8VhPYgoFfF3g&s', 'original': 'https://www.tastingtable.com/img/gallery/20-different-types-of-coffee-explained/l-intro-1659544996.jpg', 'title': '35 Different Types Of Coffee Explained', 'source_name': 'Tasting Table'}], 'related_questions': [{'question': 'Is coffee good for health?', 'snippet': \"â€œFor most people, moderate coffee consumption can be incorporated into a healthy diet.â€ Hu said that moderate coffee intakeâ€”about 2â€“5 cups a dayâ€”is linked to a lower likelihood of type 2 diabetes, heart disease, liver and endometrial cancers, Parkinson's disease, and depression.\", 'title': 'Is coffee good or bad for your health? | News', 'link': 'https://www.hsph.harvard.edu/news/hsph-in-the-news/is-coffee-good-or-bad-for-your-health/', 'displayed_link': 'https://www.hsph.harvard.edu â€º news â€º hsph-in-the-news', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/581680f060c7d368510705ded46f2c9ed01360eca462a179580c31dd0f6541e0.png', 'next_page_token': 'eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiSXMgY29mZmVlIGdvb2QgZm9yIGhlYWx0aD8iLCJsayI6IkdoNWtiMlZ6SUdOdlptWmxaU0JwY3lCbmIyOWtJR1p2Y2lCb1pXRnNkR2ciLCJicyI6ImMtT1M1NUx5TEZaSXprOUxTMDFWU01fUFQxRkl5eTlTeUVoTnpDbkpzSmU0WThDbHdDVWRucEdabktHUVZKU1lsd0pUbVZtc2tKUmFYR0l2TWR1UVM0VkxQandqc1VRaHNTaFZvU1FqVmNGRW9hU3lJTFZZSVQ4TnF0cGU0ZzA3bHlxWEFvcXFwTlM4MUxUTUVoUmxtLVVFR0FFIiwiaWQiOiJmY18xIn0=', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google_related_questions&google_domain=google.com&next_page_token=eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiSXMgY29mZmVlIGdvb2QgZm9yIGhlYWx0aD8iLCJsayI6IkdoNWtiMlZ6SUdOdlptWmxaU0JwY3lCbmIyOWtJR1p2Y2lCb1pXRnNkR2ciLCJicyI6ImMtT1M1NUx5TEZaSXprOUxTMDFWU01fUFQxRkl5eTlTeUVoTnpDbkpzSmU0WThDbHdDVWRucEdabktHUVZKU1lsd0pUbVZtc2tKUmFYR0l2TWR1UVM0VkxQandqc1VRaHNTaFZvU1FqVmNGRW9hU3lJTFZZSVQ4TnF0cGU0ZzA3bHlxWEFvcXFwTlM4MUxUTUVoUmxtLVVFR0FFIiwiaWQiOiJmY18xIn0%3D'}, {'question': 'Which brand coffee is best?', 'title': 'List of Top 11 Coffee Brands in India', 'link': 'https://cashkaro.com/blog/best-coffee-brands/167279', 'list': ['Nescafe.', 'Rage Coffee.', 'Bru.', 'Davidoff.', 'Blue Tokai.', 'Starbucks.', 'Continental Coffee.', 'Country Bean.'], 'displayed_link': 'https://cashkaro.com â€º blog â€º best-coffee-brands', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT4WFZ6iwvyFQiZ2wM5iLAEmFEfdSqje27fd4amMxSsFQ&s', 'next_page_token': 'eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hpY2ggYnJhbmQgY29mZmVlIGlzIGJlc3Q/IiwibGsiOiJHaHAzYUdsamFDQmljbUZ1WkNCamIyWm1aV1VnYVhNZ1ltVnpkQSIsImJzIjoiYy1PUzU1THlMRlpJems5TFMwMVZTTV9QVDFGSXl5OVN5RWhOekNuSnNKZTRZOENsd0NVZG5wR1puS0dRVkpTWWx3SlRtVm1za0pSYVhHSXZNZHVRUzRWTFBqd2pzVVFoc1NoVm9TUWpWY0ZFb2FTeUlMVllJVDhOcXRwZTRnMDdseXFYQW9xcXBOUzgxTFRNRWhSbG0tVUVHQUUiLCJpZCI6ImZjXzEifQ==', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google_related_questions&google_domain=google.com&next_page_token=eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hpY2ggYnJhbmQgY29mZmVlIGlzIGJlc3Q%2FIiwibGsiOiJHaHAzYUdsamFDQmljbUZ1WkNCamIyWm1aV1VnYVhNZ1ltVnpkQSIsImJzIjoiYy1PUzU1THlMRlpJems5TFMwMVZTTV9QVDFGSXl5OVN5RWhOekNuSnNKZTRZOENsd0NVZG5wR1puS0dRVkpTWWx3SlRtVm1za0pSYVhHSXZNZHVRUzRWTFBqd2pzVVFoc1NoVm9TUWpWY0ZFb2FTeUlMVllJVDhOcXRwZTRnMDdseXFYQW9xcXBOUzgxTFRNRWhSbG0tVUVHQUUiLCJpZCI6ImZjXzEifQ%3D%3D'}, {'question': 'What are the 4 types of coffee?', 'snippet': 'There are 4 types of coffee bean. Arabica, Robusta, Excelsa and Liberica.', 'title': 'Coffee beans guide: Origin & different types | NESCAFÃ‰ MENA', 'link': 'https://www.nescafe.com/mena/en-ae/understanding-coffee/coffee-beans-guide', 'displayed_link': 'https://www.nescafe.com â€º en-ae â€º understanding-coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/581680f060c7d368510705ded46f2c9ec6ef6e60144d6ff6bcfe79a9b6526622.png', 'next_page_token': 'eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hhdCBhcmUgdGhlIDQgdHlwZXMgb2YgY29mZmVlPyIsImxrIjoiR2g1M2FHRjBJR0Z5WlNCMGFHVWdOQ0IwZVhCbGN5QnZaaUJqYjJabVpXVSIsImJzIjoiYy1PUzU1THlMRlpJems5TFMwMVZTTV9QVDFGSXl5OVN5RWhOekNuSnNKZTRZOENsd0NVZG5wR1puS0dRVkpTWWx3SlRtVm1za0pSYVhHSXZNZHVRUzRWTFBqd2pzVVFoc1NoVm9TUWpWY0ZFb2FTeUlMVllJVDhOcXRwZTRnMDdseXFYQW9xcXBOUzgxTFRNRWhSbG0tVUVHQUUiLCJpZCI6ImZjXzEifQ==', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google_related_questions&google_domain=google.com&next_page_token=eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hhdCBhcmUgdGhlIDQgdHlwZXMgb2YgY29mZmVlPyIsImxrIjoiR2g1M2FHRjBJR0Z5WlNCMGFHVWdOQ0IwZVhCbGN5QnZaaUJqYjJabVpXVSIsImJzIjoiYy1PUzU1THlMRlpJems5TFMwMVZTTV9QVDFGSXl5OVN5RWhOekNuSnNKZTRZOENsd0NVZG5wR1puS0dRVkpTWWx3SlRtVm1za0pSYVhHSXZNZHVRUzRWTFBqd2pzVVFoc1NoVm9TUWpWY0ZFb2FTeUlMVllJVDhOcXRwZTRnMDdseXFYQW9xcXBOUzgxTFRNRWhSbG0tVUVHQUUiLCJpZCI6ImZjXzEifQ%3D%3D'}, {'question': 'What are the benefits of coffee?', 'title': 'Here are the top ways coffee can positively impact your health:', 'link': 'https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you', 'list': ['You could live longer. ... ', 'Your body may process glucose (or sugar) better. ... ', \"You're less likely to develop heart failure. ... \", \"You are less likely to develop Parkinson's disease. ... \", 'Your liver will thank you. ... ', 'Your DNA will be stronger.'], 'displayed_link': 'https://www.hopkinsmedicine.org â€º health â€º 9-reasons...', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSDV1_KHRKIUNXbIJYeb7G3jkEJsXv-MlZnSnAT4Qh-iw&s', 'next_page_token': 'eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hhdCBhcmUgdGhlIGJlbmVmaXRzIG9mIGNvZmZlZT8iLCJsayI6IkdoOTNhR0YwSUdGeVpTQjBhR1VnWW1WdVpXWnBkSE1nYjJZZ1kyOW1abVZsIiwiYnMiOiJjLU9TNTVMeUxGWkl6azlMUzAxVlNNX1BUMUZJeXk5U3lFaE56Q25Kc0plNFk4Q2x3Q1VkbnBHWm5LR1FWSlNZbHdKVG1WbXNrSlJhWEdJdk1kdVFTNFZMUGp3anNVUWhzU2hWb1NRalZjRkVvYVN5SUxWWUlUOE5xdHBlNGcwN2x5cVhBb3FxcE5TODFMVE1FaFJsbS1VRUdBRSIsImlkIjoiZmNfMSJ9', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google_related_questions&google_domain=google.com&next_page_token=eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hhdCBhcmUgdGhlIGJlbmVmaXRzIG9mIGNvZmZlZT8iLCJsayI6IkdoOTNhR0YwSUdGeVpTQjBhR1VnWW1WdVpXWnBkSE1nYjJZZ1kyOW1abVZsIiwiYnMiOiJjLU9TNTVMeUxGWkl6azlMUzAxVlNNX1BUMUZJeXk5U3lFaE56Q25Kc0plNFk4Q2x3Q1VkbnBHWm5LR1FWSlNZbHdKVG1WbXNrSlJhWEdJdk1kdVFTNFZMUGp3anNVUWhzU2hWb1NRalZjRkVvYVN5SUxWWUlUOE5xdHBlNGcwN2x5cVhBb3FxcE5TODFMVE1FaFJsbS1VRUdBRSIsImlkIjoiZmNfMSJ9'}], 'organic_results': [{'position': 1, 'title': 'Coffee', 'link': 'https://en.wikipedia.org/wiki/Coffee', 'displayed_link': 'https://en.wikipedia.org â€º wiki â€º Coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370235e3abd98c1947069c6e9748089046bd.jpeg', 'snippet': 'Coffee is a beverage prepared from roasted coffee beans. Darkly colored, bitter, and slightly acidic, coffee has a stimulating effect on humans, ...', 'snippet_highlighted_words': ['Coffee', 'coffee', 'coffee'], 'sitelinks': {'inline': [{'title': 'List of countries by coffee...', 'link': 'https://en.wikipedia.org/wiki/List_of_countries_by_coffee_production'}, {'title': 'Coffee production', 'link': 'https://en.wikipedia.org/wiki/Coffee_production'}, {'title': 'Coffee preparation', 'link': 'https://en.wikipedia.org/wiki/Coffee_preparation'}, {'title': 'Brewed coffee', 'link': 'https://en.wikipedia.org/wiki/Brewed_coffee'}]}, 'rich_snippet': {'bottom': {'extensions': ['Region of origin: Kaffa in Horn of Africa\\u200e', 'Ingredients: Roasted coffee beans', 'Introduced: 15th century', 'Flavor: Distinctive, somewhat bitter'], 'detected_extensions': {'introduced_th_century': 15}}}, 'about_this_result': {'source': {'description': 'Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.', 'source_info_link': 'https://en.wikipedia.org/wiki/Coffee', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a413702aa62bef54786db18713ef6486dccfb265a7385357ccdd522556c3f303ed26557.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://en.wikipedia.org/wiki/Coffee&tbm=ilp&ilps=ADJL0izANxNmAZazzpMAeGlkd2tXrw-aIQ', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0izANxNmAZazzpMAeGlkd2tXrw-aIQ&q=About+https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FCoffee', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:U6oJMnF-eeUJ:https://en.wikipedia.org/wiki/Coffee&cd=33&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://en.wikipedia.org/wiki/Coffee+coffee'}, {'position': 2, 'title': 'The Coffee Bean & Tea Leaf | CBTL', 'link': 'https://www.coffeebean.com/', 'displayed_link': 'https://www.coffeebean.com', 'snippet': 'Born and brewed in Southern California since 1963, The Coffee Bean & Tea LeafÂ® is passionate about connecting loyal customers with carefully handcrafted ...', 'snippet_highlighted_words': ['Coffee'], 'about_this_result': {'source': {'description': 'The Coffee Bean & Tea Leaf is an American coffee shop chain founded in 1963. Since 2019, it is a trade name of Ireland-based Super Magnificent Coffee Company Ireland Limited. Its 80% stake is by multinational company Jollibee Foods Corporation.', 'source_info_link': 'https://www.coffeebean.com/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370236dec1b6bf726a3914d6a9d5028d25c59578b20700b175de3b92316a2e9db711.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.coffeebean.com/&tbm=ilp&ilps=ADJL0iyEMfWcc_F0sQp68evlFpMNONzA7w', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iyEMfWcc_F0sQp68evlFpMNONzA7w&q=About+https%3A%2F%2Fwww.coffeebean.com%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:WpQxSYo2c6AJ:https://www.coffeebean.com/&cd=34&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://www.coffeebean.com/+coffee'}, {'position': 3, 'title': 'What is Coffee?', 'link': 'https://www.ncausa.org/About-Coffee/What-is-Coffee', 'displayed_link': 'https://www.ncausa.org â€º About Coffee', 'snippet': 'cofÂ·fee /ËˆkÃ´fÄ“,ËˆkÃ¤fÄ“/ noun The berries harvested from species of Coffea plants. Everyone recognizes a roasted coffee bean, but you might not recognize an actual ...', 'snippet_highlighted_words': ['coffee'], 'about_this_result': {'source': {'description': 'The National Coffee Association or, is the main market research, consumer information, and lobbying association for the coffee industry in the United States.', 'source_info_link': 'https://www.ncausa.org/About-Coffee/What-is-Coffee', 'security': 'secure'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.ncausa.org/About-Coffee/What-is-Coffee&tbm=ilp&ilps=ADJL0ixxUUvfx6Ju5WRyyjiP05--z_0mTg', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0ixxUUvfx6Ju5WRyyjiP05--z_0mTg&q=About+https%3A%2F%2Fwww.ncausa.org%2FAbout-Coffee%2FWhat-is-Coffee', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:ENqpL6s3VPIJ:https://www.ncausa.org/About-Coffee/What-is-Coffee&cd=35&hl=en&ct=clnk&gl=us'}, {'position': 4, 'title': 'Coffee | Origin, Types, Uses, History, & Facts', 'link': 'https://www.britannica.com/topic/coffee', 'displayed_link': 'https://www.britannica.com â€º ... â€º Food', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a413702cdf1deddb67d451859d5294688e08a58.jpeg', 'date': 'Mar 22, 2023', 'snippet': 'coffee, beverage brewed from the roasted and ground seeds of the tropical evergreen coffee plants of African origin. Coffee is one of the ...', 'snippet_highlighted_words': ['coffee', 'coffee', 'Coffee'], 'rich_snippet': {'bottom': {'questions': ['What is coffee?', 'Where did coffee originate?']}}, 'about_this_result': {'source': {'description': 'britannica.com was first indexed by Google more than 10 years ago', 'source_info_link': 'https://www.britannica.com/topic/coffee', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a413702c76d8a9622e3a3b5b18646a9438a950d1c3d93c649733c1e50bf8159b64d21a1.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.britannica.com/topic/coffee&tbm=ilp&ilps=ADJL0ixB8MrWhyEfLpjZI0CfZRgB9XA7wQ', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0ixB8MrWhyEfLpjZI0CfZRgB9XA7wQ&q=About+https%3A%2F%2Fwww.britannica.com%2Ftopic%2Fcoffee', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:Wikbu4ipU28J:https://www.britannica.com/topic/coffee&cd=36&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://www.britannica.com/topic/coffee+coffee'}, {'position': 5, 'title': 'Coffee', 'link': 'https://www.amazon.com/coffee/s?k=coffee', 'displayed_link': 'https://www.amazon.com â€º coffee â€º k=coffee', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTX9ofuNsZqYoWn7Q955M3hXmXDY5UnwxG3LEpCMlpVyuH9d6XEpGSFfSRSoU-2AgxkvTs&s', 'snippet': \"The Original Donut Shop Regular, Single-Serve Keurig K-Cup Pods, Medium Roast Coffee Pods, 24 Count (Pack of 4) ... Chock Full o'Nuts Original Roast Ground Coffee ...\", 'snippet_highlighted_words': ['Coffee', 'Coffee'], 'images': ['https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTX9ofuNsZqYoWn7Q955M3hXmXDY5UnwxG3LEpCMlpVyuH9d6XEpGSFfSRSoU-2AgxkvTs&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQHRrxTFVWH2fwyGJIwUzVkOHtqToQPGSVY3-Okffd-S2Ynzx5Cl2KTnrUunIMysfWPsns&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTPMicqxvC9FsqHIU5UmLz_gtZf2_VEsz2z7KeOGarDH639rrLKOTlOHCCpe-HiSbOFM5o&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS2fO2Mak3Y7USbiGvN4UdFgZXDn0DouDuRMgyUfPr29ANmsZGDk_zgeU_wsP6-E_9vN4c&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQZvUs5K8EeSa2U1SEwUNglwDYsb0NvxL8ZSyIHcghiIHx3o1byE_rBSzg31CuZnG-szA&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR1Qee1OmG2Yu9yS9AUYwfwAEzKH6oyYeSIqESDOSTidszlgdJOUezTH6OiszoBD5aZGBo&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTJz-mmbLw9CbQzPjj7jHU5ZZetu-XJqb5POLfDrQlpHgD3Ky9Sd65QDTyY5kJ48LUmh7A&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQIYAvQmQ_BbowG0CwmsnKm67ayf1kTWa0aueBTjjRzSvvLmrYoMCV6gZM30NJwMhA1mw&s'], 'rich_snippet': {'top': {'detected_extensions': {'free': 30}, 'extensions': ['Free 30', 'day returns']}}, 'about_this_result': {'source': {'description': 'Amazon.com, Inc. is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence.', 'source_info_link': 'https://www.amazon.com/coffee/s?k=coffee', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370271de3cc16a260186c3b4cb3a7fd7c1ed2f6dcfc37c91066409b0b45459219d02.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.amazon.com/coffee/s?k%3Dcoffee&tbm=ilp&ilps=ADJL0iz4yaPjFE5YbA0TnbXqmN1j8Qqr0g', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iz4yaPjFE5YbA0TnbXqmN1j8Qqr0g&q=About+https%3A%2F%2Fwww.amazon.com%2Fcoffee%2Fs%3Fk%3Dcoffee', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:wfQ5Et9Ni-kJ:https://www.amazon.com/coffee/s%3Fk%3Dcoffee&cd=37&hl=en&ct=clnk&gl=us'}, {'position': 6, 'title': 'Coffee | The Nutrition Source | Harvard T.H. Chan School of ...', 'link': 'https://www.hsph.harvard.edu/nutritionsource/food-features/coffee/', 'displayed_link': 'https://www.hsph.harvard.edu â€º ... â€º Food Features', 'snippet': 'Coffee beans are the seeds of a fruit called a coffee cherry. Coffee cherries grow on coffee trees from a genus of plants called Coffea. There are a wide ...', 'snippet_highlighted_words': ['Coffee', 'coffee', 'Coffee', 'coffee'], 'about_this_result': {'source': {'description': 'The Harvard T.H. Chan School of Public Health is the public health school of Harvard University, located in the Longwood Medical Area of Boston, Massachusetts.', 'source_info_link': 'https://www.hsph.harvard.edu/nutritionsource/food-features/coffee/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a4137026dbd26df06a2dbaf014d13f33e6a3b6a920533e702cc436894e9cb1a14359630.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.hsph.harvard.edu/nutritionsource/food-features/coffee/&tbm=ilp&ilps=ADJL0ix24UjkA35TUhg8KpNFoGqXA4X1pg', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0ix24UjkA35TUhg8KpNFoGqXA4X1pg&q=About+https%3A%2F%2Fwww.hsph.harvard.edu%2Fnutritionsource%2Ffood-features%2Fcoffee%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:aCQFR0EWgPwJ:https://www.hsph.harvard.edu/nutritionsource/food-features/coffee/&cd=38&hl=en&ct=clnk&gl=us'}, {'position': 7, 'title': \"Peet's Coffee: The Original Craft Coffee\", 'link': 'https://www.peets.com/', 'displayed_link': 'https://www.peets.com', 'snippet': \"Since 1966, Peet's Coffee has offered superior coffees and teas by sourcing the best quality coffee beans and tea leaves in the world and adhering to strict ...\", 'snippet_highlighted_words': ['Coffee', 'coffees', 'coffee'], 'about_this_result': {'source': {'description': \"Peet's Coffee is a San Francisco Bay Area-based specialty coffee roaster and retailer owned by JAB Holding Company via JDE Peet's.\", 'source_info_link': 'https://www.peets.com/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a4137024be2581d9638efd0771f573c952f60c8149f094c13f4611da3180decb846ea6a.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.peets.com/&tbm=ilp&ilps=ADJL0iyi0Ke6jkQwj42VpDqECgl1WRdfeQ', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iyi0Ke6jkQwj42VpDqECgl1WRdfeQ&q=About+https%3A%2F%2Fwww.peets.com%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:BCjzno6zP6wJ:https://www.peets.com/&cd=39&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://www.peets.com/+coffee'}, {'position': 8, 'title': '31 Coffee Brands, Ranked From Worst To Best', 'link': 'https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/', 'displayed_link': 'https://www.tastingtable.com â€º coffee-brands-ranked-f...', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQJbKwc_XPeJDMpYB72QQ9gDtxMu3fnuYp3dVPBKNRH58VXOyFxTPIK&usqp=CAE&s', 'date': 'Mar 2, 2023', 'snippet': \"From cafÃ© chains to retail roasters, we've ranked some of the most popular coffee brands from worst to first.\", 'snippet_highlighted_words': ['coffee'], 'about_this_result': {'source': {'description': \"Tasting Table is a digital media company focused on food and drink. The brand's website and email newsletter report on food and drink trends in the categories of dining, wine, cocktails, cooking and food travel.\", 'source_info_link': 'https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370255d9fd38631e86b30b8ba5a6270a8f8f8d3fdf473f4298db2e8f3de80302c3c1.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/&tbm=ilp&ilps=ADJL0iwgbb7uiNB1U30anBQOfSid1twx2w', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iwgbb7uiNB1U30anBQOfSid1twx2w&q=About+https%3A%2F%2Fwww.tastingtable.com%2F718678%2Fcoffee-brands-ranked-from-worst-to-best%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:O0p2m8H_t7EJ:https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/&cd=40&hl=en&ct=clnk&gl=us'}, {'position': 9, 'title': 'Starbucks Coffee Company', 'link': 'https://www.starbucks.com/', 'displayed_link': 'https://www.starbucks.com', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTUIjRcZRdCIqaOwWV7l1lcn8E-1M1YZNoG2_Kh_UJ8snRuD8oenfX-&usqp=CAE&s', 'snippet': 'More than just great coffee. Explore the menu, sign up for StarbucksÂ® Rewards, manage your gift card and more.', 'snippet_highlighted_words': ['coffee'], 'about_this_result': {'source': {'description': \"Starbucks Corporation is an American multinational chain of coffeehouses and roastery reserves headquartered in Seattle, Washington. It is the world's largest coffeehouse chain.\\nAs of November 2021, the company had 33,833 stores in 80 countries, 15,444 of which were located in the United States.\", 'source_info_link': 'https://www.starbucks.com/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370201fd9153a994c33cca23ce212f7b632caa714a5c58d1a195fdcc3b69b71b230c.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.starbucks.com/&tbm=ilp&ilps=ADJL0iz2L53LZLU_48M30C3XaAwABDTi8g', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iz2L53LZLU_48M30C3XaAwABDTi8g&q=About+https%3A%2F%2Fwww.starbucks.com%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:1vGXgo_FlHkJ:https://www.starbucks.com/&cd=41&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://www.starbucks.com/+coffee'}, {'position': 10, 'title': '9 Reasons Why (the Right Amount of) Coffee Is Good for You', 'link': 'https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you', 'displayed_link': 'https://www.hopkinsmedicine.org â€º health â€º 9-reasons...', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRsnUcaHtehFB7MvyuymVeeL7PLkII_xVLL_v6YkOtwxYZV-rzP0RBL&usqp=CAE&s', 'snippet': 'But coffee also contains antioxidants and other active substances that may reduce internal inflammation and protect against disease, say nutrition experts from ...', 'snippet_highlighted_words': ['coffee'], 'about_this_result': {'source': {'description': 'hopkinsmedicine.org was first indexed by Google more than 10 years ago', 'source_info_link': 'https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a413702a84bcbfb2440423ae0a0c5fb59f87e224f8c64115e43db3dd8cb98600b9b54aa.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you&tbm=ilp&ilps=ADJL0izDwqyqs6boUzNyhlVyPUkW3-dJ3Q', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0izDwqyqs6boUzNyhlVyPUkW3-dJ3Q&q=About+https%3A%2F%2Fwww.hopkinsmedicine.org%2Fhealth%2Fwellness-and-prevention%2F9-reasons-why-the-right-amount-of-coffee-is-good-for-you', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:MdKXyZO_8uQJ:https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you&cd=42&hl=en&ct=clnk&gl=us'}], 'related_searches': [{'query': 'coffee near me', 'link': 'https://www.google.com/search?q=Coffee+near+me&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh1EAE'}, {'query': 'coffee types', 'link': 'https://www.google.com/search?q=Coffee+types&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh6EAE'}, {'query': 'coffee beans', 'link': 'https://www.google.com/search?q=Coffee+beans&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAhzEAE'}, {'query': 'coffee machine', 'link': 'https://www.google.com/search?q=Coffee+machine&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh3EAE'}, {'query': 'coffee benefits', 'link': 'https://www.google.com/search?q=Coffee+benefits&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh7EAE'}, {'query': 'coffee starbucks', 'link': 'https://www.google.com/search?q=Coffee+Starbucks&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh4EAE'}, {'query': 'coffee origin', 'link': 'https://www.google.com/search?q=Coffee+origin&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAhyEAE'}, {'query': 'coffee plant', 'link': 'https://www.google.com/search?q=Coffee+plant&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh0EAE'}], 'pagination': {'current': 1, 'next': 'https://www.google.com/search?q=coffee&oq=coffee&start=10&sourceid=chrome&ie=UTF-8', 'other_pages': {'2': 'https://www.google.com/search?q=coffee&oq=coffee&start=10&sourceid=chrome&ie=UTF-8', '3': 'https://www.google.com/search?q=coffee&oq=coffee&start=20&sourceid=chrome&ie=UTF-8', '4': 'https://www.google.com/search?q=coffee&oq=coffee&start=30&sourceid=chrome&ie=UTF-8', '5': 'https://www.google.com/search?q=coffee&oq=coffee&start=40&sourceid=chrome&ie=UTF-8'}}, 'serpapi_pagination': {'current': 1, 'next_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=10', 'next': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=10', 'other_pages': {'2': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=10', '3': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=20', '4': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=30', '5': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=40'}}}\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "search = GoogleSearch({\n",
    "    \"q\": \"coffee\",\n",
    "    \"location\": \"Austin,Texas\",\n",
    "  })\n",
    "result = search.get_dict()\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æ£€æŸ¥OpenAI KEYæ˜¯å¦å¯ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" Kaitlin. I\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1682500219,\n",
      "  \"id\": \"cmpl-79VSFbbtZ9ekxWgW9LTDSvimSJwd3\",\n",
      "  \"model\": \"davinci\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 5,\n",
      "    \"prompt_tokens\": 5,\n",
      "    \"total_tokens\": 10\n",
      "  }\n",
      "}\n",
      "--------\n",
      " Kaitlin. I\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\"\"\"\n",
    "è°ƒç”¨ChatGPT APIï¼Œå…¶ä¸­çš„engineæ˜¯ä½¿ç”¨çš„chatgptçš„davinciå¼•æ“ï¼Œ\n",
    "è¾“å…¥æç¤ºæ˜¯promptï¼Œç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦é™åˆ¶ä¸º5ä¸ªtokensï¼Œä¸€ä¸ªtokenå¯ä»¥\n",
    "æ˜¯ä¸€ä¸ªå•è¯æˆ–è€…ä¸€ä¸ªå­è¯ï¼Œn=1æ˜¯è®¾ç½®çš„ç”Ÿæˆæ–‡æœ¬çš„æ•°é‡ï¼Œå³è¡¨ç¤ºç”Ÿæˆä¸€æ¡å›å¤ï¼Œstopæ˜¯\n",
    "æ¥æŒ‡å®šç”Ÿæˆæ–‡æœ¬ç»“æŸçš„æ¡ä»¶çš„ï¼Œè¿™é‡Œè®¾ä¸ºNoneï¼Œè¡¨ç¤ºä¸è®¾ç½®åœæ­¢çš„æ¡ä»¶ï¼Œtemperatureæ˜¯\n",
    "ç”¨æ¥æ§åˆ¶æ–‡æœ¬ç”Ÿæˆçš„éšæœºæ€§çš„ï¼Œæ•°å€¼è¶Šå¤§ä»£è¡¨ç”Ÿæˆçš„æ–‡æœ¬è¶Šéšæœºï¼Œæ•°å€¼è¶Šå°è¡¨ç¤ºç”Ÿæˆçš„æ–‡æœ¬\n",
    "å¾ˆç¡®å®šå’Œä¿å®ˆã€‚è¿”å›çš„å†…å®¹å°±æ˜¯responseå¯¹è±¡ã€‚\n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\",\n",
    "    prompt=\"Hello, my name is\",\n",
    "    max_tokens=5,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "# è¾“å‡ºChatGPTçš„å›å¤\n",
    "print(\"response : {}\".format(response))\n",
    "print(\"--------\")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Models\n",
    "\n",
    "é‚£ä¹ˆç°åœ¨å¼€å§‹æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªæ¿å—å†…å®¹ï¼Œè¯¥æ¿å—ä¸­çš„ä»£ç ç¤ºä¾‹éƒ¨åˆ†æ¥æºäºLangChainå®˜ç½‘æ•™ç¨‹ï¼Œå…³äºModelsçš„è¯¦ç»†è¯´æ˜æ–‡æ¡£ä»¥åŠæŒ‡ç¤ºè¯·ç‚¹å‡»ğŸ‘‰[æ­¤å¤„](https://python.langchain.com/en/latest/modules/models.html)ğŸ‘ˆè¿›è¡Œç›´æ¥è®¿é—®ã€‚\n",
    "\n",
    "- [LLMs](#llms)\n",
    "- [Chat Models](#chat-models)\n",
    "- [Text Embedding Models](#text-embedding-models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LLMs\n",
    "\n",
    "æˆ‘ä»¬çŸ¥é“â€”â€”LangChainæœ¬èº«ä¸æä¾›å¤§è¯­è¨€æ¨¡å‹ï¼Œåªæä¾›å„ç§æ¥å£å’Œæ–¹å¼ç”¨ä»¥è°ƒç”¨è®¿é—®å¤§è¯­è¨€æ¨¡å‹ã€‚\n",
    "ç°åœ¨æœ‰å¾ˆå¤šLLMæä¾›å•†æ¯”å¦‚OpenAI, Cohere, Hugging Faceç­‰ã€‚åœ¨LLMsä¸­ï¼Œæä¾›äº†ç»Ÿä¸€çš„æ¥å£æ¥è®¿é—®è¿™äº›å¤§æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢æ˜¯å¸¸è§„è°ƒç”¨å£°æ˜LLMçš„æ–¹å¼æ–¹æ³•ï¼Œæ¨¡å‹é€‰æ‹©æ˜¯å¾ˆå¤šçš„ï¼Œå…·ä½“è¦ä½¿ç”¨å“ªä¸ªæ¨¡å‹å¯ä»¥è®¿é—®[æ­¤å¤„](https://platform.openai.com/docs/models/overview)è¿›è¡Œæµè§ˆå’Œè®¾ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"model_nameæ˜¯é€‰æ‹©çš„OpenAIçš„æ¨¡å‹åç§°ï¼Œn=2æ˜¯ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹æ˜¯ä¸¤æ¡ï¼Œbest_ofæ˜¯ä»2ä¸ªé‡Œé¢é€‰æ‹©å‡ºæœ€ä½³çš„ä¸€æ¡ä½œä¸ºè¾“å‡º\"\"\"\n",
    "llm = OpenAI(model_name=\"text-ada-001\", n=2, best_of=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é‚£ä¹ˆæˆ‘ä»¬çœ‹ä¸€ä¸‹è¿™ä¸ªllmå…·ä½“çš„å‚æ•°æƒ…å†µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-ada-001', 'temperature': 0.7, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 2, 'best_of': 2, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ç”Ÿæˆæ–‡æœ¬ï¼šLLMæœ€åŸºæœ¬çš„åŠŸèƒ½å°±æ˜¯èƒ½å¤Ÿè°ƒç”¨å®ƒï¼Œä¼ é€’ä¸€ä¸ªå­—ç¬¦ä¸²å¹¶è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚å…¶ä¸­çš„\"tell me...story\"å°±æ˜¯queryï¼Œä¼ é€’è¿›æ¨¡å‹ä¸­è°ƒç”¨é—®ç­”æ¨¡å‹ç»™å‡ºå›ç­”ï¼Œqueryçš„ç±»å‹æ˜¯å­—ç¬¦ä¸²ï¼Œæ²¡æœ‰é™åˆ¶å®ƒå¿…é¡»æ˜¯ç–‘é—®å¥è¿˜æ˜¯é™ˆè¿°å¥ï¼ŒChatGPTç­‰å¤§è¯­è¨€æ¨¡å‹ä¼šå¯¹å…¶å†…å®¹è¿›è¡Œç›¸åº”çš„è§£æä¸äº†è§£ï¼Œè¯»è€…ä¸å¿…çº ç»“åœ¨æ­¤å¤„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nOnce upon a time there was a princess who was very scared. She was sitting in her bedroom when she saw a scary scene in a movie. The princess was scared and started to cry. Her parents tried to soothe her and eventually she fell asleep. When she woke up, she found herself in a dark place. She couldn't make head or tail of what was going on and started to scream. A big part of her population felt sorry for her and helped her, but she wasn't alone. The people who were supposed to be helping her started to leave without her. The princess was scared and started to run around. She didn't know where she was going or what she was doing. Eventually she got her hands on a knife and started to kill people. She was scared and full of Syndicate, but she didn't care. The princess died in the dark, but her story is still shareable online.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Tell me a scared story\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "llmå¯ä»¥æ¥å—æ–‡æœ¬åˆ—è¡¨ï¼Œç”Ÿæˆå„ä¸ªè¯­å¥çš„å›ç­”ï¼Œè¿˜åŒ…æ‹¬apiä¾›åº”å•†çš„è¿”å›ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "llm_result = llm.generate([\"How to study English\", \"How to generate a new idea\"]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='\\n\\nThere are a few ways to study English:\\n\\n1. Use online resources.\\n\\n2. Take classes from an English teacher.\\n\\n3. Use English-speaking books and articles.\\n\\n4. Take English-speaking courses at your school.', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text=' in a foreign country\\n\\nThere are a number of ways to study English in a foreign country. One way is to go to a training course offered by a English speaking teacher. Another way is to use online resources.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=\"\\n\\n1. Take a step back. What is the best idea you've heard?\\n2. Ask yourself how it would be used. Is the idea unique to you, or is it something that is commonly used?\\n3. How would you create it? This might be a difficult question to answer. Try to think of ways to create the idea that is most unique to you.\\n4. What ingredients would you need? The ingredients for the idea might be different for you, but the process will be the same.\\n5. What resources do you have? You might be able to find the idea through reading articles or Watch this video on how to generate a new idea.\\n6. How do you want to create it? The idea might be something that ismopolitan or consumer-based, so it might be a challenge to create a business around it.\\n7. What resources do you have? The resources for creating a new idea are same, but the process might be different.\", generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\n1. Create a problem\\n\\n2. rescued a kitten from a euthanasia\\n\\n3. created a Pawtucket Mystic\\n\\n4. designed a one mile run\\n\\n5. written a story for the blog\\n\\n6. created a product for a product\\n\\n7. created a company in town\\n\\n8. designed a campaign', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThere is no one-size-fits-all answer to this question, as the best way to study English will vary depending on your level of English proficientness. However, some tips on how to study English include using an online English course option, studying at a frequency that is comfortable for you, and using online resources.', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nThere are a few ways to study English:\\n\\n1. Use online resources.\\n\\n2. Use online textbooks.\\n\\n3. Use local resources.\\n\\n4. Use online lectures.\\n\\n5. Use online vocabulary.\\n\\n6. Use online grammar.\\n\\n7. Use online writing.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThere is no one way to generate a new idea. You will likely have to consider what people want, what might be appealing to them, and what you think will be a strong signal to investors. You will also need to create a plan for achieving your new idea.', generation_info={'finish_reason': None, 'logprobs': None}), Generation(text='\\n\\n1. brainstorm\\n2. create a scenario\\n3. think about what it does\\n4. come up with specific steps\\n5. test out the scenario\\n6. keep track of how it goes\\n7. Jr. Album', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=\" in a foreign country\\n\\nThere is no one-size-fits-all answer to this question, as the best way to study English in a foreign country will vary depending on the individual's individual skills and knowledge. However, some ways to study English in a foreign country include attending English-language classes, taking classes from a English-speaking tutor, or studying English content in absence-friendly websites.\", generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nThere are a few ways to study English:\\n\\n1. Online courses: There are many online courses that teach English, including some free courses and some paid courses.\\n\\n2. Meeting English-speaking people: meeting English-speaking people can help you learn more about English culture and the language.\\n\\n3. Online groups and websites: there are many online groups and websites that teach English, and they offer resources about different topics.\\n\\n4. classroom learning: classroom learning is one of the most common ways to study English, because it is a more direct way to learning the language.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThere is no one way to generate a new idea. You will need to consider what is important to you and what is comfortable for you to talk about. You also need to create a plan in how you will go about creating the idea.', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nThere is no one way to generate a new idea. You will need to have some kind of metaphor or metaphor with people, things, or something. For example, you could say that you are creating a new kind of product, but be specific about how you think this new product might be used. You could also use a metaphor with people or something to mean different things.\\n\\nFor example, you could create a new type of product that uses people as the main character. This could be a type of product that people use to find new things to do. The product might be called \"People\\'s Way.\" People use the product to find new ways to do things. The new way people are using the product is called \"People\\'s Way\\'s new way.\" People\\'s Way is different from the old way and people using the old way is called \"The old way.\"', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 1074, 'prompt_tokens': 30, 'completion_tokens': 1044}, 'model_name': 'text-ada-001'}\n"
     ]
    }
   ],
   "source": [
    "llm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llm_result.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Generation(text='\\n\\n1. Open a English course in your local university or department.\\n\\n2. Find a course on English you want to take and take it in your local university.\\n\\n3. Find a tutor or course Tutor English for you to learn from.\\n\\n4. Finish your coursework and you will have completed English studies in your local university.', generation_info={'finish_reason': 'stop', 'logprobs': None}),\n",
       " Generation(text='\\n\\nThere are a few ways to study English:\\n\\n1. Online courses: Take online courses from various English schools.\\n\\n2. Practice tests: Performance test materials and practice questions in real time so you can become comfortable with the material.\\n\\n3. Print books: Read print books and learn key concepts in the same way as if they were video lessons.\\n\\n4. Location: Take classes and workshops near you at a nearby school or organization.\\n\\n5. Online courses: Take online courses that interest you. Check out free courses beforeempying to sink in for real.', generation_info={'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.generations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Generation(text='\\n\\n\\nThere are a few ways to generate new ideas:\\n\\n1. Look at what others have done in their line of work and experiment with different ideas.\\n\\n2. Take a step back and look at the whole work process from a different perspective.\\n\\n3. Think about different ways to do a task that is popular or efficient in another job market.\\n\\n4.Solution:\\n\\nTake a step back and think about different ways to do a task that is popular or efficient in another job market. For example, think about how to automate task completion times in a specific industry.', generation_info={'finish_reason': 'stop', 'logprobs': None}),\n",
       " Generation(text=' for a game\\n\\nThere is no one definitive way to generate a new idea for a game. However, some methods you may consider include searching online forums for various ideas, creating a list of specific ideas you have, or searching Google for \" game idea\" resources. Additionally, if you have any specific ideas you would like to see included in this resource, be sure to include them in a comment!', generation_info={'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.generations[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ç»™å‡ºè°ƒç”¨apiçš„ä¾›åº”å•†è¿”å›ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 42,\n",
       "  'completion_tokens': 1407,\n",
       "  'total_tokens': 1449},\n",
       " 'model_name': 'text-ada-001'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.llm_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "è¯„ä¼°å­—ç¬¦ä¸²èŠ±è´¹Tokensæ•°é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(\"å‡è®¾ä½ æ˜¯ä¸ªæ•™å¸ˆï¼Œå¦‚ä½•æ•™è‹±è¯­\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Chat Models\n",
    "ChatGPTæ¥å£ä½¿ç”¨çš„æ˜¯ turbo çš„æ¨¡å‹ï¼Œå¯¹äºèŠå¤©æœºå™¨äººçš„è®¾è®¡ï¼Œè¿™é‡Œæœ‰å¾ˆé‡è¦çš„ä¸‰ä¸ªè§’è‰²:systemã€humanã€AIï¼Œä¸‹é¢è¿™å¼ å›¾å±•ç¤ºçš„æ˜¯èŠå¤©æœºå™¨äººåœ¨æ•è·ä¿¡æ¯å¹¶è¿›è¡Œå¤„ç†çš„å›¾ç”»å±•ç¤ºï¼š \n",
    "\n",
    "<img src=\"./three.png\" align=center width=100% />\n",
    "\n",
    "å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¿™ä¸‰ä¸ªè§’è‰²åˆ†åˆ«æ˜¯å¦‚ä¸‹çš„å®šä¹‰ï¼š\n",
    "- systemï¼šé’ˆå¯¹ç°å®ä¸–ç•Œä¸­çš„ä¸€åˆ‡æè¿°ï¼Œæˆ‘ä»¬çš„systemè¦å†³å®šæœ€ç»ˆæƒ³è¦AIåšä»€ä¹ˆï¼Œä¸€ä¸ªç›´ç™½çš„èƒŒæ™¯æˆ–è€…è¯´æ˜¯è§’è‰²çš„å®šä½ï¼Œä¾‹å¦‚ç¿»è¯‘å‘˜ã€é“¶è¡Œå®¶ç­‰ï¼› \n",
    "- humanï¼šå…·ä½“çš„äº‹æƒ…ï¼Œä¾‹å¦‚æƒ³è¦AIç¿»è¯‘çš„è¯­å¥æˆ–è€…æƒ³è¦AIå†™å‡ºä¸€å¥é…·ä¼¼æ–¹æ–‡å±±çš„æ­Œè¯ï¼›\n",
    "- AIï¼šå¤§æ¨¡å‹å†³å®šè¿”å›çš„å†…å®¹ ä½¿ç”¨langchainå·¥å…·ç®±å®ç°è¿™ä¸ªåŠŸèƒ½ã€‚\n",
    "\n",
    "åœ¨ä»£ç ä¸­æˆ‘ä»¬å°†ä¼šé€šè¿‡langchain.schemaå¼•å…¥çš„SystemMessage, HumanMessage, AIMessageæ¥æ“çºµå…·ä½“çš„éœ€æ±‚æ­¥éª¤ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#å¯¼å…¥æˆ‘ä»¬æ‰€éœ€è¦çš„ç›¸å…³åº“å‡½æ•°\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fad12836580>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key=None, openai_organization=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#å®šä¹‰èŠå¤©æœºå™¨äººä½¿ç”¨çš„èŠå¤©é—®ç­”æ¨¡å‹\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "chat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢çš„è¾“å‡ºchatå¦‚ä¸‹ï¼š\n",
    "ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fad12836580>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key=None, openai_organization=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ç”±AIå›å¤humançš„æ¶ˆæ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='æˆ‘å–œæ¬¢ç¼–ç¨‹ã€‚', additional_kwargs={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#humanç»™å‡ºçš„ä¿¡æ¯æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²å†…å®¹ï¼Œç»™åˆ°chatä¹‹åä¼šè¿”å›ä¸€ä¸ªAIMessageä¿¡æ¯ï¼Œå…¶ä¸­çš„å†…å®¹å°†æ˜¯ç»™å‡ºçš„åé¦ˆç­”æ¡ˆ\n",
    "chat([HumanMessage(content=\"Translate this sentence from English to Chinese. I love programming.\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æ­£å¦‚æˆ‘ä»¬ä¸Šé¢å›¾ä¸­å±•ç¤ºçš„é‚£æ ·ï¼Œæˆ‘ä»¬ä¸€èˆ¬å®šä¹‰systemmessageçš„å†…å®¹ä¸ºç»™å®šå®ƒä¸€ä¸ªè§’è‰²ä½¿OpenAIæ¨¡å‹èƒ½å¤Ÿåœ¨ä¸€ä¸ªçŸ¥è¯†é¢†åŸŸå†…å›ç­”ï¼Œè¿™æ ·åšçš„å¥½å¤„å°±æ˜¯å¯¹äºç»™å‡ºçš„ç­”æ¡ˆä¼šæ›´åŠ å‡†ç¡®ï¼Œè¿™é‡Œç‰¹åˆ«è¯´æ˜ä¸€ç‚¹â€”â€”OpenaièŠå¤©æ¨¡å‹æ”¯æŒä¸€æ¬¡è¾“å…¥å¤šæ®µä¿¡æ¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='æˆ‘å–œæ¬¢ç¼–ç¨‹ã€‚', additional_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to Chinese.\"),\n",
    "    HumanMessage(content=\"Translate this sentence from English to Chinese. I love programming.\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "å¯ä»¥ä½¿ç”¨chat.generateæ–¹æ³•å¤„ç†å¤šå¯¹å„¿å¯¹è¯å†…å®¹ï¼Œè¿”å›å€¼LLMResultåŒ…å«æœ‰è¾“å…¥ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text=\"J'aime programmer.\", generation_info=None, message=AIMessage(content=\"J'aime programmer.\", additional_kwargs={}))], [ChatGeneration(text='æˆ‘å–œæ¬¢äººå·¥æ™ºèƒ½ã€‚', generation_info=None, message=AIMessage(content='æˆ‘å–œæ¬¢äººå·¥æ™ºèƒ½ã€‚', additional_kwargs={}))]], llm_output={'token_usage': {'prompt_tokens': 73, 'completion_tokens': 16, 'total_tokens': 89}, 'model_name': 'gpt-3.5-turbo'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to Chinese.\"),\n",
    "        HumanMessage(content=\"Translate this sentence from English to Chinese. I love artificial intelligence.\")\n",
    "    ],\n",
    "]\n",
    "result = chat.generate(batch_messages)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢çš„è¾“å‡ºä¿¡æ¯æˆ‘ä»¬ä¸ºäº†æ‚¨çš„ç›´è§‚çœ‹åˆ°ï¼Œæˆ‘ä»¬å°†å…¶å‘ˆç°åœ¨è¿™é‡Œï¼š\n",
    "\n",
    "OUTï¼š\n",
    "\n",
    "LLMResult(generations=[[ChatGeneration(text=\"J'aime programmer.\", generation_info=None, message=AIMessage(content=\"J'aime programmer.\", additional_kwargs={}))], [ChatGeneration(text='æˆ‘å–œæ¬¢äººå·¥æ™ºèƒ½ã€‚', generation_info=None, message=AIMessage(content='æˆ‘å–œæ¬¢äººå·¥æ™ºèƒ½ã€‚', additional_kwargs={}))]], llm_output={'token_usage': {'prompt_tokens': 73, 'completion_tokens': 16, 'total_tokens': 89}, 'model_name': 'gpt-3.5-turbo'})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æˆ‘ä»¬å¯ä»¥ä»resultä¸­å¾—åˆ°ä¸€äº›ä¿¡æ¯å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 73,\n",
       "  'completion_tokens': 16,\n",
       "  'total_tokens': 89},\n",
       " 'model_name': 'gpt-3.5-turbo'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### åœ¨èŠå¤©æ¨¡å‹ï¼ˆchatmodelï¼‰ä¸­ä½¿ç”¨æç¤ºæ¨¡æ¿\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸‹é¢ä½¿ç”¨æ¨¡æ¿åŒ…è£…SystemMessageå’ŒHumanMessageã€‚æ–¹ä¾¿ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#é¦–å…ˆæ„å»ºæ¨¡ç‰ˆï¼Œç”¨å‡ ä¸ªå®Œå½¢å¾…å¡«é¡¹è¡¨ç¤ºè¦ä¼ å…¥çš„å†…å®¹ï¼Œinput_variablesåœ¨è¿™ä¸ªæ¨¡ç‰ˆä¸­æ˜¯ä¸¤ä¸ª\n",
    "template=\"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "#å®šä¹‰systemmessageçš„æç¤ºæ¨¡ç‰ˆï¼Œè¿›è¡Œç›¸åº”çš„æ¨¡ç‰ˆæ ¼å¼åŒ–\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "#æ„å»ºhumanæ¨¡ç‰ˆï¼Œç”¨æ¥ä¼ å…¥æˆ‘ä»¬æƒ³è¦æŸ¥è¯¢çš„å†…å®¹\n",
    "human_template=\"{text}\"\n",
    "#å°†humanæ¨¡ç‰ˆè¿›è¡Œæ ¼å¼åŒ–\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#å°†ä¸Šé¢çš„ä¸¤ç±»æ¨¡ç‰ˆï¼Œä¹Ÿå°±æ˜¯systemå’Œhumançš„æ¨¡ç‰ˆï¼Œå°†ä¸¤ä¸ªæ¨¡ç‰ˆé€šè¿‡åˆå¹¶çš„æ–¹å¼åˆ›å»º\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "# ä½¿ç”¨èŠå¤©æç¤ºæ¨¡ç‰ˆæ¥åˆ›å»ºä¸€ä¸ªèŠå¤©è¡¥å…¨ï¼Œå…¶ä¸­çš„å„é¡¹å‚æ•°éƒ½æ˜¯input_variablesï¼Œé€šè¿‡to_messagesæ–¹æ³•ä¼ é€’ç»™chatæ¨¡å‹å®ŒæˆèŠå¤©å¯¹è¯\n",
    "chat(chat_prompt.format_prompt(input_language=\"English\", output_language=\"French\", text=\"I love programming.\").to_messages())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¹Ÿå¯ä»¥ç”¨ä¸‹é¢çš„æ–¹æ³•æ›´ç›´æ¥çš„åˆ›å»ºsystem_messageæ¨¡æ¿ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input_language', 'output_language'], output_parser=None, partial_variables={}, template='You are a helpful assistant that translates {input_language} to {output_language}.', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "    input_variables=[\"input_language\", \"output_language\"],\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], output_parser=None, partial_variables={}, template='You are a helpful assistant that translates {input_language} to {output_language}.', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n",
    "system_message_prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LLMChain\n",
    "ç»“åˆLLMChainå’ŒPromptã€Chat modelï¼Œå¯ä»¥æ›´æ–¹ä¾¿åœ°å¼€å±•å¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=None, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fad12836580>, verbose=False, prompt=ChatPromptTemplate(input_variables=['text', 'output_language', 'input_language'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], output_parser=None, partial_variables={}, template='You are a helpful assistant that translates {input_language} to {output_language}.', template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='{text}', template_format='f-string', validate_template=True), additional_kwargs={})]), llm=ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fad12836580>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key=None, openai_organization=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=None), output_key='text')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æˆ‘å–œæ¬¢ç¼–ç¨‹å’Œæ¸¸æ³³ã€‚'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_language=\"English\", output_language=\"Chinese\", text=\"I love programming and swimming\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### æµå¼å¯¹è¯\n",
    "é€šè¿‡å›è°ƒå‡½æ•°å¤„ç†å¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸€åŠ ä¸€ç­‰äºäºŒæ˜¯å› ä¸ºè¿™æ˜¯æˆ‘ä»¬æ‰€æ¥å—çš„åŸºæœ¬æ•°å­¦åŸç†ä¹‹ä¸€ã€‚åœ¨åè¿›åˆ¶æ•°ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬å°†æ•°å­—1è¡¨ç¤ºä¸ºä¸€ä¸ªå•ä½ï¼Œæ•°å­—2è¡¨ç¤ºä¸ºä¸¤ä¸ªå•ä½ã€‚å½“æˆ‘ä»¬å°†ä¸€ä¸ªå•ä½ä¸å¦ä¸€ä¸ªå•ä½ç›¸åŠ æ—¶ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸¤ä¸ªå•ä½ï¼Œå³æ•°å­—2ã€‚è¿™æ˜¯å› ä¸ºåŠ æ³•æ˜¯ä¸€ç§åŸºæœ¬çš„ç®—æœ¯è¿ç®—ï¼Œå®ƒè¡¨ç¤ºå°†ä¸¤ä¸ªæˆ–å¤šä¸ªæ•°å€¼ç›¸åŠ ä»¥å¾—åˆ°å®ƒä»¬çš„æ€»å’Œã€‚å› æ­¤ï¼Œä¸€åŠ ä¸€ç­‰äºäºŒæ˜¯æ•°å­¦ä¸­çš„åŸºæœ¬åŸç†ä¹‹ä¸€ï¼Œå®ƒè¢«å¹¿æ³›æ¥å—å¹¶è¢«ç”¨äºå„ç§æ•°å­¦å’Œç§‘å­¦åº”ç”¨ä¸­ã€‚"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\"\"\"\n",
    "streaming=Trueæ˜¯å¯ç”¨äº†èŠå¤©çš„æµå¼æ¨¡å¼ï¼Œä¹Ÿå°±æ˜¯å“åº”çš„å†…å®¹å°†ä¼šåœ¨é€æ­¥ç”Ÿæˆçš„æ•°æ®å—ä¸­é€æ­¥è¿”å›ï¼›\n",
    "è€Œcallback_mangerç”¨äºç®¡ç†èŠå¤©è¿‡ç¨‹ä¸­çš„å›è°ƒå‡½æ•°çš„å¯¹è±¡ï¼Œæµå¼å¯¹è±¡å°†ä¼šé€æ­¥è¿”å›å†…å®¹è€Œä¸æ˜¯æ•´ä¸ª\n",
    "å“åº”å®Œæˆä¹‹åä¸€æ¬¡æ€§è¿”å›ï¼Œå¦‚æœä¸ä¼ é€’callback_managerå‚æ•°ï¼Œåˆ™èŠå¤©è¿‡ç¨‹ä¸­å°†ä¼šä»¥é»˜è®¤çš„æ–¹å¼è¿è¡Œï¼Œä¹Ÿ\n",
    "å°±æ˜¯å“åº”å®Œæˆä¹‹åä¸€æ¬¡æ€§è¿”å›ï¼›verboseæ˜¯è¯¦ç»†æ¨¡å¼ï¼Œå†³å®šæ˜¯å¦æ‰“å°å‡ºå…·ä½“çš„ä¿¡æ¯ï¼›temperatureçš„è®¾ç½®\n",
    "åˆ™æ˜¯å†³å®šéšæœºæ€§\n",
    "\"\"\"\n",
    "chat = ChatOpenAI(streaming=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True, temperature=0)\n",
    "resp = chat([HumanMessage(content=\"å¸®æˆ‘åˆ†æä¸€ä¸‹ä¸ºä»€ä¹ˆä¸€åŠ ä¸€ç­‰äºäºŒï¼Ÿ\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I cannot provide instructions on how to become a fictional character like Superman. However, I can suggest some ways to become a better version of yourself:\n",
      "\n",
      "1. Set goals and work towards them consistently.\n",
      "2. Exercise regularly to improve physical strength and endurance.\n",
      "3. Learn new skills and knowledge to enhance mental abilities.\n",
      "4. Practice empathy and kindness towards others.\n",
      "5. Be courageous and stand up for what is right.\n",
      "6. Develop a positive mindset and attitude towards life.\n",
      "7. Surround yourself with supportive and positive people.\n",
      "8. Take care of your health by eating a balanced diet and getting enough rest.\n",
      "9. Continuously challenge yourself to grow and improve.\n",
      "10. Believe in yourself and your abilities."
     ]
    }
   ],
   "source": [
    "resp_another = chat([HumanMessage(content=\"tell me how to become a superman?\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Text Embedding Models\n",
    "è¯åµŒå…¥æ”¯æŒå°†è‡ªç„¶è¯­è¨€è½¬å˜ä¸ºå‘é‡ã€‚LangChainä¸­æœ€é‡è¦çš„ä¸¤ä¸ªembeddingæ–¹æ³•ä¸ºembed_documents å’Œ embed_queryæ–¹æ³•ã€‚å› ä¸ºå¤„ç†å¤šä¸ªæ–‡æœ¬æ–‡ä»¶å’Œå¤„ç†ä¸€ä¸ªæ–‡ä»¶æœ‰å¾ˆå¤§çš„ä¸åŒï¼Œæ‰€ä»¥LangChainå°†å…¶åˆ†ä¸ºä¸¤ä¸ªç±»ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LangChainä¸­é›†æˆäº†å¾ˆå¤šæ¥è‡ªä¸åŒå¹³å°çš„APIå¯ä»¥è¿›è¡Œè¯åµŒå…¥ç¼–ç ï¼Œè¿™é‡Œä¸¾ä¸€ä¸ªç”¨OpenAiè¿›è¡Œè¯åµŒå…¥çš„æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#æˆ‘ä»¬ä½¿ç”¨è¾ƒå¤šçš„ä¹Ÿæ˜¯OpenAIçš„embeddingsæ–¹æ³•\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"This is a test document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0031265460635144116,\n",
       " 0.011133635493097378,\n",
       " -0.004037691773639618,\n",
       " -0.011746618046080886,\n",
       " -0.000993598608605281,\n",
       " 0.01080715570571065,\n",
       " -0.010440697965211392,\n",
       " -0.005253663322651083,\n",
       " -0.009874355115762394,\n",
       " -0.026171704933991537,\n",
       " 0.020348368352341755,\n",
       " 0.02257376179702522,\n",
       " -0.00752236652698065,\n",
       " 0.017230149476854816,\n",
       " -0.005986577872327018,\n",
       " 0.01914905397335298,\n",
       " 0.021254515421344024,\n",
       " -0.015644390243455687,\n",
       " 0.007642298058011785,\n",
       " -0.018402813128865346,\n",
       " -0.0006866907980891692,\n",
       " -0.006416332020722187,\n",
       " -0.010967063792870444,\n",
       " 0.0180030410483207,\n",
       " -0.022173991579125737,\n",
       " -0.0030682459684349844,\n",
       " 0.014405098842676966,\n",
       " -0.029982859474719296,\n",
       " 0.018496092535934365,\n",
       " -0.007935463505353126,\n",
       " 0.01004758949773389,\n",
       " -0.019442219420694323,\n",
       " -0.003694554583399551,\n",
       " -0.024279453027116777,\n",
       " -0.005540166088247863,\n",
       " 0.0038311432844533796,\n",
       " -0.00566676076668485,\n",
       " -0.029449831896638266,\n",
       " 0.018576046579514262,\n",
       " -0.016643818582172135,\n",
       " 0.007529029208725211,\n",
       " 0.012452880937455994,\n",
       " -0.0009711115338484352,\n",
       " -0.010693886390762786,\n",
       " 0.010034264134244767,\n",
       " -0.012566149321081278,\n",
       " 0.03358080261168561,\n",
       " -0.026957921868946542,\n",
       " -0.007935463505353126,\n",
       " 0.028970105772513726,\n",
       " 0.019735384868035666,\n",
       " -0.002010517301808462,\n",
       " -0.027397671902603716,\n",
       " -0.008768321075165222,\n",
       " -0.00623976629787841,\n",
       " 0.0019855315467744218,\n",
       " -0.007389109166799102,\n",
       " 0.027930699480684745,\n",
       " 0.00680944048819969,\n",
       " -0.009288023289757131,\n",
       " -0.022533785706557855,\n",
       " 0.010460686941767657,\n",
       " -0.013612218294654818,\n",
       " -0.011120309198285674,\n",
       " -0.004873880684323994,\n",
       " -0.008301921245852384,\n",
       " -0.0058333320012504955,\n",
       " 0.011120309198285674,\n",
       " 0.006299731830563333,\n",
       " 0.004460783240290227,\n",
       " 0.010627257710672012,\n",
       " 0.012452880937455994,\n",
       " 0.005370263512809938,\n",
       " 0.005436891727239422,\n",
       " 0.008941555457136718,\n",
       " 0.00428421751744645,\n",
       " -0.022693693793717648,\n",
       " -0.013212447145432755,\n",
       " 0.01123357851323354,\n",
       " -0.005710069129347079,\n",
       " 0.00980772643567162,\n",
       " -0.024439362976921734,\n",
       " -0.008555109671403776,\n",
       " 0.007875497507006914,\n",
       " 0.0025502087257872805,\n",
       " 0.007562343548770598,\n",
       " 0.005740052128520186,\n",
       " 0.028223864928026088,\n",
       " -0.022960208514080743,\n",
       " -0.015564436199875789,\n",
       " -0.008215303589205346,\n",
       " 0.02005520104235525,\n",
       " 0.003584617540646548,\n",
       " 0.012779361656165304,\n",
       " -0.01647058513152322,\n",
       " 0.031555295207274466,\n",
       " 0.013532264251074922,\n",
       " 0.030382631555263943,\n",
       " -0.006206451957833024,\n",
       " -0.049678266389642435,\n",
       " -0.0037212060088697317,\n",
       " -0.001316747287950374,\n",
       " -0.007055966232006522,\n",
       " 0.0035246517751309804,\n",
       " -0.03486007103425428,\n",
       " -0.009028172182461176,\n",
       " 0.021960778312719132,\n",
       " -0.007275840783173818,\n",
       " 0.015431178839694241,\n",
       " -0.008281932269296119,\n",
       " -0.016457257905388937,\n",
       " 0.005083760281551867,\n",
       " -0.006366360510654107,\n",
       " -0.03603273654890997,\n",
       " 0.01561773858515486,\n",
       " 0.00566676076668485,\n",
       " 0.006486292041685242,\n",
       " -0.021907476858762643,\n",
       " -0.010260800901495335,\n",
       " 0.0010419043318218987,\n",
       " 0.0006621215188718254,\n",
       " 0.016883680712911825,\n",
       " 0.026504848334445406,\n",
       " -0.02753092926278526,\n",
       " 0.010580618007137502,\n",
       " 0.013292401189012652,\n",
       " -0.00880829809695517,\n",
       " -0.04184274776707063,\n",
       " -0.006469634871662549,\n",
       " -0.005530172065631021,\n",
       " 0.019109076020240454,\n",
       " 0.021454401461616344,\n",
       " 0.01419188743891552,\n",
       " 0.017509989560707036,\n",
       " -0.023333328005001982,\n",
       " 0.037312004971478636,\n",
       " -0.04040357125734217,\n",
       " 0.024772504514730443,\n",
       " -0.0432286228228426,\n",
       " -0.008435177674711351,\n",
       " 0.008308583927596945,\n",
       " 0.027397671902603716,\n",
       " -0.019162379336842107,\n",
       " -0.016936984029513477,\n",
       " 0.010294115241540723,\n",
       " 0.01395202437685325,\n",
       " 0.008255280610995293,\n",
       " -0.024812482467842973,\n",
       " 0.012506184254057646,\n",
       " -0.021147910650785882,\n",
       " 0.0031082232230555777,\n",
       " 0.001852274419423519,\n",
       " 0.017763178917581012,\n",
       " 0.002528554544456166,\n",
       " 0.015551109905064087,\n",
       " 0.03144868857407117,\n",
       " 0.0038577947099235604,\n",
       " -0.009514560988330279,\n",
       " -0.018029693637944107,\n",
       " -0.01961545287134324,\n",
       " 0.0030682459684349844,\n",
       " 0.02218731694261486,\n",
       " 0.00956786337360935,\n",
       " 0.0018689315894462124,\n",
       " 0.023466585365183527,\n",
       " 0.034700162947094486,\n",
       " 0.004007708774466511,\n",
       " 0.007648960739756346,\n",
       " -0.0016307344306507275,\n",
       " -0.015404527181393415,\n",
       " -0.025039019235093538,\n",
       " 0.02475917915124132,\n",
       " -0.02537216263554741,\n",
       " 0.007655623421500907,\n",
       " -0.0201884584025368,\n",
       " 0.014271841482495417,\n",
       " 0.007202549421338483,\n",
       " 0.0034780118387658255,\n",
       " -0.0044374633885229725,\n",
       " -0.004037691773639618,\n",
       " -0.033873968059026954,\n",
       " 0.016883680712911825,\n",
       " 0.01480486999189903,\n",
       " 0.03179515547536899,\n",
       " -0.017056916026205904,\n",
       " -0.006936035166636677,\n",
       " 0.024226151573160288,\n",
       " -0.009534549033563962,\n",
       " 0.001379211559120152,\n",
       " -0.00461736045223903,\n",
       " 0.023200070644820433,\n",
       " 0.021880824269139235,\n",
       " -0.0063430406588868525,\n",
       " -0.01480486999189903,\n",
       " -0.7023184943753603,\n",
       " -0.016363978498319918,\n",
       " 0.004297543346596862,\n",
       " -0.017230149476854816,\n",
       " 0.022173991579125737,\n",
       " 0.03136873266784611,\n",
       " 0.024599271064081527,\n",
       " 0.002137111747414804,\n",
       " -0.0060098977240942725,\n",
       " 0.02185417354216099,\n",
       " -0.0226670430667394,\n",
       " -0.012706069363007388,\n",
       " -0.009201406564432673,\n",
       " -0.013212447145432755,\n",
       " -0.014111932464013044,\n",
       " -0.023160094554353066,\n",
       " -0.016963636619136885,\n",
       " -0.003323100297253163,\n",
       " -0.01761659619391034,\n",
       " 0.013085852466995769,\n",
       " 0.014924801057268873,\n",
       " 0.015457830497995068,\n",
       " -0.015711018923546458,\n",
       " -0.01672377262575203,\n",
       " 0.000518870077865774,\n",
       " 0.00890824111709133,\n",
       " 0.01309251514874033,\n",
       " -0.006133160595997688,\n",
       " 0.017483338833728792,\n",
       " 0.01689700793904611,\n",
       " -0.026211682887104064,\n",
       " -0.003571291711496135,\n",
       " -0.0009452929435963248,\n",
       " 0.008548446989659215,\n",
       " 0.033260986437366025,\n",
       " -0.0020588231414404023,\n",
       " -0.014485052886256863,\n",
       " -0.025039019235093538,\n",
       " 0.016590515265570482,\n",
       " 0.0008794972151389435,\n",
       " -0.016830379258955336,\n",
       " -0.000344802889780038,\n",
       " 0.0048205778333836324,\n",
       " -0.0017423372602551933,\n",
       " -0.004604034623088617,\n",
       " -0.0025218916298809595,\n",
       " 0.018829235936388234,\n",
       " 0.0003429289523317189,\n",
       " 0.027450973356560205,\n",
       " 0.017656572284377708,\n",
       " -0.016590515265570482,\n",
       " -0.0005492693200249316,\n",
       " 0.006656195082784458,\n",
       " -0.003491337435085593,\n",
       " 0.0010210829857088546,\n",
       " -0.010434035283466831,\n",
       " 0.021640962138399545,\n",
       " 0.007728915248997534,\n",
       " 0.010833806432688895,\n",
       " 0.016563864538592238,\n",
       " -0.0011426800707608075,\n",
       " 0.011879875406262435,\n",
       " -0.005626783279233612,\n",
       " -0.016883680712911825,\n",
       " -0.028943455045535478,\n",
       " -0.007495714868679824,\n",
       " -0.020841419839955418,\n",
       " 0.022547111070046977,\n",
       " 0.0010219158209269247,\n",
       " -0.019002471249682313,\n",
       " -0.003724537582572657,\n",
       " 0.012512846935802208,\n",
       " -0.010254138219750774,\n",
       " -0.01970873414105742,\n",
       " 0.020761463933730358,\n",
       " 0.015497807519785016,\n",
       " 0.00976108673213711,\n",
       " -0.009987623499387678,\n",
       " -0.00933466392461422,\n",
       " 0.016790401305842806,\n",
       " 0.00371454332712517,\n",
       " 0.003584617540646548,\n",
       " -0.014338470162586192,\n",
       " -0.015431178839694241,\n",
       " 0.01085379540924516,\n",
       " -0.02024176171913845,\n",
       " -0.04610697584229952,\n",
       " -0.01299923574167131,\n",
       " -0.0066761835936794325,\n",
       " 0.013385681527404252,\n",
       " 0.021547682731330526,\n",
       " 0.0014358458673481166,\n",
       " -0.007935463505353126,\n",
       " -0.0004426636181442092,\n",
       " 0.008928229162325016,\n",
       " -0.0027784116291352783,\n",
       " 0.0011585044055654307,\n",
       " 0.003967731752676563,\n",
       " 0.030142769424524252,\n",
       " -0.0019239002272380366,\n",
       " 0.0014741573351172471,\n",
       " 0.0024169515984363774,\n",
       " 0.0006317222185050064,\n",
       " 0.011733292682591764,\n",
       " 0.021161236014275005,\n",
       " 0.005247000640906522,\n",
       " 0.003637920391586909,\n",
       " 0.024452688340410856,\n",
       " 0.018256230405194675,\n",
       " -0.008488480991313004,\n",
       " -0.007169235081293096,\n",
       " -0.008988195160671227,\n",
       " -0.009554538010120227,\n",
       " 0.0015707686651351598,\n",
       " -0.016057487687489453,\n",
       " -0.034220438685615105,\n",
       " 0.008035406525489288,\n",
       " 0.011246903876722662,\n",
       " 0.0023653144179321566,\n",
       " 0.0033880630740771513,\n",
       " 0.01404530378392227,\n",
       " 0.017723200964468482,\n",
       " 0.013339040892547161,\n",
       " -0.0016365643935925412,\n",
       " 0.004580714771321362,\n",
       " -0.002518560289008679,\n",
       " 0.003941080560037028,\n",
       " -0.019415566831070916,\n",
       " -0.01719017338638745,\n",
       " -0.009707783415535458,\n",
       " -0.0194288940572052,\n",
       " -0.0017639915580016305,\n",
       " 0.03371405997186716,\n",
       " -0.01419188743891552,\n",
       " 0.007722252101591682,\n",
       " 0.002328668737014489,\n",
       " 0.0038078231998554795,\n",
       " -0.0052803149809519095,\n",
       " 0.021361122054547325,\n",
       " -0.009727772392091723,\n",
       " -0.013019223786904994,\n",
       " 0.013312390165568917,\n",
       " -0.006969349041020773,\n",
       " -0.009108126226041072,\n",
       " -0.011913189746307822,\n",
       " -0.02232057430279641,\n",
       " -0.017989715684831577,\n",
       " -0.0030299346170811763,\n",
       " 0.0009786072254340506,\n",
       " 0.00995430915934229,\n",
       " -0.022107362899034963,\n",
       " 0.0013617215538793885,\n",
       " -0.010100892814335542,\n",
       " -0.005843326489528627,\n",
       " -0.00813534954562545,\n",
       " -0.011106983834796552,\n",
       " -0.017070241389695026,\n",
       " -0.02627831156719484,\n",
       " 0.0010627257943502657,\n",
       " -0.0014475059096470666,\n",
       " -0.008601749374938286,\n",
       " 0.017549967513819566,\n",
       " -0.006196457935216181,\n",
       " 0.0011410144003246672,\n",
       " -0.02651817369793453,\n",
       " -0.018242905041705552,\n",
       " -0.03302112244398117,\n",
       " 0.033181030531140965,\n",
       " -0.009974298135898554,\n",
       " -0.0339006187860052,\n",
       " -0.018309533721796327,\n",
       " 0.005167046131665335,\n",
       " -0.013492287229284973,\n",
       " -0.0020704830673240297,\n",
       " 0.005017132067122384,\n",
       " -0.010527315621858432,\n",
       " -0.015737669650524706,\n",
       " 0.007842183166961527,\n",
       " 0.010354081239886934,\n",
       " -0.02133447132756908,\n",
       " -0.0049904804088215585,\n",
       " 0.0034580230950402063,\n",
       " 0.012279646555484499,\n",
       " 0.0020305058127034364,\n",
       " 0.01181324672617166,\n",
       " 0.015084710075751248,\n",
       " 0.013465635570984147,\n",
       " 0.007075954742901496,\n",
       " -0.012646104295983757,\n",
       " 0.0025885203099717336,\n",
       " 0.008042069207233849,\n",
       " 0.0033064431272304693,\n",
       " -0.01461831024643841,\n",
       " 0.009274697926268009,\n",
       " -0.007648960739756346,\n",
       " 0.01985531686472809,\n",
       " -0.029689694027377957,\n",
       " 0.010447360646955953,\n",
       " 0.012872641063234323,\n",
       " 0.02385303021959389,\n",
       " 0.02257376179702522,\n",
       " 0.008708355076819009,\n",
       " 0.0038544631362206344,\n",
       " -0.022720344520695893,\n",
       " 0.00016542626076378224,\n",
       " -0.03541975120195872,\n",
       " -0.01313915578359742,\n",
       " -0.0027151145227474302,\n",
       " 0.013552252296308605,\n",
       " 0.006339709318014572,\n",
       " 0.012885967358046027,\n",
       " -0.017643246920888585,\n",
       " -0.02470587583463967,\n",
       " 0.017390059426659773,\n",
       " 0.02152103014170712,\n",
       " 0.005450217556389835,\n",
       " -0.010134206223058348,\n",
       " -0.002833380383342425,\n",
       " -0.006746143614642487,\n",
       " -0.0020538258973013365,\n",
       " 0.0066895094228298455,\n",
       " 0.004837234537745035,\n",
       " 0.012559486639336717,\n",
       " -0.007282503464918379,\n",
       " -0.01624404650162749,\n",
       " 0.011493429620529494,\n",
       " 0.028596986281592487,\n",
       " 0.03259469963645829,\n",
       " 0.02300018460454811,\n",
       " -0.024159522893069513,\n",
       " -0.018362835175752816,\n",
       " 0.002605177479994427,\n",
       " 0.0008570100821744363,\n",
       " 0.0012476201022053896,\n",
       " 0.0031781832440186328,\n",
       " 0.010460686941767657,\n",
       " 0.02242717907335455,\n",
       " -0.01938891610409267,\n",
       " 0.028730243641774036,\n",
       " 0.00035979433115892995,\n",
       " 0.011486766938784932,\n",
       " 0.018829235936388234,\n",
       " 0.028650287735548976,\n",
       " -0.008501806354802126,\n",
       " 0.02290690519747909,\n",
       " -9.301974269190048e-05,\n",
       " 0.028197214201047843,\n",
       " 0.0085684350348929,\n",
       " -0.004021034603616924,\n",
       " 0.03147533930104941,\n",
       " -0.010707212685574488,\n",
       " 0.0018039686962069014,\n",
       " 0.001005258650904231,\n",
       " 0.004180943156438008,\n",
       " 0.03246144227627674,\n",
       " -0.026917945778479172,\n",
       " -0.013412332254382497,\n",
       " 0.0018822573021813028,\n",
       " 0.014338470162586192,\n",
       " 0.03123547717030972,\n",
       " 0.022227293033082227,\n",
       " 0.005023794748866945,\n",
       " -0.0026301630021978223,\n",
       " 0.0012159715490114653,\n",
       " 0.023213396008309555,\n",
       " -0.004550731772148256,\n",
       " -0.013205784463688194,\n",
       " 0.003389728977343937,\n",
       " -0.020015224951887883,\n",
       " -0.01304587544520582,\n",
       " -0.0056067947683386375,\n",
       " -0.0014141915696016796,\n",
       " 0.018082995091900596,\n",
       " 0.0024502659384817646,\n",
       " 0.0246658997441723,\n",
       " 0.010580618007137502,\n",
       " 0.02590519021362844,\n",
       " 0.012039784424744808,\n",
       " 0.01647058513152322,\n",
       " 0.001490814388724618,\n",
       " -0.009081475499062828,\n",
       " -0.022373875756752898,\n",
       " 0.0006258921973555314,\n",
       " 0.01218636714841548,\n",
       " 0.012292972850296202,\n",
       " -0.011719966387780062,\n",
       " -0.010247475538006213,\n",
       " 0.004657337474028978,\n",
       " -0.007442412017739463,\n",
       " 0.006479629359940681,\n",
       " 0.00400104609272195,\n",
       " -4.937281880562186e-05,\n",
       " 0.01709689397931843,\n",
       " -0.023160094554353066,\n",
       " -5.1793308003778376e-05,\n",
       " 0.01596420641777527,\n",
       " 0.008888252140535067,\n",
       " -0.0055368347473755825,\n",
       " -0.010147532517870051,\n",
       " -0.007815532439983282,\n",
       " 0.011180275196631888,\n",
       " -0.0075756693779210115,\n",
       " 0.008761658393420661,\n",
       " 0.00623643495700613,\n",
       " 0.02009517899546778,\n",
       " 0.0003102393260113764,\n",
       " -0.0026085088208667078,\n",
       " -0.012959258719881362,\n",
       " -0.01341899586744964,\n",
       " -0.010300777923285284,\n",
       " 0.01804301900143323,\n",
       " 0.003874451879946254,\n",
       " -0.014005326762132321,\n",
       " -0.005956594873153911,\n",
       " 0.015604413221665737,\n",
       " -0.005650103596662157,\n",
       " 0.0015449501912983721,\n",
       " 0.0133323782108026,\n",
       " 0.016830379258955336,\n",
       " 0.012819338677955252,\n",
       " -0.01537787552309259,\n",
       " -0.006882732315696315,\n",
       " -0.01809632231803488,\n",
       " 0.010727200730808172,\n",
       " 0.0489586781347782,\n",
       " 0.04320196837057403,\n",
       " 0.0025801917249603868,\n",
       " -0.010893772431035108,\n",
       " 0.0037012174979747575,\n",
       " -0.019308962060512774,\n",
       " -0.02694459650545742,\n",
       " -0.0135189388875858,\n",
       " 0.006366360510654107,\n",
       " -0.002205405865111073,\n",
       " -0.007882161120074055,\n",
       " -0.004354177538409504,\n",
       " 0.01624404650162749,\n",
       " 0.001379211559120152,\n",
       " 0.016630493218683012,\n",
       " 0.007122594912097296,\n",
       " -0.0013892058145676392,\n",
       " -0.0024735860230796648,\n",
       " -0.009487909330029453,\n",
       " -0.012279646555484499,\n",
       " 0.002900008830602554,\n",
       " 0.007708926272441269,\n",
       " 0.007688937761546295,\n",
       " 0.003371406136885103,\n",
       " 0.01209974949176844,\n",
       " -0.02133447132756908,\n",
       " 0.007722252101591682,\n",
       " 0.0016107459197557533,\n",
       " 0.0002640157490475955,\n",
       " -0.020361693715830877,\n",
       " -0.01419188743891552,\n",
       " 0.019215682653443755,\n",
       " 0.01014086983612549,\n",
       " 0.018109647681524003,\n",
       " -0.0006242264687117299,\n",
       " 0.03288786508379963,\n",
       " -0.0044308002411171206,\n",
       " -0.015790972967126355,\n",
       " 0.007755566441637069,\n",
       " 0.004847229026023168,\n",
       " 0.009254709881034323,\n",
       " 0.004580714771321362,\n",
       " -0.003394725988652358,\n",
       " -0.008261943292739854,\n",
       " -0.007149246570398122,\n",
       " 0.00025672823716266707,\n",
       " -0.016657143945661257,\n",
       " 0.003386397403641011,\n",
       " -0.008635063714983673,\n",
       " -0.007555680867026037,\n",
       " 0.012079761446534757,\n",
       " -0.01770987560097936,\n",
       " -0.0012184701710809985,\n",
       " -0.015417852544882538,\n",
       " 0.02875689436875228,\n",
       " 0.023306677278023737,\n",
       " 0.004390823219327172,\n",
       " 0.006816103635605542,\n",
       " -0.0022070715355472135,\n",
       " -0.017536642150330444,\n",
       " -0.029876254704161154,\n",
       " -0.006792783318176996,\n",
       " -0.011373498555159648,\n",
       " -0.009301349584568833,\n",
       " -0.011413475576949597,\n",
       " -0.03043593487186559,\n",
       " -0.023506561455650898,\n",
       " -0.013345704505614304,\n",
       " -0.020161807675558554,\n",
       " 0.0037212060088697317,\n",
       " 0.010980389156359566,\n",
       " -0.01760327083042122,\n",
       " -0.024785831740864725,\n",
       " -0.016217395774649247,\n",
       " 0.02899675649949197,\n",
       " -0.013938698082041547,\n",
       " 0.0005355271896808063,\n",
       " 0.01304587544520582,\n",
       " 0.0014974773032998246,\n",
       " 0.022533785706557855,\n",
       " -0.010840470045756037,\n",
       " -0.022507133116934447,\n",
       " 0.005899960681341269,\n",
       " -0.02413287030344611,\n",
       " -0.005899960681341269,\n",
       " 0.016843704622444458,\n",
       " -0.003987720263571537,\n",
       " 0.0067761261481543026,\n",
       " -0.0027351030336424044,\n",
       " 0.01047401230525678,\n",
       " -0.006076526404185046,\n",
       " -0.002423614513011584,\n",
       " -0.004863886196045861,\n",
       " -0.02936987785305837,\n",
       " 0.016350653134830796,\n",
       " -0.008768321075165222,\n",
       " 0.0019888631204773477,\n",
       " 0.007482389505190702,\n",
       " -0.00866837805502906,\n",
       " -0.004130971646369927,\n",
       " -0.015537784541574963,\n",
       " -0.001499975808954035,\n",
       " -0.009128115202597337,\n",
       " 0.0016174087179156372,\n",
       " 0.020788116523353765,\n",
       " -0.019055772703638802,\n",
       " -0.013379018845659691,\n",
       " 0.01689700793904611,\n",
       " -0.023293350051889452,\n",
       " -0.007715589419847121,\n",
       " -0.010460686941767657,\n",
       " -0.018162950998125656,\n",
       " 0.009587852350165614,\n",
       " -0.020015224951887883,\n",
       " 0.002370311662071223,\n",
       " 0.017443360880616262,\n",
       " -0.007422423506844489,\n",
       " 0.022014081629320784,\n",
       " -0.010260800901495335,\n",
       " -0.030169420151502497,\n",
       " 6.792991963538974e-05,\n",
       " -0.009801063753927058,\n",
       " 0.011086995789562869,\n",
       " 0.03563296446836532,\n",
       " 0.022080710309411555,\n",
       " 0.029209967903253413,\n",
       " -0.008768321075165222,\n",
       " -0.0030016175211748557,\n",
       " -0.014218538165893765,\n",
       " 0.007915475460119442,\n",
       " -0.00509375476983,\n",
       " 0.0011701644478643808,\n",
       " -0.007782218099937894,\n",
       " -0.0041976003264607015,\n",
       " -0.018882539252989886,\n",
       " -0.01143346362218328,\n",
       " -0.001524128728770005,\n",
       " 0.013672184293001032,\n",
       " -0.005263657810929216,\n",
       " -0.0106605720507174,\n",
       " -0.015084710075751248,\n",
       " 0.013658857998189328,\n",
       " 0.011393486600393332,\n",
       " -0.009168092224387286,\n",
       " -0.02567865344637787,\n",
       " -0.029822951387559502,\n",
       " -0.02170759081849032,\n",
       " 0.010107555496080103,\n",
       " -0.020574905119592323,\n",
       " 0.0008586758108182379,\n",
       " 0.021147910650785882,\n",
       " 0.0003445946809755205,\n",
       " -0.011626686980711043,\n",
       " -0.00490719455870809,\n",
       " 0.015830950920238885,\n",
       " -0.029396528580036614,\n",
       " -0.004813914685977781,\n",
       " 0.006193126128682611,\n",
       " 0.016217395774649247,\n",
       " 0.02710450459261721,\n",
       " 0.02270701915720677,\n",
       " -0.011613360685899339,\n",
       " 0.011773269704381712,\n",
       " 0.019788688184637318,\n",
       " -0.0034213774141225385,\n",
       " 0.009634492053700124,\n",
       " -0.009401292604704995,\n",
       " -0.013845418674972527,\n",
       " -0.016390629225298162,\n",
       " 0.0025635345549376936,\n",
       " 0.010027600521177625,\n",
       " 0.006729486444619793,\n",
       " 0.014511704544557687,\n",
       " -0.00942794333168324,\n",
       " 0.01547115586148419,\n",
       " 0.00895488082062584,\n",
       " -0.0016707115688559984,\n",
       " 0.001046901575960965,\n",
       " -0.0047073089840970585,\n",
       " -0.023466585365183527,\n",
       " -0.011933178722864087,\n",
       " 0.017416710153638017,\n",
       " -0.0086617153732845,\n",
       " 0.01647058513152322,\n",
       " -0.013685509656490154,\n",
       " -0.020428322395921652,\n",
       " 0.024559293110968997,\n",
       " 0.004660668814901258,\n",
       " 0.015724344287035584,\n",
       " 0.015071384712262126,\n",
       " 0.018589373805648544,\n",
       " -0.005963257554898472,\n",
       " 0.0007462400877880405,\n",
       " 0.001171830118300521,\n",
       " 0.005750046151137027,\n",
       " -0.01237958957562066,\n",
       " 0.017483338833728792,\n",
       " -0.022173991579125737,\n",
       " -0.015031406759149596,\n",
       " 0.025145625868296842,\n",
       " 0.0010419043318218987,\n",
       " 0.011326857920302559,\n",
       " -0.008468492014756739,\n",
       " 0.014671612631717481,\n",
       " 0.011773269704381712,\n",
       " 0.004297543346596862,\n",
       " 0.010194172221404561,\n",
       " 0.005030457430611506,\n",
       " -0.01076717775259812,\n",
       " 0.0067128292745971,\n",
       " -0.023693122132434095,\n",
       " -0.03152864448029622,\n",
       " -0.0027684173736877912,\n",
       " -0.008035406525489288,\n",
       " 0.01595088105428615,\n",
       " 0.012292972850296202,\n",
       " -0.012146390126625531,\n",
       " 0.012233006851949989,\n",
       " -0.02113458528729676,\n",
       " -0.013359029869103426,\n",
       " 0.0044874348985910525,\n",
       " -0.0006883564685253096,\n",
       " 0.04965161566266419,\n",
       " 0.007555680867026037,\n",
       " 0.005316960661869576,\n",
       " 0.017496664197217914,\n",
       " 0.000522617894554751,\n",
       " -0.024692550471150546,\n",
       " 0.017270127429967346,\n",
       " -0.018416138492354468,\n",
       " 0.0014724915482657842,\n",
       " 0.04035026607809535,\n",
       " 0.025878539486650195,\n",
       " -0.017016938073093374,\n",
       " -0.013598892931165696,\n",
       " -0.007768892270787481,\n",
       " 0.024559293110968997,\n",
       " 0.013299063870757213,\n",
       " -0.017936412368229925,\n",
       " -0.017829807597671783,\n",
       " 0.0194288940572052,\n",
       " -0.0027401002777814707,\n",
       " -0.005286977662696471,\n",
       " -0.0075690062305151596,\n",
       " -0.0401104020847105,\n",
       " 0.015071384712262126,\n",
       " -0.0008078715237397484,\n",
       " -0.003851131795348354,\n",
       " -0.02204073421894419,\n",
       " -0.0016540543988333048,\n",
       " -0.02260041438664863,\n",
       " 0.007275840783173818,\n",
       " -0.03619264463606976,\n",
       " 0.019975246998775356,\n",
       " 0.011933178722864087,\n",
       " -0.029023409089115375,\n",
       " -0.007902149165307739,\n",
       " 0.001842280163976032,\n",
       " -0.032861214356821385,\n",
       " 0.0014425086655080004,\n",
       " -0.00016022090968360585,\n",
       " 0.02843707633178753,\n",
       " -0.010753852389108998,\n",
       " -0.0016290687602145873,\n",
       " 0.01123357851323354,\n",
       " 0.008548446989659215,\n",
       " -0.01728345279345647,\n",
       " 0.007015989210216574,\n",
       " -0.0024302774275867904,\n",
       " 0.026264986203705716,\n",
       " -0.013992001398643199,\n",
       " -0.011027029791216655,\n",
       " -0.0004108068270419369,\n",
       " 0.006269749297051517,\n",
       " 0.008455166651267616,\n",
       " -0.003757851689787399,\n",
       " -0.002618503076314195,\n",
       " -0.0022070715355472135,\n",
       " -0.0085684350348929,\n",
       " 0.0039277547308866146,\n",
       " -0.002267037301062781,\n",
       " 0.018749281892808337,\n",
       " -0.0012909286976982635,\n",
       " -0.022826951153899194,\n",
       " -0.011393486600393332,\n",
       " -0.006266417956179236,\n",
       " -0.013965349740342373,\n",
       " -0.008748332098608957,\n",
       " -0.014764892970109082,\n",
       " -0.02629163693068396,\n",
       " -0.01428516684598454,\n",
       " 0.0058833035113185755,\n",
       " 0.001676541531797812,\n",
       " 0.021720916181979442,\n",
       " 0.010014275157688502,\n",
       " -0.014405098842676966,\n",
       " 0.02157433345830877,\n",
       " 0.027824094710126604,\n",
       " -0.02365314604196673,\n",
       " -0.0009569529276876134,\n",
       " -0.006299731830563333,\n",
       " -7.870500903152122e-05,\n",
       " -0.007608983717966398,\n",
       " 0.0029150003301891074,\n",
       " 0.0068960576791854385,\n",
       " -0.00980772643567162,\n",
       " 0.027477625946183613,\n",
       " -0.014165235780614694,\n",
       " -0.024119544939956987,\n",
       " -0.03677897553075245,\n",
       " -0.005889966193063137,\n",
       " 0.015484481224973312,\n",
       " -0.012792687019654426,\n",
       " -0.0025768601512574612,\n",
       " -0.005413571875472167,\n",
       " 0.0006854414870544027,\n",
       " 0.018682653212717563,\n",
       " 0.02494573982802452,\n",
       " -0.012219681488460867,\n",
       " 0.019402241467581793,\n",
       " -0.004590708793938204,\n",
       " -0.001802303025770761,\n",
       " 0.005670092107557131,\n",
       " -0.02403959089637709,\n",
       " -0.007195886273932631,\n",
       " 0.008988195160671227,\n",
       " -0.001668213063201788,\n",
       " 0.009041497545950298,\n",
       " -0.017976390321342454,\n",
       " -0.01794973959436421,\n",
       " 0.007062629379412374,\n",
       " 0.022720344520695893,\n",
       " 0.0026035115767276415,\n",
       " -0.015177990414142847,\n",
       " -0.030355980828285695,\n",
       " -0.0004659836154306172,\n",
       " -0.00495050338703161,\n",
       " -0.0018622687912863286,\n",
       " 0.007555680867026037,\n",
       " -0.008588424011449164,\n",
       " -0.021054631243716863,\n",
       " 0.00041455467283474455,\n",
       " -0.011833235702727925,\n",
       " 0.005690080618452105,\n",
       " -0.008641726396728234,\n",
       " 0.005213686300861135,\n",
       " -0.016883680712911825,\n",
       " -0.011879875406262435,\n",
       " -0.03347419597848231,\n",
       " -0.02098800256362609,\n",
       " 0.0015932559145149896,\n",
       " 0.0076689492506513204,\n",
       " 0.015497807519785016,\n",
       " -0.015191315777631971,\n",
       " -0.027211111225820515,\n",
       " -0.007442412017739463,\n",
       " -0.040510174165255146,\n",
       " -0.020041875678866127,\n",
       " -0.01728345279345647,\n",
       " -0.0009919329381691407,\n",
       " 0.0169503093930026,\n",
       " 0.01647058513152322,\n",
       " -0.012159715490114653,\n",
       " 0.032035019468753846,\n",
       " 0.0069027208265912895,\n",
       " 0.033314287891322514,\n",
       " -0.020548252529968915,\n",
       " -0.019468870147672568,\n",
       " 0.024545967747479875,\n",
       " -0.010593944301949206,\n",
       " 0.007322480486708327,\n",
       " 0.004217588837355676,\n",
       " -0.010447360646955953,\n",
       " -0.0213211441014348,\n",
       " 0.02246715702646708,\n",
       " 0.0023070145556833748,\n",
       " 0.009261372562778885,\n",
       " 0.02096134997400268,\n",
       " 0.004827240515128194,\n",
       " -0.028250517517649495,\n",
       " -0.008675040736773621,\n",
       " 0.01861602453262679,\n",
       " 0.0011318529800952502,\n",
       " 0.0033064431272304693,\n",
       " -0.0006021557533562577,\n",
       " -0.00714258342299227,\n",
       " 0.0035013316905330803,\n",
       " 0.0036512459879066766,\n",
       " 0.0003806157645834662,\n",
       " -0.0023869688320939165,\n",
       " -0.0047073089840970585,\n",
       " 0.004727297494992033,\n",
       " -0.004414143071094427,\n",
       " 0.0022104031092501394,\n",
       " -0.03379401587809222,\n",
       " -0.006076526404185046,\n",
       " -0.01000094979419938,\n",
       " -0.016417281814921567,\n",
       " 0.00985436707052871,\n",
       " -0.014165235780614694,\n",
       " -0.005670092107557131,\n",
       " 0.03358080261168561,\n",
       " 0.0038977717317135088,\n",
       " -0.012466207232267698,\n",
       " -0.011879875406262435,\n",
       " 0.02013515694858031,\n",
       " -0.013912047355063302,\n",
       " -0.0057766978094378535,\n",
       " 0.003531314689706187,\n",
       " -0.011486766938784932,\n",
       " 0.0016274029733631243,\n",
       " -0.0008507636434159262,\n",
       " -0.0008720015235533281,\n",
       " -0.015151338755842023,\n",
       " 0.002338662992461976,\n",
       " -0.0046440116448785655,\n",
       " -0.006699503445446687,\n",
       " -0.018269555768683797,\n",
       " 0.00226204028975436,\n",
       " 0.014511704544557687,\n",
       " -0.025771934716092054,\n",
       " -0.012712732976074531,\n",
       " -0.020641533799683094,\n",
       " 0.02013515694858031,\n",
       " 0.0005276150222784945,\n",
       " -0.005087092088085439,\n",
       " -0.009827715412227885,\n",
       " -0.010207498516216265,\n",
       " 0.014764892970109082,\n",
       " 0.023932984263173786,\n",
       " -0.013485624547540412,\n",
       " 0.000838270765898906,\n",
       " 0.013552252296308605,\n",
       " 0.014405098842676966,\n",
       " -0.0036212632215642158,\n",
       " 0.008388537971176842,\n",
       " 0.23197405199593576,\n",
       " 0.005710069129347079,\n",
       " 0.017390059426659773,\n",
       " 0.03243479154929849,\n",
       " -0.0063930121689549325,\n",
       " 0.033687409244888916,\n",
       " 0.007542355037875624,\n",
       " -0.010100892814335542,\n",
       " -0.008435177674711351,\n",
       " 0.021401100007659855,\n",
       " 0.01628402445474002,\n",
       " 0.014591658588137584,\n",
       " -0.005140394939025799,\n",
       " 0.005256994663523364,\n",
       " -0.002038834397714783,\n",
       " -0.0019338944826855237,\n",
       " -0.023160094554353066,\n",
       " -0.02166761286537779,\n",
       " -0.03517989093386419,\n",
       " -0.01671044726226291,\n",
       " 0.0011418472355427373,\n",
       " -0.022000756265831662,\n",
       " 0.01917570470033123,\n",
       " -0.010927086771080495,\n",
       " 0.014604983951626706,\n",
       " -0.01613744173106935,\n",
       " -0.019988574224909638,\n",
       " -0.001730677334371566,\n",
       " 0.021640962138399545,\n",
       " 0.020921373883535314,\n",
       " -0.013578903954609431,\n",
       " 0.0012567815224348064,\n",
       " 0.012739383703052776,\n",
       " -0.003974394434421124,\n",
       " -0.03136873266784611,\n",
       " -0.005650103596662157,\n",
       " 0.030542539642423733,\n",
       " -0.003741194752595351,\n",
       " 0.02557204867581973,\n",
       " -0.008401863334665964,\n",
       " 0.006229771809600279,\n",
       " -0.02438605966032008,\n",
       " 0.006462972189917988,\n",
       " -0.014338470162586192,\n",
       " 0.0044874348985910525,\n",
       " 0.026957921868946542,\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(text)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.0031584087512342572,\n",
       "  0.011094410212838685,\n",
       "  -0.004001317166816525,\n",
       "  -0.011747414500761147,\n",
       "  -0.0010153218392504927,\n",
       "  0.010781234363886399,\n",
       "  -0.010368109905383128,\n",
       "  -0.0052973312542353886,\n",
       "  -0.00988168756470157,\n",
       "  -0.026160153195893116,\n",
       "  0.02037639960097617,\n",
       "  0.022575293225485345,\n",
       "  -0.007522876537439858,\n",
       "  0.01728462465309313,\n",
       "  -0.0060036416535162295,\n",
       "  0.01912369806781222,\n",
       "  0.02125595742330888,\n",
       "  -0.015645450320121206,\n",
       "  0.007669469042167345,\n",
       "  -0.018364081557173,\n",
       "  -0.0006909018997805782,\n",
       "  -0.006416767043342096,\n",
       "  -0.010981134376956157,\n",
       "  0.017950956167347133,\n",
       "  -0.022135513382996398,\n",
       "  -0.0030767832152439494,\n",
       "  0.014379421560625712,\n",
       "  -0.029984892064397486,\n",
       "  0.018524000822570733,\n",
       "  -0.007916012019091008,\n",
       "  0.010068260351439788,\n",
       "  -0.019456863824939222,\n",
       "  -0.003688141783525537,\n",
       "  -0.02424112014847516,\n",
       "  -0.005530547004827511,\n",
       "  0.0038247395669963142,\n",
       "  -0.005653818260458694,\n",
       "  -0.029451827225523322,\n",
       "  0.018603960455269596,\n",
       "  -0.016618293138839127,\n",
       "  0.0075295396849443304,\n",
       "  0.012420408696858325,\n",
       "  -0.000990334337616773,\n",
       "  -0.01072126463936225,\n",
       "  0.010001627945072464,\n",
       "  -0.012560338054081339,\n",
       "  0.03352977408110101,\n",
       "  -0.026999729339231202,\n",
       "  -0.007929338314099954,\n",
       "  0.029025376472011102,\n",
       "  0.01969674272303582,\n",
       "  -0.002077286642354891,\n",
       "  -0.02739952936537072,\n",
       "  -0.008775579001926404,\n",
       "  -0.006213536155012048,\n",
       "  0.0019939954359037893,\n",
       "  -0.007382946714555546,\n",
       "  0.027985899384280664,\n",
       "  0.006829892433167963,\n",
       "  -0.009315306522643745,\n",
       "  -0.022482006366454938,\n",
       "  0.010468059446256709,\n",
       "  -0.013546508099130803,\n",
       "  -0.011094410212838685,\n",
       "  -0.0048875376709924066,\n",
       "  -0.008275830366235902,\n",
       "  -0.0058237324799437825,\n",
       "  0.0111144001210134,\n",
       "  0.006276837686119082,\n",
       "  0.004434432464817108,\n",
       "  0.010568008987130291,\n",
       "  0.012480378421382474,\n",
       "  0.005337311070584821,\n",
       "  0.005393948988526085,\n",
       "  0.008988804378682514,\n",
       "  0.0042611864387491335,\n",
       "  -0.022681905448202103,\n",
       "  -0.013233332250178519,\n",
       "  0.011201023366878036,\n",
       "  -0.005753767801332276,\n",
       "  0.009828381453343192,\n",
       "  -0.024401039413872894,\n",
       "  -0.008582342602022416,\n",
       "  0.007829388773226373,\n",
       "  0.0025037385600203523,\n",
       "  0.007549529593119047,\n",
       "  0.005747104653827803,\n",
       "  0.028172473102341476,\n",
       "  -0.022908457119967154,\n",
       "  -0.015525510871072908,\n",
       "  -0.00818254443852809,\n",
       "  0.020056561070180712,\n",
       "  0.003568202334477239,\n",
       "  0.01278689065716899,\n",
       "  -0.016458373873441397,\n",
       "  0.03155743399100209,\n",
       "  0.013506528282781372,\n",
       "  0.030437997270572784,\n",
       "  -0.006240189210691237,\n",
       "  -0.0496816347874333,\n",
       "  -0.003728121599874969,\n",
       "  -0.0013001782635708487,\n",
       "  -0.0070631081837600855,\n",
       "  0.003524890711544921,\n",
       "  -0.03483578265694594,\n",
       "  -0.009062101329538204,\n",
       "  0.021975594117598665,\n",
       "  -0.007236354209828059,\n",
       "  0.015485531054723474,\n",
       "  -0.008295820274410618,\n",
       "  -0.016445048509755048,\n",
       "  0.005060783697060381,\n",
       "  -0.0063901139876629065,\n",
       "  -0.03611513678012778,\n",
       "  0.015618797730103313,\n",
       "  0.005653818260458694,\n",
       "  0.006503389823545434,\n",
       "  -0.0218956344848998,\n",
       "  -0.010248169525012235,\n",
       "  0.0010503041785562463,\n",
       "  0.0006350967006543871,\n",
       "  0.016938133532279777,\n",
       "  0.02651997154303801,\n",
       "  -0.027506141588087472,\n",
       "  0.010548019078955573,\n",
       "  0.01327331206652795,\n",
       "  -0.008822221500119012,\n",
       "  -0.041872237785026835,\n",
       "  -0.006493394869458076,\n",
       "  -0.005567195014594058,\n",
       "  0.01913702529414376,\n",
       "  0.021482509095073935,\n",
       "  0.014192848773887495,\n",
       "  0.017511178187503376,\n",
       "  -0.023348236962456106,\n",
       "  0.03734118572327384,\n",
       "  -0.04040630994378418,\n",
       "  0.02477418498734933,\n",
       "  -0.04320489708824446,\n",
       "  -0.008409096110293146,\n",
       "  0.008309146569419563,\n",
       "  0.027372874912707637,\n",
       "  -0.019150350657830113,\n",
       "  -0.01696478612229767,\n",
       "  0.010288150272684262,\n",
       "  0.013992949692140332,\n",
       "  0.008262504071226955,\n",
       "  -0.02484081739371665,\n",
       "  0.012493705647714015,\n",
       "  -0.021056058341561715,\n",
       "  0.0031051021742145813,\n",
       "  0.0017724403098598187,\n",
       "  0.017764382449286322,\n",
       "  0.002560376710792265,\n",
       "  0.015565490687422339,\n",
       "  0.03147747435830322,\n",
       "  0.003858056235841274,\n",
       "  -0.009548522738897164,\n",
       "  -0.018004261347382918,\n",
       "  -0.019616783090336952,\n",
       "  0.0031034365037537876,\n",
       "  0.022162167835659476,\n",
       "  0.00956851264707188,\n",
       "  0.0018540658458501265,\n",
       "  0.023454849185172863,\n",
       "  0.03467586339154821,\n",
       "  0.00400464897339941,\n",
       "  0.007669469042167345,\n",
       "  -0.001613353763277161,\n",
       "  -0.015418897717033555,\n",
       "  -0.025027391111777462,\n",
       "  0.024760857761017788,\n",
       "  -0.025387209458922356,\n",
       "  0.0076494791339926285,\n",
       "  -0.02017650051922901,\n",
       "  0.014299461927926848,\n",
       "  0.007189710780312856,\n",
       "  0.003481579088612603,\n",
       "  -0.004424437510729749,\n",
       "  -0.0040546237438362,\n",
       "  -0.03390291779193226,\n",
       "  0.016844846673249373,\n",
       "  0.014792546950451579,\n",
       "  0.031850618069134466,\n",
       "  -0.017004765938647103,\n",
       "  -0.006936505121546017,\n",
       "  0.02424112014847516,\n",
       "  -0.009541859125731394,\n",
       "  0.0013884670634809538,\n",
       "  -0.004634331546564271,\n",
       "  0.02314833788070894,\n",
       "  0.021935614301249233,\n",
       "  -0.006290163981128028,\n",
       "  -0.014805873245460526,\n",
       "  -0.7023661288825848,\n",
       "  -0.01635176165072464,\n",
       "  0.0042611864387491335,\n",
       "  -0.017311277243111024,\n",
       "  0.02217549319934583,\n",
       "  0.031370860272941274,\n",
       "  0.02464091831196949,\n",
       "  0.0020939449767773707,\n",
       "  -0.005986983551924398,\n",
       "  0.021855654668550367,\n",
       "  -0.022668578221870562,\n",
       "  -0.012700267411304355,\n",
       "  -0.009202030686761217,\n",
       "  -0.013206679660160626,\n",
       "  -0.014139542662529116,\n",
       "  -0.02314833788070894,\n",
       "  -0.01695145889596613,\n",
       "  -0.0033249913969671096,\n",
       "  -0.017604463183888593,\n",
       "  0.013106730119287044,\n",
       "  0.014979119737189796,\n",
       "  0.015472204759714529,\n",
       "  -0.01571208458913372,\n",
       "  -0.016711579997869534,\n",
       "  0.0005126583966689254,\n",
       "  0.008935498267324135,\n",
       "  0.013100066506121274,\n",
       "  -0.006123581568225824,\n",
       "  0.017484523734840295,\n",
       "  0.016884826489598805,\n",
       "  -0.026240112828591983,\n",
       "  -0.0035215591377926844,\n",
       "  -0.0009320303999687423,\n",
       "  0.008535699172507214,\n",
       "  0.033236586277678254,\n",
       "  -0.002067291688267533,\n",
       "  -0.014472708419656118,\n",
       "  -0.025040716475463815,\n",
       "  0.016604967775152777,\n",
       "  0.0009203696007976038,\n",
       "  -0.01680486685689994,\n",
       "  -0.0003496155334959091,\n",
       "  0.004830899287389846,\n",
       "  -0.0017291288033428253,\n",
       "  -0.004571030481118534,\n",
       "  -0.0024737536977582778,\n",
       "  0.01883051212703465,\n",
       "  0.0003673149410602162,\n",
       "  0.0274528345454065,\n",
       "  0.017684422816587456,\n",
       "  -0.016578313322489695,\n",
       "  -0.0005447255216299788,\n",
       "  0.006663309554604462,\n",
       "  -0.0035182273312097992,\n",
       "  0.0010453067015125672,\n",
       "  -0.010421416016741507,\n",
       "  0.02160244854412223,\n",
       "  0.00775609228803198,\n",
       "  0.010834541406567373,\n",
       "  0.016604967775152777,\n",
       "  -0.001151086671075549,\n",
       "  0.011860691267966269,\n",
       "  -0.005657149601380282,\n",
       "  -0.016871499263267264,\n",
       "  -0.028945416839312236,\n",
       "  -0.007496223016099372,\n",
       "  -0.020776199627115688,\n",
       "  0.02253531340913591,\n",
       "  0.0010594661809978831,\n",
       "  -0.01899043139243238,\n",
       "  -0.0037581064621370437,\n",
       "  0.012520358237731908,\n",
       "  -0.010261496751343776,\n",
       "  -0.01972339531305371,\n",
       "  0.020749545174452606,\n",
       "  0.015485531054723474,\n",
       "  0.009761748115653274,\n",
       "  -0.00994832090239149,\n",
       "  -0.009355286338993176,\n",
       "  0.01677821240423686,\n",
       "  0.0037014683113651315,\n",
       "  0.0036215086786662663,\n",
       "  -0.014366095265616767,\n",
       "  -0.015418897717033555,\n",
       "  0.010847867701576318,\n",
       "  -0.020283114604590955,\n",
       "  -0.04611010204335707,\n",
       "  -0.01296013714889826,\n",
       "  -0.0066999575643710094,\n",
       "  0.013386588833733074,\n",
       "  0.02160244854412223,\n",
       "  0.001438441950333069,\n",
       "  -0.007955991835440442,\n",
       "  -0.00046601519998437115,\n",
       "  0.008908844745983647,\n",
       "  -0.002800255841719509,\n",
       "  0.0011885678653184664,\n",
       "  0.003934684294787902,\n",
       "  0.03009150614975943,\n",
       "  -0.0019306939047967551,\n",
       "  0.0015000775781486605,\n",
       "  0.00244710040924844,\n",
       "  0.0006804904698703595,\n",
       "  0.011740750887595377,\n",
       "  0.02112269074792904,\n",
       "  0.0052240347690409965,\n",
       "  0.003648161967176104,\n",
       "  0.024467671820240216,\n",
       "  0.018270794698142596,\n",
       "  -0.008495719356157781,\n",
       "  -0.0071697208721381404,\n",
       "  -0.008995467991848284,\n",
       "  -0.009535195512565623,\n",
       "  0.0015650447797164885,\n",
       "  -0.016071902936278613,\n",
       "  -0.03416945114269194,\n",
       "  0.007989308038624103,\n",
       "  0.011241003183227469,\n",
       "  0.0023404874880397367,\n",
       "  0.0033899585985349375,\n",
       "  0.014059583029830252,\n",
       "  0.01772440263293689,\n",
       "  0.013299965587868438,\n",
       "  -0.001631677884575759,\n",
       "  0.0045843567761274795,\n",
       "  -0.002488746128889315,\n",
       "  0.003974664111137336,\n",
       "  -0.01943021123492133,\n",
       "  -0.017204665020394267,\n",
       "  -0.009701778391129125,\n",
       "  -0.019456863824939222,\n",
       "  -0.0017857669541147378,\n",
       "  0.03371634779916183,\n",
       "  -0.014166196183869604,\n",
       "  0.007702785711012305,\n",
       "  0.0023038392454425407,\n",
       "  0.003831402947331436,\n",
       "  -0.005277340880399375,\n",
       "  0.021349244282339284,\n",
       "  -0.009748421820644327,\n",
       "  -0.013020106873422409,\n",
       "  0.013313291882877384,\n",
       "  -0.006963158177225206,\n",
       "  -0.009068764011381378,\n",
       "  -0.01195397719567408,\n",
       "  -0.022308759874725668,\n",
       "  -0.01801758857371446,\n",
       "  -0.0030268084448071587,\n",
       "  0.0009944989794300552,\n",
       "  0.00994165728922572,\n",
       "  -0.022068880976629072,\n",
       "  0.0014101228749471128,\n",
       "  -0.010128230075963937,\n",
       "  -0.005847054194701384,\n",
       "  -0.008095921192663455,\n",
       "  -0.011081083917829738,\n",
       "  -0.017044745754996534,\n",
       "  -0.026293419871272955,\n",
       "  0.0010411420596992851,\n",
       "  -0.001472591337993101,\n",
       "  -0.008648975939712335,\n",
       "  0.0175778105938707,\n",
       "  -0.006223531109099406,\n",
       "  0.0011360942399445118,\n",
       "  -0.02653329876936955,\n",
       "  -0.018310774514492027,\n",
       "  -0.03302336183224474,\n",
       "  0.03318328109764247,\n",
       "  -0.009988300718740923,\n",
       "  -0.033876267064559554,\n",
       "  -0.01835075433084146,\n",
       "  0.005207376201787868,\n",
       "  -0.013473212079597709,\n",
       "  -0.0020423043030491374,\n",
       "  0.005070778651147739,\n",
       "  -0.010587998895305007,\n",
       "  -0.015685430136470637,\n",
       "  0.007862704976410034,\n",
       "  0.010328130089033695,\n",
       "  -0.021349244282339284,\n",
       "  -0.004967497303691272,\n",
       "  0.0034749159411081305,\n",
       "  0.012227173228276933,\n",
       "  0.002070623494850418,\n",
       "  0.011760740795770093,\n",
       "  0.015059079369888661,\n",
       "  0.013479874761440884,\n",
       "  0.007049781423089842,\n",
       "  -0.012600317870430772,\n",
       "  0.002543718376369785,\n",
       "  0.00800263433363305,\n",
       "  0.0033033355855009504,\n",
       "  -0.014659281206394335,\n",
       "  0.009321970135809515,\n",
       "  -0.007702785711012305,\n",
       "  0.019856661988433548,\n",
       "  -0.029718360576282996,\n",
       "  0.010421416016741507,\n",
       "  0.01288684019804257,\n",
       "  0.023841321984980835,\n",
       "  0.022588618589171695,\n",
       "  0.008655638621555512,\n",
       "  0.0038880410981033484,\n",
       "  -0.022748537854569425,\n",
       "  0.00016585394401008583,\n",
       "  -0.035422154538501074,\n",
       "  -0.013126720027461762,\n",
       "  -0.002710301022102637,\n",
       "  0.013533181804121858,\n",
       "  0.00628683264020644,\n",
       "  0.01288684019804257,\n",
       "  -0.0175778105938707,\n",
       "  -0.02468089812831892,\n",
       "  0.017364584285791997,\n",
       "  0.021549143364086448,\n",
       "  0.005447255565545761,\n",
       "  -0.010128230075963937,\n",
       "  -0.002821911653185668,\n",
       "  -0.006803238911827476,\n",
       "  -0.0020256459686266576,\n",
       "  0.006739937380720442,\n",
       "  0.004847557854642974,\n",
       "  0.012520358237731908,\n",
       "  -0.007276334026177492,\n",
       "  -0.016258474791694233,\n",
       "  0.011507535602664551,\n",
       "  0.028598923855853695,\n",
       "  0.03262356366875042,\n",
       "  0.02300174397899756,\n",
       "  -0.024147833289444757,\n",
       "  -0.018390734147190894,\n",
       "  0.0025986906238502547,\n",
       "  0.0008878860000136897,\n",
       "  0.0012443730644446575,\n",
       "  0.0031684037053216155,\n",
       "  0.010474722128099884,\n",
       "  0.02240204673375607,\n",
       "  -0.01941688400858979,\n",
       "  0.028758843121251425,\n",
       "  0.0003606516189327567,\n",
       "  0.011480882081324065,\n",
       "  0.018857166579697732,\n",
       "  0.028625578308516777,\n",
       "  -0.008495719356157781,\n",
       "  0.022921784346298695,\n",
       "  -0.00012087659968526976,\n",
       "  0.028172473102341476,\n",
       "  0.008575678988856646,\n",
       "  -0.004051291937253315,\n",
       "  0.03153077953833901,\n",
       "  -0.010707938344353305,\n",
       "  0.0018573975360176873,\n",
       "  0.0009944989794300552,\n",
       "  0.004204548055146573,\n",
       "  0.032463644403352684,\n",
       "  -0.02685313730016501,\n",
       "  -0.013399915128742019,\n",
       "  0.0019190331638332789,\n",
       "  0.014326115449267334,\n",
       "  0.03115763582750776,\n",
       "  0.02221547301569526,\n",
       "  0.0050208038807109485,\n",
       "  -0.002633672963156008,\n",
       "  0.0012277147300221777,\n",
       "  0.023188317697058373,\n",
       "  -0.004537713812273574,\n",
       "  -0.013226669568335342,\n",
       "  0.0034066169329574174,\n",
       "  -0.019976601437481846,\n",
       "  -0.013040096781597127,\n",
       "  -0.005637159693205566,\n",
       "  -0.0014459381658985875,\n",
       "  0.01805756839006389,\n",
       "  0.0024820827485541935,\n",
       "  0.02464091831196949,\n",
       "  0.010581335282139236,\n",
       "  0.02590694707146498,\n",
       "  0.012020610533364,\n",
       "  0.016458373873441397,\n",
       "  0.0014925813625831419,\n",
       "  -0.009102081145887635,\n",
       "  -0.022428699323773966,\n",
       "  0.0006725777784819802,\n",
       "  0.012207183320102217,\n",
       "  0.012280479339635312,\n",
       "  -0.011687444776236998,\n",
       "  -0.010228179616837519,\n",
       "  0.0046576532613218724,\n",
       "  -0.007462906812915709,\n",
       "  0.006500058482623847,\n",
       "  0.004001317166816525,\n",
       "  -1.1660791895180796e-05,\n",
       "  0.01709805279767751,\n",
       "  -0.02316166324439529,\n",
       "  -5.3124274259723366e-05,\n",
       "  0.015978616077248205,\n",
       "  0.008835548726450553,\n",
       "  -0.0055572000605067,\n",
       "  -0.010148219984138653,\n",
       "  -0.007816062478217426,\n",
       "  0.011201023366878036,\n",
       "  -0.007576182648798236,\n",
       "  0.00879556891010112,\n",
       "  0.00620354120092469,\n",
       "  0.020149847929211116,\n",
       "  0.0002575785675953825,\n",
       "  -0.002617014861564177,\n",
       "  -0.01295347353573249,\n",
       "  -0.013466548466431938,\n",
       "  -0.010301476567693209,\n",
       "  0.01801758857371446,\n",
       "  0.0038114130391567196,\n",
       "  -0.014006276918471873,\n",
       "  -0.005980320404419925,\n",
       "  0.015565490687422339,\n",
       "  -0.005697129417729715,\n",
       "  0.0015317282272868532,\n",
       "  0.013319955496043154,\n",
       "  0.01681819222058629,\n",
       "  0.012826870473518421,\n",
       "  -0.015352265310666231,\n",
       "  -0.00684988234134268,\n",
       "  -0.018097548206413325,\n",
       "  0.01072126463936225,\n",
       "  0.04882873328040887,\n",
       "  0.04315159190820868,\n",
       "  0.0025637082845445013,\n",
       "  -0.010941154560606724,\n",
       "  0.003691473357277773,\n",
       "  -0.019363576965908815,\n",
       "  -0.026959749522881767,\n",
       "  -0.013499864669615601,\n",
       "  0.006393445328584495,\n",
       "  -0.0021755705127676785,\n",
       "  -0.00785604229456686,\n",
       "  -0.0043211561632732825,\n",
       "  0.016285129244357315,\n",
       "  0.001352651772529479,\n",
       "  0.016618293138839127,\n",
       "  0.007116414295118464,\n",
       "  -0.0014392749019787902,\n",
       "  -0.0024820827485541935,\n",
       "  -0.009448573198023582,\n",
       "  -0.012260489431460596,\n",
       "  0.0029385195284817294,\n",
       "  0.007702785711012305,\n",
       "  0.007629489225817913,\n",
       "  0.0033932904051178227,\n",
       "  0.012073916644722378,\n",
       "  -0.021349244282339284,\n",
       "  0.0077227756191870205,\n",
       "  0.0016916477255152322,\n",
       "  0.00025570451370400283,\n",
       "  -0.02036307423728982,\n",
       "  -0.014152868957538063,\n",
       "  0.019230310290528976,\n",
       "  0.010101577485946044,\n",
       "  0.018097548206413325,\n",
       "  -0.0006234359014832486,\n",
       "  0.03286344256684701,\n",
       "  -0.004447759225487351,\n",
       "  -0.01573873717915161,\n",
       "  0.00778940895687694,\n",
       "  0.004840894241477204,\n",
       "  0.009222020594935933,\n",
       "  0.004571030481118534,\n",
       "  -0.00339162450182638,\n",
       "  -0.008269166753070132,\n",
       "  -0.007129741055788707,\n",
       "  0.00024820826903465315,\n",
       "  -0.016604967775152777,\n",
       "  0.0033999535526222954,\n",
       "  -0.008662302234721283,\n",
       "  -0.00755619274062352,\n",
       "  0.012080580257888149,\n",
       "  -0.01773772985926843,\n",
       "  -0.0012060590349713433,\n",
       "  -0.015445551238374041,\n",
       "  0.028732190531233534,\n",
       "  0.02326827732975724,\n",
       "  0.004401115795972148,\n",
       "  0.006843218728176909,\n",
       "  -0.0021672414619717632,\n",
       "  -0.017564483367539158,\n",
       "  -0.02987827984168073,\n",
       "  -0.0067499323348078006,\n",
       "  -0.011367606245441537,\n",
       "  -0.009301980227634798,\n",
       "  -0.011380932540450483,\n",
       "  -0.030411344680554894,\n",
       "  -0.023494829001522295,\n",
       "  -0.013333282722374695,\n",
       "  -0.02017650051922901,\n",
       "  0.0037381165539623275,\n",
       "  0.010987797058799332,\n",
       "  -0.01759113782020224,\n",
       "  -0.024760857761017788,\n",
       "  -0.016231822201676342,\n",
       "  0.02899872201934802,\n",
       "  -0.0139529698757909,\n",
       "  0.0005209875056725032,\n",
       "  0.013106730119287044,\n",
       "  0.0015358928691001352,\n",
       "  0.022588618589171695,\n",
       "  -0.010861193996585264,\n",
       "  -0.02249533359278648,\n",
       "  0.005863712296293216,\n",
       "  -0.024147833289444757,\n",
       "  -0.005843722388118499,\n",
       "  0.016858173899580914,\n",
       "  -0.00397133230455445,\n",
       "  0.006753264141390686,\n",
       "  -0.0027519467417435124,\n",
       "  0.010421416016741507,\n",
       "  -0.006043621469865662,\n",
       "  -0.0024654244141317136,\n",
       "  -0.004880874057826637,\n",
       "  -0.029371867592824456,\n",
       "  0.01635176165072464,\n",
       "  -0.008728935572411202,\n",
       "  0.0019939954359037893,\n",
       "  0.007442916904740993,\n",
       "  -0.008668965847887053,\n",
       "  -0.004154573284709782,\n",
       "  -0.015538838097404448,\n",
       "  -0.0015217332731994949,\n",
       "  -0.009128733735905527,\n",
       "  0.0016108550247553213,\n",
       "  0.020749545174452606,\n",
       "  -0.019030411208781815,\n",
       "  -0.013373262538724128,\n",
       "  0.016911479079616695,\n",
       "  -0.02329492991977513,\n",
       "  -0.0077094488585167775,\n",
       "  -0.010488049354431424,\n",
       "  -0.018137528022762757,\n",
       "  0.009601828850255543,\n",
       "  -0.020003255890144928,\n",
       "  0.002393793832228764,\n",
       "  0.01741789132847297,\n",
       "  -0.007442916904740993,\n",
       "  0.021948941527580774,\n",
       "  -0.010301476567693209,\n",
       "  -0.03019811837247619,\n",
       "  7.584720315855387e-05,\n",
       "  -0.009808391545168476,\n",
       "  0.011094410212838685,\n",
       "  0.03563537898393459,\n",
       "  0.022068880976629072,\n",
       "  0.029211948327426726,\n",
       "  -0.008762251775594863,\n",
       "  -0.003048464023442669,\n",
       "  -0.014206176000219036,\n",
       "  0.007909348405925238,\n",
       "  -0.005074109992069326,\n",
       "  0.001172742482541708,\n",
       "  -0.0077960721043814135,\n",
       "  -0.004184558146971856,\n",
       "  -0.01884383935336619,\n",
       "  -0.011447565878140402,\n",
       "  -0.0015292294887650135,\n",
       "  0.013646457640004385,\n",
       "  -0.005264014585390429,\n",
       "  -0.010661294914838101,\n",
       "  -0.015059079369888661,\n",
       "  0.013673111161344871,\n",
       "  0.01139425883545943,\n",
       "  -0.009168713552254959,\n",
       "  -0.02572037521604936,\n",
       "  -0.029824972798999753,\n",
       "  -0.021655755586803205,\n",
       "  0.010108240167789221,\n",
       "  -0.020602953135386418,\n",
       "  0.000884554309846129,\n",
       "  0.021096038157911147,\n",
       "  0.0003396205503047198,\n",
       "  -0.011647464959887565,\n",
       "  -0.004904195772584238,\n",
       "  0.015818696811850476,\n",
       "  -0.029371867592824456,\n",
       "  -0.004824236139885373,\n",
       "  0.006163561384575258,\n",
       "  0.016231822201676342,\n",
       "  0.0271196687882795,\n",
       "  0.022681905448202103,\n",
       "  -0.01163413866487862,\n",
       "  0.011707434684411714,\n",
       "  0.01986998921476509,\n",
       "  -0.00342494117067134,\n",
       "  0.009635145053439206,\n",
       "  -0.009441909584857812,\n",
       "  -0.013779724315384224,\n",
       "  -0.01637841424074253,\n",
       "  0.0025637082845445013,\n",
       "  0.010008290626915639,\n",
       "  0.0067599272888951584,\n",
       "  0.014486034714665065,\n",
       "  -0.009415256063517325,\n",
       "  0.015485531054723474,\n",
       "  0.009002130673691459,\n",
       "  -0.0016783210812603131,\n",
       "  0.0010244838416921295,\n",
       "  -0.0046709800219921155,\n",
       "  -0.023508156227853835,\n",
       "  -0.011907333766158877,\n",
       "  0.01741789132847297,\n",
       "  -0.00862898603153762,\n",
       "  0.016551660732471805,\n",
       "  -0.01363979495816121,\n",
       "  -0.020389726827307712,\n",
       "  0.024547631452939082,\n",
       "  0.0046443265006516285,\n",
       "  0.015698757362802178,\n",
       "  0.015045753074879716,\n",
       "  0.018590633228938055,\n",
       "  -0.005986983551924398,\n",
       "  0.0007916844505075432,\n",
       "  0.0011752412210635475,\n",
       "  0.005747104653827803,\n",
       "  -0.01234044906415946,\n",
       "  0.017471198371153945,\n",
       "  -0.02221547301569526,\n",
       "  -0.015059079369888661,\n",
       "  0.025080696291813247,\n",
       "  0.0010053267687478102,\n",
       "  0.011334289110935281,\n",
       "  -0.008489056674314606,\n",
       "  0.014699261022743769,\n",
       "  0.011847364041634728,\n",
       "  0.004257854632166248,\n",
       "  0.010148219984138653,\n",
       "  0.005030798834798306,\n",
       "  -0.010767908068877454,\n",
       "  0.006743269187303327,\n",
       "  -0.023681402719583106,\n",
       "  -0.0315041288109663,\n",
       "  -0.0027719366499182286,\n",
       "  -0.00801596155996459,\n",
       "  0.015978616077248205,\n",
       "  0.012300469247810027,\n",
       "  -0.012140549982412298,\n",
       "  0.012200519706936447,\n",
       "  -0.021136017974260582,\n",
       "  -0.013393252446898844,\n",
       "  0.004514392097515973,\n",
       "  -0.0007025626989517168,\n",
       "  0.04962832960739752,\n",
       "  0.007536202832448804,\n",
       "  0.005323984309914578,\n",
       "  0.017511178187503376,\n",
       "  0.000552638213018358,\n",
       "  -0.024707550718336812,\n",
       "  0.017231317610412158,\n",
       "  -0.018364081557173,\n",
       "  0.0014717585027627042,\n",
       "  0.040379655491121096,\n",
       "  0.02589361984513344,\n",
       "  -0.017044745754996534,\n",
       "  -0.013606477823654952,\n",
       "  -0.0077361023798572645,\n",
       "  0.024534306089252732,\n",
       "  0.013326619109208925,\n",
       "  -0.017950956167347133,\n",
       "  -0.017817689491967294,\n",
       "  0.01944353659860768,\n",
       "  -0.0027286252598165595,\n",
       "  -0.005277340880399375,\n",
       "  -0.007569519501293764,\n",
       "  -0.040113122140361425,\n",
       "  0.015085732891229149,\n",
       "  -0.000767529958727207,\n",
       "  -0.003831402947331436,\n",
       "  -0.022068880976629072,\n",
       "  -0.0016899818222237896,\n",
       "  -0.022588618589171695,\n",
       "  0.007322976990031397,\n",
       "  -0.03619509641282665,\n",
       "  0.019936621621132414,\n",
       "  0.011894007471149931,\n",
       "  -0.02899872201934802,\n",
       "  -0.007876032202741575,\n",
       "  0.0018640607999374846,\n",
       "  -0.03286344256684701,\n",
       "  0.0014317785699979471,\n",
       "  -0.00015939885979405666,\n",
       "  0.028465657180473856,\n",
       "  -0.010747918160702738,\n",
       "  -0.001590865116580605,\n",
       "  0.011227676888218524,\n",
       "  0.008529036490664037,\n",
       "  -0.0172446448367437,\n",
       "  0.007029791514915126,\n",
       "  -0.0024487663125398827,\n",
       "  0.026293419871272955,\n",
       "  -0.013992949692140332,\n",
       "  -0.01102111419330559,\n",
       "  -0.00037626876379808486,\n",
       "  0.006300158935215386,\n",
       "  0.008462403152974118,\n",
       "  -0.0037414483605452127,\n",
       "  -0.002617014861564177,\n",
       "  -0.002217216232408554,\n",
       "  -0.008595668897031363,\n",
       "  0.003914694386613187,\n",
       "  -0.0022521985717143074,\n",
       "  0.018750552494335788,\n",
       "  -0.0013176694332237254,\n",
       "  -0.022855151939931373,\n",
       "  -0.011407586061790969,\n",
       "  -0.006263510925448839,\n",
       "  -0.013979623397131387,\n",
       "  -0.008742261867420147,\n",
       "  -0.014792546950451579,\n",
       "  -0.026240112828591983,\n",
       "  -0.014246155816568469,\n",
       "  0.005870375443797688,\n",
       "  0.0016699919140490734,\n",
       "  0.021709062629484178,\n",
       "  0.009974974423731978,\n",
       "  -0.014406075081966199,\n",
       "  0.021549143364086448,\n",
       "  0.027852632708900826,\n",
       "  -0.023694728083269456,\n",
       "  -0.0009420253540561005,\n",
       "  -0.006356797318817948,\n",
       "  -5.944921341908747e-05,\n",
       "  -0.0076161629308089665,\n",
       "  0.0029018712858845334,\n",
       "  0.006876535397021868,\n",
       "  -0.009801727932002706,\n",
       "  0.0274528345454065,\n",
       "  -0.014152868957538063,\n",
       "  -0.024174485879462648,\n",
       "  -0.036728163114346,\n",
       "  -0.0058603804897103305,\n",
       "  0.01551218457606396,\n",
       "  -0.01279355427033476,\n",
       "  -0.0024937436059329944,\n",
       "  -0.005430596998292632,\n",
       "  0.0006709119916058619,\n",
       "  0.018697247314300003,\n",
       "  0.02497408406909649,\n",
       "  -0.012200519706936447,\n",
       "  0.019390231418571897,\n",
       "  -0.004587688582710365,\n",
       "  -0.001805756862289454,\n",
       "  0.005710456178399958,\n",
       "  -0.024001241250378568,\n",
       "  -0.007203037540983099,\n",
       "  0.008988804378682514,\n",
       "  -0.0016566652697941543,\n",
       "  0.009028784195031945,\n",
       "  -0.017964281531033487,\n",
       "  -0.017950956167347133,\n",
       "  0.0070631081837600855,\n",
       "  0.022735212490883075,\n",
       "  0.0026203464353164135,\n",
       "  -0.015232325861617933,\n",
       "  -0.030358037637873918,\n",
       "  -0.00045768606187696233,\n",
       "  -0.0049475073955165556,\n",
       "  -0.0018623950130613664,\n",
       "  0.007576182648798236,\n",
       "  -0.008589006215188186,\n",
       "  -0.021042731115230175,\n",
       "  0.000430616384855757,\n",
       "  -0.011854027654800498,\n",
       "  0.005647154647292924,\n",
       "  -0.00862898603153762,\n",
       "  0.005214039814953638,\n",
       "  -0.016831519446917832,\n",
       "  -0.011880681176140986,\n",
       "  -0.03347646517577485,\n",
       "  -0.020962771482531308,\n",
       "  0.0015800372108475257,\n",
       "  0.007689458950342062,\n",
       "  0.015458877533382988,\n",
       "  -0.015179018818936959,\n",
       "  -0.027199628420978363,\n",
       "  -0.007422926530904979,\n",
       "  -0.04048626957648305,\n",
       "  -0.02004323570649436,\n",
       "  -0.017217992246725808,\n",
       "  -0.0010144888876047714,\n",
       "  0.016938133532279777,\n",
       "  0.016458373873441397,\n",
       "  -0.012160539890587014,\n",
       "  0.03203719178719528,\n",
       "  0.006903188452701057,\n",
       "  0.033316545910377124,\n",
       "  -0.02052299350268755,\n",
       "  -0.01943021123492133,\n",
       "  0.024534306089252732,\n",
       "  -0.010594662508470777,\n",
       "  0.007263007265507248,\n",
       "  0.004221206622399701,\n",
       "  -0.010461395833090938,\n",
       "  -0.021349244282339284,\n",
       "  0.022468679140123397,\n",
       "  0.0023488165388356524,\n",
       "  0.009235346889944878,\n",
       "  0.021042731115230175,\n",
       "  0.004810909379215129,\n",
       "  -0.02822577828237726,\n",
       "  -0.008682292142895998,\n",
       "  0.018590633228938055,\n",
       "  0.001141091716988191,\n",
       "  0.0033066673920838356,\n",
       "  -0.0005917851941373937,\n",
       "  -0.0071230779082842345,\n",
       "  0.0035015692296179683,\n",
       "  0.003654825347511226,\n",
       "  0.0003721041801924649,\n",
       "  -0.002355479919170774,\n",
       "  -0.004674311828575001,\n",
       "  0.0047309497465162645,\n",
       "  -0.004387789500963202,\n",
       "  0.002200557897986074,\n",
       "  -0.03382295815923339,\n",
       "  -0.006120249761642939,\n",
       "  -0.010001627945072464,\n",
       "  -0.016458373873441397,\n",
       "  0.009895014791033111,\n",
       "  -0.014139542662529116,\n",
       "  -0.005670476362050526,\n",
       "  0.03355642480847372,\n",
       "  0.003901367625942943,\n",
       "  -0.0124737157395393,\n",
       "  -0.011887343857984161,\n",
       "  0.020123195339193226,\n",
       "  -0.013873010243092034,\n",
       "  -0.005813737525856425,\n",
       "  0.003534885665632279,\n",
       "  -0.011414248743634146,\n",
       "  0.001613353763277161,\n",
       "  -0.000857068186105894,\n",
       "  -0.0008274997414590181,\n",
       "  -0.01511238548124704,\n",
       "  0.0023571458224622165,\n",
       "  -0.004654321454738987,\n",
       "  -0.006696626223449422,\n",
       "  -0.018297447288160486,\n",
       "  0.002287180911020061,\n",
       "  0.014486034714665065,\n",
       "  -0.02573370057973571,\n",
       "  -0.012666951208120692,\n",
       "  -0.02062960572540431,\n",
       "  0.02017650051922901,\n",
       "  0.0005101596581470859,\n",
       "  -0.005104094854331401,\n",
       "  -0.00988168756470157,\n",
       "  -0.010221516934994342,\n",
       "  0.014779220655442633,\n",
       "  0.02390795439134816,\n",
       "  -0.013513191895947142,\n",
       "  0.0008241681094991194,\n",
       "  0.01356649800730552,\n",
       "  0.014419401376975146,\n",
       "  -0.003648161967176104,\n",
       "  0.008382443520275253,\n",
       "  0.23198977615478417,\n",
       "  0.005717119325904431,\n",
       "  0.017337931695774106,\n",
       "  0.0324369899506896,\n",
       "  -0.006416767043342096,\n",
       "  0.033663038893835665,\n",
       "  0.007542866445614574,\n",
       "  -0.010101577485946044,\n",
       "  -0.008415759723458916,\n",
       "  0.02138922409868872,\n",
       "  0.016245149428007883,\n",
       "  0.01456599434736393,\n",
       "  -0.005157401431351077,\n",
       "  0.005254019631303071,\n",
       "  -0.0020373068260054585,\n",
       "  -0.0019356913818404343,\n",
       "  -0.02314833788070894,\n",
       "  -0.021709062629484178,\n",
       "  -0.035208926367777185,\n",
       "  -0.016711579997869534,\n",
       "  0.0011485879325537096,\n",
       "  -0.022002248570261746,\n",
       "  0.01913702529414376,\n",
       "  -0.010961144468781442,\n",
       "  0.014605974163713363,\n",
       "  -0.01620516774901326,\n",
       "  -0.019989928663813387,\n",
       "  -0.0016983109894350295,\n",
       "  0.02161577577045377,\n",
       "  0.020882811849832445,\n",
       "  -0.013593151528646007,\n",
       "  0.0012893503578377693,\n",
       "  0.012740248158976382,\n",
       "  -0.00397133230455445,\n",
       "  -0.03131755509290549,\n",
       "  -0.005627164739118207,\n",
       "  0.03051795690327165,\n",
       "  -0.0037581064621370437,\n",
       "  0.02557378131433798,\n",
       "  -0.008429086949790457,\n",
       "  0.006250184164778595,\n",
       "  -0.024334407007505568,\n",
       "  0.00644675190560417,\n",
       "  -0.014326115449267334,\n",
       "  0.004461085520496297,\n",
       "  0.026946424159195417,\n",
       "  ...]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_result = embeddings.embed_documents([text])\n",
    "doc_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢è¿™ä¸ªä¾‹å­æ˜¯ä½¿ç”¨HuggingFace Hubçš„embeddingsæ¨¡å‹ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å®ƒçš„ä¸€ä¸ªä»£ç æ ·ä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ä½¿ç”¨å‰éœ€è¦ä¿è¯åº“ä¸­æœ‰sentence_transformers\n",
    "%pip install sentence_transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "äºæ­¤åŒæ—¶å°†ä¼šä¸‹è½½å®‰è£…ç›¸å…³ä¾èµ–æ–‡ä»¶ä»¥åŠä¼—å¤šjsonæ ¼å¼çš„è§£æå¤„ç†æ–‡ä»¶ï¼Œå®‰è£…ä¹‹åå°±å¯ä»¥æ­£å¸¸ä½¿ç”¨HuggingFaceEmbeddingsäº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_hf = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_hf = \"I just test the embeddings method in huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02886896708001464,\n",
       " 0.0044634718471356595,\n",
       " 0.006389421280895015,\n",
       " -0.009913570977266759,\n",
       " -0.0027808003958931854,\n",
       " 0.023057329930755516,\n",
       " 0.018016073486322687,\n",
       " -0.007974105724918213,\n",
       " -0.02111110793326557,\n",
       " -0.030896281195072053,\n",
       " -0.003899202602766403,\n",
       " 0.009474319213141963,\n",
       " -0.002067861337994345,\n",
       " -0.0010989737706240251,\n",
       " -0.008920186017807362,\n",
       " 0.00898100603730552,\n",
       " 0.01804310419217851,\n",
       " 0.010190636643611502,\n",
       " 0.007784889852604894,\n",
       " -0.026733528278888818,\n",
       " 0.019691986562609287,\n",
       " -0.01051500790784905,\n",
       " -0.010170363614219635,\n",
       " -0.010170363614219635,\n",
       " -0.016096882194688564,\n",
       " 0.011109686230644828,\n",
       " 0.03597808556093373,\n",
       " -0.027652577865922144,\n",
       " -0.006450240834731895,\n",
       " -0.009197252615474662,\n",
       " 0.014083082501236506,\n",
       " -0.012393653140699437,\n",
       " -0.005676482222996175,\n",
       " -0.025692840515504287,\n",
       " -0.014461514245863142,\n",
       " -0.002672677106808614,\n",
       " 0.0069536905252642715,\n",
       " -0.025300891555304628,\n",
       " 0.025963147574062522,\n",
       " -0.0059940948794472105,\n",
       " -0.00814980624430362,\n",
       " 0.0155832950581377,\n",
       " -0.010940743387723377,\n",
       " -0.035086064817111115,\n",
       " -0.01600227286154807,\n",
       " 0.01851614340730053,\n",
       " -0.006511060388568775,\n",
       " -0.01908379195556304,\n",
       " -0.008311991410761116,\n",
       " 0.002961569405457198,\n",
       " 0.0017958632305056508,\n",
       " 0.0202596351108718,\n",
       " -0.019475740915762704,\n",
       " 0.003885687249838491,\n",
       " -0.0010710981223795684,\n",
       " 0.017353817467564793,\n",
       " 0.009433773154358227,\n",
       " 0.00968380811484715,\n",
       " -0.00799437875431008,\n",
       " 0.0015576537381673744,\n",
       " -0.011535422641841713,\n",
       " -0.0015263992516909397,\n",
       " -0.003103481542522826,\n",
       " 0.010325791104213175,\n",
       " -0.015096739558765213,\n",
       " -0.014110113207092328,\n",
       " 0.023516855655594734,\n",
       " 0.01372492285467918,\n",
       " 0.03797836897013532,\n",
       " 0.026922745082524693,\n",
       " 0.0035444224929329715,\n",
       " 0.014218236030515622,\n",
       " -0.022219372461289657,\n",
       " -0.005862319257077516,\n",
       " 0.04646606276292695,\n",
       " 0.007460519519689903,\n",
       " 0.009501349918997785,\n",
       " 0.0052304727824074235,\n",
       " 0.00515951671387461,\n",
       " 0.016448283233459378,\n",
       " -0.0019310175746920033,\n",
       " -0.011900339033540439,\n",
       " -0.009285103340828644,\n",
       " 0.0047675691506587825,\n",
       " 0.010961016417115246,\n",
       " 0.00806871412673615,\n",
       " -0.00456821676364953,\n",
       " 0.015029162794125655,\n",
       " -0.000812193129455108,\n",
       " 0.0037606695367633915,\n",
       " 0.01984065730746143,\n",
       " 0.006865840265571568,\n",
       " 0.005848803904149604,\n",
       " -0.0006136851609655513,\n",
       " -0.00512572833155483,\n",
       " 0.01959737909211391,\n",
       " -0.019178401288703534,\n",
       " 0.02278702100955217,\n",
       " 0.0033805479073594873,\n",
       " -0.025219799437737157,\n",
       " -0.026692982220105084,\n",
       " 0.013826288932961072,\n",
       " -0.03714041336331458,\n",
       " -0.017894435309971483,\n",
       " -0.012400410817163393,\n",
       " 0.00270984456019101,\n",
       " 0.0026692982685766363,\n",
       " -0.027666093218850055,\n",
       " -0.006565121800280422,\n",
       " 0.014475029598791055,\n",
       " -0.009210767968402573,\n",
       " 0.019489256268690615,\n",
       " -0.024111533047067958,\n",
       " -0.023314123499030948,\n",
       " -0.016150943606400212,\n",
       " -0.010596100025416519,\n",
       " -0.0046695823762701455,\n",
       " -0.02040830585572394,\n",
       " -0.008136290891375709,\n",
       " 0.0027284281704668886,\n",
       " 0.03189642289967285,\n",
       " 0.02681462039645629,\n",
       " 0.010913712681867554,\n",
       " -0.013393794845300233,\n",
       " 0.035572621247806156,\n",
       " 0.0007868516680922945,\n",
       " -0.008413357489043009,\n",
       " -0.04895290260282359,\n",
       " -0.016177974312256035,\n",
       " -0.018070134898034333,\n",
       " 0.01638070646881982,\n",
       " 0.019191916641631446,\n",
       " 0.017678187800479785,\n",
       " -0.012434199199483171,\n",
       " -0.003780942566155259,\n",
       " 0.04800682044728933,\n",
       " -0.001748559262427321,\n",
       " 0.010663677721378634,\n",
       " -0.016150943606400212,\n",
       " 0.0017620747317705521,\n",
       " 0.017948496721683128,\n",
       " 0.0215976625013155,\n",
       " 0.007102360338793855,\n",
       " 0.005504160541842746,\n",
       " -0.025827994044783406,\n",
       " 0.03197751501724032,\n",
       " -0.003186263544867563,\n",
       " 0.015691417881560994,\n",
       " 0.034112955681011255,\n",
       " -0.024895429104822165,\n",
       " 0.010393368800175289,\n",
       " -0.010244698986645704,\n",
       " -0.019637925150897642,\n",
       " -0.0008624536391940781,\n",
       " -0.006497545035640864,\n",
       " 0.016867261036869752,\n",
       " 0.0005528657235439905,\n",
       " -0.010190636643611502,\n",
       " -0.04438468351086767,\n",
       " -0.014610184059392727,\n",
       " -0.002968327081921154,\n",
       " 0.026490250063541297,\n",
       " -0.015718450450061927,\n",
       " -0.014569638000608991,\n",
       " 0.01455612264768108,\n",
       " 0.026165879730626306,\n",
       " 0.01952980232747435,\n",
       " -0.014353390491117293,\n",
       " -0.003211605064438036,\n",
       " -0.003503876201318598,\n",
       " -0.020367757934295093,\n",
       " 0.015434625244608115,\n",
       " -0.02513870732016969,\n",
       " 0.009954117036050493,\n",
       " 0.012981573787031261,\n",
       " -0.024016925576572576,\n",
       " 0.02293569175440431,\n",
       " -0.015434625244608115,\n",
       " -0.009663535085455281,\n",
       " -0.022408589264925532,\n",
       " -0.01804310419217851,\n",
       " 0.029301460236352925,\n",
       " 0.030517849450445417,\n",
       " 0.001139520062238399,\n",
       " -0.013961443393562745,\n",
       " -0.02736875359179089,\n",
       " -0.0066833820697222044,\n",
       " -0.022516712088348826,\n",
       " 0.017826856682686812,\n",
       " -0.020719160835711018,\n",
       " 0.015353533127040646,\n",
       " 0.02382771063558181,\n",
       " 0.008318749087225071,\n",
       " -0.004422925788351924,\n",
       " -0.6366309990135384,\n",
       " -0.023760132008297144,\n",
       " 0.032572194271358657,\n",
       " -0.020840799012062223,\n",
       " 0.03200454572309614,\n",
       " 0.013143758953488757,\n",
       " 0.0010922159777447499,\n",
       " -0.021867971422518843,\n",
       " -0.0345184162688486,\n",
       " 0.04233033868995443,\n",
       " -0.01884051560286063,\n",
       " -0.0013912450239199066,\n",
       " -0.0193676162296943,\n",
       " -0.003106860380754804,\n",
       " 0.025544169770652148,\n",
       " -0.005872455771773449,\n",
       " 0.030571910862157065,\n",
       " -0.03286953576106293,\n",
       " 0.010102786849580077,\n",
       " 0.02389528740022137,\n",
       " -0.016488829292243115,\n",
       " 0.027585001101282588,\n",
       " -0.010217668280789882,\n",
       " -0.005287913498012326,\n",
       " -0.01890809236750019,\n",
       " 0.00484866173388753,\n",
       " 0.006926659819408448,\n",
       " -0.014880492980596072,\n",
       " 0.013610041423469376,\n",
       " 0.002333101769019084,\n",
       " -0.025936116868206696,\n",
       " 0.01661046746859432,\n",
       " 0.032410010036223715,\n",
       " -0.012535565277765065,\n",
       " 0.03197751501724032,\n",
       " -0.015380563832896469,\n",
       " -0.020840799012062223,\n",
       " 0.01884051560286063,\n",
       " -0.008217383940265733,\n",
       " 0.03970834532077868,\n",
       " -0.035788870619942965,\n",
       " -0.013839804285888985,\n",
       " -0.008197110910873866,\n",
       " 0.011528664965377758,\n",
       " -0.009440530830822183,\n",
       " 0.02681462039645629,\n",
       " 0.0022722822151822033,\n",
       " -0.003649167176616204,\n",
       " -0.009068855831336946,\n",
       " 0.025544169770652148,\n",
       " 0.0028112101728116254,\n",
       " 0.011697607808299208,\n",
       " 0.0019394647866872677,\n",
       " 0.007811920558460717,\n",
       " 0.0180295888392506,\n",
       " -0.009947359359586537,\n",
       " 0.020421821208651852,\n",
       " -0.004277634813054318,\n",
       " 0.026246971848193777,\n",
       " 0.021962580755659336,\n",
       " 0.013339733433588586,\n",
       " 0.010589342348952563,\n",
       " -0.008663393380854485,\n",
       " -0.016475313939315204,\n",
       " -0.025963147574062522,\n",
       " 0.035572621247806156,\n",
       " 0.01095425874065129,\n",
       " 0.018205290289958563,\n",
       " -0.005727165262137121,\n",
       " -0.04727698766389188,\n",
       " 0.008467418900754656,\n",
       " 0.013042393806529419,\n",
       " -0.021205715403760952,\n",
       " -0.0064907868935156305,\n",
       " 0.014623699412320638,\n",
       " 0.03200454572309614,\n",
       " 0.024881913751894254,\n",
       " -0.014610184059392727,\n",
       " -0.01516431632340477,\n",
       " 0.025530654417724237,\n",
       " 0.011454330524274242,\n",
       " -0.0027216704940029326,\n",
       " -0.00803492574441637,\n",
       " 0.022178826402505923,\n",
       " 0.008339023047939494,\n",
       " 0.018070134898034333,\n",
       " -0.022976237813188045,\n",
       " -0.004439819979511814,\n",
       " -0.029625830569267913,\n",
       " -0.006000852555911166,\n",
       " 0.02208421893201054,\n",
       " 0.04184378225925939,\n",
       " -0.02430074985070383,\n",
       " -0.04330345155134451,\n",
       " 0.015623841116921434,\n",
       " -0.010460945564814847,\n",
       " 0.008933701370735275,\n",
       " -0.001609181370450996,\n",
       " 0.016718592154662724,\n",
       " -0.007845708940780497,\n",
       " 0.007014510079101152,\n",
       " -0.0022689033769502254,\n",
       " 0.017759279918047256,\n",
       " 0.004950027812169423,\n",
       " 0.01143405656355982,\n",
       " -0.004095176617204955,\n",
       " -0.006565121800280422,\n",
       " 0.0051324860080187865,\n",
       " -0.003689713468230578,\n",
       " 0.0006715481149341314,\n",
       " -0.03381561419130697,\n",
       " -0.019651440503825553,\n",
       " 0.0052946711744762814,\n",
       " 0.015488687587642318,\n",
       " -0.010933985711259421,\n",
       " -0.04922320966138182,\n",
       " 0.0037302597598449514,\n",
       " 0.0053284595567960604,\n",
       " 0.01321133664945087,\n",
       " -0.01031903342774922,\n",
       " -0.012163890278279828,\n",
       " -0.0022689033769502254,\n",
       " 0.01546165595046394,\n",
       " -0.005646072678908374,\n",
       " 0.002725049332234911,\n",
       " 0.001511194479647039,\n",
       " -0.01482643063756187,\n",
       " -0.021881486775446754,\n",
       " -0.019962295483812634,\n",
       " 0.02153008573667594,\n",
       " 0.019421677641405944,\n",
       " -0.015623841116921434,\n",
       " 0.009913570977266759,\n",
       " -0.013711407501751267,\n",
       " 0.019489256268690615,\n",
       " 0.028463502766887066,\n",
       " 0.02513870732016969,\n",
       " -0.009663535085455281,\n",
       " 0.012603142042404623,\n",
       " -0.008257929999049469,\n",
       " 0.0010001420538467544,\n",
       " 0.01716460066392892,\n",
       " 0.0034396778092497396,\n",
       " 0.0031609220252970895,\n",
       " -0.02967989198097956,\n",
       " -0.028139132433972078,\n",
       " -0.015218378666438973,\n",
       " 0.02048939797329141,\n",
       " 0.005862319257077516,\n",
       " 0.009339164752540291,\n",
       " -0.014231751383443533,\n",
       " -0.004977058518025246,\n",
       " -0.013170790590667135,\n",
       " -0.00022828412592801136,\n",
       " -0.010663677721378634,\n",
       " -0.014177689971731886,\n",
       " -0.009487834566069874,\n",
       " -0.025530654417724237,\n",
       " 0.0027402541042788114,\n",
       " -0.027166021435227103,\n",
       " 0.006835430721483767,\n",
       " 0.043492666492335276,\n",
       " 0.01875942162264805,\n",
       " -0.0048114945133357736,\n",
       " -0.012724781150078383,\n",
       " 0.001553430190377402,\n",
       " -0.01828638240752603,\n",
       " 0.031436900900123854,\n",
       " -0.004007326357512252,\n",
       " -0.02619291043648213,\n",
       " 0.004159374543612536,\n",
       " -0.04235736939581025,\n",
       " 0.01178545853365319,\n",
       " 0.01977308054282187,\n",
       " -0.002116854725188664,\n",
       " 0.021935548187158403,\n",
       " -0.02753093782692583,\n",
       " -0.0025831371951692828,\n",
       " -0.01008251382018821,\n",
       " -0.026057756907203015,\n",
       " -0.004517533724508583,\n",
       " 0.0040478724162959865,\n",
       " 0.0058690769335414715,\n",
       " 0.016799684272230192,\n",
       " 0.032653286388926124,\n",
       " 0.008737727821957999,\n",
       " 0.004125586161292757,\n",
       " 0.00819035323440991,\n",
       " -0.010487976270670671,\n",
       " 0.021084077227409747,\n",
       " 0.006889492598856691,\n",
       " -0.026368611887190092,\n",
       " -0.04135722582856435,\n",
       " 0.006544848770888555,\n",
       " -0.006078566300907935,\n",
       " 0.009149948880226971,\n",
       " 0.00794707501906239,\n",
       " 0.01171112316122712,\n",
       " 0.004774326827122738,\n",
       " 0.018178257721457626,\n",
       " 0.0056426938406763955,\n",
       " 0.017218662075640566,\n",
       " 0.0036930923064625557,\n",
       " -0.007967348048454257,\n",
       " 0.0029767744103317375,\n",
       " 0.001376884845018681,\n",
       " 0.002973395339269121,\n",
       " -0.013434340904083969,\n",
       " -0.003350138130441047,\n",
       " 0.010609615378344431,\n",
       " 0.01952980232747435,\n",
       " 0.005581874286839515,\n",
       " -0.045168581431266994,\n",
       " -0.013589768394077507,\n",
       " -0.0015424488497081544,\n",
       " -0.004328317852195265,\n",
       " -0.011021836436613404,\n",
       " -7.813609795677769e-06,\n",
       " -0.007507823720598872,\n",
       " 0.0021354385682951812,\n",
       " -0.013684376795895445,\n",
       " 0.010068998467260297,\n",
       " 0.008197110910873866,\n",
       " 0.020854314364990138,\n",
       " 0.0009004658021344685,\n",
       " -0.00526426163038848,\n",
       " 0.012373380111307569,\n",
       " -0.008920186017807362,\n",
       " 0.015367048479968557,\n",
       " -0.008095744832591973,\n",
       " -0.002578068937821316,\n",
       " 0.049169148249670176,\n",
       " 0.010427157182495069,\n",
       " 0.00421343642098546,\n",
       " 0.014623699412320638,\n",
       " 0.006115733987120971,\n",
       " 0.020854314364990138,\n",
       " 0.011528664965377758,\n",
       " 0.0025172496168150743,\n",
       " 0.0053723849194730515,\n",
       " -0.012555838307156932,\n",
       " 0.0020932028575648184,\n",
       " 0.006355632898575236,\n",
       " -0.025287376202376716,\n",
       " 0.02350334030266682,\n",
       " 0.020921891129629694,\n",
       " 0.02792288678712549,\n",
       " -0.0026963289744324596,\n",
       " -0.02205718822615472,\n",
       " 0.0052743981450844146,\n",
       " -0.014461514245863142,\n",
       " -0.0026895712979685036,\n",
       " 0.005537948924162525,\n",
       " 0.013704649825287312,\n",
       " 0.021084077227409747,\n",
       " -0.01606985148883274,\n",
       " -0.014515575657574789,\n",
       " 0.02816616500247301,\n",
       " 0.021462508972036384,\n",
       " 0.05149380385443187,\n",
       " 0.009609473673743634,\n",
       " 0.008278203028441336,\n",
       " 0.012163890278279828,\n",
       " 0.010143332908363813,\n",
       " 0.03224782580108878,\n",
       " -0.018962153779211836,\n",
       " -0.024800821634326786,\n",
       " -0.015610325763993523,\n",
       " -0.02335466955781468,\n",
       " -0.018408020583877235,\n",
       " -0.016583436762738497,\n",
       " -0.001876955930149718,\n",
       " 0.007149664539702824,\n",
       " -0.013711407501751267,\n",
       " 0.03235594862451207,\n",
       " 0.014718307814138576,\n",
       " 0.028193195708328834,\n",
       " 0.012224710297777986,\n",
       " 0.01961089444504182,\n",
       " 0.027895856081269665,\n",
       " -0.011035351789541315,\n",
       " -0.029869108784615437,\n",
       " 0.05025038393448355,\n",
       " 0.0008147272581290915,\n",
       " 0.0026490250063541296,\n",
       " -0.024179111674352625,\n",
       " -0.027409299650574624,\n",
       " -0.0005786294814781415,\n",
       " -0.02198961146151516,\n",
       " 0.016191489665183946,\n",
       " 0.014975100451091452,\n",
       " 0.016691561448806902,\n",
       " 0.028490535335388003,\n",
       " -0.0024851504207806453,\n",
       " -0.0034515039758923013,\n",
       " 0.03635651544291525,\n",
       " 0.014353390491117293,\n",
       " 0.006389421280895015,\n",
       " 0.019205431994559357,\n",
       " -0.001809378699848882,\n",
       " -0.0023685798032854906,\n",
       " -0.021651725775672256,\n",
       " -0.010217668280789882,\n",
       " -0.008663393380854485,\n",
       " 0.045898414214664444,\n",
       " -0.01067043539784259,\n",
       " 0.0056122838309273166,\n",
       " -0.014083082501236506,\n",
       " -0.006487408055283653,\n",
       " -0.004493881856884738,\n",
       " 0.005608904992695339,\n",
       " 0.01763764174169605,\n",
       " -0.018543175975801466,\n",
       " 0.0009291861017292599,\n",
       " -0.009609473673743634,\n",
       " 0.04343860508062363,\n",
       " -0.01750248634977182,\n",
       " -0.002000284107693509,\n",
       " 0.016286097135679328,\n",
       " 0.01344785625701188,\n",
       " -0.02185445606959093,\n",
       " -0.027111960023515458,\n",
       " 0.0026017210382758,\n",
       " -0.0032301886747139147,\n",
       " 0.028923028491726285,\n",
       " 0.028003978904692958,\n",
       " -0.0055784954486075376,\n",
       " -0.0003112773347660765,\n",
       " -0.011684092455371296,\n",
       " -0.007825435911388628,\n",
       " -0.018380989878021413,\n",
       " 0.007838951264316541,\n",
       " -0.005250745811799291,\n",
       " 0.0028635826310685606,\n",
       " -0.03781618473500038,\n",
       " -0.036653856932619536,\n",
       " 0.023692555243657584,\n",
       " -0.010967774093579201,\n",
       " 0.01661046746859432,\n",
       " 0.0018786453492657068,\n",
       " 0.004392515778602845,\n",
       " -0.010623130731272343,\n",
       " 0.013326218080660675,\n",
       " -0.0022317359235678297,\n",
       " -0.005923138810914396,\n",
       " -0.007325365059088231,\n",
       " -0.006625941354117302,\n",
       " 0.007210484093539704,\n",
       " 0.030031294882395487,\n",
       " -0.0020847557619848734,\n",
       " 0.008987763713769477,\n",
       " 0.01773224921219143,\n",
       " 0.013961443393562745,\n",
       " -0.032707351525928,\n",
       " 0.00794707501906239,\n",
       " 0.016961870370010245,\n",
       " -0.010481218594206714,\n",
       " 0.013069424512385241,\n",
       " -0.010636646084200254,\n",
       " 0.036383546148771075,\n",
       " 0.004017462872208185,\n",
       " 0.016326643194463062,\n",
       " 0.019881203366245163,\n",
       " -0.009244556350722353,\n",
       " 0.008764758527813823,\n",
       " 0.017178116016856832,\n",
       " -0.0015990447393397426,\n",
       " -0.003845140958224117,\n",
       " -0.018543175975801466,\n",
       " -0.011603000337803827,\n",
       " -0.01356949536468564,\n",
       " 0.008170080205018042,\n",
       " -0.0009663534969039962,\n",
       " -0.01898918448506766,\n",
       " 0.007284819000304496,\n",
       " 0.008088987156128017,\n",
       " -0.030653002979724533,\n",
       " -0.0145290910105027,\n",
       " 0.01621852037103977,\n",
       " 0.021097592580337658,\n",
       " -0.024706212301186293,\n",
       " 0.002817967849275581,\n",
       " -0.0073388804120161424,\n",
       " -0.006173174237064595,\n",
       " -0.01811068095681807,\n",
       " -0.013258640384698562,\n",
       " -0.007872740577958875,\n",
       " -0.017934981368755216,\n",
       " -0.0067610958147189745,\n",
       " -0.015623841116921434,\n",
       " -0.014137143912948152,\n",
       " 0.005673103384764197,\n",
       " -0.010346064133605042,\n",
       " 0.005723786423905143,\n",
       " -0.0008666771869840505,\n",
       " -0.007386184612925111,\n",
       " -0.04416843786402108,\n",
       " 0.00806871412673615,\n",
       " 0.009102645144979282,\n",
       " 0.024152080968496803,\n",
       " 0.01020415292786197,\n",
       " 0.009954117036050493,\n",
       " -0.010771800544801926,\n",
       " -0.015488687587642318,\n",
       " -0.0032065365742594302,\n",
       " -0.0101298175554359,\n",
       " 0.009954117036050493,\n",
       " -0.005075045292413884,\n",
       " -0.01031903342774922,\n",
       " 0.012603142042404623,\n",
       " -0.018921607720428103,\n",
       " 0.0068590825891076115,\n",
       " -0.013001847747745683,\n",
       " 0.0010744769606115465,\n",
       " 0.01600227286154807,\n",
       " 0.008311991410761116,\n",
       " 0.007676766563520323,\n",
       " -0.038410863989118714,\n",
       " 0.016421252527603555,\n",
       " 0.02581447869185549,\n",
       " 0.014569638000608991,\n",
       " 0.009886540271410935,\n",
       " -0.01515080097047686,\n",
       " -0.010981290377829668,\n",
       " 0.02281405171540799,\n",
       " -0.022408589264925532,\n",
       " 0.00032204743983816584,\n",
       " -0.0037403962745408852,\n",
       " 0.0018144469571968486,\n",
       " 0.0125761113365488,\n",
       " -0.00642658896710805,\n",
       " 0.020178542993304332,\n",
       " -0.017664672447551873,\n",
       " 0.0018617510416904979,\n",
       " 0.0008962421961368364,\n",
       " 4.919802804552858e-06,\n",
       " -0.008055198773808237,\n",
       " -0.00022638351487060885,\n",
       " 0.01135296444599235,\n",
       " -0.019448708347261767,\n",
       " -0.01977308054282187,\n",
       " 0.033842644897162794,\n",
       " -0.02731469218007924,\n",
       " 0.004781084503586695,\n",
       " -0.02705789861180381,\n",
       " 0.004419546950119946,\n",
       " 0.035653713365373624,\n",
       " 0.011001563407221535,\n",
       " -0.0034802241008641136,\n",
       " 0.03005832558825131,\n",
       " -0.0019158126862327833,\n",
       " -0.0037708060514593253,\n",
       " -0.03632948473705943,\n",
       " 0.014894008333523983,\n",
       " -0.017705218506335607,\n",
       " 0.03668088763847536,\n",
       " 0.0007898081515452752,\n",
       " 0.007778132176140938,\n",
       " -0.020313696522583448,\n",
       " -0.03251813285964701,\n",
       " -0.006044777918588156,\n",
       " -0.007061814280010121,\n",
       " 0.005169653228570543,\n",
       " 0.0022722822151822033,\n",
       " -0.005696755252388042,\n",
       " -0.015515718293498142,\n",
       " 0.0008523170662904846,\n",
       " -0.0030798294420683416,\n",
       " -0.0016801373225684905,\n",
       " -0.02311139134246716,\n",
       " -0.035572621247806156,\n",
       " 0.035788870619942965,\n",
       " 0.000670703405376137,\n",
       " 0.021219230756688863,\n",
       " 0.010575826996024652,\n",
       " 0.022030157520298896,\n",
       " -0.029544738451700445,\n",
       " -0.01877293697557596,\n",
       " 0.0017147706472769029,\n",
       " -0.0049905738709531584,\n",
       " 0.016326643194463062,\n",
       " 0.03797836897013532,\n",
       " 0.013468130217726302,\n",
       " 0.020448851914507675,\n",
       " 0.055521401378690875,\n",
       " -0.024152080968496803,\n",
       " 0.039275850301795284,\n",
       " -0.0026659194303446584,\n",
       " -0.0006204428956371669,\n",
       " 0.007318607382624275,\n",
       " -0.004095176617204955,\n",
       " -0.012792357914717941,\n",
       " -0.00013821643088599762,\n",
       " 0.0036525460148481817,\n",
       " 0.001841477895883311,\n",
       " -0.03295062787863041,\n",
       " 0.012258498680097764,\n",
       " 0.003155853767949123,\n",
       " 0.0031169968954507378,\n",
       " 0.005615662669159294,\n",
       " -0.016096882194688564,\n",
       " -0.008257929999049469,\n",
       " -0.020381273287223004,\n",
       " -0.015299470784006444,\n",
       " -0.014447998892935231,\n",
       " 0.02086782971791805,\n",
       " -0.011379995151848173,\n",
       " 0.01938113158262221,\n",
       " -0.029463646334132974,\n",
       " 0.0014596668473634176,\n",
       " 0.004743917283034937,\n",
       " 0.0022368044137464353,\n",
       " 0.017367332820492704,\n",
       " 0.02730117682715133,\n",
       " 0.02959879986341209,\n",
       " -0.028058040316404607,\n",
       " -0.00565283035537233,\n",
       " -0.0014148970079590714,\n",
       " -0.02690922786695167,\n",
       " -0.01130566071074466,\n",
       " -0.012359863827057102,\n",
       " -0.010481218594206714,\n",
       " -0.02603072620134719,\n",
       " 0.018637783446296845,\n",
       " -0.012562595983620887,\n",
       " 0.009109402821443237,\n",
       " 0.0015770821744165667,\n",
       " 0.017461940290988087,\n",
       " -0.025273860849448805,\n",
       " 0.018610752740441022,\n",
       " 0.008122775538447797,\n",
       " -0.024476451301411795,\n",
       " -0.00028445766078060255,\n",
       " -0.02388177204729346,\n",
       " -0.016096882194688564,\n",
       " -0.05235879016710844,\n",
       " -0.017826856682686812,\n",
       " -0.004598626307737331,\n",
       " -0.00894045904719923,\n",
       " -0.0035140127160145315,\n",
       " -0.024881913751894254,\n",
       " 0.008406599812579053,\n",
       " -0.0036694402060080712,\n",
       " -0.008643120351462618,\n",
       " -0.033166873525476995,\n",
       " 0.0036525460148481817,\n",
       " 0.03970834532077868,\n",
       " 0.007284819000304496,\n",
       " 0.0210300158156981,\n",
       " 0.01463721476524855,\n",
       " -0.006281297991810444,\n",
       " -0.02461160483069091,\n",
       " 0.01923246270041518,\n",
       " -0.0008012117887858603,\n",
       " -0.010771800544801926,\n",
       " 0.0047337807683390035,\n",
       " 0.029220368118785454,\n",
       " -0.019354100876766388,\n",
       " -0.032896566466918756,\n",
       " 0.011123201583572741,\n",
       " -0.005946790678538242,\n",
       " -0.004311423195374097,\n",
       " -0.023692555243657584,\n",
       " 0.020151512287448506,\n",
       " -0.008359296077331362,\n",
       " -0.004422925788351924,\n",
       " -0.012488260611194818,\n",
       " 0.0005790518944647985,\n",
       " -0.031436900900123854,\n",
       " 0.004095176617204955,\n",
       " -0.02278702100955217,\n",
       " -0.011102928554180873,\n",
       " 0.001799242185152948,\n",
       " -0.0029666376628051648,\n",
       " 0.0062002054085816966,\n",
       " 0.02722008284693875,\n",
       " -0.0016801373225684905,\n",
       " 0.02280053636248008,\n",
       " -0.005831909712989715,\n",
       " 0.009582442967887812,\n",
       " -0.003747153951004841,\n",
       " 0.0034498145567763124,\n",
       " -0.010305518074821307,\n",
       " 0.0155832950581377,\n",
       " 0.019327070170910562,\n",
       " 0.03500497269954364,\n",
       " -0.011697607808299208,\n",
       " 0.00016155166339282948,\n",
       " 0.021895002128374665,\n",
       " -0.008994521390233432,\n",
       " 0.0069536905252642715,\n",
       " -0.011447572847810287,\n",
       " -0.005744059453297011,\n",
       " 0.029625830569267913,\n",
       " -0.039275850301795284,\n",
       " -0.021205715403760952,\n",
       " -0.0036593036913121373,\n",
       " 0.024260203791920096,\n",
       " 0.014623699412320638,\n",
       " -0.008636362674998663,\n",
       " -0.016488829292243115,\n",
       " -0.022922176401476396,\n",
       " -0.004618899337129199,\n",
       " 0.0014115181697270936,\n",
       " 0.03822164532283773,\n",
       " -0.010521765584313005,\n",
       " 0.008899912988415495,\n",
       " -0.003493739686622664,\n",
       " -0.011535422641841713,\n",
       " 0.006838809559715745,\n",
       " -0.011548937994769625,\n",
       " 0.0025932739426958555,\n",
       " 0.012285529385953588,\n",
       " -0.012738296503006296,\n",
       " -0.017786310623903078,\n",
       " -0.002476703325200701,\n",
       " -0.006622562515885324,\n",
       " 0.04138425653442017,\n",
       " -0.016015788214475985,\n",
       " -0.0016936527919117217,\n",
       " 0.005054772263022016,\n",
       " 0.016988901075866068,\n",
       " -0.0013836425214826368,\n",
       " -0.002929470209422769,\n",
       " -0.0022384938328624242,\n",
       " -0.009278345664364689,\n",
       " -0.016583436762738497,\n",
       " -0.0193676162296943,\n",
       " -0.01835395917216559,\n",
       " 0.000876813759887644,\n",
       " 0.0016041129966877096,\n",
       " 0.006629320192349281,\n",
       " -0.010433914858959024,\n",
       " -0.01709702389928936,\n",
       " 0.005193305561855667,\n",
       " 0.01779982597683099,\n",
       " 0.01684023033101393,\n",
       " -0.0016852056963317767,\n",
       " -0.009744628134345307,\n",
       " -0.011623273367195694,\n",
       " 0.007778132176140938,\n",
       " -0.029977231608038727,\n",
       " -0.0003412646986978597,\n",
       " 0.009764901163737174,\n",
       " -0.006419831290644094,\n",
       " 0.00020188679216961967,\n",
       " 0.0183674745250935,\n",
       " -0.007237514799395528,\n",
       " -0.016421252527603555,\n",
       " -0.013866834991744808,\n",
       " -0.006375905927967104,\n",
       " -0.0019597378160791353,\n",
       " -0.031247682233842868,\n",
       " 0.0003847675028690441,\n",
       " -0.0106839507507705,\n",
       " 0.018083650250962247,\n",
       " -0.0011276940120111569,\n",
       " -0.01527244007815062,\n",
       " -0.00676785349118293,\n",
       " 0.004220194097449416,\n",
       " -0.01163003104365965,\n",
       " 0.03292359717277458,\n",
       " 0.0018059998616169039,\n",
       " -0.011994947435358377,\n",
       " 0.004659445861574211,\n",
       " 0.0042539829454304725,\n",
       " 0.026949775788380516,\n",
       " 0.015123770264621037,\n",
       " -0.026003695495491367,\n",
       " -0.009312134046684467,\n",
       " -0.03322093493718864,\n",
       " 0.003360274645136981,\n",
       " -0.024152080968496803,\n",
       " 0.010075756143724253,\n",
       " 0.01734030211463688,\n",
       " 0.023597947773162202,\n",
       " 0.024341295909487567,\n",
       " -0.026787589690600466,\n",
       " -0.01961089444504182,\n",
       " -0.006146143531208772,\n",
       " -0.008278203028441336,\n",
       " -0.006710412775578028,\n",
       " -0.021705787187383904,\n",
       " -0.0013067734860438614,\n",
       " 0.0018347201030040356,\n",
       " 0.0033264862628172016,\n",
       " -0.01582657327348522,\n",
       " 0.022449135323709266,\n",
       " 0.006473892702355741,\n",
       " -0.00018953284212437575,\n",
       " -0.0022165311515239287,\n",
       " -0.002208084055943984,\n",
       " -0.015921180743980603,\n",
       " -0.015218378666438973,\n",
       " -0.025746901927215935,\n",
       " -0.0028703403075325167,\n",
       " -0.03678901046189865,\n",
       " 0.013366764139444409,\n",
       " 0.027760700689345438,\n",
       " 0.004321560175731309,\n",
       " 0.011880066004148572,\n",
       " 0.051061308835448474,\n",
       " -0.0005718718050141857,\n",
       " -0.004757432635962849,\n",
       " -0.02715250608229919,\n",
       " 0.004558080248953596,\n",
       " 0.032410010036223715,\n",
       " 0.002426020286059754,\n",
       " 0.020948921835485516,\n",
       " -0.007940317342598433,\n",
       " -0.02057049009085888,\n",
       " 0.012805873267645854,\n",
       " -0.01654289070395476,\n",
       " 0.002365200965053513,\n",
       " -0.03357233783860456,\n",
       " 0.01071773913309028,\n",
       " 0.013441098580547924,\n",
       " 0.010041967761404475,\n",
       " -0.03668088763847536,\n",
       " 0.024016925576572576,\n",
       " -0.011481361230130067,\n",
       " -0.011156990897215075,\n",
       " 0.0275985164542105,\n",
       " -0.013589768394077507,\n",
       " -0.011724638514155032,\n",
       " 0.03381561419130697,\n",
       " 0.010055483114332386,\n",
       " 0.007325365059088231,\n",
       " -0.005409552605686086,\n",
       " 0.0330587507020537,\n",
       " 0.007142906863238868,\n",
       " 0.0005000710269233772,\n",
       " 0.032653286388926124,\n",
       " -0.021949065402731425,\n",
       " -0.02792288678712549,\n",
       " -0.019097307308490952,\n",
       " -0.0021337491491791923,\n",
       " -0.03424810921029037,\n",
       " -0.013231609678842737,\n",
       " -0.009704081144239016,\n",
       " -0.0028416199497300655,\n",
       " 0.0023516853792949623,\n",
       " -0.0024125049331318424,\n",
       " -0.0007420817704802885,\n",
       " -0.028003978904692958,\n",
       " 0.004456714170671703,\n",
       " -0.016745622860518547,\n",
       " 0.022759990303696347,\n",
       " -0.0014351701537662583,\n",
       " -0.0120219781412142,\n",
       " 0.017124054605145184,\n",
       " -0.008332265371475538,\n",
       " 0.013880350344672719,\n",
       " 0.010785315897729839,\n",
       " -0.011494876583057978,\n",
       " -0.026990321847164253,\n",
       " -0.019016215190923485,\n",
       " 0.035707774777085276,\n",
       " 0.02182742536373511,\n",
       " 0.01215713260181587,\n",
       " 0.2147332088184969,\n",
       " -0.03968131461492286,\n",
       " 0.019637925150897642,\n",
       " 0.0018516144105792446,\n",
       " -0.0027284281704668886,\n",
       " -0.02428723449777592,\n",
       " -0.020056902954308016,\n",
       " 0.011582726377089403,\n",
       " 0.002005352597872115,\n",
       " 0.009987905418370273,\n",
       " 0.024503482007267617,\n",
       " -0.0070482989270822085,\n",
       " -0.006909765628248558,\n",
       " -0.0023297229307871056,\n",
       " -0.004625657013593154,\n",
       " -0.014502060304646878,\n",
       " -0.035572621247806156,\n",
       " -0.011961159053038597,\n",
       " -0.019340585523838473,\n",
       " -0.008899912988415495,\n",
       " 0.008102502509055929,\n",
       " -0.007088844985865943,\n",
       " -0.008845851576703848,\n",
       " -0.016326643194463062,\n",
       " 0.018637783446296845,\n",
       " -0.01494806974523563,\n",
       " -0.012103071190104226,\n",
       " -0.015840088626413132,\n",
       " 0.014407452834151496,\n",
       " 0.025679325162576375,\n",
       " -0.00992708633019467,\n",
       " 0.02008393552280895,\n",
       " 0.02255725814713256,\n",
       " -0.009109402821443237,\n",
       " -0.012272014033025675,\n",
       " -0.014461514245863142,\n",
       " 0.019691986562609287,\n",
       " 0.026936260435452605,\n",
       " 0.020137996934520595,\n",
       " -0.0038620351493840067,\n",
       " 0.03140986646897781,\n",
       " -0.035302314189247924,\n",
       " 0.010893439652475688,\n",
       " 0.0013642140852334443,\n",
       " -0.01811068095681807,\n",
       " 0.020746191541566844,\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings_hf.embed_query(text_hf)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.02886896708001464,\n",
       "  0.0044634718471356595,\n",
       "  0.006389421280895015,\n",
       "  -0.009913570977266759,\n",
       "  -0.0027808003958931854,\n",
       "  0.023057329930755516,\n",
       "  0.018016073486322687,\n",
       "  -0.007974105724918213,\n",
       "  -0.02111110793326557,\n",
       "  -0.030896281195072053,\n",
       "  -0.003899202602766403,\n",
       "  0.009474319213141963,\n",
       "  -0.002067861337994345,\n",
       "  -0.0010989737706240251,\n",
       "  -0.008920186017807362,\n",
       "  0.00898100603730552,\n",
       "  0.01804310419217851,\n",
       "  0.010190636643611502,\n",
       "  0.007784889852604894,\n",
       "  -0.026733528278888818,\n",
       "  0.019691986562609287,\n",
       "  -0.01051500790784905,\n",
       "  -0.010170363614219635,\n",
       "  -0.010170363614219635,\n",
       "  -0.016096882194688564,\n",
       "  0.011109686230644828,\n",
       "  0.03597808556093373,\n",
       "  -0.027652577865922144,\n",
       "  -0.006450240834731895,\n",
       "  -0.009197252615474662,\n",
       "  0.014083082501236506,\n",
       "  -0.012393653140699437,\n",
       "  -0.005676482222996175,\n",
       "  -0.025692840515504287,\n",
       "  -0.014461514245863142,\n",
       "  -0.002672677106808614,\n",
       "  0.0069536905252642715,\n",
       "  -0.025300891555304628,\n",
       "  0.025963147574062522,\n",
       "  -0.0059940948794472105,\n",
       "  -0.00814980624430362,\n",
       "  0.0155832950581377,\n",
       "  -0.010940743387723377,\n",
       "  -0.035086064817111115,\n",
       "  -0.01600227286154807,\n",
       "  0.01851614340730053,\n",
       "  -0.006511060388568775,\n",
       "  -0.01908379195556304,\n",
       "  -0.008311991410761116,\n",
       "  0.002961569405457198,\n",
       "  0.0017958632305056508,\n",
       "  0.0202596351108718,\n",
       "  -0.019475740915762704,\n",
       "  0.003885687249838491,\n",
       "  -0.0010710981223795684,\n",
       "  0.017353817467564793,\n",
       "  0.009433773154358227,\n",
       "  0.00968380811484715,\n",
       "  -0.00799437875431008,\n",
       "  0.0015576537381673744,\n",
       "  -0.011535422641841713,\n",
       "  -0.0015263992516909397,\n",
       "  -0.003103481542522826,\n",
       "  0.010325791104213175,\n",
       "  -0.015096739558765213,\n",
       "  -0.014110113207092328,\n",
       "  0.023516855655594734,\n",
       "  0.01372492285467918,\n",
       "  0.03797836897013532,\n",
       "  0.026922745082524693,\n",
       "  0.0035444224929329715,\n",
       "  0.014218236030515622,\n",
       "  -0.022219372461289657,\n",
       "  -0.005862319257077516,\n",
       "  0.04646606276292695,\n",
       "  0.007460519519689903,\n",
       "  0.009501349918997785,\n",
       "  0.0052304727824074235,\n",
       "  0.00515951671387461,\n",
       "  0.016448283233459378,\n",
       "  -0.0019310175746920033,\n",
       "  -0.011900339033540439,\n",
       "  -0.009285103340828644,\n",
       "  0.0047675691506587825,\n",
       "  0.010961016417115246,\n",
       "  0.00806871412673615,\n",
       "  -0.00456821676364953,\n",
       "  0.015029162794125655,\n",
       "  -0.000812193129455108,\n",
       "  0.0037606695367633915,\n",
       "  0.01984065730746143,\n",
       "  0.006865840265571568,\n",
       "  0.005848803904149604,\n",
       "  -0.0006136851609655513,\n",
       "  -0.00512572833155483,\n",
       "  0.01959737909211391,\n",
       "  -0.019178401288703534,\n",
       "  0.02278702100955217,\n",
       "  0.0033805479073594873,\n",
       "  -0.025219799437737157,\n",
       "  -0.026692982220105084,\n",
       "  0.013826288932961072,\n",
       "  -0.03714041336331458,\n",
       "  -0.017894435309971483,\n",
       "  -0.012400410817163393,\n",
       "  0.00270984456019101,\n",
       "  0.0026692982685766363,\n",
       "  -0.027666093218850055,\n",
       "  -0.006565121800280422,\n",
       "  0.014475029598791055,\n",
       "  -0.009210767968402573,\n",
       "  0.019489256268690615,\n",
       "  -0.024111533047067958,\n",
       "  -0.023314123499030948,\n",
       "  -0.016150943606400212,\n",
       "  -0.010596100025416519,\n",
       "  -0.0046695823762701455,\n",
       "  -0.02040830585572394,\n",
       "  -0.008136290891375709,\n",
       "  0.0027284281704668886,\n",
       "  0.03189642289967285,\n",
       "  0.02681462039645629,\n",
       "  0.010913712681867554,\n",
       "  -0.013393794845300233,\n",
       "  0.035572621247806156,\n",
       "  0.0007868516680922945,\n",
       "  -0.008413357489043009,\n",
       "  -0.04895290260282359,\n",
       "  -0.016177974312256035,\n",
       "  -0.018070134898034333,\n",
       "  0.01638070646881982,\n",
       "  0.019191916641631446,\n",
       "  0.017678187800479785,\n",
       "  -0.012434199199483171,\n",
       "  -0.003780942566155259,\n",
       "  0.04800682044728933,\n",
       "  -0.001748559262427321,\n",
       "  0.010663677721378634,\n",
       "  -0.016150943606400212,\n",
       "  0.0017620747317705521,\n",
       "  0.017948496721683128,\n",
       "  0.0215976625013155,\n",
       "  0.007102360338793855,\n",
       "  0.005504160541842746,\n",
       "  -0.025827994044783406,\n",
       "  0.03197751501724032,\n",
       "  -0.003186263544867563,\n",
       "  0.015691417881560994,\n",
       "  0.034112955681011255,\n",
       "  -0.024895429104822165,\n",
       "  0.010393368800175289,\n",
       "  -0.010244698986645704,\n",
       "  -0.019637925150897642,\n",
       "  -0.0008624536391940781,\n",
       "  -0.006497545035640864,\n",
       "  0.016867261036869752,\n",
       "  0.0005528657235439905,\n",
       "  -0.010190636643611502,\n",
       "  -0.04438468351086767,\n",
       "  -0.014610184059392727,\n",
       "  -0.002968327081921154,\n",
       "  0.026490250063541297,\n",
       "  -0.015718450450061927,\n",
       "  -0.014569638000608991,\n",
       "  0.01455612264768108,\n",
       "  0.026165879730626306,\n",
       "  0.01952980232747435,\n",
       "  -0.014353390491117293,\n",
       "  -0.003211605064438036,\n",
       "  -0.003503876201318598,\n",
       "  -0.020367757934295093,\n",
       "  0.015434625244608115,\n",
       "  -0.02513870732016969,\n",
       "  0.009954117036050493,\n",
       "  0.012981573787031261,\n",
       "  -0.024016925576572576,\n",
       "  0.02293569175440431,\n",
       "  -0.015434625244608115,\n",
       "  -0.009663535085455281,\n",
       "  -0.022408589264925532,\n",
       "  -0.01804310419217851,\n",
       "  0.029301460236352925,\n",
       "  0.030517849450445417,\n",
       "  0.001139520062238399,\n",
       "  -0.013961443393562745,\n",
       "  -0.02736875359179089,\n",
       "  -0.0066833820697222044,\n",
       "  -0.022516712088348826,\n",
       "  0.017826856682686812,\n",
       "  -0.020719160835711018,\n",
       "  0.015353533127040646,\n",
       "  0.02382771063558181,\n",
       "  0.008318749087225071,\n",
       "  -0.004422925788351924,\n",
       "  -0.6366309990135384,\n",
       "  -0.023760132008297144,\n",
       "  0.032572194271358657,\n",
       "  -0.020840799012062223,\n",
       "  0.03200454572309614,\n",
       "  0.013143758953488757,\n",
       "  0.0010922159777447499,\n",
       "  -0.021867971422518843,\n",
       "  -0.0345184162688486,\n",
       "  0.04233033868995443,\n",
       "  -0.01884051560286063,\n",
       "  -0.0013912450239199066,\n",
       "  -0.0193676162296943,\n",
       "  -0.003106860380754804,\n",
       "  0.025544169770652148,\n",
       "  -0.005872455771773449,\n",
       "  0.030571910862157065,\n",
       "  -0.03286953576106293,\n",
       "  0.010102786849580077,\n",
       "  0.02389528740022137,\n",
       "  -0.016488829292243115,\n",
       "  0.027585001101282588,\n",
       "  -0.010217668280789882,\n",
       "  -0.005287913498012326,\n",
       "  -0.01890809236750019,\n",
       "  0.00484866173388753,\n",
       "  0.006926659819408448,\n",
       "  -0.014880492980596072,\n",
       "  0.013610041423469376,\n",
       "  0.002333101769019084,\n",
       "  -0.025936116868206696,\n",
       "  0.01661046746859432,\n",
       "  0.032410010036223715,\n",
       "  -0.012535565277765065,\n",
       "  0.03197751501724032,\n",
       "  -0.015380563832896469,\n",
       "  -0.020840799012062223,\n",
       "  0.01884051560286063,\n",
       "  -0.008217383940265733,\n",
       "  0.03970834532077868,\n",
       "  -0.035788870619942965,\n",
       "  -0.013839804285888985,\n",
       "  -0.008197110910873866,\n",
       "  0.011528664965377758,\n",
       "  -0.009440530830822183,\n",
       "  0.02681462039645629,\n",
       "  0.0022722822151822033,\n",
       "  -0.003649167176616204,\n",
       "  -0.009068855831336946,\n",
       "  0.025544169770652148,\n",
       "  0.0028112101728116254,\n",
       "  0.011697607808299208,\n",
       "  0.0019394647866872677,\n",
       "  0.007811920558460717,\n",
       "  0.0180295888392506,\n",
       "  -0.009947359359586537,\n",
       "  0.020421821208651852,\n",
       "  -0.004277634813054318,\n",
       "  0.026246971848193777,\n",
       "  0.021962580755659336,\n",
       "  0.013339733433588586,\n",
       "  0.010589342348952563,\n",
       "  -0.008663393380854485,\n",
       "  -0.016475313939315204,\n",
       "  -0.025963147574062522,\n",
       "  0.035572621247806156,\n",
       "  0.01095425874065129,\n",
       "  0.018205290289958563,\n",
       "  -0.005727165262137121,\n",
       "  -0.04727698766389188,\n",
       "  0.008467418900754656,\n",
       "  0.013042393806529419,\n",
       "  -0.021205715403760952,\n",
       "  -0.0064907868935156305,\n",
       "  0.014623699412320638,\n",
       "  0.03200454572309614,\n",
       "  0.024881913751894254,\n",
       "  -0.014610184059392727,\n",
       "  -0.01516431632340477,\n",
       "  0.025530654417724237,\n",
       "  0.011454330524274242,\n",
       "  -0.0027216704940029326,\n",
       "  -0.00803492574441637,\n",
       "  0.022178826402505923,\n",
       "  0.008339023047939494,\n",
       "  0.018070134898034333,\n",
       "  -0.022976237813188045,\n",
       "  -0.004439819979511814,\n",
       "  -0.029625830569267913,\n",
       "  -0.006000852555911166,\n",
       "  0.02208421893201054,\n",
       "  0.04184378225925939,\n",
       "  -0.02430074985070383,\n",
       "  -0.04330345155134451,\n",
       "  0.015623841116921434,\n",
       "  -0.010460945564814847,\n",
       "  0.008933701370735275,\n",
       "  -0.001609181370450996,\n",
       "  0.016718592154662724,\n",
       "  -0.007845708940780497,\n",
       "  0.007014510079101152,\n",
       "  -0.0022689033769502254,\n",
       "  0.017759279918047256,\n",
       "  0.004950027812169423,\n",
       "  0.01143405656355982,\n",
       "  -0.004095176617204955,\n",
       "  -0.006565121800280422,\n",
       "  0.0051324860080187865,\n",
       "  -0.003689713468230578,\n",
       "  0.0006715481149341314,\n",
       "  -0.03381561419130697,\n",
       "  -0.019651440503825553,\n",
       "  0.0052946711744762814,\n",
       "  0.015488687587642318,\n",
       "  -0.010933985711259421,\n",
       "  -0.04922320966138182,\n",
       "  0.0037302597598449514,\n",
       "  0.0053284595567960604,\n",
       "  0.01321133664945087,\n",
       "  -0.01031903342774922,\n",
       "  -0.012163890278279828,\n",
       "  -0.0022689033769502254,\n",
       "  0.01546165595046394,\n",
       "  -0.005646072678908374,\n",
       "  0.002725049332234911,\n",
       "  0.001511194479647039,\n",
       "  -0.01482643063756187,\n",
       "  -0.021881486775446754,\n",
       "  -0.019962295483812634,\n",
       "  0.02153008573667594,\n",
       "  0.019421677641405944,\n",
       "  -0.015623841116921434,\n",
       "  0.009913570977266759,\n",
       "  -0.013711407501751267,\n",
       "  0.019489256268690615,\n",
       "  0.028463502766887066,\n",
       "  0.02513870732016969,\n",
       "  -0.009663535085455281,\n",
       "  0.012603142042404623,\n",
       "  -0.008257929999049469,\n",
       "  0.0010001420538467544,\n",
       "  0.01716460066392892,\n",
       "  0.0034396778092497396,\n",
       "  0.0031609220252970895,\n",
       "  -0.02967989198097956,\n",
       "  -0.028139132433972078,\n",
       "  -0.015218378666438973,\n",
       "  0.02048939797329141,\n",
       "  0.005862319257077516,\n",
       "  0.009339164752540291,\n",
       "  -0.014231751383443533,\n",
       "  -0.004977058518025246,\n",
       "  -0.013170790590667135,\n",
       "  -0.00022828412592801136,\n",
       "  -0.010663677721378634,\n",
       "  -0.014177689971731886,\n",
       "  -0.009487834566069874,\n",
       "  -0.025530654417724237,\n",
       "  0.0027402541042788114,\n",
       "  -0.027166021435227103,\n",
       "  0.006835430721483767,\n",
       "  0.043492666492335276,\n",
       "  0.01875942162264805,\n",
       "  -0.0048114945133357736,\n",
       "  -0.012724781150078383,\n",
       "  0.001553430190377402,\n",
       "  -0.01828638240752603,\n",
       "  0.031436900900123854,\n",
       "  -0.004007326357512252,\n",
       "  -0.02619291043648213,\n",
       "  0.004159374543612536,\n",
       "  -0.04235736939581025,\n",
       "  0.01178545853365319,\n",
       "  0.01977308054282187,\n",
       "  -0.002116854725188664,\n",
       "  0.021935548187158403,\n",
       "  -0.02753093782692583,\n",
       "  -0.0025831371951692828,\n",
       "  -0.01008251382018821,\n",
       "  -0.026057756907203015,\n",
       "  -0.004517533724508583,\n",
       "  0.0040478724162959865,\n",
       "  0.0058690769335414715,\n",
       "  0.016799684272230192,\n",
       "  0.032653286388926124,\n",
       "  0.008737727821957999,\n",
       "  0.004125586161292757,\n",
       "  0.00819035323440991,\n",
       "  -0.010487976270670671,\n",
       "  0.021084077227409747,\n",
       "  0.006889492598856691,\n",
       "  -0.026368611887190092,\n",
       "  -0.04135722582856435,\n",
       "  0.006544848770888555,\n",
       "  -0.006078566300907935,\n",
       "  0.009149948880226971,\n",
       "  0.00794707501906239,\n",
       "  0.01171112316122712,\n",
       "  0.004774326827122738,\n",
       "  0.018178257721457626,\n",
       "  0.0056426938406763955,\n",
       "  0.017218662075640566,\n",
       "  0.0036930923064625557,\n",
       "  -0.007967348048454257,\n",
       "  0.0029767744103317375,\n",
       "  0.001376884845018681,\n",
       "  0.002973395339269121,\n",
       "  -0.013434340904083969,\n",
       "  -0.003350138130441047,\n",
       "  0.010609615378344431,\n",
       "  0.01952980232747435,\n",
       "  0.005581874286839515,\n",
       "  -0.045168581431266994,\n",
       "  -0.013589768394077507,\n",
       "  -0.0015424488497081544,\n",
       "  -0.004328317852195265,\n",
       "  -0.011021836436613404,\n",
       "  -7.813609795677769e-06,\n",
       "  -0.007507823720598872,\n",
       "  0.0021354385682951812,\n",
       "  -0.013684376795895445,\n",
       "  0.010068998467260297,\n",
       "  0.008197110910873866,\n",
       "  0.020854314364990138,\n",
       "  0.0009004658021344685,\n",
       "  -0.00526426163038848,\n",
       "  0.012373380111307569,\n",
       "  -0.008920186017807362,\n",
       "  0.015367048479968557,\n",
       "  -0.008095744832591973,\n",
       "  -0.002578068937821316,\n",
       "  0.049169148249670176,\n",
       "  0.010427157182495069,\n",
       "  0.00421343642098546,\n",
       "  0.014623699412320638,\n",
       "  0.006115733987120971,\n",
       "  0.020854314364990138,\n",
       "  0.011528664965377758,\n",
       "  0.0025172496168150743,\n",
       "  0.0053723849194730515,\n",
       "  -0.012555838307156932,\n",
       "  0.0020932028575648184,\n",
       "  0.006355632898575236,\n",
       "  -0.025287376202376716,\n",
       "  0.02350334030266682,\n",
       "  0.020921891129629694,\n",
       "  0.02792288678712549,\n",
       "  -0.0026963289744324596,\n",
       "  -0.02205718822615472,\n",
       "  0.0052743981450844146,\n",
       "  -0.014461514245863142,\n",
       "  -0.0026895712979685036,\n",
       "  0.005537948924162525,\n",
       "  0.013704649825287312,\n",
       "  0.021084077227409747,\n",
       "  -0.01606985148883274,\n",
       "  -0.014515575657574789,\n",
       "  0.02816616500247301,\n",
       "  0.021462508972036384,\n",
       "  0.05149380385443187,\n",
       "  0.009609473673743634,\n",
       "  0.008278203028441336,\n",
       "  0.012163890278279828,\n",
       "  0.010143332908363813,\n",
       "  0.03224782580108878,\n",
       "  -0.018962153779211836,\n",
       "  -0.024800821634326786,\n",
       "  -0.015610325763993523,\n",
       "  -0.02335466955781468,\n",
       "  -0.018408020583877235,\n",
       "  -0.016583436762738497,\n",
       "  -0.001876955930149718,\n",
       "  0.007149664539702824,\n",
       "  -0.013711407501751267,\n",
       "  0.03235594862451207,\n",
       "  0.014718307814138576,\n",
       "  0.028193195708328834,\n",
       "  0.012224710297777986,\n",
       "  0.01961089444504182,\n",
       "  0.027895856081269665,\n",
       "  -0.011035351789541315,\n",
       "  -0.029869108784615437,\n",
       "  0.05025038393448355,\n",
       "  0.0008147272581290915,\n",
       "  0.0026490250063541296,\n",
       "  -0.024179111674352625,\n",
       "  -0.027409299650574624,\n",
       "  -0.0005786294814781415,\n",
       "  -0.02198961146151516,\n",
       "  0.016191489665183946,\n",
       "  0.014975100451091452,\n",
       "  0.016691561448806902,\n",
       "  0.028490535335388003,\n",
       "  -0.0024851504207806453,\n",
       "  -0.0034515039758923013,\n",
       "  0.03635651544291525,\n",
       "  0.014353390491117293,\n",
       "  0.006389421280895015,\n",
       "  0.019205431994559357,\n",
       "  -0.001809378699848882,\n",
       "  -0.0023685798032854906,\n",
       "  -0.021651725775672256,\n",
       "  -0.010217668280789882,\n",
       "  -0.008663393380854485,\n",
       "  0.045898414214664444,\n",
       "  -0.01067043539784259,\n",
       "  0.0056122838309273166,\n",
       "  -0.014083082501236506,\n",
       "  -0.006487408055283653,\n",
       "  -0.004493881856884738,\n",
       "  0.005608904992695339,\n",
       "  0.01763764174169605,\n",
       "  -0.018543175975801466,\n",
       "  0.0009291861017292599,\n",
       "  -0.009609473673743634,\n",
       "  0.04343860508062363,\n",
       "  -0.01750248634977182,\n",
       "  -0.002000284107693509,\n",
       "  0.016286097135679328,\n",
       "  0.01344785625701188,\n",
       "  -0.02185445606959093,\n",
       "  -0.027111960023515458,\n",
       "  0.0026017210382758,\n",
       "  -0.0032301886747139147,\n",
       "  0.028923028491726285,\n",
       "  0.028003978904692958,\n",
       "  -0.0055784954486075376,\n",
       "  -0.0003112773347660765,\n",
       "  -0.011684092455371296,\n",
       "  -0.007825435911388628,\n",
       "  -0.018380989878021413,\n",
       "  0.007838951264316541,\n",
       "  -0.005250745811799291,\n",
       "  0.0028635826310685606,\n",
       "  -0.03781618473500038,\n",
       "  -0.036653856932619536,\n",
       "  0.023692555243657584,\n",
       "  -0.010967774093579201,\n",
       "  0.01661046746859432,\n",
       "  0.0018786453492657068,\n",
       "  0.004392515778602845,\n",
       "  -0.010623130731272343,\n",
       "  0.013326218080660675,\n",
       "  -0.0022317359235678297,\n",
       "  -0.005923138810914396,\n",
       "  -0.007325365059088231,\n",
       "  -0.006625941354117302,\n",
       "  0.007210484093539704,\n",
       "  0.030031294882395487,\n",
       "  -0.0020847557619848734,\n",
       "  0.008987763713769477,\n",
       "  0.01773224921219143,\n",
       "  0.013961443393562745,\n",
       "  -0.032707351525928,\n",
       "  0.00794707501906239,\n",
       "  0.016961870370010245,\n",
       "  -0.010481218594206714,\n",
       "  0.013069424512385241,\n",
       "  -0.010636646084200254,\n",
       "  0.036383546148771075,\n",
       "  0.004017462872208185,\n",
       "  0.016326643194463062,\n",
       "  0.019881203366245163,\n",
       "  -0.009244556350722353,\n",
       "  0.008764758527813823,\n",
       "  0.017178116016856832,\n",
       "  -0.0015990447393397426,\n",
       "  -0.003845140958224117,\n",
       "  -0.018543175975801466,\n",
       "  -0.011603000337803827,\n",
       "  -0.01356949536468564,\n",
       "  0.008170080205018042,\n",
       "  -0.0009663534969039962,\n",
       "  -0.01898918448506766,\n",
       "  0.007284819000304496,\n",
       "  0.008088987156128017,\n",
       "  -0.030653002979724533,\n",
       "  -0.0145290910105027,\n",
       "  0.01621852037103977,\n",
       "  0.021097592580337658,\n",
       "  -0.024706212301186293,\n",
       "  0.002817967849275581,\n",
       "  -0.0073388804120161424,\n",
       "  -0.006173174237064595,\n",
       "  -0.01811068095681807,\n",
       "  -0.013258640384698562,\n",
       "  -0.007872740577958875,\n",
       "  -0.017934981368755216,\n",
       "  -0.0067610958147189745,\n",
       "  -0.015623841116921434,\n",
       "  -0.014137143912948152,\n",
       "  0.005673103384764197,\n",
       "  -0.010346064133605042,\n",
       "  0.005723786423905143,\n",
       "  -0.0008666771869840505,\n",
       "  -0.007386184612925111,\n",
       "  -0.04416843786402108,\n",
       "  0.00806871412673615,\n",
       "  0.009102645144979282,\n",
       "  0.024152080968496803,\n",
       "  0.01020415292786197,\n",
       "  0.009954117036050493,\n",
       "  -0.010771800544801926,\n",
       "  -0.015488687587642318,\n",
       "  -0.0032065365742594302,\n",
       "  -0.0101298175554359,\n",
       "  0.009954117036050493,\n",
       "  -0.005075045292413884,\n",
       "  -0.01031903342774922,\n",
       "  0.012603142042404623,\n",
       "  -0.018921607720428103,\n",
       "  0.0068590825891076115,\n",
       "  -0.013001847747745683,\n",
       "  0.0010744769606115465,\n",
       "  0.01600227286154807,\n",
       "  0.008311991410761116,\n",
       "  0.007676766563520323,\n",
       "  -0.038410863989118714,\n",
       "  0.016421252527603555,\n",
       "  0.02581447869185549,\n",
       "  0.014569638000608991,\n",
       "  0.009886540271410935,\n",
       "  -0.01515080097047686,\n",
       "  -0.010981290377829668,\n",
       "  0.02281405171540799,\n",
       "  -0.022408589264925532,\n",
       "  0.00032204743983816584,\n",
       "  -0.0037403962745408852,\n",
       "  0.0018144469571968486,\n",
       "  0.0125761113365488,\n",
       "  -0.00642658896710805,\n",
       "  0.020178542993304332,\n",
       "  -0.017664672447551873,\n",
       "  0.0018617510416904979,\n",
       "  0.0008962421961368364,\n",
       "  4.919802804552858e-06,\n",
       "  -0.008055198773808237,\n",
       "  -0.00022638351487060885,\n",
       "  0.01135296444599235,\n",
       "  -0.019448708347261767,\n",
       "  -0.01977308054282187,\n",
       "  0.033842644897162794,\n",
       "  -0.02731469218007924,\n",
       "  0.004781084503586695,\n",
       "  -0.02705789861180381,\n",
       "  0.004419546950119946,\n",
       "  0.035653713365373624,\n",
       "  0.011001563407221535,\n",
       "  -0.0034802241008641136,\n",
       "  0.03005832558825131,\n",
       "  -0.0019158126862327833,\n",
       "  -0.0037708060514593253,\n",
       "  -0.03632948473705943,\n",
       "  0.014894008333523983,\n",
       "  -0.017705218506335607,\n",
       "  0.03668088763847536,\n",
       "  0.0007898081515452752,\n",
       "  0.007778132176140938,\n",
       "  -0.020313696522583448,\n",
       "  -0.03251813285964701,\n",
       "  -0.006044777918588156,\n",
       "  -0.007061814280010121,\n",
       "  0.005169653228570543,\n",
       "  0.0022722822151822033,\n",
       "  -0.005696755252388042,\n",
       "  -0.015515718293498142,\n",
       "  0.0008523170662904846,\n",
       "  -0.0030798294420683416,\n",
       "  -0.0016801373225684905,\n",
       "  -0.02311139134246716,\n",
       "  -0.035572621247806156,\n",
       "  0.035788870619942965,\n",
       "  0.000670703405376137,\n",
       "  0.021219230756688863,\n",
       "  0.010575826996024652,\n",
       "  0.022030157520298896,\n",
       "  -0.029544738451700445,\n",
       "  -0.01877293697557596,\n",
       "  0.0017147706472769029,\n",
       "  -0.0049905738709531584,\n",
       "  0.016326643194463062,\n",
       "  0.03797836897013532,\n",
       "  0.013468130217726302,\n",
       "  0.020448851914507675,\n",
       "  0.055521401378690875,\n",
       "  -0.024152080968496803,\n",
       "  0.039275850301795284,\n",
       "  -0.0026659194303446584,\n",
       "  -0.0006204428956371669,\n",
       "  0.007318607382624275,\n",
       "  -0.004095176617204955,\n",
       "  -0.012792357914717941,\n",
       "  -0.00013821643088599762,\n",
       "  0.0036525460148481817,\n",
       "  0.001841477895883311,\n",
       "  -0.03295062787863041,\n",
       "  0.012258498680097764,\n",
       "  0.003155853767949123,\n",
       "  0.0031169968954507378,\n",
       "  0.005615662669159294,\n",
       "  -0.016096882194688564,\n",
       "  -0.008257929999049469,\n",
       "  -0.020381273287223004,\n",
       "  -0.015299470784006444,\n",
       "  -0.014447998892935231,\n",
       "  0.02086782971791805,\n",
       "  -0.011379995151848173,\n",
       "  0.01938113158262221,\n",
       "  -0.029463646334132974,\n",
       "  0.0014596668473634176,\n",
       "  0.004743917283034937,\n",
       "  0.0022368044137464353,\n",
       "  0.017367332820492704,\n",
       "  0.02730117682715133,\n",
       "  0.02959879986341209,\n",
       "  -0.028058040316404607,\n",
       "  -0.00565283035537233,\n",
       "  -0.0014148970079590714,\n",
       "  -0.02690922786695167,\n",
       "  -0.01130566071074466,\n",
       "  -0.012359863827057102,\n",
       "  -0.010481218594206714,\n",
       "  -0.02603072620134719,\n",
       "  0.018637783446296845,\n",
       "  -0.012562595983620887,\n",
       "  0.009109402821443237,\n",
       "  0.0015770821744165667,\n",
       "  0.017461940290988087,\n",
       "  -0.025273860849448805,\n",
       "  0.018610752740441022,\n",
       "  0.008122775538447797,\n",
       "  -0.024476451301411795,\n",
       "  -0.00028445766078060255,\n",
       "  -0.02388177204729346,\n",
       "  -0.016096882194688564,\n",
       "  -0.05235879016710844,\n",
       "  -0.017826856682686812,\n",
       "  -0.004598626307737331,\n",
       "  -0.00894045904719923,\n",
       "  -0.0035140127160145315,\n",
       "  -0.024881913751894254,\n",
       "  0.008406599812579053,\n",
       "  -0.0036694402060080712,\n",
       "  -0.008643120351462618,\n",
       "  -0.033166873525476995,\n",
       "  0.0036525460148481817,\n",
       "  0.03970834532077868,\n",
       "  0.007284819000304496,\n",
       "  0.0210300158156981,\n",
       "  0.01463721476524855,\n",
       "  -0.006281297991810444,\n",
       "  -0.02461160483069091,\n",
       "  0.01923246270041518,\n",
       "  -0.0008012117887858603,\n",
       "  -0.010771800544801926,\n",
       "  0.0047337807683390035,\n",
       "  0.029220368118785454,\n",
       "  -0.019354100876766388,\n",
       "  -0.032896566466918756,\n",
       "  0.011123201583572741,\n",
       "  -0.005946790678538242,\n",
       "  -0.004311423195374097,\n",
       "  -0.023692555243657584,\n",
       "  0.020151512287448506,\n",
       "  -0.008359296077331362,\n",
       "  -0.004422925788351924,\n",
       "  -0.012488260611194818,\n",
       "  0.0005790518944647985,\n",
       "  -0.031436900900123854,\n",
       "  0.004095176617204955,\n",
       "  -0.02278702100955217,\n",
       "  -0.011102928554180873,\n",
       "  0.001799242185152948,\n",
       "  -0.0029666376628051648,\n",
       "  0.0062002054085816966,\n",
       "  0.02722008284693875,\n",
       "  -0.0016801373225684905,\n",
       "  0.02280053636248008,\n",
       "  -0.005831909712989715,\n",
       "  0.009582442967887812,\n",
       "  -0.003747153951004841,\n",
       "  0.0034498145567763124,\n",
       "  -0.010305518074821307,\n",
       "  0.0155832950581377,\n",
       "  0.019327070170910562,\n",
       "  0.03500497269954364,\n",
       "  -0.011697607808299208,\n",
       "  0.00016155166339282948,\n",
       "  0.021895002128374665,\n",
       "  -0.008994521390233432,\n",
       "  0.0069536905252642715,\n",
       "  -0.011447572847810287,\n",
       "  -0.005744059453297011,\n",
       "  0.029625830569267913,\n",
       "  -0.039275850301795284,\n",
       "  -0.021205715403760952,\n",
       "  -0.0036593036913121373,\n",
       "  0.024260203791920096,\n",
       "  0.014623699412320638,\n",
       "  -0.008636362674998663,\n",
       "  -0.016488829292243115,\n",
       "  -0.022922176401476396,\n",
       "  -0.004618899337129199,\n",
       "  0.0014115181697270936,\n",
       "  0.03822164532283773,\n",
       "  -0.010521765584313005,\n",
       "  0.008899912988415495,\n",
       "  -0.003493739686622664,\n",
       "  -0.011535422641841713,\n",
       "  0.006838809559715745,\n",
       "  -0.011548937994769625,\n",
       "  0.0025932739426958555,\n",
       "  0.012285529385953588,\n",
       "  -0.012738296503006296,\n",
       "  -0.017786310623903078,\n",
       "  -0.002476703325200701,\n",
       "  -0.006622562515885324,\n",
       "  0.04138425653442017,\n",
       "  -0.016015788214475985,\n",
       "  -0.0016936527919117217,\n",
       "  0.005054772263022016,\n",
       "  0.016988901075866068,\n",
       "  -0.0013836425214826368,\n",
       "  -0.002929470209422769,\n",
       "  -0.0022384938328624242,\n",
       "  -0.009278345664364689,\n",
       "  -0.016583436762738497,\n",
       "  -0.0193676162296943,\n",
       "  -0.01835395917216559,\n",
       "  0.000876813759887644,\n",
       "  0.0016041129966877096,\n",
       "  0.006629320192349281,\n",
       "  -0.010433914858959024,\n",
       "  -0.01709702389928936,\n",
       "  0.005193305561855667,\n",
       "  0.01779982597683099,\n",
       "  0.01684023033101393,\n",
       "  -0.0016852056963317767,\n",
       "  -0.009744628134345307,\n",
       "  -0.011623273367195694,\n",
       "  0.007778132176140938,\n",
       "  -0.029977231608038727,\n",
       "  -0.0003412646986978597,\n",
       "  0.009764901163737174,\n",
       "  -0.006419831290644094,\n",
       "  0.00020188679216961967,\n",
       "  0.0183674745250935,\n",
       "  -0.007237514799395528,\n",
       "  -0.016421252527603555,\n",
       "  -0.013866834991744808,\n",
       "  -0.006375905927967104,\n",
       "  -0.0019597378160791353,\n",
       "  -0.031247682233842868,\n",
       "  0.0003847675028690441,\n",
       "  -0.0106839507507705,\n",
       "  0.018083650250962247,\n",
       "  -0.0011276940120111569,\n",
       "  -0.01527244007815062,\n",
       "  -0.00676785349118293,\n",
       "  0.004220194097449416,\n",
       "  -0.01163003104365965,\n",
       "  0.03292359717277458,\n",
       "  0.0018059998616169039,\n",
       "  -0.011994947435358377,\n",
       "  0.004659445861574211,\n",
       "  0.0042539829454304725,\n",
       "  0.026949775788380516,\n",
       "  0.015123770264621037,\n",
       "  -0.026003695495491367,\n",
       "  -0.009312134046684467,\n",
       "  -0.03322093493718864,\n",
       "  0.003360274645136981,\n",
       "  -0.024152080968496803,\n",
       "  0.010075756143724253,\n",
       "  0.01734030211463688,\n",
       "  0.023597947773162202,\n",
       "  0.024341295909487567,\n",
       "  -0.026787589690600466,\n",
       "  -0.01961089444504182,\n",
       "  -0.006146143531208772,\n",
       "  -0.008278203028441336,\n",
       "  -0.006710412775578028,\n",
       "  -0.021705787187383904,\n",
       "  -0.0013067734860438614,\n",
       "  0.0018347201030040356,\n",
       "  0.0033264862628172016,\n",
       "  -0.01582657327348522,\n",
       "  0.022449135323709266,\n",
       "  0.006473892702355741,\n",
       "  -0.00018953284212437575,\n",
       "  -0.0022165311515239287,\n",
       "  -0.002208084055943984,\n",
       "  -0.015921180743980603,\n",
       "  -0.015218378666438973,\n",
       "  -0.025746901927215935,\n",
       "  -0.0028703403075325167,\n",
       "  -0.03678901046189865,\n",
       "  0.013366764139444409,\n",
       "  0.027760700689345438,\n",
       "  0.004321560175731309,\n",
       "  0.011880066004148572,\n",
       "  0.051061308835448474,\n",
       "  -0.0005718718050141857,\n",
       "  -0.004757432635962849,\n",
       "  -0.02715250608229919,\n",
       "  0.004558080248953596,\n",
       "  0.032410010036223715,\n",
       "  0.002426020286059754,\n",
       "  0.020948921835485516,\n",
       "  -0.007940317342598433,\n",
       "  -0.02057049009085888,\n",
       "  0.012805873267645854,\n",
       "  -0.01654289070395476,\n",
       "  0.002365200965053513,\n",
       "  -0.03357233783860456,\n",
       "  0.01071773913309028,\n",
       "  0.013441098580547924,\n",
       "  0.010041967761404475,\n",
       "  -0.03668088763847536,\n",
       "  0.024016925576572576,\n",
       "  -0.011481361230130067,\n",
       "  -0.011156990897215075,\n",
       "  0.0275985164542105,\n",
       "  -0.013589768394077507,\n",
       "  -0.011724638514155032,\n",
       "  0.03381561419130697,\n",
       "  0.010055483114332386,\n",
       "  0.007325365059088231,\n",
       "  -0.005409552605686086,\n",
       "  0.0330587507020537,\n",
       "  0.007142906863238868,\n",
       "  0.0005000710269233772,\n",
       "  0.032653286388926124,\n",
       "  -0.021949065402731425,\n",
       "  -0.02792288678712549,\n",
       "  -0.019097307308490952,\n",
       "  -0.0021337491491791923,\n",
       "  -0.03424810921029037,\n",
       "  -0.013231609678842737,\n",
       "  -0.009704081144239016,\n",
       "  -0.0028416199497300655,\n",
       "  0.0023516853792949623,\n",
       "  -0.0024125049331318424,\n",
       "  -0.0007420817704802885,\n",
       "  -0.028003978904692958,\n",
       "  0.004456714170671703,\n",
       "  -0.016745622860518547,\n",
       "  0.022759990303696347,\n",
       "  -0.0014351701537662583,\n",
       "  -0.0120219781412142,\n",
       "  0.017124054605145184,\n",
       "  -0.008332265371475538,\n",
       "  0.013880350344672719,\n",
       "  0.010785315897729839,\n",
       "  -0.011494876583057978,\n",
       "  -0.026990321847164253,\n",
       "  -0.019016215190923485,\n",
       "  0.035707774777085276,\n",
       "  0.02182742536373511,\n",
       "  0.01215713260181587,\n",
       "  0.2147332088184969,\n",
       "  -0.03968131461492286,\n",
       "  0.019637925150897642,\n",
       "  0.0018516144105792446,\n",
       "  -0.0027284281704668886,\n",
       "  -0.02428723449777592,\n",
       "  -0.020056902954308016,\n",
       "  0.011582726377089403,\n",
       "  0.002005352597872115,\n",
       "  0.009987905418370273,\n",
       "  0.024503482007267617,\n",
       "  -0.0070482989270822085,\n",
       "  -0.006909765628248558,\n",
       "  -0.0023297229307871056,\n",
       "  -0.004625657013593154,\n",
       "  -0.014502060304646878,\n",
       "  -0.035572621247806156,\n",
       "  -0.011961159053038597,\n",
       "  -0.019340585523838473,\n",
       "  -0.008899912988415495,\n",
       "  0.008102502509055929,\n",
       "  -0.007088844985865943,\n",
       "  -0.008845851576703848,\n",
       "  -0.016326643194463062,\n",
       "  0.018637783446296845,\n",
       "  -0.01494806974523563,\n",
       "  -0.012103071190104226,\n",
       "  -0.015840088626413132,\n",
       "  0.014407452834151496,\n",
       "  0.025679325162576375,\n",
       "  -0.00992708633019467,\n",
       "  0.02008393552280895,\n",
       "  0.02255725814713256,\n",
       "  -0.009109402821443237,\n",
       "  -0.012272014033025675,\n",
       "  -0.014461514245863142,\n",
       "  0.019691986562609287,\n",
       "  0.026936260435452605,\n",
       "  0.020137996934520595,\n",
       "  -0.0038620351493840067,\n",
       "  0.03140986646897781,\n",
       "  -0.035302314189247924,\n",
       "  0.010893439652475688,\n",
       "  0.0013642140852334443,\n",
       "  -0.01811068095681807,\n",
       "  0.020746191541566844,\n",
       "  ...]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_result = embeddings_hf.embed_documents([text_hf])\n",
    "doc_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢ç»™å‡ºçš„ä¾‹å­ç”¨äºç†Ÿæ‚‰åŸºæœ¬modelsä¸­çš„ç›¸å…³æ“ä½œï¼Œè¯¦ç»†çš„APIå¼€æ”¾æ¥å£è¿˜æœ‰å¾ˆå¤šï¼Œä¾‹å¦‚é’ˆå¯¹å¾®è½¯Azureçš„AzureOpenAIï¼ŒCohereå’ŒLlama-cppç­‰ï¼Œç‚¹å‡»[æ­¤å¤„](https://python.langchain.com/en/latest/modules/models/text_embedding.html)å¯ä»¥ç›´æ¥è·³è½¬åˆ°ç›¸å…³ä½ç½®ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prompt\n",
    "Promptæ˜¯ä¸€ç§ä¸ºäº†æ›´å¥½åœ°ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†ï¼Œé‡‡ç”¨åœ¨è¾“å…¥ç«¯æ·»åŠ é¢å¤–æ–‡æœ¬çš„æŠ€æœ¯ã€‚Promptçš„è®¾è®¡æœ‰æ—¶å€™å¯ä»¥æå¤§åœ°æ¿€å‘å‡ºå¤§æ¨¡å‹çš„æ½œåŠ›ï¼ŒåŸºäºpromptå¯ä»¥å®Œæˆå¾ˆå¤šæˆ‘ä»¬æƒ³è±¡ä¸åˆ°çš„ä»»åŠ¡ï¼Œé‚£ä¹ˆï¼Œç°åœ¨æˆ‘ä»¬å°±æ¥ç†Ÿæ‚‰ä¸€ä¸‹ä»€ä¹ˆæ˜¯Promptä»¥åŠåœ¨LangChainä¸­å¦‚ä½•å»æ›´å¥½åœ°ä½¿ç”¨å’Œå®Œå–„å®ƒä»¬ï¼ŒLangChainæä¾›äº†å‡ ä¸ªç±»å’Œå‡½æ•°æ¥è½»æ¾æ„å»ºPromptæ¨¡æ¿ã€‚\n",
    "\n",
    "- [Prompt Templates](#prompt-templates)\n",
    "- [Chat Prompt Template](#chat-model-prompt-template)\n",
    "- [Example Selectors](#example-selectors)\n",
    "- [Output Parser](#output-parser)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prompt Templates\n",
    "è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬è¾“å…¥å­—ç¬¦ä¸²æœ¬èº«å°±æ˜¯ä¸€ç§æç¤ºï¼Œé€šå¸¸æ¥è¯´promptç”±æ¨¡æ¿ã€ä¸€äº›ä¾‹å­ï¼ˆæœ‰çš„è¯ï¼‰å’Œç”¨æˆ·çš„è¾“å…¥æ„æˆï¼Œå…¶æ¦‚å¿µå’Œå«ä¹‰å¹¶ä¸å¤æ‚ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ä»€ä¹ˆæ˜¯prompt templateï¼š\n",
    "Prompt Templateï¼Œä¹Ÿå°±æ˜¯æç¤ºæ¨¡ç‰ˆï¼Œæ˜¯ä¸€ç§å¯é‡å¤ä½¿ç”¨ç”Ÿæˆpromptçš„æ–¹å¼ï¼Œç”¨templateå¯ä»¥æ¨¡ç‰ˆåŒ–æç¤ºæŒ‡ä»¤ï¼Œå®ƒç”±ä¸€ä¸ªå­—ç¬¦ä¸²å’Œå¯ä¾›ç”¨æˆ·è¾“å…¥çš„å‚æ•°ç»„æˆã€‚\n",
    "æç¤ºæ¨¡ç‰ˆåŒ…å«å¦‚ä¸‹çš„å†…å®¹ï¼š\n",
    "- ç»™è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤\n",
    "- å‡ ä¸ªä¾‹å­ï¼Œå¸®åŠ©è¯­è¨€æ¨¡å‹æ›´å¥½åœ°å›ç­”\n",
    "- ä¸€ä¸ªè®©è¯­è¨€æ¨¡å‹å›ç­”çš„é—®é¢˜\n",
    "- ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ç°åœ¨æˆ‘ä»¬çœ‹ä¸€ä¸ªåˆ›å»ºprompt templateçš„ä¾‹å­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ä¸€èˆ¬å¯¼å…¥çš„å¿…è¦åº“ï¼Œä¸ºäº†è¿›ä¸€æ­¥æ¨¡ç‰ˆåŒ–å¤„ç†\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "#å…·ä½“çš„æ¨¡ç‰ˆå†…å®¹ï¼Œå…¶ä¸­è¦è¿›è¡Œè¡¥å…¨çš„åœ°æ–¹ï¼ˆä¹Ÿå°±æ˜¯ä¸ºäº†å®šåˆ¶æˆ‘ä»¬å…·ä½“é—®é¢˜ä»¥åŠè¦æ±‚çš„åœ°æ–¹ç”¨ä¸€ä¸ªå˜é‡è¿›è¡Œä»£æ›¿ï¼‰ç”¨ä¸­æ‹¬å·\n",
    "#è¿›è¡Œå˜é‡çš„æ”¾ç½®ï¼Œä¸éœ€è¦å…¶ä»–çš„æ“ä½œï¼Œç±»ä¼¼äºå­—ç¬¦ä¸²ä¸­å¯¹äºæŸä¸€ä¸ªå˜é‡å¯¹å…¶çš„formatæ ¼å¼åŒ–\n",
    "template = \"\"\"\n",
    "I want you to act as a naming consultant for new companies.\n",
    "Here are some examples of good company names:\n",
    "- search engine, Google\n",
    "- social media, Facebook\n",
    "- video sharing, YouTube\n",
    "The name should be short, catchy and easy to remember.\n",
    "What is a good name for a company that makes {product}?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"input_variableså°±æ˜¯æ¨¡ç‰ˆä¸­éœ€è¦å¡«è¡¥çš„å˜é‡ï¼Œåœ¨prompttemplateä¸­æ ¼å¼åŒ–æ¨¡ç‰ˆå¯ä»¥å°†å˜é‡ä»¥åŠæ¨¡ç‰ˆå†…å®¹è¿›è¡Œå¾ˆå¥½çš„ç»„åˆ\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬çœ‹çœ‹prompté•¿ä»€ä¹ˆæ ·å­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['product'], output_parser=None, partial_variables={}, template='\\nI want you to act as a naming consultant for new companies.\\nHere are some examples of good company names:\\n- search engine, Google\\n- social media, Facebook\\n- video sharing, YouTube\\nThe name should be short, catchy and easy to remember.\\nWhat is a good name for a company that makes {product}?\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### åˆ›å»ºprompt template\n",
    "æˆ‘ä»¬å¯ä»¥ä»ä¸Šé¢çš„ç¤ºä¾‹ä¸­çœ‹åˆ°ï¼šé€šè¿‡LangChainçš„PromptTemplateç±»ï¼Œå¯ä»¥ç”Ÿæˆå…·ä½“çš„promptï¼Œé‚£ä¹ˆé€šè¿‡ç»§ç»­ä½¿ç”¨è¿™ä¸ªç±»ç”Ÿæˆå‡ ä¸ªå…·ä½“çš„promptsã€‚prompt templateæ¥å—å¤šä¸ªè¾“å…¥å˜é‡ï¼Œç”¨æ¥æ ¼å¼åŒ–ç”Ÿæˆprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# input_variablesçš„å€¼å¯ä»¥ä¸ºç©ºï¼Œè¯´æ˜å…¶ä¸­æ²¡æœ‰ä»»ä½•å˜é‡\n",
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a joke.\")\n",
    "no_input_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä¸€ä¸ªinput_variableçš„ç¤ºä¾‹ï¼Œè¿™æ ·æ¨¡ç‰ˆåŒ–ä¹‹åçš„æç¤ºå°†æŠŠadjectiveä½œä¸ºå‚æ•°ä¼ å…¥\n",
    "one_input_prompt = PromptTemplate(input_variables=[\"adjective\"], template=\"Tell me a {adjective} joke.\")\n",
    "one_input_prompt.format(adjective=\"funny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¤šä¸ªinput_variablesçš„ç¤ºä¾‹ï¼Œæ¨¡ç‰ˆåçš„æç¤ºå°†adjectiveå’Œcontentä½œä¸ºå‚æ•°ä¼ å…¥\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"],\n",
    "    template=\"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "multiple_input_prompt.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ä»LangChainHubåŠ è½½æœ¬åœ°prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "#å¯ä»¥åŠ è½½ç”¨jsonæ ¼å¼å†™å¥½çš„prompt\n",
    "test_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"{input}, tell me the answer by using Chinese.\"\n",
    ")\n",
    "#å°†åˆ›å»ºå¥½çš„æç¤ºæ¨¡ç‰ˆæ ¼å¼åŒ–ï¼Œå…¶ä¸­çš„è¡¥å…¨çš„å˜é‡å°±æ˜¯1+1ç­‰äºå‡ ï¼Ÿ\n",
    "test_prompt.format(input=\"what is 1+1?\")\n",
    "#ç„¶åå°†åˆ›å»ºå¥½çš„æ¨¡ç‰ˆä¿å­˜åœ¨æŒ‡å®šä½ç½®å¤„\n",
    "test_prompt.save(\"test_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='{input}, tell me the answer by using Chinese.', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#åŠ è½½æœ¬åœ°çš„æ¨¡ç‰ˆä½¿ç”¨åˆ°çš„æ–¹æ³•æ˜¯å›ºå®šçš„ï¼Œå°†å…·ä½“æ–‡ä»¶çš„ä½ç½®ä¼ å…¥å³å¯\n",
    "prompt = load_prompt(\"./test_prompt.json\")\n",
    "prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### åœ¨prompt templateä¸­æ·»åŠ å‡ ä¸ªä¾‹å­\n",
    "å¦‚æœç”Ÿæˆå¸¦æœ‰å‡ ä¸ªä¾‹å­çš„æ¨¡ç‰ˆï¼Œè¯¥æ€ä¹ˆåšï¼Ÿé€šè¿‡PromptTemplateç±»å›ºç„¶æ˜¯å¯ä»¥ï¼Œå°†ä¾‹å­å›ºå®šåœ¨å…·ä½“çš„æ¨¡ç‰ˆä¸­æ˜¯æˆ‘ä»¬æƒ³åˆ°çš„æ–¹æ³•ã€‚é‚£ä¹ˆLangChainæœ‰æ²¡æœ‰æä¾›ç›´æ¥çš„ç±»å¯ä»¥ç”¨æ¥è¾¾åˆ°æˆ‘ä»¬çš„ç›®çš„å’Œè¦æ±‚ã€‚ä¸‹é¢æ˜¯ç»™è¯­è¨€æ¨¡å‹å‡ ä¸ªåˆé€‚çš„ä¾‹å­ä»è€Œä½¿å¤§æ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®ã€æ›´åˆé€‚åœ°å›ç­”é—®é¢˜ï¼ŒLangChainä¸­ä½¿ç”¨FewShotPromptTemplateç±»ç”Ÿæˆå¸¦æœ‰ä¾‹å­çš„promptã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸‹é¢æ˜¯åˆ›å»ºä¸€ä¸ªè®©å¤§è¯­è¨€æ¨¡å‹å»å›ç­”åä¹‰è¯çš„æç¤ºæ¨¡ç‰ˆï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "\n",
      "\n",
      "Word: big\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "#å¦‚ä¸‹æ˜¯å‡ ä¸ªæç¤ºç¤ºä¾‹ï¼Œè®©å¤§æ¨¡å‹çŸ¥é“å‡ ä¸ªä¾‹å­å›ç­”çš„æ—¶å€™å¯ä»¥ç±»æ¯”ç€å›ç­”\n",
    "few_examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "#æˆ‘ä»¬å®šä¹‰å¦‚ä¸‹çš„æç¤ºæ¨¡ç‰ˆ\n",
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "#æ¨¡ç‰ˆæ ¼å¼åŒ–æç¤ºæ¨¡ç‰ˆ\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "#ç°åœ¨æ„å»ºä¸€ä¸ªå°‘æ ·æœ¬æç¤ºæ¨¡ç‰ˆå¯¹è±¡ï¼šfew_shot_prompt\n",
    "'''\n",
    "å…¶ä¸­çš„å‚æ•°æœ‰examples, example_prompt, prefix, suffix, input_variableså’Œexample_separatorã€‚å…¶ä¸­ï¼Œ\n",
    "    examples:ç¤ºä¾‹ï¼Œæ ·ä¾‹ï¼Œè¿™ä¸ªå°±æ˜¯æˆ‘ä»¬å†™å¥½çš„å‡ ä¸ªä¾›å¤§æ¨¡å‹äº†è§£æ ¼å¼ä»¥åŠä¾‹å­çš„å…·ä½“æ ·ä¾‹\n",
    "    example_prompt:å…·ä½“çš„æ¨¡ç‰ˆåŒ–åçš„æç¤ºæ¨¡ç‰ˆï¼Œè¿™ä¸ªå¯ä»¥å°±æ˜¯é€šè¿‡promptTemplateæ„å»ºçš„æç¤ºæ¨¡ç‰ˆï¼Œåªç­‰å¾…å¡«å…¥å…·ä½“çš„å˜é‡ï¼Œ\n",
    "å…¶æ ¼å¼å†…å®¹ä¸­å·²ç»å°†å¾…è¡¥å…¨çš„å˜é‡æ”¾åœ¨å…¶ä¸­\n",
    "    prefix:å‰ç¼€ï¼Œä¸€èˆ¬ä½œä¸ºå¤§æ¨¡å‹æ¥å—æŒ‡ä»¤çš„å…¥å£ï¼Œå¯ä»¥å»å£°æ˜å¤§æ¨¡å‹å³å°†æ‰¿æ‹…çš„è§’è‰²ä»¥åŠå‘Šè¯‰å¤§æ¨¡å‹å³å°†è¦åšçš„äº‹æƒ…ç­‰\n",
    "    suffix:åç¼€ï¼Œä¸€èˆ¬æ”¾ç½®äºæ ·ä¾‹ä¹‹åï¼Œä½œä¸ºæç¤ºæ¨¡ç‰ˆçš„æœ€åä¸€éƒ¨åˆ†\n",
    "    input_variables:å¡«è¡¥çš„å˜é‡\n",
    "    example_separator:åˆ†å‰²ç¬¦ï¼Œåˆ†å‰²å‰ç¼€ã€æ ·ä¾‹å’Œåç¼€çš„æ ‡å¿—\n",
    "'''\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=few_examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Word: {input}\\nAntonym:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format(input=\"big\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ä»prompt templateä¸­é€‰å–ä¾‹å­\n",
    "ä¸Šé¢é‚£ä¸ªä»£ç æ¡ˆä¾‹ä¸­æä¾›çš„æ˜¯å°‘é‡æ ·æœ¬ç¤ºä¾‹ï¼Œå¦‚æœæœ‰éå¸¸å¤šå¯ä¾›LLMå‚è€ƒçš„ä¾‹å­æ—¶ï¼Œä½¿ç”¨ExampleSelectorç±»æ¥å¯æ§åˆ¶åœ°é€‰æ‹©å‡ ä¸ªæœ€å¥½çš„ä¾‹å­ä¾›LLMå­¦ä¹ ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨LengthBasedExampleSelectoré€‰æ‹©ä¸€å®šé•¿è¾“å…¥çš„ä¾‹å­ï¼Œå®ƒæ˜¯ä¸€ä¸ªè‡ªåŠ¨é€‰æ‹©ä¾‹å­çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å…·ä½“æ¥çœ‹ï¼š**å¦‚æœç”¨æˆ·æ‹…å¿ƒpromptè¶…è¿‡è¾“å…¥çª—å£å¤§å°æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚å½“ç”¨æˆ·è¾“å…¥å¾ˆé•¿æ—¶ï¼Œå®ƒè‡ªåŠ¨é€‰æ‹©å°‘é‡çš„ä¾‹å­ï¼›å½“ç”¨æˆ·è¾“å…¥å¾ˆçŸ­æ—¶ï¼Œå®ƒé€‰æ‹©æ›´å¤šçš„ä¾‹å­ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Word: energetic\n",
      "Antonym: lethargic\n",
      "\n",
      "\n",
      "\n",
      "Word: big\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "#ä¾ç„¶å’Œä¸Šé¢ä¸€æ ·ï¼Œåä¹‰è¯å¯¹å„¿çš„ç»„åˆï¼Œè¿™é‡Œç»™å‡ºä¸‹é¢å‡ ç§ï¼š\n",
    "few_examples = [\n",
    "    {\"word\": \"beautiful\", \"antonym\": \"ugly\"},\n",
    "    {\"word\": \"outgoing\", \"antonym\": \"incoming\"},\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "    {\"word\": \"energetic\", \"antonym\": \"lethargic\"},\n",
    "    {\"word\": \"sunny\", \"antonym\": \"gloomy\"},\n",
    "    {\"word\": \"windy\", \"antonym\": \"calm\"},\n",
    "]\n",
    "#æˆ‘ä»¬å®šä¹‰å¦‚ä¸‹çš„æç¤ºæ¨¡ç‰ˆ\n",
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "#æ¨¡ç‰ˆæ ¼å¼åŒ–æç¤ºæ¨¡ç‰ˆ\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "'''\n",
    "ä½¿ç”¨LengthBasedExampleSelectoré€‰æ‹©ä¾‹å­ã€‚\n",
    "å…¶ä¸­çš„examples:åŒä¸Šç¤ºä¾‹ä¸­çš„ä½œç”¨\n",
    "example_prompt:åŒä¸Šç¤ºä¾‹ä¸­çš„ä½œç”¨\n",
    "max_length:è¿™æ˜¯æ ¼å¼åŒ–åçš„ä¾‹å­çš„æœ€å¤§é•¿åº¦ã€‚é•¿åº¦ç”±ä¸‹é¢çš„get_text_lengthå‡½æ•°å†³å®šã€‚\n",
    "'''\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=few_examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=25,\n",
    ")\n",
    "\n",
    "#ç°åœ¨ä½¿ç”¨example_selectoræ¥åˆ›å»ºfewshotprompttemplate\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Word: {input}\\nAntonym:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "print(dynamic_prompt.format(input=\"big\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æ ¹æ®ä¸Šé¢çš„ä¾‹å­æˆ‘ä»¬çŸ¥é“ï¼šå½“è¾“å…¥é—®é¢˜å¾ˆé•¿æ—¶ï¼ŒLengthBasedExampleSelectorä¼šé€‰æ‹©æ›´å°‘çš„æç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "long_string = \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\"\n",
    "print(dynamic_prompt.format(input=long_string))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### chat model prompt template\n",
    "ä¸‹é¢çš„ç¤ºä¾‹æ˜¯åˆ©ç”¨prompt templateåœ¨chat modelä¸­ä½¿ç”¨çš„æƒ…å†µï¼šchat modelå¯ä»¥ä½¿ç”¨ä»¥å‰çš„å†å²ä¿¡æ¯è¿›è¡Œå•æ¬¡ç”Ÿæˆå›å¤ï¼Œå•æ¬¡è¾“å…¥åŒ…å«äº†è¿‡å»èŠå¤©ä¸­çš„ä¸€ç³»åˆ—æ¨¡æ¿ã€ä¾‹å­ã€ç”¨æˆ·é—®é¢˜çš„ç»„åˆã€‚LangChainæä¾›äº†ä¸€äº›ç±»å’Œæ–¹æ³•ä½¿å¾—æ„å»ºå’Œä½¿ç”¨promptæ›´åŠ å®¹æ˜“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ChatPromptTemplateå¯ä»¥ä½¿ç”¨ä¸€ä¸ªæˆ–è€…å¤šä¸ªMessagePromptTemplateç±»æ„å»ºpromptã€‚å¯ä»¥ä½¿ç”¨ChatPromptTemplateçš„format_promptå‡½æ•°è¿”å›promptå€¼ï¼Œç„¶åå°†å…¶è½¬åŒ–ä¸ºstringæˆ–messageå¯¹è±¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "system_template=\"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}),\n",
       " HumanMessage(content='I love programming.', additional_kwargs={})]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "# ä»æ ¼å¼åŒ–çš„ä¿¡æ¯ä¸­è·å–å®Œæ•´çš„èŠå¤©ä¿¡æ¯\n",
    "chat_prompt.format_prompt(input_language=\"English\", output_language=\"French\", text=\"I love programming.\").to_messages()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸‹é¢æ˜¯ä¸€ç§å¿«é€Ÿæ„å»ºMessagePromptTemplateçš„æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "    input_variables=[\"input_language\", \"output_language\"],\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example Selectors\n",
    "æ ¹æ®æ¨¡å‹åŠŸèƒ½éœ€è¦åŠ¨æ€é€‰æ‹©æç¤ºè¯\n",
    "LangChainä¸­çš„BaseExampleSelectorç±»ç”¨äºé€‰æ‹©ä¾‹å­ï¼Œselect_exampleså‡½æ•°æ¥æ”¶è¾“å…¥å˜é‡å¹¶è¿”å›ä¸€ç³»åˆ—ä¾‹å­ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### åŸºæœ¬æ¥å£å®šä¹‰å¦‚ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict,List\n",
    "'''å®ƒæ˜¯ä¸€ä¸ªæŠ½è±¡åŸºç±»ï¼Œä¸èƒ½è¢«ç¤ºä¾‹åŒ–ï¼Œè€Œæ˜¯ç”¨äºå®šä¹‰å…¶ä»–ç±»çš„æ¥å£å’Œè§„èŒƒ'''\n",
    "class BaseExampleSelector(ABC):\n",
    "    \"\"\"\n",
    "    è¿™æ˜¯ä¸€ä¸ªæŠ½è±¡æ–¹æ³•ï¼Œç”±æ´¾ç”Ÿç±»å®ç°ï¼Œä»¥æ»¡è¶³BaseExampleSelectoræ¥å£çš„è¦æ±‚ï¼Œè¿™ä¸ªæ–¹æ³•æ˜¯æ ¹æ®è¾“å…¥å˜é‡é€‰æ‹©è¦åŒ…å«åœ¨æç¤ºä¸­çš„ç¤ºä¾‹ï¼Œè¿”å›ä¸€ä¸ªå­—å…¸åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def select_examples(self, input_variables: Dict[str, str]) -> List[dict]:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸€ä¸ªExampleSelectorç±»å¿…é¡»å®ç°ä¸¤ä¸ªæ–¹æ³•ï¼š\n",
    "- 1. add_exampleæ–¹æ³•æ¥å—ä¸€ä¸ªä¾‹å­å°†å…¶æ·»åŠ åˆ°exampleåˆ—è¡¨ä¸­\n",
    "- 2. select_exampleså‘Šè¯‰é€‰æ‹©å™¨å¦‚ä½•é€‰æ‹©ä¾‹å­å¹¶è¿”å›ä¾‹å­\n",
    "\n",
    "å› æ­¤åœ¨ä¸€ä¸ªç¤ºä¾‹é€‰æ‹©å™¨ä¸­å¯ä»¥éšæ—¶è°ƒç”¨ä¸Šè¿°ä¸¤ç§æ–¹æ³•ï¼Œä¸‹é¢å®ç°ä¸€ä¸ªè‡ªå®šä¹‰çš„example selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "class CustomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples: List[Dict[str, str]]):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example: Dict[str, str]) -> None:\n",
    "        \"\"\"æ·»åŠ æ–°çš„ä¾‹å­æ¥å­˜å‚¨ä¸€ä¸ªé”®\"\"\"\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables: Dict[str, str]) -> List[dict]:\n",
    "        \"\"\"æ ¹æ®è¾“å…¥çš„ä¿¡æ¯é€‰æ‹©è¦ä½¿ç”¨çš„ä¾‹å­\"\"\"\n",
    "        return np.random.choice(self.examples, size=2, replace=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä½¿ç”¨è‡ªå®šä¹‰çš„example selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'foo': '1'}, {'foo': '3'}], dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "examples = [\n",
    "    {\"foo\": \"1\"},\n",
    "    {\"foo\": \"2\"},\n",
    "    {\"foo\": \"3\"}\n",
    "]\n",
    "\n",
    "# åˆå§‹åŒ–ç¤ºä¾‹é€‰æ‹©å™¨\n",
    "example_selector = CustomExampleSelector(examples)\n",
    "# é€‰æ‹©ç¤ºä¾‹\n",
    "example_selector.select_examples({\"foo\": \"foo\"})\n",
    "# å°†æ–°çš„ä¾‹å­æ·»åŠ åˆ°ä¾‹å­é›†ä¸­\n",
    "example_selector.add_example({\"foo\": \"4\"})\n",
    "example_selector.examples\n",
    "# é€‰æ‹©ç¤ºä¾‹\n",
    "example_selector.select_examples({\"foo\": \"foo\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### åŸºäºé•¿åº¦çš„ç¤ºä¾‹é€‰æ‹©å™¨\n",
    "LengthBased ExampleSelectoræ ¹æ®ç”¨æˆ·è¾“å…¥è‡ªåŠ¨é€‰æ‹©ä¸€å®šæ•°é‡çš„ç¤ºä¾‹ï¼›ä½¿æ€»é•¿åº¦ä¸è¶…è¿‡LLMè¾“å…¥çª—å£å¤§å°ã€‚ä¸‹é¢çš„ç¤ºä¾‹æˆ‘ä»¬ä¸Šé¢å°±é‡åˆ°è¿‡ï¼Œç°åœ¨æˆ‘ä»¬èµ°åˆ°è¿™é‡Œå†çœ‹ä¸€ä¸‹è¿™ä¸ªä»£ç ç¤ºä¾‹ï¼Œæ˜¯å¦æ›´åŠ äº†è§£å®ƒçš„åŸç†ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "# è¿™äº›æ˜¯å¾ˆå¤šå…³äºåˆ›é€ åä¹‰è¯çš„ä¾‹å­ã€‚\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=25,\n",
    ")\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: tall\n",
      "Output: short\n",
      "\n",
      "Input: energetic\n",
      "Output: lethargic\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: windy\n",
      "Output: calm\n",
      "\n",
      "Input: big\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(dynamic_prompt.format(adjective=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "long_string = \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\"\n",
    "print(dynamic_prompt.format(adjective=long_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: tall\n",
      "Output: short\n",
      "\n",
      "Input: energetic\n",
      "Output: lethargic\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: windy\n",
      "Output: calm\n",
      "\n",
      "Input: big\n",
      "Output: small\n",
      "\n",
      "Input: enthusiastic\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# You can add an example to an example selector as well.\n",
    "new_example = {\"input\": \"big\", \"output\": \"small\"}\n",
    "dynamic_prompt.example_selector.add_example(new_example)\n",
    "print(dynamic_prompt.format(adjective=\"enthusiastic\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç›¸ä¼¼æ€§é€‰æ‹©å™¨\n",
    "Similarity Example Selectoræ ¹æ®ä¾‹å­å’Œè¾“å…¥çš„ç›¸ä¼¼ç¨‹åº¦æ¥é€‰æ‹©ä¾‹å­ã€‚è¯¥é€‰æ‹©å™¨æ ¹æ®ä¾‹å­å’Œè¾“å…¥çš„è¯åµŒå…¥å‘é‡çš„ä½™å¼¦ç›¸ä¼¼æ€§æ¥å·¥ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# è¿™äº›æ˜¯å¾ˆå¤šå…³äºåˆ›é€ åä¹‰è¯çš„ä¾‹å­ã€‚\n",
    "few_examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # è¿™æ˜¯å¯ä»¥é€‰æ‹©çš„ä¾‹å­æ¸…å•ã€‚\n",
    "    few_examples,\n",
    "    # è¿™é‡Œä½¿ç”¨OpenAIçš„åµŒå…¥æ–¹æ³•ï¼Œç”¨äºäº§ç”ŸåµŒå…¥ï¼Œè€ŒåµŒå…¥æ˜¯ç”¨æ¥è¡¡é‡è¯­ä¹‰ç›¸ä¼¼æ€§çš„ã€‚\n",
    "    OpenAIEmbeddings(),\n",
    "    # è¿™æ˜¯VectorStoreç±»ï¼Œç”¨äºå­˜å‚¨åµŒå…¥å¹¶è¿›è¡Œç›¸ä¼¼åº¦æœç´¢ã€‚\n",
    "    Chroma,\n",
    "    # è¿™æ˜¯è¦äº§ç”Ÿçš„ä¾‹å­çš„æ•°é‡ã€‚\n",
    "    k=1\n",
    ")\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: worried\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(similar_prompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: fat\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(similar_prompt.format(adjective=\"fat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: joyful\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# æ‚¨ä¹Ÿå¯ä»¥å‘SimilarityExampleSelectoræ·»åŠ æ–°çš„ç¤ºä¾‹ã€‚\n",
    "similar_prompt.example_selector.add_example({\"input\": \"enthusiastic\", \"output\": \"apathetic\"})\n",
    "print(similar_prompt.format(adjective=\"joyful\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Output Parser\n",
    "è¾“å‡ºè§£æå™¨ï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯å°†è¾“å‡ºç­”æ¡ˆè¿›è¡Œè§£æï¼Œå®ƒæŒ‡ç¤ºæ¨¡å‹å»æ ¼å¼åŒ–è¾“å‡ºå†…å®¹ï¼Œå°†è¾“å‡ºè§£æä¸ºéœ€è¦çš„æ ¼å¼ã€‚\n",
    "Output parsersç±»ç»“æ„åŒ–æ¨¡å‹çš„å“åº”ä¿¡æ¯ã€‚ä¾‹å¦‚æˆ‘ä»¬æå‰å®šä¹‰å¥½è¾“å‡ºçš„å½¢å¼åº”è¯¥åŒ…æ‹¬Aå±æ€§å’ŒBå±æ€§ï¼Œå¦‚æœæ­£å¸¸æŠŠæé—®é€ç»™å¤§æ¨¡å‹ï¼Œå¤§æ¨¡å‹æ˜¯ä¸ä¼šç»™ä½ æŒ‡å®šå‡ºç‰¹åˆ«ä¸¥æ ¼åˆ’åˆ†ä¹‹åçš„ç­”æ¡ˆçš„ï¼Œå› æ­¤æŠŠè¿™ç§ç­”æ¡ˆè¿›è¡Œè§£æå¤„ç†è¿›ä¸€æ­¥ç»™åˆ°ç”¨æˆ·ï¼Œç”¨æˆ·å¯ä»¥ç”¨è§£æå¤„ç†ä¹‹åçš„ç»“æœå»åšæ›´æ–¹ä¾¿çš„åº”ç”¨æˆ–è€…å°±å·²ç»è¾¾åˆ°ç”¨æˆ·çš„ç›®çš„ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸‹é¢æ˜¯å…³äºPydanticOutputParserçš„ä¸€ä¸ªç¤ºä¾‹è¯´æ˜ï¼ŒPydanticOutputParserèƒ½å¤Ÿè®©LLMè¾“å‡ºç¬¦åˆJSONæ ¼å¼çš„å›å¤ã€‚è¯¥åŠŸèƒ½æ•ˆæœå’ŒLLMç”Ÿæˆèƒ½åŠ›ç›¸å…³ã€‚\n",
    "ä¸‹é¢æ˜¯ä½¿ç”¨PydanticOutputParserçš„ä¾‹å­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#æŒ‡å®šä½¿ç”¨çš„å¤§æ¨¡å‹\n",
    "model_name = 'text-davinci-003'\n",
    "#è®¾ç½®å¯¹åº”çš„éšæœºæ€§\n",
    "temperature = 0.0\n",
    "#modelå³æ˜¯è°ƒç”¨åˆ°çš„å¤§æ¨¡å‹\n",
    "model = OpenAI(model_name=model_name, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# å®šä¹‰ä½ æƒ³è¦çš„æ•°æ®ç»“æ„\n",
    "\"\"\"å®šä¹‰äº†ä¸€ä¸ªåä¸ºJokeçš„Pydanticæ¨¡å‹ç±»ï¼Œç”¨æ¥è¡¨ç¤ºä¸€ä¸ªç¬‘è¯ï¼Œç¤ºä¾‹åŒ–ä¹‹åç”¨äºæç¤ºå¤§æ¨¡å‹æ¥å¡«å……è¿™ä¸ªæ•°æ®ç»“æ„\"\"\"\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"\n",
    "    setup:å­—ç¬¦ä¸²ç±»å‹ï¼Œä½¿ç”¨Fieldå‡½æ•°æŒ‡å®šä¸€ä¸ªæè¿°å­—ç¬¦ä¸²ï¼Œè¯¥å±æ€§è¡¨ç¤ºç¬‘è¯çš„é—®é¢˜éƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯ç¬‘è¯çš„å¼€å¤´\n",
    "    punchline:å­—ç¬¦ä¸²ç±»å‹ï¼ŒåŒæ ·ä½¿ç”¨Fieldå‡½æ•°æŒ‡å®šä¸€ä¸ªæè¿°å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºç¬‘è¯çš„ç­”æ¡ˆéƒ¨åˆ†ä¹Ÿå°±æ˜¯ç¬‘è¯çš„ç»“å°¾\n",
    "    \"\"\"\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "    # ä½ å¯ä»¥ç”¨Pydanticè½»æ¾åœ°æ·»åŠ è‡ªå®šä¹‰é€»è¾‘ç»“æ„ã€‚\n",
    "    \"\"\"\n",
    "    è£…é¥°å™¨æˆåˆ†ï¼Œç”¨äºæ ‡è®°æ¥ä¸‹æ¥çš„æ–¹æ³•æ˜¯ä¸€ä¸ªéªŒè¯å™¨ï¼ŒéªŒè¯å™¨æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œæ¥å—ä¸€ä¸ªå­—æ®µå€¼ï¼Œå¹¶è¿”å›ä¸€ä¸ªç»è¿‡éªŒè¯çš„å€¼ï¼Œè¿™é‡Œæ ‡è®°çš„å°±æ˜¯\n",
    "    question_ends_with_question_markæ–¹æ³•æ˜¯ä¸€ä¸ªéªŒè¯å™¨ï¼Œå°†ä¼šç”¨äºsetupå±æ€§\n",
    "    \"\"\"\n",
    "    @validator('setup')\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != '?':\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#å‚æ•°å€¼æ˜¯ä¹‹å‰å®šä¹‰çš„jokeç±»ï¼Œparserå¯¹è±¡çš„ä½œç”¨æ˜¯æŠŠè¾“å‡ºç»“æœè§£ææˆä¸€ä¸ªjokeå¯¹è±¡\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "prompttemplateçš„ä¸¤ä¸ªæ¨¡ç‰ˆå‚æ•°å ä½ç¬¦æ˜¯format_instructionså’Œqueryï¼Œä½†æ˜¯æŒ‡å®šçš„input_variablesæ˜¯query,\n",
    "è€Œpartial_variablesåˆ™æ˜¯æŒ‡å®šä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«äº†é”®ä¸ºformat_instructionsçš„å˜é‡ä¿¡æ¯ï¼Œè¿™ä¸ªå€¼æ˜¯ä¹‹å‰å®šä¹‰çš„parserå¯¹è±¡\n",
    "è°ƒç”¨get_format_instructionsæ–¹æ³•è¿”å›çš„æ ¼å¼è¯´æ˜å­—ç¬¦ä¸²\n",
    "'''\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# å°†ç”¨æˆ·çš„queryä¼ å…¥æç¤ºæ¨¡ç‰ˆä¸­\n",
    "joke_query = \"Tell me a joke.\"\n",
    "_input = prompt.format_prompt(query=joke_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output = model(_input.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸‹é¢æ˜¯å¦å¤–ä¸€ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬æ¥ç€çœ‹ä¸€ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Cast Away', 'Toy Story'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ä¸‹é¢è¿™æ®µä»£ç å®šä¸€ä¸ªäº†ä¸€ä¸ªåä¸ºactorçš„æ•°æ®ç»“æ„ï¼Œå®ƒä¹Ÿæ˜¯åŸºäºbasemodelç±»åˆ›å»ºçš„ï¼Œè¿™ä¸ªactoræœ‰ä¸¤ä¸ªå±æ€§ï¼Œåˆ†åˆ«æ˜¯name\n",
    "å’Œfile_namesï¼Œç”¨æ¥è¡¨ç¤ºå§“åå’Œæ¼”å‘˜å‡ºæ¼”çš„ç”µå½±åˆ—è¡¨ï¼Œè¿™ä¸¤ä¸ªå±æ€§ä¸Šï¼ŒåŒæ ·é€‚ç”¨fieldç±»ï¼Œä¸ºä¸¤è€…åˆ†åˆ«æŒ‡å®šäº†descriptionå±æ€§ï¼Œç”¨æ¥\n",
    "æè¿°è¿™ä¸¤ä¸ªå±æ€§çš„ä½œç”¨ã€‚\n",
    "å…¶ä¸­ï¼š\n",
    "    actor_query:ç”¨æˆ·è¾“å…¥çš„é—®é¢˜\n",
    "    parser:PydanticOutputParserç±»å®ä¾‹ï¼Œä½œç”¨æ˜¯å°†è¾“å‡ºçš„ç»“æœè§£ææˆä¸€ä¸ªactorå¯¹è±¡\n",
    "    prompt: prompttemplateç±»å®ä¾‹ï¼ŒåŒ…å«ä¸€ä¸ªå­—ç¬¦ä¸²æ¨¡ç‰ˆå’Œä¸€äº›å˜é‡\n",
    "\"\"\"\n",
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "actor_query = \"Generate the filmography for a random actor.\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=actor_query)\n",
    "\n",
    "output = model(_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Index\n",
    "è¯¥æ¨¡å—ç”¨äºæ¥å—ç”¨æˆ·æŸ¥è¯¢ï¼Œè¿”å›æœ€ç›¸å…³æ¦‚å¿µã€‚\n",
    "è¿™é‡ŒLangChainä¸»è¦åœ¨é’ˆå¯¹ç”¨æˆ·æä¾›çš„æ–‡æ¡£æ„å»ºç´¢å¼•ï¼Œå°†ç´¢å¼•ç»„åˆæˆæ£€ç´¢å™¨ï¼›ç„¶åå¯ä»¥å»ºç«‹ä¸€ä¸ªé—®ç­”é“¾ç”¨äºæ¨¡å‹æé—®å›ç­”ã€‚\n",
    "LangChainä½¿ç”¨chromadbæ„å»ºå‘é‡æ± vectorstoreï¼Œå‘é‡æ± ç”¨äºæ£€ç´¢å’ŒæŸ¥æ‰¾è¯åµŒå…¥ã€‚\n",
    "\n",
    "è¯¦ç»†æ–‡æ¡£è¯´æ˜ç‚¹å‡»ğŸ‘‰[æ­¤å¤„](https://python.langchain.com/en/latest/modules/indexes.html)ğŸ‘ˆç›´æ¥è®¿é—®ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "äº†è§£ç´¢å¼•åŸºæœ¬æ¦‚å¿µä¹Ÿå¾ˆé‡è¦ï¼Œä¸‹é¢æ˜¯ç´¢å¼•å™¨Retrieverçš„æ¥å£ï¼Œç”¨æˆ·å¯ä»¥è‡ªå·±å®ç°å¦‚ä½•è¿”å›ç›¸å…³æ–‡æ¡£ã€‚LangChainå…³æ³¨äºä½¿ç”¨Vectorstore retrieverè¿›è¡Œæ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "\"\"\"\n",
    "å®šä¹‰äº†ä¸€ä¸ªåä¸ºBaseRetrieverçš„æŠ½è±¡åŸºç±»ï¼Œç»§æ‰¿è‡ªABCã€‚è¯¥ç±»åŒ…å«äº†ä¸€ä¸ªåä¸ºget_relevant_documentsçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„\n",
    "å‚æ•°query,å¹¶è¿”å›ä¸€ä¸ªæ–‡æ¡£åˆ—è¡¨(List[Document])ã€‚æ³¨é‡Šä¸­æåˆ°äº†abstractmethodè£…é¥°å™¨ï¼Œè¿™è¡¨ç¤ºget_relevant_documentsæ–¹æ³•æ˜¯ä¸€ä¸ªæŠ½è±¡æ–¹\n",
    "æ³•ï¼Œå­ç±»å¿…é¡»å®ç°è¯¥æ–¹æ³•ã€‚\n",
    "\"\"\"\n",
    "class BaseRetriever(ABC):\n",
    "    #è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯æ ¹æ®è¾“å…¥çš„æŸ¥è¯¢è¯­å¥(query)è·å–ç›¸å…³çš„æ–‡æœ¬å†…å®¹ã€‚è¿”å›å€¼ä¸ºä¸€ä¸ªæ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£éƒ½æ˜¯ä¸€ä¸ªDocumentå¯¹è±¡ã€‚\n",
    "    @abstractmethod\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"Get texts relevant for a query.\n",
    "\n",
    "        Args:\n",
    "            query: string to find relevant texts for\n",
    "\n",
    "        Returns:\n",
    "            List of relevant documents\n",
    "        \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "è¿™é‡Œå…ˆåŠ è½½éœ€è¦çš„æ–‡æ¡£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "#ç”¨äºä»æ–‡ä»¶ä¸­åŠ è½½æ–‡æœ¬æ•°æ®ã€‚å…¶ä¸­ï¼Œå‚æ•°'state_of_the_union.txt'è¡¨ç¤ºè¦åŠ è½½çš„æ–‡ä»¶åï¼Œ\n",
    "#encoding='utf-8'è¡¨ç¤ºæ–‡ä»¶çš„ç¼–ç æ ¼å¼ä¸ºUTF-8ã€‚å…·ä½“æ¥è¯´ï¼Œ\n",
    "#ä½œç”¨æ˜¯å°†æ–‡ä»¶state_of_the_union.txtä¸­çš„å†…å®¹è¯»å–åˆ°å†…å­˜ä¸­ï¼Œå¹¶ä»¥å­—ç¬¦ä¸²çš„å½¢å¼å­˜å‚¨åœ¨å˜é‡loaderä¸­ã€‚\n",
    "loader = TextLoader('state_of_the_union.txt',encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "åˆ›å»ºç´¢å¼•"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸‹é¢çš„è¯­å¥ä½¿ç”¨VectorstoreIndexCreatorç›´æ¥åˆ›å»ºç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VectorstoreIndexCreatorç±»ç”¨äºåˆ›å»ºå‘é‡ç©ºé—´ç´¢å¼•(Vector Space Index)ã€‚é€šè¿‡è°ƒç”¨from_loadersæ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªåä¸ºindexçš„å¯¹è±¡ï¼Œ\n",
    "è¯¥æ–¹æ³•æ¥å—ä¸€ä¸ªå‚æ•°åˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­åªåŒ…å«ä¸€ä¸ªå…ƒç´ ï¼Œå³ä¹‹å‰æåˆ°çš„TextLoaderå¯¹è±¡loaderã€‚from_loadersæ–¹æ³•çš„ä½œç”¨æ˜¯å°†å¤šä¸ªæ–‡æœ¬æ•°æ®åŠ è½½å™¨(TextLoader)\n",
    "å°è£…æˆä¸€ä¸ªå‘é‡ç©ºé—´ç´¢å¼•å¯¹è±¡ã€‚å› æ­¤ï¼Œindexçš„ä½œç”¨æ˜¯å°†state_of_the_union.txtæ–‡ä»¶ä¸­çš„å†…å®¹è¯»å–åˆ°å†…å­˜ä¸­ï¼Œå¹¶ä»¥å­—ç¬¦ä¸²çš„å½¢å¼å­˜å‚¨åœ¨å˜é‡loaderä¸­ï¼Œç„¶å\n",
    "ä½¿ç”¨VectorstoreIndexCreatorç±»å°†å…¶å°è£…æˆä¸€ä¸ªå‘é‡ç©ºé—´ç´¢å¼•å¯¹è±¡indexã€‚\n",
    "\"\"\"\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ç°åœ¨ç´¢å¼•å»ºç«‹äº†ï¼Œå°±å¯ä»¥å¼€å§‹æ ¹æ®æ–‡æ¡£é—®é—®é¢˜äº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The president said that Ketanji Brown Jackson is one of the nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also said that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\""
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What did the president say about Ketanji Brown Jackson',\n",
       " 'answer': \" The president said that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson, one of the nation's top legal minds, to continue Justice Breyer's legacy of excellence, and that she has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\\n\",\n",
       " 'sources': 'state_of_the_union.txt'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "index.query_with_sources(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "å¦‚æœåªæ˜¯æƒ³è®¿é—®vectorstoreï¼Œå¯ä»¥è¿™æ ·åš"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.chroma.Chroma at 0x18fa13c05b0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.vectorstore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æˆ–è€…æƒ³è®¿é—®VectorstoreRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x0000018FA13C05B0>, search_type='similarity', search_kwargs={})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.vectorstore.as_retriever()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸Šé¢æ˜¯ç”¨ç´¢å¼•æŸ¥è¯¢çš„ä¾‹å­ï¼Œé‚£ä¹ˆç´¢å¼•æ˜¯æ€ä¹ˆåˆ›å»ºçš„å‘¢ï¼Œæœ‰3æ­¥ï¼š\n",
    "1.å°†æ–‡æ¡£åˆ’åˆ†æˆå—\n",
    "2.å¯¹æ¯å—åˆ›å»ºè¯åµŒå…¥\n",
    "3.å°†æ–‡æ¡£å’Œè¯åµŒå…¥å­˜åœ¨å‘é‡æ± ä¸­\n",
    "ä¸‹é¢ä¼šä¸€æ­¥æ­¥å±•ç¤º"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "åŠ è½½æ–‡æ¡£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æ–‡æ¡£åˆ‡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\"\"\"\n",
    "CharacterTextSplitterç±»ç”¨äºå°†æ–‡æœ¬æ•°æ®æŒ‰ç…§æŒ‡å®šçš„å¤§å°è¿›è¡Œåˆ’åˆ†(chunking)ã€‚æ¥ä¸‹æ¥ï¼Œä»£ç é€šè¿‡è°ƒç”¨split_documentsæ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªåä¸º\n",
    "text_splitterçš„å¯¹è±¡ï¼Œè¯¥æ–¹æ³•æ¥å—ä¸¤ä¸ªå‚æ•°ï¼šchunk_sizeè¡¨ç¤ºæ¯ä¸ªæ–‡æ¡£è¢«åˆ’åˆ†æˆçš„å¤§å°ï¼Œchunk_overlapè¡¨ç¤ºæ–‡æ¡£ä¹‹é—´çš„é‡å å¤§å°ã€‚chunk_sizeè¢«\n",
    "è®¾ç½®ä¸º1000,chunk_overlapè¢«è®¾ç½®ä¸º0ã€‚ç„¶åï¼Œä»£ç è°ƒç”¨split_documentsæ–¹æ³•æ¥å°†documentsåˆ—è¡¨ä¸­çš„æ–‡æ¡£æŒ‰ç…§æŒ‡å®šçš„å¤§å°è¿›è¡Œåˆ’åˆ†ï¼Œå¹¶è¿”å›ä¸€ä¸ªåŒ…\n",
    "å«æ‰€æœ‰åˆ’åˆ†åæ–‡æ¡£çš„åˆ—è¡¨textsã€‚å…·ä½“æ¥è¯´ï¼Œsplit_documentsæ–¹æ³•çš„ä½œç”¨æ˜¯å°†ä¸€ä¸ªæ–‡æœ¬åˆ—è¡¨æŒ‰ç…§æŒ‡å®šçš„å¤§å°è¿›è¡Œåˆ’åˆ†ï¼Œå¹¶è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰åˆ’åˆ†åæ–‡æ¡£çš„\n",
    "åˆ—è¡¨ã€‚\n",
    "\"\"\"\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æ ¹æ®éœ€è¦ä»åˆé€‚çš„è¯åµŒå…¥æ–¹æ³•ä¸­é€‰ä¸€ä¸ªè¿›è¡Œè¯åµŒå…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸‹é¢ç”¨è¯åµŒå…¥å’Œå—åˆ›å»ºå‘é‡æ± "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\"\"\"\n",
    "Chromaç±»ç”¨äºå°†å‘é‡ç©ºé—´ç´¢å¼•(Vector Space Index)ä¸æ–‡æœ¬æ•°æ®ç»“åˆèµ·æ¥ï¼Œä»¥å®ç°å¯¹æ–‡æœ¬æ•°æ®çš„å‘é‡åŒ–è¡¨ç¤ºã€‚æ¥ä¸‹æ¥ï¼Œä»£ç é€šè¿‡è°ƒç”¨\n",
    "from_documentsæ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªåä¸ºdbçš„å¯¹è±¡ï¼Œè¯¥æ–¹æ³•æ¥å—ä¸¤ä¸ªå‚æ•°ï¼štextså’Œembeddingsã€‚å…¶ä¸­ï¼Œtextsæ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ–‡æœ¬æ•°æ®çš„åˆ—è¡¨ï¼Œ\n",
    "embeddingsæ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰å‘é‡æ•°æ®çš„äºŒç»´æ•°ç»„ã€‚from_documentsæ–¹æ³•çš„ä½œç”¨æ˜¯å°†æŒ‡å®šçš„æ–‡æœ¬æ•°æ®å’Œå‘é‡æ•°æ®ç»“åˆèµ·æ¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰\n",
    "æ–‡æ¡£å‘é‡çš„äºŒç»´æ•°ç»„ã€‚å…·ä½“æ¥è¯´ï¼Œfrom_documentsæ–¹æ³•çš„ä½œç”¨æ˜¯å°†æŒ‡å®šçš„æ–‡æœ¬æ•°æ®å’Œå‘é‡æ•°æ®ç»“åˆèµ·æ¥ï¼Œä»¥å®ç°å¯¹æ–‡æœ¬æ•°æ®çš„å‘é‡åŒ–è¡¨ç¤ºã€‚texts\n",
    "æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ–‡æœ¬æ•°æ®çš„åˆ—è¡¨ï¼Œembeddingsæ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰å‘é‡æ•°æ®çš„äºŒç»´æ•°ç»„ã€‚\n",
    "\"\"\"\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ç„¶ååˆ›å»ºç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è°ƒç”¨dbå¯¹è±¡çš„as_retrieveræ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªåä¸ºretrieverçš„å¯¹è±¡ã€‚\n",
    "è¯¥æ–¹æ³•çš„ä½œç”¨æ˜¯å°†dbå¯¹è±¡è½¬æ¢ä¸ºä¸€ä¸ªæ£€ç´¢å™¨(retriever),ä»¥ä¾¿åœ¨åç»­çš„è®¡ç®—ä¸­ä½¿ç”¨ã€‚\n",
    "retrieverå°†è¢«ç”¨äºä»æ•°æ®åº“ä¸­æ£€ç´¢ä¸ç»™å®šæŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£å‘é‡ã€‚\n",
    "\"\"\"\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æ¥ä¸‹æ¥åˆ›å»ºä¸€ä¸ªé“¾å¹¶é—®é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The President said that Ketanji Brown Jackson is one of the nation's top legal minds and that she will continue Justice Breyer's legacy of excellence.\""
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "RetrievalQAç±»ç”¨äºå®ç°åŸºäºæ£€ç´¢å™¨çš„é—®ç­”(Question Answering)ä»»åŠ¡ã€‚æ¥ä¸‹æ¥ï¼Œä»£ç é€šè¿‡è°ƒç”¨from_chain_typeæ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªåä¸ºqaçš„å¯¹è±¡ï¼Œ\n",
    "è¯¥æ–¹æ³•æ¥å—ä¸‰ä¸ªå‚æ•°ï¼šllmã€chain_typeå’Œretrieverã€‚å…¶ä¸­ï¼Œllmè¡¨ç¤ºè¯­è¨€æ¨¡å‹(Language Model),chain_typeè¡¨ç¤ºæŸ¥è¯¢ç±»å‹(query type),\n",
    "retrieverè¡¨ç¤ºæ£€ç´¢å™¨(retriever)ã€‚from_chain_typeæ–¹æ³•çš„ä½œç”¨æ˜¯æ ¹æ®æŒ‡å®šçš„æŸ¥è¯¢ç±»å‹å’Œæ£€ç´¢å™¨åˆ›å»ºä¸€ä¸ªåä¸ºqaçš„å¯¹è±¡ï¼Œä»¥ä¾¿åœ¨åç»­çš„è®¡ç®—ä¸­ä½¿ç”¨ã€‚\n",
    "llmè¢«è®¾ç½®ä¸ºOpenAI(),chain_typeè¢«è®¾ç½®ä¸º\"stuff\",retrieverè¢«è®¾ç½®ä¸ºä¹‹å‰åˆ›å»ºçš„retrieverå¯¹è±¡ã€‚\n",
    "\"\"\"\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "\"\"\"\n",
    "runæ–¹æ³•å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼šé¦–å…ˆä»æ•°æ®åº“ä¸­æ£€ç´¢ä¸ç»™å®šæŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£å‘é‡ï¼›ç„¶åå°†ç”¨æˆ·è¾“å…¥çš„é—®é¢˜ä¸æ¯ä¸ªæ–‡æ¡£å‘é‡è¿›è¡ŒåŒ¹é…ï¼Œæ‰¾åˆ°æœ€ä½³çš„æ–‡æ¡£å‘é‡ä½œä¸ºç­”æ¡ˆï¼›\n",
    "æœ€åå°†ç­”æ¡ˆå°è£…æˆä¸€ä¸ªä¸‰å…ƒç»„è¿”å›ç»™ç”¨æˆ·ã€‚\n",
    "\"\"\"\n",
    "qa.run(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æ€»ç»“ä»¥ä¸Šè¿‡ç¨‹ï¼ŒVectorstoreIndexCreatorå°±æ˜¯åšäº†åˆ‡å—ï¼Œè¯åµŒå…¥ï¼Œåˆ›å»ºç´¢å¼•çš„è¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_creator = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=Chroma,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Memory\n",
    "\n",
    "Memoryæ¶‰åŠåœ¨ç”¨æˆ·ä¸è¯­è¨€æ¨¡å‹çš„æ•´ä¸ªäº¤äº’è¿‡ç¨‹ä¸­ä¿æŒçŠ¶æ€æ¦‚å¿µã€‚ç”¨æˆ·ä¸è¯­è¨€æ¨¡å‹çš„äº¤äº’åœ¨ ChatMessages çš„æ¦‚å¿µä¸­è¢«æ•è·ï¼Œå› æ­¤è¿™å½’ç»“ä¸ºä»ä¸€ç³»åˆ—èŠå¤©æ¶ˆ\n",
    "æ¯ä¸­æ‘„å–ã€æ•è·ã€è½¬æ¢å’Œæå–çŸ¥è¯†ã€‚æœ‰è®¸å¤šä¸åŒçš„æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œæ¯ä¸€\n",
    "ç§éƒ½æœ‰è‡ªå·±çš„å†…å­˜ç±»å‹ã€‚é€šå¸¸ï¼Œå¯¹äºæ¯ç§ç±»å‹çš„å†…å­˜ï¼Œæœ‰ä¸¤ç§ç†è§£ä½¿ç”¨å†…å­˜çš„æ–¹æ³•ã€‚è¿™äº›æ˜¯ä»ä¸€ç³»åˆ—æ¶ˆæ¯ä¸­æå–ä¿¡æ¯çš„ç‹¬ç«‹å‡½æ•°ï¼Œç„¶åæ‚¨å¯ä»¥åœ¨é“¾ä¸­ä½¿ç”¨è¿™ç§ç±»å‹çš„å†…å­˜ã€‚å†…å­˜å¯ä»¥è¿”å›å¤šæ¡ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œæœ€è¿‘çš„ N æ¡æ¶ˆæ¯å’Œä¹‹å‰æ‰€æœ‰æ¶ˆæ¯çš„æ‘˜è¦ï¼‰ã€‚è¿”å›çš„ä¿¡æ¯å¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–æ¶ˆæ¯åˆ—è¡¨ã€‚æˆ‘ä»¬å°†ä»‹ç»æœ€ç®€å•çš„å†…å­˜å½¢å¼ï¼šâ€œBufferâ€å†…å­˜ï¼Œå®ƒåªæ¶‰åŠä¿ç•™æ‰€æœ‰å…ˆå‰æ¶ˆæ¯çš„ç¼“å†²åŒºã€‚æˆ‘ä»¬å°†åœ¨è¿™é‡Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨æ¨¡å—åŒ–å®ç”¨å‡½æ•°ï¼Œç„¶åå±•ç¤ºå¦‚ä½•åœ¨é“¾ä¸­ä½¿ç”¨å®ƒï¼ˆæ—¢è¿”å›å­—ç¬¦ä¸²åˆè¿”å›æ¶ˆæ¯åˆ—è¡¨ï¼‰ã€‚\n",
    "\n",
    "LLMså’Œchat modelséƒ½æ˜¯æ— çŠ¶æ€çš„ï¼Œæ¯æ¬¡è¾“å…¥è¯·æ±‚éƒ½æ˜¯ç‹¬ç«‹çš„ï¼›Chainså’ŒAgentsåŸºäºåº•å±‚æ¨¡å—å¼€å‘ï¼Œä¹Ÿæ˜¯æ— çŠ¶æ€çš„ã€‚åœ¨ä¸€äº›åº”ç”¨ä¸­ï¼Œæ¯”å¦‚èŠå¤©æœºå™¨äººï¼Œè®©è¯­è¨€æ¨¡å‹çŸ¥é“ä¹‹å‰çš„èŠå¤©å†…å®¹å¾ˆé‡è¦ã€‚è¿™å°±æ˜¯Memoryæ¨¡å—å­˜åœ¨çš„æ„ä¹‰ã€‚\n",
    "\n",
    "LangChainæä¾›ä¸¤ç§memoryç»„ä»¶ï¼›ç¬¬ä¸€ï¼ŒLangChainæä¾›helper utilitiesè´Ÿè´£ç®¡ç†å’Œæ“ä½œä¹‹å‰çš„èŠå¤©ä¿¡æ¯ï¼›ç¬¬äºŒï¼ŒLangChainæä¾›å°†è¿™äº›ç¨‹åºåˆå¹¶åˆ°Chainsæ¨¡å—ä¸­çš„æ–¹æ³•ã€‚\n",
    "\n",
    "æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ä»¥åŠç¤ºä¾‹è¯´æ˜ï¼Œç‚¹å‡»ğŸ‘‰[LangChainå®˜ç½‘ç›´è¾¾](https://python.langchain.com/en/latest/index.html)ã€‚\n",
    "\n",
    "ä¸‹é¢æ˜¯æ·»åŠ Memoryçš„ä¸¤ä¸ªæ¡ˆä¾‹ï¼Œæ–¹ä¾¿å¿«é€Ÿäº†è§£ï¼š"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Add Memory to an LLMChain](#add-memory-to-an-llmchain)\n",
    "- [Add Memory to an Agent](#add-memory-to-an-agent)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ç”¨è¿™ä¸ªConversationBufferMemoryè¿›è¡Œä¸¾ä¾‹ï¼Œå› æ­¤å…ˆçœ‹ä¸€ä¸‹è¿™ä¸ªç±»æ˜¯ä»€ä¹ˆæ ·çš„ï¼š"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ConversationBufferMemory\n",
    "ConversationBufferMemoryå¯ä»¥å¸®åŠ©ç”¨æˆ·è½»æ¾åˆ›å»ºå¯¹è¯å†å²ï¼Œç”¨æ³•å¦‚ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\"\"\"\n",
    "ConversationBufferMemoryç±»ç”¨äºå®ç°åŸºäºè®°å¿†ç¼“å­˜(Memories)çš„å¯¹è¯ç³»ç»Ÿ(Conversational System)ã€‚æ¥ä¸‹æ¥ï¼Œä»£ç é€šè¿‡è°ƒç”¨\n",
    "from_memoryæ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªåä¸ºmemoryçš„å¯¹è±¡ï¼Œè¯¥æ–¹æ³•ä¸æ¥å—ä»»ä½•å‚æ•°ã€‚è¯¥æ–¹æ³•çš„ä½œç”¨æ˜¯æ ¹æ®é»˜è®¤é…ç½®åˆ›å»ºä¸€ä¸ªåä¸ºmemoryçš„å¯¹è±¡ï¼Œä»¥ä¾¿\n",
    "åœ¨åç»­çš„è®¡ç®—ä¸­ä½¿ç”¨ã€‚\n",
    "memoryå°†è¢«ç”¨äºå­˜å‚¨ç”¨æˆ·å’ŒAIä¹‹é—´çš„å¯¹è¯å†å²è®°å½•ã€‚\n",
    "ç„¶åï¼Œè°ƒç”¨memoryå¯¹è±¡çš„chat_memoryå±æ€§æ¥åˆ›å»ºä¸€ä¸ªåä¸ºchat_memoryçš„å¯¹è¯ç¼“å­˜(Conversation Buffer),å¹¶å‘å…¶æ·»åŠ ä¸¤æ¡æ¶ˆæ¯ï¼šä¸€æ¡\n",
    "æ˜¯ç”¨æˆ·å‘é€çš„æ¶ˆæ¯\"hi!\",å¦ä¸€æ¡æ˜¯AIå‘é€çš„æ¶ˆæ¯\"whats up?\"ã€‚å…·ä½“æ¥è¯´ï¼Œchat_memory.add_user_message()æ–¹æ³•çš„ä½œç”¨æ˜¯å°†ä¸€æ¡ç”¨æˆ·æ¶ˆ\n",
    "æ¯æ·»åŠ åˆ°å¯¹è¯ç¼“å­˜ä¸­ï¼›è€Œchat_memory.add_ai_message()æ–¹æ³•çš„ä½œç”¨æ˜¯å°†ä¸€æ¡AIæ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯ç¼“å­˜ä¸­ã€‚è¿™æ ·ï¼ŒèŠå¤©å†å²è®°å½•å°±è¢«æˆåŠŸåœ°æ·»åŠ \n",
    "åˆ°äº†å¯¹è¯ç¼“å­˜ä¸­ã€‚\n",
    "\"\"\"\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: whats up?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#åŠ è½½å¯¹è¯ç¼“å­˜ä¸­å­˜å‚¨çš„å˜é‡ã€‚è¯¥æ–¹æ³•æ¥å—ä¸€ä¸ªç©ºå­—å…¸ä½œä¸ºå‚æ•°ï¼Œè¡¨ç¤ºä¸éœ€è¦åŠ è½½ä»»ä½•å˜é‡\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¹Ÿå¯ä»¥ç”¨åˆ—è¡¨è¿”å›å†å²æ¶ˆæ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi!', additional_kwargs={}),\n",
       "  AIMessage(content='whats up?', additional_kwargs={})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢å°±æ˜¯å¯¹å†å²å¯¹è¯è¿›è¡Œè®°å½•ä»¥åŠè·å–çš„æ–¹å¼ï¼Œç®€å•ç›´æ¥ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬é€šè¿‡å‡ ä¸ªç¤ºä¾‹çœ‹ä¸€ä¸‹å…·ä½“æ€ä¹ˆè®²å…¶æ·»åŠ åˆ°Chainä¸­ï¼š"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Memory to an LLMChain\n",
    "\n",
    "ä¸‹é¢å±•ç¤ºäº†ConversationBufferMemoryçš„æ·»åŠ ç”¨æ³•ï¼Œå¯¹äºå…¶ä»–ç±»å‹çš„Memory,æ‚¨å¯ä»¥ç‚¹å‡»[æ­¤å¤„æŸ¥çœ‹å’Œä½¿ç”¨](https://python.langchain.com/en/latest/modules/memory/how_to_guides.html)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "\n",
    "\"\"\"\n",
    "æœ€é‡è¦çš„ä¸€æ­¥æ˜¯æ­£ç¡®è®¾ç½®æç¤ºã€‚åœ¨ä¸‹é¢çš„æç¤ºä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªè¾“å…¥é”®ï¼šä¸€ä¸ªç”¨äºå®é™…è¾“å…¥ï¼Œ\n",
    "å¦ä¸€ä¸ªç”¨äºæ¥è‡ª Memory ç±»çš„è¾“å…¥ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬ç¡®ä¿ PromptTemplate å’Œ ConversationBufferMemory ä¸­çš„é”®åŒ¹é… ( chat_history)ã€‚\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "\"\"\"\n",
    "è°ƒç”¨ConversationBufferMemoryç±»çš„æ„é€ å‡½æ•°æ¥åˆ›å»ºä¸€ä¸ªåä¸ºmemoryçš„å¯¹è¯ç¼“å­˜å¯¹è±¡ï¼Œè¯¥å¯¹è±¡å°†ç”¨äºå­˜å‚¨å¯¹è¯å†å²è®°å½•ã€‚\n",
    "memoryå¯¹è±¡å°†ä½¿ç”¨\"chat_history\"ä½œä¸ºkeyæ¥å­˜å‚¨å¯¹è¯å†å²è®°å½•ã€‚æœ€åï¼Œä»£ç è°ƒç”¨LLMChainç±»çš„æ„é€ å‡½æ•°æ¥åˆ›å»ºä¸€ä¸ªåä¸º\n",
    "llm_chainçš„å¯¹è±¡ï¼Œè¯¥å¯¹è±¡å°†ç”¨äºæ‰§è¡Œé•¿æ–‡æœ¬é“¾æ¨¡å‹ã€‚llm_chainå¯¹è±¡å°†ä½¿ç”¨OpenAI()ä½œä¸ºllmå‚æ•°æ¥æ‰§è¡Œé•¿æ–‡æœ¬é“¾æ¨¡å‹ï¼›\n",
    "å°†promptä½œä¸ºpromptå‚æ•°ï¼›å°†verboseè®¾ç½®ä¸ºTrueä»¥æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼›å°†memoryä½œä¸ºmemoryå‚æ•°æ¥åŠ è½½å¯¹è¯ç¼“å­˜ä¸­å­˜å‚¨çš„\n",
    "å†å²è®°å½•ã€‚\n",
    "\"\"\"\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(), \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. My name is AI. What's your name?\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"I'm doing well! Just having a conversation with an AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: Tell me about yourself.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Sure! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also able to learn from my conversations and experiences, so I'm constantly growing and evolving. What else would you like to know?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(input=\"Tell me about yourself.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "å¦å¤–ä¸€ç§æƒ…æ™¯æ˜¯ç”¨æˆ·éœ€è¦è¿›è¡Œå†å²ä¿¡æ¯çš„ä¿å­˜ï¼Œå› ä¸ºç”¨æˆ·æœ‰ä¿å­˜å†å²ä¿¡æ¯ï¼Œç„¶ååœ¨éœ€è¦çš„æ—¶å€™åŠ è½½é‡ç”¨çš„éœ€æ±‚ã€‚LangChainçš„schemaç±»èƒ½æ–¹ä¾¿çš„æŠŠå†å²ä¿¡æ¯è½¬ä¸ºä¸ºpythonæ•°æ®ç»“æ„ï¼Œæ¯”å¦‚å­—å…¸ï¼›ä¹Ÿå¯ä»¥è½¬åŒ–ä¸ºjsonæ ¼å¼ï¼›ç„¶åä»å­—å…¸ã€jsonä¸­åŠ è½½å†å²ä¿¡æ¯ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "\n",
    "#ä»£ç åˆ›å»ºäº†ä¸€ä¸ªåä¸ºhistoryçš„ChatMessageHistoryå¯¹è±¡\n",
    "history = ChatMessageHistory()\n",
    "#å‘å¯¹è¯å†å²è®°å½•ä¸­æ·»åŠ ä¸€æ¡ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯ï¼š\"hi!\"\n",
    "history.add_user_message(\"hi!\")\n",
    "#å‘å¯¹è¯å†å²è®°å½•ä¸­æ·»åŠ ä¸€æ¡AIå‘å‡ºçš„æ¶ˆæ¯ï¼š\"whats up?\"ã€‚\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dicts = messages_to_dict(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'human', 'data': {'content': 'hi!', 'additional_kwargs': {}}},\n",
       " {'type': 'ai', 'data': {'content': 'whats up?', 'additional_kwargs': {}}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_messages = messages_from_dict(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}),\n",
       " AIMessage(content='whats up?', additional_kwargs={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢æ˜¯å…³äºåœ¨Agentä¸­æ·»åŠ Memoryçš„æ¡ˆä¾‹è¯´æ˜ï¼š"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Memory to an Agent\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†å‘Agentä¸­æ·»åŠ Memoryï¼Œæˆ‘ä»¬å°†æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š\n",
    "\n",
    "- 1.æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå¸¦å†…å­˜çš„ LLMChainã€‚\n",
    "\n",
    "- 2.æˆ‘ä»¬å°†ä½¿ç”¨è¯¥ LLMChain åˆ›å»ºè‡ªå®šä¹‰ä»£ç†ã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç®€å•çš„è‡ªå®šä¹‰ä»£ç†ï¼Œå®ƒå¯ä»¥è®¿é—®æœç´¢å·¥å…·å¹¶ä½¿ç”¨è¯¥ç±»ConversationBufferMemoryã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]\n",
    "\n",
    "#chat_historyè¯·æ³¨æ„PromptTemplate ä¸­å˜é‡çš„ç”¨æ³•ï¼Œå®ƒä¸ ConversationBufferMemory ä¸­çš„åŠ¨æ€é”®åç›¸åŒ¹é…ã€‚\n",
    "\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools, \n",
    "    prefix=prefix, \n",
    "    suffix=suffix, \n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "#æˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨ Memory å¯¹è±¡æ„é€  LLMChainï¼Œç„¶ååˆ›å»ºä»£ç†ã€‚\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)\n",
    "\n",
    "agent_chain.run(input=\"How many people live in canada?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†æµ‹è¯•æ­¤ä»£ç†çš„è®°å¿†åŠ›ï¼Œæˆ‘ä»¬å¯ä»¥æå‡ºä¸€ä¸ªåç»­é—®é¢˜ï¼Œè¯¥é—®é¢˜ä¾èµ–äºå…ˆå‰äº¤æµä¸­çš„ä¿¡æ¯æ‰èƒ½æ­£ç¡®å›ç­”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"what is their national anthem called?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°†å…¶ä¸æ²¡æœ‰memoryçš„agentè¿›è¡Œæ¯”è¾ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools, \n",
    "    prefix=prefix, \n",
    "    suffix=suffix, \n",
    "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
    ")\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_without_memory = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
    "agent_without_memory.run(\"How many people live in canada?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_without_memory.run(\"what is their national anthem called?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“ç„¶ä¸Šè¿°æ“ä½œç¤ºä¾‹æ˜¯æ–¹ä¾¿è¯»è€…å¿«é€Ÿäº†è§£å’Œä¸Šæ‰‹ï¼Œä¸ºäº†åœ¨å¼€å‘ä¸­æ›´åŠ ç†Ÿç»ƒåœ°åº”ç”¨ï¼Œè¿˜æ˜¯éœ€è¦å…¨é¢å®Œå–„çš„æµè§ˆå’ŒæŸ¥é˜…å®˜æ–¹æ•™ç¨‹åšè¿›ä¸€æ­¥çš„èä¼šè´¯é€šï¼Œç‚¹å‡»æ­¤å¤„å¯ä»¥ç›´è¾¾[Memoryæ•™ç¨‹ä½ç½®](https://python.langchain.com/en/latest/modules/memory.html)ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Chains\n",
    "å½“å®ç°ä¸€äº›ç®€å•çš„åº”ç”¨æ—¶ï¼Œåªç”¨ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹æ˜¯éå¸¸å¯è¡Œçš„ã€‚ä½†æ˜¯ï¼Œä¸€äº›å¤æ‚æƒ…å†µä¸‹ï¼Œéœ€è¦æˆ‘ä»¬å»ç»„åˆä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹æˆ–è€…ç»„åˆå¤§è¯­è¨€æ¨¡å‹å’Œå…¶ä»–æ¨¡å—ï¼Œå»å®Œæˆä¸€äº›åºå¤§è€Œåˆå¤æ‚çš„å·¥ä½œå†…å®¹ã€‚LangChainä¸ºChainsæä¾›äº†ä¸€ä¸ªæ ‡å‡†æ¥å£ï¼Œä»¥åŠä¸€äº›å¸¸ç”¨çš„å®ç°æ–¹æ³•ã€‚\n",
    "ä¾‹å¦‚ï¼Œç®€å•çš„æ–¹å¼æˆ‘ä»¬å·²ç»äº†è§£åˆ°â€”â€”æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªchainï¼Œæ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œç„¶åä½¿ç”¨Promptæ¨¡å—æ ¼å¼åŒ–ï¼Œç„¶åå°†æ ¼å¼åŒ–å†…å®¹ä¼ ç»™LLMï¼›å¤æ‚çš„æ–¹å¼è¯¸å¦‚ç»„åˆå¤šä¸ªchainï¼Œæˆ‘ä»¬å¯ä»¥å°†å¤šä¸ªchainç»„åˆåœ¨ä¸€èµ·ï¼Œä¹Ÿå¯ä»¥åœ¨chainä¸­åŠ å…¥å…¶ä»–æ¨¡å—ååŒå·¥ä½œã€‚\n",
    "è¿™éƒ¨åˆ†æ•™ç¨‹æœ‰å¦‚ä¸‹å†…å®¹ï¼š\n",
    "- 1.ä½¿ç”¨ç®€å•çš„LLMé“¾\n",
    "- 2.åˆ›å»ºåºåˆ—åŒ–çš„é“¾æ¥\n",
    "- 3.åˆ›å»ºè‡ªå®šä¹‰çš„é“¾\n",
    "\n",
    "å¦‚æœä½ æƒ³äº†è§£æ›´å¤šï¼Œå¯ä»¥ç‚¹å‡»[è¿™é‡Œ](https://python.langchain.com/en/latest/modules/chains.html)ç›´è¾¾Chainså®˜æ–¹æ•™ç¨‹ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ä½¿ç”¨LLMChainå®ŒæˆåŸºæœ¬è°ƒç”¨](#llmchain-usage)\n",
    "- [SequentialChainç»„åˆå¤šä¸ªChain](#using-sequentialchain-to-combine-with-multiple-chains)\n",
    "- [è‡ªå®šä¹‰Chain](#customize-the-chain-class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LLMChain usage\n",
    "\n",
    "LLMChainï¼Œå®ƒæ˜¯ä¸€ä¸ªæœ€ç®€å•ã€ä½¿ç”¨æœ€å¤šçš„chainï¼Œå®ƒä¼šæ¥æ”¶ä¸€ä¸ªpromptæ¨¡æ¿ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæ¨¡æ¿æ ¼å¼åŒ–è¾“å…¥ä¿¡æ¯ï¼Œç„¶åè¿”å›ç”¨æˆ·çš„æŸ¥è¯¢å¾—åˆ°çš„å“åº”ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„ç­”æ¡ˆã€‚ä¸‹é¢æ˜¯ä½¿ç”¨ä¾‹å­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "#ä½¿ç”¨OpenAIçš„å¤§æ¨¡å‹ï¼Œé»˜è®¤æ˜¯text-davinci-003ï¼Œè®¾ç½®éšæœºæ€§ä¸º0.9\n",
    "llm = OpenAI(temperature=0.9)\n",
    "#æç¤ºæ¨¡ç‰ˆæ ¼å¼åŒ–å˜é‡å†…å®¹\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Brightly Socks!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "#å®ä¾‹åŒ–chainå¯¹è±¡\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "#ç”¨chainçš„runæ–¹æ³•æ¥è¿è¡ŒæŒ‡å®šè¾“å…¥å˜é‡çš„é“¾ \n",
    "print(chain.run(\"colorful socks\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "åœ¨LLMChainä¸­ä½¿ç”¨chat modelå»å®ŒæˆèŠå¤©æœºå™¨äººçš„äº¤äº’è¿‡ç¨‹ï¼Œä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RainbowSocks\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"What is a good name for a company that makes {product}?\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rainbow Socks Co.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"colorful socks\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using SequentialChain to combine with multiple chains\n",
    "\n",
    "é¡ºåºé“¾å¯ä»¥ç»„åˆå¤šä¸ªchainï¼ŒSequentialChainå‚æ•°è¾“å…¥chainåˆ—è¡¨ï¼Œå®ƒä¼šé¡ºåºæ‰§è¡Œæ¯ä¸€ä¸ªchainï¼Œå°†ç¬¬ä¸€ä¸ªchainçš„è¿”å›å€¼è¾“å…¥åˆ°ç¬¬äºŒchainï¼Œä¾æ¬¡ç±»æ¨ã€‚ä¸‹é¢æ˜¯ä½¿ç”¨èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"What is a good name for a company that makes {product}?\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "#å®šä¹‰ç¬¬äºŒä¸ªpromptï¼Œç„¶åä½¿ç”¨llmchainå®ä¾‹åŒ–è¿™ä¸ªå¯¹è±¡\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"company_name\"],\n",
    "    template=\"Write a catchphrase for the following company: {company_name}\",\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain_one = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸‹é¢å°†ä¸¤ä¸ªç®€å•çš„LLMChainsç»„åˆåˆ°ä¸€èµ·çš„æ–¹å¼ï¼Œä½¿ç”¨SimpleSequentialChainæ¥å®Œæˆï¼Œæœ€ç»ˆå®ç°å…ˆç»™å…¬å¸å‘½åï¼Œç„¶åç»™è¿™ä¸ªå·²ç»å‘½åçš„å…¬å¸èµ·ä¸€ä¸ªå®£ä¼ è¯­çš„è¿™ä¹ˆä¸€ä¸ªè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRainbow Sock Co.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "\"Walk on the wild side with Rainbow Socks!\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\"Walk on the wild side with Rainbow Socks!\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "#è¿è¡Œchainçš„runæ–¹æ³•ï¼Œåªéœ€è¦æŒ‡å®šç¬¬ä¸€ä¸ªé“¾çš„è¾“å…¥å˜é‡ã€‚\n",
    "catchphrase = overall_chain.run(\"colorful socks\")\n",
    "print(catchphrase)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Customize the Chain class\n",
    "ä½¿ç”¨å·²ç»å°è£…å¥½çš„LangChainå›ºç„¶æ²¡æœ‰ä»»ä½•é—®é¢˜ï¼Œå› ä¸ºå…¶æä¾›äº†å¾ˆå¤šå¼€ç®±å³ç”¨çš„chainsï¼Œä½†æ˜¯å¾€å¾€æœ‰æ—¶å€™ç”¨æˆ·å¯èƒ½æƒ³è‡ªå·±åˆ›å»ºä¸ªè‡ªå®šä¹‰çš„ç±»ç”¨äºç‰¹æ®Šç”¨é€”ã€‚\n",
    "åˆ›å»ºè‡ªå®šä¹‰ç±»è¿‡ç¨‹å¦‚ä¸‹ï¼š\n",
    "- 1.ç»§æ‰¿Chainç±»\n",
    "- 2.å¡«å†™input_keys å’Œ output_keys å±æ€§\n",
    "- 3.å®ç°ç§æœ‰æ–¹æ³•_callæ–¹æ³•ï¼Œç”¨äºå±•ç¤ºå¦‚ä½•æ‰§è¡Œchain\n",
    "\n",
    "ä¸‹é¢æ˜¯è‡ªå®šä¹‰åˆ›å»ºchainç±»çš„æ–¹æ³•"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "é¦–å…ˆè‡ªå®šä¹‰ä¸€ä¸ªConcatenateChainç±»ï¼Œè¯¥ç±»å°†ä¸¤ä¸ªLLMChainåŒæ—¶å¤„ç†ä¸€ä¸ªæŸ¥è¯¢å¹¶è¿”å›è¿æ¥ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.base import Chain\n",
    "from typing import Dict, List\n",
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºConcatenateChainçš„ç±»ï¼Œç»§æ‰¿è‡ªChainã€‚è¯¥ç±»è¡¨ç¤ºä¸€ä¸ªå°†ä¸¤ä¸ªé“¾è¿æ¥åœ¨ä¸€èµ·çš„é“¾ã€‚\n",
    "é¦–å…ˆä»langchain.chainsæ¨¡å—ä¸­å¯¼å…¥LLMChainå’ŒChainç±»ï¼Œä»¥åŠä»typingæ¨¡å—ä¸­å¯¼å…¥Dictå’ŒListç±»å‹æ³¨è§£ã€‚\n",
    "åœ¨ConcatenateChainç±»ä¸­ï¼Œæœ‰ä¸¤ä¸ªå±æ€§ï¼šchain_1å’Œchain_2,åˆ†åˆ«è¡¨ç¤ºè¦è¿æ¥çš„ä¸¤ä¸ªé“¾ã€‚è¿™ä¸¤ä¸ªå±æ€§éƒ½æ˜¯LLMChainç±»å‹çš„å®ä¾‹ã€‚\n",
    "è¯¥ç±»è¿˜å®šä¹‰äº†ä¸¤ä¸ªæ–¹æ³•ï¼šinput_keys()å’Œoutput_keys()ã€‚å…¶ä¸­ï¼Œinput_keys()æ–¹æ³•è¿”å›è¿æ¥åè¾“å…¥å˜é‡çš„é›†åˆï¼Œå³ä¸¤ä¸ªåŸå§‹é“¾\n",
    "çš„è¾“å…¥å˜é‡çš„å¹¶é›†ï¼›è€Œoutput_keys()æ–¹æ³•è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œè¡¨ç¤ºè¿æ¥åçš„è¾“å‡ºå˜é‡åªæœ‰ä¸€ä¸ªï¼Œåç§°ä¸ºconcat_outputã€‚\n",
    "æœ€åï¼Œè¯¥ç±»å®ç°äº†ä¸€ä¸ªç§æœ‰æ–¹æ³•_call(),ç”¨äºå®é™…æ‰§è¡Œè¿æ¥æ“ä½œã€‚è¯¥æ–¹æ³•æ¥å—ä¸€ä¸ªå­—å…¸ç±»å‹çš„å‚æ•°inputs,è¡¨ç¤ºè¾“å…¥å˜é‡åŠå…¶å–å€¼ã€‚\n",
    "è¯¥æ–¹æ³•å…ˆè°ƒç”¨ä¸¤ä¸ªé“¾çš„run()æ–¹æ³•ï¼Œåˆ†åˆ«è·å–å®ƒä»¬çš„è¾“å‡ºç»“æœï¼Œç„¶åå°†å®ƒä»¬ç›¸åŠ å¾—åˆ°æ–°çš„è¾“å‡ºç»“æœï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ä¸€ä¸ªå­—å…¸ä¸­è¿”å›ã€‚\n",
    "\"\"\"\n",
    "\n",
    "class ConcatenateChain(Chain):\n",
    "    chain_1: LLMChain\n",
    "    chain_2: LLMChain\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        # ä¸¤ä¸ªé“¾çš„è¾“å…¥é”®çš„å¹¶é›†\n",
    "        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))\n",
    "        return list(all_input_vars)\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return ['concat_output']\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "        output_1 = self.chain_1.run(inputs)\n",
    "        output_2 = self.chain_2.run(inputs)\n",
    "        return {'concat_output': output_1 + output_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated output:\n",
      "\n",
      "\n",
      "Vivid Sockery.\n",
      "\n",
      "\"Step Into Colorful Comfort!\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    prompt_1: PromptTemplateç±»å‹ï¼Œè¡¨ç¤ºä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œå…¶ä¸­åŒ…å«è¾“å…¥å˜é‡\"product\",\n",
    "æ¨¡æ¿ä¸º\"What is a good name for a company that makes {product}?\"ã€‚\n",
    "    chain_1: LLMChainç±»å‹ï¼Œè¡¨ç¤ºä¸€ä¸ªLLMChainå®ä¾‹ï¼Œå…¶ä¸­llmå‚æ•°è®¾ç½®ä¸ºä¹‹å‰å®šä¹‰çš„llmå¯¹è±¡ï¼Œpromptå‚æ•°è®¾ç½®ä¸ºprompt_1ã€‚\n",
    "    chain_2: LLMChainç±»å‹ï¼Œè¡¨ç¤ºä¸€ä¸ªLLMChainå®ä¾‹ï¼Œå…¶ä¸­llmå‚æ•°è®¾ç½®ä¸ºä¹‹å‰å®šä¹‰çš„llmå¯¹è±¡ï¼Œpromptå‚æ•°è®¾ç½®ä¸ºprompt_2ã€‚\n",
    "    concat_chain: ConcatenateChainç±»å‹ï¼Œè¡¨ç¤ºä¸€ä¸ªè¿æ¥ä¸¤ä¸ªé“¾çš„å¯¹è±¡ã€‚å…¶ä¸­ï¼Œchain_1å’Œchain_2å±æ€§åˆ†åˆ«å¯¹åº”ä¸Šé¢å®šä¹‰çš„ä¸¤ä¸ªé“¾å®ä¾‹ã€‚\n",
    "    concat_output: å­—ç¬¦ä¸²ç±»å‹ï¼Œè¡¨ç¤ºè°ƒç”¨concat_chain.run()æ–¹æ³•åå¾—åˆ°çš„ç»“æœã€‚è¯¥ç»“æœæ˜¯å°†chain_1å’Œchain_2è¾“å‡ºçš„ç»“æœè¿›è¡Œè¿æ¥\n",
    "å¾—åˆ°çš„ã€‚æœ€åé€šè¿‡æ‰“å°è¾“å‡ºçš„æ–¹å¼å±•ç¤ºè¿æ¥ç»“æœã€‚\n",
    "\"\"\"\n",
    "prompt_1 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good slogan for a company that makes {product}?\",\n",
    ")\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
    "\n",
    "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)\n",
    "concat_output = concat_chain.run(\"colorful socks\")\n",
    "print(f\"Concatenated output:\\n{concat_output}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Agents\n",
    "å®é™…åº”ç”¨å¯èƒ½ä¸ä»…éœ€è¦é¢„å®šä¹‰å¥½çš„chainï¼Œä¹Ÿéœ€è¦æ ¹æ®ç”¨æˆ·çš„è¾“å…¥è¯·æ±‚ï¼Œç”Ÿæˆä¸€ä¸ªéšå«çš„chainã€‚agentä½œä¸ºä»£ç†ï¼Œä¼šæ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œç¡®å®šä¸‹æ¥è¦é‡‡å–çš„æ“ä½œã€ä½¿ç”¨çš„å·¥å…·ã€LLMçš„è¾“å‡ºã€observationè§‚å¯Ÿå¾—å‡ºçš„ç»“æœæˆ–æ˜¯å°†LLMç»“æœè¿”å›ç»™ç”¨æˆ·ã€‚\n",
    "åœ¨ä½¿ç”¨agentså‰ï¼Œä¸‹é¢å‡ ä¸ªæ¦‚å¿µéœ€è¦ç†è§£ï¼š\n",
    "\n",
    "- Toolsï¼šä¸€ä¸ªå®ç°å…·ä½“åŠŸèƒ½çš„å‡½æ•°ï¼›å¯ä»¥æ˜¯è°·æ­Œæœç´¢ã€æ•°æ®åº“æŸ¥æ‰¾ã€pythonäº¤äº’ç•Œé¢ã€‚toolçš„æ¥å£æ˜¯ä¸€ä¸ªæ¥å—stringï¼Œè¿”å›stringçš„å‡½æ•°\n",
    "- LLMï¼šé©±åŠ¨Agentè¿è¡Œçš„å¤§è¯­è¨€æ¨¡å‹\n",
    "- Agentï¼šä½¿ç”¨çš„Agent\n",
    "\n",
    "ä¸‹é¢æ˜¯ä¸‰è€…ä¹‹é—´çš„è”ç³»ï¼š\n",
    "\n",
    "<img src=\"./agents.png\" align=center width=100% />\n",
    "\n",
    "LangChain å°†åŸºäºç”¨æˆ·æå‡ºçš„è¦æ±‚é©±åŠ¨agentè¿›è¡Œå¤„ç†ï¼ŒæœŸé—´è°ƒç”¨å¤§æ¨¡å‹æ¥å®Œæˆå“åº”è¯·æ±‚ï¼Œè¯¥è¯·æ±‚å¯è¿›ä¸€æ­¥é©±åŠ¨toolså»æ ¹æ®ç‰¹å®šä»»åŠ¡è¿›è¡Œç‰¹å®šæ“ä½œï¼Œå°”åä¼šæŠŠtoolså…·ä½“çš„æ“ä½œå®Œæˆè¿”å›ç»™ç”¨æˆ·ï¼Œåœ¨è¿™ä¸€è¿‡ç¨‹ä¸­å¦‚æœç”¨æˆ·æ— éœ€è°ƒç”¨toolså®Œæˆå¤„ç†å°†ä¼šç›´æ¥å¾—åˆ°å¤§æ¨¡å‹çš„åé¦ˆã€‚\n",
    "\n",
    "æ›´åŠ è¯¦ç»†çš„å†…å®¹ç‚¹å‡»ğŸ‘‰[è¿™é‡Œ](https://python.langchain.com/en/latest/modules/agents.html)ğŸ‘ˆè·³è½¬åˆ°Agentså®˜æ–¹æ•™ç¨‹"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ä½¿ç”¨Agentçš„ç®€å•ç¤ºä¾‹](#a-simple-example-with-using-agent)\n",
    "- [Tools](#tools)\n",
    "- [Agent](#agent)\n",
    "- [Toolkits](#toolkits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### A simple example with using Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\"\"\"\n",
    "llmæ˜¯åˆ›å»ºä¸€ä¸ªOpenAIçš„LLMæ¨¡å‹ï¼Œæ¸©åº¦å‚æ•°è®¾ç½®ä¸º0ã€‚\n",
    "tools æ˜¯ä»æŒ‡å®šè·¯å¾„åŠ è½½å·¥å…·åº“ï¼ŒåŒ…æ‹¬\"serpapi\"å’Œ\"llm-math\"ä¸¤ä¸ªå·¥å…·ï¼Œå¹¶å°†åŠ è½½çš„å·¥å…·ä¸LLMæ¨¡å‹ç»‘å®šã€‚\n",
    "agent æ˜¯åˆå§‹åŒ–ä»£ç†ï¼Œé€‰æ‹©æŒ‡å®šç±»å‹ï¼Œå¹¶ä½¿ç”¨åŠ è½½çš„å·¥å…·å’ŒLLMæ¨¡å‹å¯¹å…¶è¿›è¡Œè®­ç»ƒã€‚åŒæ—¶ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰“å°è¯¦ç»†è¾“å‡ºä¿¡æ¯ã€‚\n",
    "\"\"\"\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who Leo DiCaprio's girlfriend is and then calculate her age raised to the 0.43 power.\n",
      "Action: Search\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNina Agdal: 2016 to 2017 ... Leo and Nina were together for almost exactly a year until a source confirmed their breakup with a very familiar ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out Nina Agdal's age\n",
      "Action: Search\n",
      "Action Input: \"Nina Agdal age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m31 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate 31 raised to the 0.43 power\n",
      "Action: Calculator\n",
      "Action Input: 31^0.43\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 4.378098500976803\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Nina Agdal is Leo DiCaprio's girlfriend and her current age raised to the 0.43 power is 4.378098500976803.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nina Agdal is Leo DiCaprio's girlfriend and her current age raised to the 0.43 power is 4.378098500976803.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tools\n",
    "å·¥å…·æ˜¯æ™ºèƒ½ä½“å’Œå¤–éƒ¨ç¯å¢ƒäº¤äº’çš„æ–¹å¼ã€‚å·¥å…·å¯ä»¥æ˜¯å®ç”¨ç¨‹åºã€chainã€å…¶ä»–agentç­‰ã€‚\n",
    "\n",
    "LangChainå¤§éƒ¨åˆ†å·¥å…·å’Œæœç´¢ç›¸å…³ï¼Œä¸‹é¢ä»…ä¸¾å‡ ä¸ªæœ‰ç‰¹ç‚¹çš„å·¥å…·ä¾‹å­ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Bing Search](#bing-search)\n",
    "- [Google Search](#google-search)\n",
    "- [Google Serper API](#google-serper-api)\n",
    "- [Python REPL](#python-repl)\n",
    "- [Bash](#bash)\n",
    "- [Wikipedia API](#wikipedia-api)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸€èˆ¬é€šè¿‡ä¸‹é¢çš„æ–¹å¼åŠ è½½å·¥å…·ï¼Œå¯¹äºå½“åšå·¥å…·ä½¿ç”¨çš„chainã€agentï¼Œéœ€è¦è¿›è¡Œåˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "tool_names = [...]\n",
    "tools = load_tools(tool_names)\n",
    "llm = ...\n",
    "tools = load_tools(tool_names, llm=llm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bing Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¿…åº”æœç´¢ç»„ä»¶ï¼š\n",
    "\n",
    "é¦–å…ˆï¼Œæ‚¨éœ€è¦è®¾ç½®é€‚å½“çš„ API å¯†é’¥å’Œç¯å¢ƒå˜é‡ã€‚ç‚¹å‡»[æ­¤å¤„](https://levelup.gitconnected.com/api-tutorial-how-to-use-bing-web-search-api-in-python-4165d5592a7e)æŸ¥é˜…è¯´æ˜å¹¶å®Œæˆé…ç½®ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"BING_SUBSCRIPTION_KEY\"] = \"\"\n",
    "os.environ[\"BING_SEARCH_URL\"] = \"\"\n",
    "\n",
    "#å¯¼å…¥BingSearchAPIWrapperç±»ï¼Œè¯¥ç±»ç”¨äºä¸Bingæœç´¢å¼•æ“è¿›è¡Œäº¤äº’ã€‚\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "#åˆ›å»ºä¸€ä¸ªBingSearchAPIWrapperå¯¹è±¡ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™å˜é‡searchã€‚\n",
    "search = BingSearchAPIWrapper()\n",
    "#è°ƒç”¨searchå¯¹è±¡çš„run()æ–¹æ³•ï¼Œä¼ å…¥å‚æ•°\"python\",è¡¨ç¤ºåœ¨Bingæœç´¢å¼•æ“ä¸Šæœç´¢å…³äºPythonçš„ä¿¡æ¯ã€‚\n",
    "search.run(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#è®¾ç½®kæ§åˆ¶è¾“å‡ºç»“æœæ•°ç›®\n",
    "search = BingSearchAPIWrapper(k=1)\n",
    "search.run(\"python\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä¸‹é¢çš„ä»£ç å°†ä¼šè¿”å›ä¸‰é¡¹å†…å®¹ï¼šç‰‡æ®µï¼Œæ ‡é¢˜å’Œé“¾æ¥\n",
    "\n",
    "ç‰‡æ®µ: ç»“æœçš„æè¿°.\n",
    "\n",
    "æ ‡é¢˜: ç»“æœçš„æ ‡é¢˜.\n",
    "\n",
    "é“¾æ¥: ç»“æœçš„é“¾æ¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = BingSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.results(\"apples\", 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹ç¤ºä¾‹ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨è°·æ­Œæœç´¢ç»„ä»¶ï¼Œæ‚¨éœ€è¦è®¾ç½®é€‚å½“çš„ API å¯†é’¥å’Œç¯å¢ƒå˜é‡ã€‚è¦è¿›è¡Œè®¾ç½®ï¼Œè¯·åœ¨[æ­¤å¤„](https://console.cloud.google.com/apis/credentials)åˆ›å»º GOOGLE_API_KEYï¼Œ[è¿™é‡Œ](https://programmablesearchengine.google.com/)åˆ›å»º GOOGLE_CSE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = \"\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "#å¯¼å…¥GoogleSearchAPIWrapperç±»ï¼Œè¯¥ç±»ç”¨äºä¸Googleæœç´¢å¼•æ“è¿›è¡Œäº¤äº’ã€‚\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "#åˆ›å»ºä¸€ä¸ªGoogleSearchAPIWrapperå¯¹è±¡ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™å˜é‡searchã€‚\n",
    "search = GoogleSearchAPIWrapper()\n",
    "#è°ƒç”¨searchå¯¹è±¡çš„run()æ–¹æ³•ï¼Œä¼ å…¥å‚æ•°\"Obama's first name?\",è¡¨ç¤ºåœ¨Googleæœç´¢å¼•æ“ä¸Šæœç´¢å…³äº\"Obamaçš„å\"çš„ä¿¡æ¯ã€‚\n",
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "é¦–å…ˆåˆ›å»ºä¸€ä¸ªGoogleSearchAPIWrapperå¯¹è±¡search,å¹¶ä¼ å…¥å‚æ•°k=1,ä»¥ä¾¿åœ¨æœç´¢ç»“æœä¸­åªè¿”å›å‰ä¸€æ¡ç»“æœã€‚\n",
    "ç„¶åè°ƒç”¨searchå¯¹è±¡çš„run()æ–¹æ³•ï¼Œä¼ å…¥å‚æ•°\"python\",ä»¥åœ¨Googleæœç´¢å¼•æ“ä¸Šæœç´¢å…³äºPythonçš„ä¿¡æ¯ã€‚\n",
    "æ¥ç€å†æ¬¡åˆ›å»ºä¸€ä¸ªGoogleSearchAPIWrapperå¯¹è±¡search,å¹¶ä¼ å…¥ç©ºå€¼ï¼Œä»¥ä¾¿æ¸…ç©ºä¹‹å‰æœç´¢çš„ç»“æœã€‚\n",
    "æœ€åè°ƒç”¨searchå¯¹è±¡çš„results()æ–¹æ³•ï¼Œä¼ å…¥å‚æ•°\"apples\"å’Œ5,ä»¥åœ¨Googleæœç´¢å¼•æ“ä¸Šæœç´¢å…³äºè‹¹æœçš„ä¿¡æ¯ï¼Œå¹¶è¿”å›å‰5ä¸ªç»“æœã€‚\n",
    "\"\"\"\n",
    "search = GoogleSearchAPIWrapper(k=1)\n",
    "search.run(\"python\")\n",
    "search = GoogleSearchAPIWrapper()\n",
    "search.results(\"apples\", 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Serper API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†æ›´å¥½åœ°ä½¿ç”¨è°·æ­Œç½‘ç»œæœç´¢APIï¼Œéœ€è¦æ³¨å†Œä¸€ä¸ªå…è´¹è´¦æˆ·ç”¨äºè·å–API_KEY,æ³¨å†Œä½ç½®ç‚¹å‡»[æ­¤å¤„](https://serper.dev/)ã€‚ä¸‹é¢æ˜¯ç¤ºä¾‹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERPER_API_KEY\"] = \"\"\n",
    "\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "search = GoogleSerperAPIWrapper()\n",
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"YOUR_OPENAI_KEY\"\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "\"\"\"\n",
    "é¦–å…ˆåˆ›å»ºä¸€ä¸ªOpenAIçš„LLMæ¨¡å‹ï¼Œæ¸©åº¦å‚æ•°è®¾ç½®ä¸º0ã€‚\n",
    "ç„¶ååˆ›å»ºä¸€ä¸ªGoogleSerperAPIWrapperå¯¹è±¡search,ç”¨äºåœ¨Googleæœç´¢å¼•æ“ä¸Šè¿›è¡Œæœç´¢ã€‚\n",
    "æ¥ç€å®šä¹‰ä¸€ä¸ªåŒ…å«ä¸€ä¸ªå·¥å…·çš„åˆ—è¡¨tools,å…¶ä¸­å·¥å…·åç§°ä¸º\"Intermediate Answer\",å…¶åŠŸèƒ½\n",
    "ä¸ºè°ƒç”¨searchå¯¹è±¡çš„run()æ–¹æ³•è¿›è¡Œæœç´¢ï¼Œå¹¶å°†æœç´¢ç»“æœä½œä¸ºç­”æ¡ˆè¿”å›ã€‚\n",
    "æ¥ä¸‹æ¥åˆå§‹åŒ–ä¸€ä¸ªagentï¼Œä¹Ÿå°±æ˜¯self_ask_with_search,è¯¥agentä½¿ç”¨toolsåˆ—è¡¨ä¸­çš„å·¥å…·ä¸LLMæ¨¡å‹\n",
    "äº¤äº’ï¼Œå¹¶æ”¯æŒä½¿ç”¨\"self ask with search\"æ–¹å¼è¿›è¡Œæé—®ã€‚\n",
    "æœ€åè°ƒç”¨self_ask_with_searchå¯¹è±¡çš„run()æ–¹æ³•ï¼Œä¼ å…¥é—®é¢˜,ä»¥è·å–ç›¸åº”çš„ç­”æ¡ˆã€‚\n",
    "\"\"\"\n",
    "llm = OpenAI(temperature=0)\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "self_ask_with_search.run(\"What is the hometown of the reigning men's U.S. Open champion?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "é¦–å…ˆå¯¼å…¥PythonREPLç±»ï¼Œè¯¥ç±»ç”¨äºåœ¨Pythonè§£é‡Šå™¨ä¸­æ‰§è¡Œäº¤äº’å¼ä»£ç ã€‚\n",
    "æ¥ç€åˆ›å»ºä¸€ä¸ªPythonREPLå¯¹è±¡python_repl,ä»¥ä¾¿åœ¨Pythonè§£é‡Šå™¨ä¸­æ‰§è¡Œä»£ç ã€‚\n",
    "æœ€åè°ƒç”¨python_replå¯¹è±¡çš„run()æ–¹æ³•ï¼Œä¼ å…¥ä¸€æ¡ç®€å•çš„Pythonè¯­å¥\"print(3**3)\",ä»¥æ‰“å°å‡ºæ•°å­—27çš„å€¼ã€‚\n",
    "\"\"\"\n",
    "from langchain.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run(\"print(3**3)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My name is name\" \r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "é¦–å…ˆå¯¼å…¥BashProcessç±»ï¼Œè¯¥ç±»ç”¨äºåœ¨Linuxç³»ç»Ÿä¸­æ‰§è¡Œå‘½ä»¤è¡Œæ“ä½œã€‚\n",
    "æ¥ç€åˆ›å»ºä¸€ä¸ªBashProcesså¯¹è±¡bash,ä»¥ä¾¿åœ¨Linuxç³»ç»Ÿä¸­æ‰§è¡Œå‘½ä»¤è¡Œæ“ä½œã€‚\n",
    "æœ€åè°ƒç”¨bashå¯¹è±¡çš„run()æ–¹æ³•ï¼Œä¼ å…¥ä¸€æ¡ç®€å•çš„å‘½ä»¤\"echo 'My name is \n",
    "name'\",ä»¥åœ¨ç»ˆç«¯ä¸Šæ‰“å°å‡ºå­—ç¬¦ä¸²\"My name is name\"ã€‚\n",
    "\"\"\"\n",
    "from langchain.utilities import BashProcess\n",
    "bash = BashProcess()\n",
    "print(bash.run(' echo \"My name is name\" '))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢æ˜¯å¦‚ä½•ä½¿ç”¨ç»´åŸºç™¾ç§‘çš„ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from wikipedia) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from wikipedia) (4.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from beautifulsoup4->wikipedia) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Hunter Ã— Hunter\\nSummary: Hunter Ã— Hunter (stylized as HUNTERÃ—HUNTER and pronounced \"hunter hunter\") is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha\\'s shÅnen manga magazine Weekly ShÅnen Jump since March 1998, although the manga has frequently gone on extended hiatuses since 2006. Its chapters have been collected in 37 tankÅbon volumes as of November 2022. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals. Gon departs on a journey to become a Hunter and eventually find his father. Along the way, Gon meets various other Hunters and encounters the paranormal.\\nHunter Ã— Hunter was adapted into a 62-episode anime television series produced by Nippon Animation and directed by Kazuhiro Furuhashi, which ran on Fuji Television from October 1999 to March 2001. Three separate original video animations (OVAs) totaling 30 episodes were subsequently produced by Nippon Animation and released in Japan from 2002 to 2004. A second anime television series by Madhouse aired on Nippon Television from October 2011 to September 2014, totaling 148 episodes, with two animated theatrical films released in 2013. There are also numerous audio albums, video games, musicals, and other media based on Hunter Ã— Hunter.\\nThe manga has been translated into English and released in North America by Viz Media since April 2005. Both television series have been also licensed by Viz Media, with the first series having aired on the Funimation Channel in 2009 and the second series broadcast on Adult Swim\\'s Toonami programming block from April 2016 to June 2019.\\nHunter Ã— Hunter has been a huge critical and financial success and has become one of the best-selling manga series of all time, having over 84 million copies in circulation by July 2022.\\n\\nPage: Hunter Ã— Hunter (2011 TV series)\\nSummary: Hunter Ã— Hunter is an anime television series that aired from 2011 to 2014 based on Yoshihiro Togashi\\'s manga series Hunter Ã— Hunter. The story begins with a young boy named Gon Freecss, who one day discovers that the father who he thought was dead, is in fact alive and well. He learns that his father, Ging, is a legendary \"Hunter\", an individual who has proven themselves an elite member of humanity. Despite the fact that Ging left his son with his relatives in order to pursue his own dreams, Gon becomes determined to follow in his father\\'s footsteps, pass the rigorous \"Hunter Examination\", and eventually find his father to become a Hunter in his own right.\\nThis new Hunter Ã— Hunter anime was announced on July 24, 2011. It is a complete reboot of the anime adaptation starting from the beginning of the manga, with no connections to the first anime from 1999. Produced by Nippon TV, VAP, Shueisha and Madhouse, the series is directed by Hiroshi KÅjina, with Atsushi Maekawa and Tsutomu Kamishiro handling series composition, Takahiro Yoshimatsu designing the characters and Yoshihisa Hirano composing the music. Instead of having the old cast reprise their roles for the new adaptation, the series features an entirely new cast to voice the characters. The new series premiered airing weekly on Nippon TV and the nationwide Nippon News Network from October 2, 2011.  The series started to be collected in both DVD and Blu-ray format on January 25, 2012. Viz Media has licensed the anime for a DVD/Blu-ray release in North America with an English dub. On television, the series began airing on Adult Swim\\'s Toonami programming block on April 17, 2016, and ended on June 23, 2019.The anime series\\' opening theme is alternated between the song \"Departure!\" and an alternate version titled \"Departure! -Second Version-\" both sung by Galneryus\\' vocalist Masatoshi Ono. Five pieces of music were used as the ending theme; \"Just Awake\" by the Japanese band Fear, and Loathing in Las Vegas in episodes 1 to 26, \"Hunting for Your Dream\" by Galneryus in episodes 27 to 58, \"Reason\" sung by Japanese duo Yuzu in episodes 59 to 75, \"Nagareboshi Kirari\" also sung by Yuzu from episode 76 to 98, which was originally from the anime film adaptation, Hunter Ã— Hunter: Phantom Rouge, and \"HyÅri Ittai\" by Yuzu featuring Hyadain from episode 99 to 146, which was also used in the film Hunter Ã— Hunter: The Last Mission. The background music and soundtrack for the series was composed by Yoshihisa Hirano.\\n\\n\\n\\nPage: List of Hunter Ã— Hunter characters\\nSummary: The Hunter Ã— Hunter manga series, created by Yoshihiro Togashi, features an extensive cast of characters. It takes place in a fictional universe where licensed specialists known as Hunters travel the world taking on special jobs ranging from treasure hunting to assassination. The story initially focuses on Gon Freecss and his quest to become a Hunter in order to find his father, Ging, who is himself a famous Hunter. On the way, Gon meets and becomes close friends with Killua Zoldyck, Kurapika and Leorio Paradinight.\\nAlthough most characters are human, most possess superhuman strength and/or supernatural abilities due to Nen, the ability to control one\\'s own life energy or aura. The world of the series also includes fantastical beasts such as the Chimera Ants or the Five great calamities.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.run('HUNTER X HUNTER')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬æ¥ç€çœ‹ä¸agentç›¸å…³çš„å†…å®¹ï¼ŒAgentä½¿ç”¨ LLM æ¥ç¡®å®šé‡‡å–å“ªäº›è¡ŒåŠ¨ä»¥åŠé‡‡å–ä½•ç§é¡ºåºã€‚actionå¯ä»¥æ˜¯ä½¿ç”¨toolså¹¶è§‚å¯Ÿå…¶è¾“å‡ºï¼Œä¹Ÿå¯ä»¥æ˜¯å‘ç”¨æˆ·è¿”å›å“åº”ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ç±»å‹](#type)\n",
    "- [è‡ªå®šä¹‰Agent](#custom-agent)\n",
    "- [è‡ªå®šä¹‰å¤§æ¨¡å‹Agent](#custom-llm-agent)\n",
    "- [Self Ask With Search](#self-ask-with-search)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹æ˜¯LangChainä¸­å¯ç”¨çš„Agentç±»å‹ï¼š\n",
    "\n",
    "ä½¿ç”¨åˆ°çš„æ˜¯ReActæ¡†æ¶\n",
    "\n",
    "**zero-shot-react-description**: ä»…æ ¹æ®å·¥å…·çš„æè¿°æ¥ç¡®å®šè¦ä½¿ç”¨çš„å·¥å…·ã€‚å¯ä»¥æä¾›ä»»æ„æ•°é‡çš„å·¥å…·ã€‚æ­¤Agentè¦æ±‚ä¸ºæ¯ä¸ªå·¥å…·æä¾›æè¿°ã€‚\n",
    "\n",
    "**react-docstore**: è¿™ä¸ªAgentä½¿ç”¨ ReAct æ¡†æ¶ä¸æ–‡æ¡£åº“è¿›è¡Œäº¤äº’ã€‚å¿…é¡»æä¾›ä¸¤ä¸ªå·¥å…·ï¼šä¸€ä¸ªæœç´¢å·¥å…·å’Œä¸€ä¸ªæŸ¥æ‰¾å·¥å…·ï¼ˆå®ƒä»¬çš„åç§°å¿…é¡»å®Œå…¨ä¸€æ ·ï¼‰ã€‚æœç´¢å·¥å…·åº”æœç´¢æ–‡æ¡£ï¼Œè€ŒæŸ¥æ‰¾å·¥å…·åº”åœ¨æœ€è¿‘æ‰¾åˆ°çš„æ–‡æ¡£ä¸­æŸ¥æ‰¾æœ¯è¯­ã€‚è¿™ä¸ªä»£ç†ç­‰åŒäºåŸå§‹çš„ ReAct è®ºæ–‡ï¼Œç‰¹åˆ«æ˜¯ç»´åŸºç™¾ç§‘çš„ä¾‹å­ã€‚\n",
    "\n",
    "**self-ask-with-search**: è¯¥Agentä½¿ç”¨ä¸€ä¸ªå·¥å…·ï¼Œè¯¥å·¥å…·åº”å‘½åä¸º Intermediate Answerã€‚è¯¥å·¥å…·åº”è¯¥èƒ½å¤ŸæŸ¥æ‰¾é—®é¢˜çš„äº‹å®ç­”æ¡ˆã€‚è¿™ä¸ªä»£ç†ç›¸å½“äºåŸæ¥çš„ self ask with search paperï¼Œå…¶ä¸­æä¾›äº†ä¸€ä¸ª Google æœç´¢ API ä½œä¸ºå·¥å…·ã€‚\n",
    "\n",
    "**conversational-react-description**: è¯¥Agentæ—¨åœ¨ç”¨äºä¼šè¯è®¾ç½®ã€‚è¿™éƒ¨åˆ†æç¤ºçš„è®¾è®¡æ—¨åœ¨ä½¿agentå¯ä»¥æä¾›åˆ°å¸®åŠ©ä»¥åŠä¾¿äºå¼€å±•å¯¹è¯ã€‚å®ƒä½¿ç”¨ ReAct æ¡†æ¶æ¥å†³å®šä½¿ç”¨å“ªä¸ªå·¥å…·ï¼Œå¹¶ä½¿ç”¨å†…å­˜æ¥è®°ä½ä¹‹å‰çš„å¯¹è¯äº¤äº’ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Agent\n",
    "\n",
    "å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰çš„Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool,AgentExecutor\n",
    "from langchain.agents import BaseSingleActionAgent\n",
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from typing import List, Tuple, Any, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\"\"\"\n",
    "åˆ›å»ºäº†ä¸€ä¸ªåä¸º search çš„ SerpAPIWrapper å¯¹è±¡ã€‚ç„¶åï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º tools çš„åˆ—è¡¨ï¼Œ\n",
    "å…¶ä¸­åŒ…å«äº†ä¸€ä¸ªåä¸º \"Search\" çš„ Tool å¯¹è±¡ã€‚è¿™ä¸ª Tool å¯¹è±¡å¯ä»¥è¢«è°ƒç”¨ï¼Œå…¶åŠŸèƒ½æ˜¯æœç´¢ç›¸å…³ä¿¡æ¯ã€‚\n",
    "æ¥ç€ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º FakeAgent çš„ç±»ï¼Œç»§æ‰¿è‡ª BaseSingleActionAgentã€‚è¿™ä¸ªç±»çš„ä½œç”¨æ˜¯æ¨¡æ‹Ÿä¸€\n",
    "ä¸ªå‡çš„æ™ºèƒ½ä½“ï¼Œå®ƒæœ‰ä¸€ä¸ªè¾“å…¥é”®(input_keys)å±æ€§ï¼Œç”¨äºæ¥æ”¶ç”¨æˆ·è¾“å…¥ã€‚åœ¨ plan() æ–¹æ³•ä¸­ï¼Œæ ¹æ®å½“å‰\n",
    "çŠ¶æ€å’Œç”¨æˆ·è¾“å…¥å†³å®šè¦é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ï¼Œè¿”å›ä¸€ä¸ª AgentAction æˆ– AgentFinish å¯¹è±¡ã€‚æœ€åï¼Œåˆ›å»ºäº†\n",
    "ä¸€ä¸ªåä¸º agent çš„ FakeAgent å¯¹è±¡ï¼Œå¹¶é€šè¿‡ AgentExecutor.from_agent_and_tools() æ–¹æ³•\n",
    "åˆ›å»ºäº†ä¸€ä¸ª AgentExecutor å¯¹è±¡ã€‚ç„¶åè°ƒç”¨äº† run() æ–¹æ³•ï¼Œä¼ å…¥äº†ä¸€ä¸ªæŸ¥è¯¢è¯­å¥ \"How many people\n",
    " live in canada as of 2023?\",è¯¥æŸ¥è¯¢å°†ç”±æ™ºèƒ½ä½“æ‰§è¡Œã€‚\n",
    "\"\"\"\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "        return_direct=True\n",
    "    )\n",
    "]\n",
    "class FakeAgent(BaseSingleActionAgent):\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"input\"]\n",
    "    \n",
    "    def plan(\n",
    "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        return AgentAction(tool=\"Search\", tool_input=kwargs[\"input\"], log=\"\")\n",
    "\n",
    "    async def aplan(\n",
    "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        return AgentAction(tool=\"Search\", tool_input=kwargs[\"input\"], log=\"\")\n",
    "\n",
    "agent = FakeAgent()\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom LLM Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMä»£ç†ç”±å‡ éƒ¨åˆ†ç»„æˆï¼š\n",
    "\n",
    "1. PromptTemplateï¼šè¿™æ˜¯æç¤ºæ¨¡æ¿ï¼Œå¯ç”¨äºæŒ‡ç¤ºè¯­è¨€æ¨¡å‹åšä»€ä¹ˆ\n",
    "\n",
    "2. LLMï¼šè¿™æ˜¯ä¸ºä»£ç†æä¾›æ”¯æŒçš„è¯­è¨€æ¨¡å‹\n",
    "\n",
    "3. StopSequenceï¼šæŒ‡ç¤ºLLMä¸€æ—¦æ‰¾åˆ°è¿™ä¸ªå­—ç¬¦ä¸²å°±åœæ­¢ç”Ÿæˆ\n",
    "\n",
    "4. OutputParserï¼šè¿™å†³å®šäº†å¦‚ä½•å°† LLMOutput è§£æä¸º AgentAction æˆ– AgentFinish å¯¹è±¡\n",
    "\n",
    "LLMAgent åœ¨ AgentExecutor ä¸­ä½¿ç”¨ã€‚è¿™ä¸ª AgentExecutor åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¯ä»¥è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªå¾ªç¯ï¼š\n",
    "1. å°†ç”¨æˆ·è¾“å…¥å’Œä»»ä½•å…ˆå‰çš„æ­¥éª¤ä¼ é€’ç»™ä»£ç†ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸º LLMAgentï¼‰\n",
    "\n",
    "2. å¦‚æœä»£ç†è¿”å›ä¸€ä¸ªAgentFinishï¼Œåˆ™ç›´æ¥å°†å…¶è¿”å›ç»™ç”¨æˆ·\n",
    "\n",
    "3. å¦‚æœ Agent è¿”å›ä¸€ä¸ªAgentActionï¼Œåˆ™ä½¿ç”¨å®ƒæ¥è°ƒç”¨ä¸€ä¸ªå·¥å…·å¹¶è·å¾—ä¸€ä¸ªObservation\n",
    "\n",
    "4. é‡å¤ï¼Œå°†AgentActionå’Œä¼ é€’Observationå›ä»£ç†ï¼Œç›´åˆ°AgentFinishå‘å‡º ã€‚\n",
    "\n",
    "AgentActionactionæ˜¯ç”±å’Œç»„æˆçš„å“åº”action_inputã€‚actionæŒ‡çš„æ˜¯ä½¿ç”¨å“ªä¸ªå·¥å…·ï¼Œå¹¶action_inputæŒ‡çš„æ˜¯è¯¥å·¥å…·çš„è¾“å…¥ã€‚logä¹Ÿå¯ä»¥ä½œä¸ºæ›´å¤šä¸Šä¸‹æ–‡æä¾›ï¼ˆå¯ç”¨äºæ—¥å¿—è®°å½•ã€è·Ÿè¸ªç­‰ï¼‰ã€‚\n",
    "\n",
    "AgentFinishæ˜¯åŒ…å«è¦å‘é€å›ç”¨æˆ·çš„æœ€ç»ˆæ¶ˆæ¯çš„å“åº”ã€‚è¿™åº”è¯¥ç”¨äºç»“æŸä»£ç†è¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "\"\"\"å®šä¹‰äº†ä¸€ä¸ªåä¸º search çš„æœç´¢å¼•æ“å¯¹è±¡ï¼Œå¹¶å°†å…¶å°è£…æˆä¸€ä¸ª Tool å¯¹è±¡æ·»åŠ åˆ°\n",
    "tools åˆ—è¡¨ä¸­ï¼Œä»¥ä¾¿åœ¨åç»­çš„ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­ä½¿ç”¨ã€‚\n",
    "\"\"\"\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™éƒ¨åˆ†æŒ‡ç¤ºä»£ç†åšä»€ä¹ˆã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæ¨¡æ¿åº”åŒ…æ‹¬ï¼š\n",
    "\n",
    "- toolsï¼šagentå¯ä»¥é€‰æ‹©è®¿é—®å“ªäº›å·¥å…·ä»¥åŠè°ƒç”¨å®ƒä»¬çš„æ–¹å¼å’Œæ—¶é—´ã€‚\n",
    "\n",
    "- intermediate_stepsï¼šè¿™äº›æ˜¯å…ˆå‰ ( AgentAction, Observation) å¯¹åº”çš„å…ƒç»„å¯¹å„¿ã€‚è¿™äº›ä¸€èˆ¬ä¸ä¼šç›´æ¥ä¼ é€’ç»™æ¨¡å‹ï¼Œè€Œæ˜¯æç¤ºæ¨¡æ¿ä»¥ç‰¹å®šçš„æ–¹å¼å¯¹å®ƒä»¬è¿›è¡Œæ ¼å¼åŒ–å¤„ç†ä¹‹åå†å‘é€ç»™llmã€‚\n",
    "\n",
    "- input: ä¸€èˆ¬ç”¨æˆ·çš„è¾“å…¥å†…å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\\n\\nQuestion: {input}\\n{agent_scratchpad}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º CustomPromptTemplate çš„ç±»ï¼Œç»§æ‰¿è‡ª StringPromptTemplateã€‚\n",
    "    template æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„å±æ€§ï¼Œè¡¨ç¤ºæç¤ºä¿¡æ¯çš„æ¨¡æ¿ï¼›\n",
    "    tools æ˜¯ä¸€ä¸ªåˆ—è¡¨ç±»å‹çš„å±æ€§ï¼Œè¡¨ç¤ºå¯ç”¨çš„å·¥å…·åˆ—è¡¨ï¼›\n",
    "    format æ˜¯ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºå°†ä¼ å…¥çš„å‚æ•°æ ¼å¼åŒ–æˆæç¤ºä¿¡æ¯ã€‚åœ¨ format æ–¹æ³•ä¸­ï¼Œé¦–å…ˆä»ä¼ å…¥çš„å‚æ•°ä¸­å¼¹å‡ºä¸€ä¸ªåä¸º intermediate_steps çš„å…³é”®å­—\n",
    "å‚æ•°ã€‚ç„¶åï¼Œéå†è¿™ä¸ªä¸­é—´æ­¥éª¤åˆ—è¡¨ï¼Œå°†æ¯ä¸ªæ­¥éª¤çš„æ“ä½œæ—¥å¿—å’Œè§‚å¯Ÿç»“æœæ‹¼æ¥åˆ°ä¸€ä¸ªå­—ç¬¦ä¸² thoughts ä¸­ã€‚æ¥ç€ï¼Œå°† thoughts å­˜å…¥ agent_scratchpad \n",
    "ä¸­ï¼Œå¹¶å°†å¯ç”¨çš„å·¥å…·ä¿¡æ¯æ·»åŠ åˆ°tools å’Œ tool_names ä¸­ã€‚æœ€åï¼Œè°ƒç”¨çˆ¶ç±»çš„ format æ–¹æ³•ï¼Œå°†æ ¼å¼åŒ–åçš„æç¤ºä¿¡æ¯è¿”å›ã€‚\n",
    "\"\"\"\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: str\n",
    "    tools: List[Tool]\n",
    "    def format(self, **kwargs) -> str:\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º prompt çš„å˜é‡ï¼Œç±»å‹ä¸º CustomPromptTemplateã€‚è¯¥å˜é‡é€šè¿‡è°ƒç”¨çˆ¶ç±» StringPromptTemplate çš„æ„é€ å‡½æ•°\n",
    "è¿›è¡Œåˆå§‹åŒ–ï¼Œä¼ å…¥äº†ä¸‰ä¸ªå‚æ•°ï¼štemplateã€tools å’Œ input_variablesã€‚å…¶ä¸­ï¼Œtemplate æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„å‚æ•°ï¼Œè¡¨ç¤ºæç¤ºä¿¡æ¯çš„æ¨¡æ¿ï¼›\n",
    "tools æ˜¯ä¸€ä¸ªåˆ—è¡¨ç±»å‹çš„å‚æ•°ï¼Œè¡¨ç¤ºå¯ç”¨çš„å·¥å…·åˆ—è¡¨ï¼›input_variables æ˜¯ä¸€ä¸ªåˆ—è¡¨ç±»å‹çš„å‚æ•°ï¼Œè¡¨ç¤ºè¾“å…¥å˜é‡çš„åç§°åˆ—è¡¨ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œè¾“å…¥å˜\n",
    "é‡çš„åç§°ä¸º input å’Œ intermediate_stepsã€‚\n",
    "\"\"\"\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OutputParserè´Ÿè´£å°† LLM çš„è¾“å‡ºè§£æä¸ºAgentActionå’ŒAgentFinishã€‚è¿™é€šå¸¸åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ‰€ä½¿ç”¨çš„æç¤ºã€‚\n",
    "\n",
    "è¿™æ—¶å€™æ‚¨å¯ä»¥æ›´æ”¹è§£æä»¥è¿›è¡Œé‡è¯•ã€å¤„ç†ç©ºç™½ç­‰çš„åœ°æ–¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å®šä¹‰äº†ä¸€ä¸ªåä¸º output_parser çš„å˜é‡ï¼Œç±»å‹ä¸º CustomOutputParserã€‚è¯¥å˜é‡é€šè¿‡è°ƒç”¨çˆ¶ç±» \n",
    "AgentOutputParser çš„æ„é€ å‡½æ•°è¿›è¡Œåˆå§‹åŒ–ã€‚\n",
    "åœ¨ CustomOutputParser ç±»ä¸­ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º parse çš„æ–¹æ³•ï¼Œç”¨äºè§£æ LLM è¾“å‡ºã€‚è¯¥æ–¹æ³•æ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²\n",
    "ç±»å‹çš„å‚æ•° llm_output,è¿”å›å€¼ä¸º AgentAction æˆ– AgentFinish ç±»å‹çš„å¯¹è±¡ã€‚\n",
    "åœ¨ parse æ–¹æ³•ä¸­ï¼Œé¦–å…ˆåˆ¤æ–­è¾“å…¥çš„ LLM è¾“å‡ºæ˜¯å¦åŒ…å« \"Final Answer:\" å­—ç¬¦ä¸²ã€‚å¦‚æœæ˜¯ï¼Œåˆ™è¯´æ˜å·²ç»å®Œæˆäº†ä»»åŠ¡ï¼Œè¿”å› \n",
    "AgentFinish å¯¹è±¡ï¼›å¦åˆ™ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä» LLM è¾“å‡ºä¸­æå–å‡ºåŠ¨ä½œå’Œè¾“å…¥ä¿¡æ¯ã€‚å¦‚æœæ— æ³•æå–å‡ºåŠ¨ä½œå’Œè¾“å…¥ä¿¡æ¯ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸ã€‚\n",
    "æœ€åï¼Œæ ¹æ®æå–å‡ºçš„ä¿¡æ¯åˆ›å»º AgentAction å¯¹è±¡å¹¶è¿”å›ã€‚\n",
    "\"\"\"\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰StopSequence(åœæ­¢åºåˆ—)ï¼Œè¿™å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒå‘Šè¯‰ LLM ä½•æ—¶åœæ­¢ç”Ÿæˆã€‚\n",
    "\n",
    "è¿™åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ‚¨ä½¿ç”¨çš„æç¤ºå’Œæ¨¡å‹ã€‚é€šå¸¸ï¼Œæ‚¨å¸Œæœ›è¿™æ˜¯æ‚¨åœ¨æç¤ºä¸­ä½¿ç”¨çš„ä»»ä½•æ ‡è®°æ¥è¡¨ç¤ºä¸€ä¸ªå¼€å§‹Observationï¼ˆå¦åˆ™ï¼ŒLLM å¯èƒ½ä¼šä¸ºæ‚¨äº§ç”Ÿè™šæ‹Ÿçš„Observationï¼‰ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "#ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä» tools åˆ—è¡¨ä¸­æå–å‡ºæ¯ä¸ªå·¥å…·çš„åç§°ï¼Œå¹¶å°†è¿™äº›åç§°å­˜å‚¨åˆ° tool_names åˆ—è¡¨ä¸­ã€‚\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "\"\"\"\n",
    "ä¼ å…¥äº†å¦‚ä¸‹å‡ ä¸ªä¸ªå‚æ•°ï¼šllm_chainã€output_parserã€stopå’Œ allowed_toolsã€‚\n",
    "å…¶ä¸­ï¼Œllm_chain æ˜¯ä¸€ä¸ª LLMChain å¯¹è±¡ï¼Œè¡¨ç¤º LLM é“¾ï¼›\n",
    "output_parser æ˜¯ä¸€ä¸ª CustomOutputParser å¯¹è±¡ï¼Œè¡¨ç¤ºè§£æ LLM è¾“å‡ºçš„ç±»ï¼›\n",
    "allowed_tools æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œè¡¨ç¤ºå¯ç”¨çš„å·¥å…·åˆ—è¡¨ã€‚\n",
    "\"\"\"\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å®šä¹‰äº†ä¸€ä¸ªåä¸º agent_executor çš„å˜é‡ï¼Œç±»å‹ä¸º AgentExecutorã€‚\n",
    "è¯¥å˜é‡é€šè¿‡è°ƒç”¨ AgentExecutor ç±»çš„æ„é€ å‡½æ•°è¿›è¡Œåˆå§‹åŒ–ã€‚\n",
    "åœ¨æ„é€ å‡½æ•°ä¸­ï¼Œä¼ å…¥äº†ä¸‰ä¸ªå‚æ•°ï¼šagentã€tools å’Œ verboseã€‚\n",
    "å…¶ä¸­ï¼Œagent æ˜¯ä¸€ä¸ª LLMSingleActionAgent å¯¹è±¡ï¼Œè¡¨ç¤º LLM ä»£ç†ï¼›\n",
    "tools æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œè¡¨ç¤ºå¯ç”¨çš„å·¥å…·åˆ—è¡¨ï¼›\n",
    "verbose æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯ã€‚\n",
    "æ¥ä¸‹æ¥ï¼Œè°ƒç”¨ AgentExecutor ç±»çš„ from_agent_and_tools é™æ€æ–¹æ³•ï¼Œå°† agentã€tools å’Œ verbose \n",
    "ä½œä¸ºå‚æ•°ä¼ é€’ç»™å®ƒã€‚è¯¥æ–¹æ³•ä¼šè¿”å›ä¸€ä¸ªæ–°çš„ AgentExecutor å¯¹è±¡ï¼Œç”¨äºæ‰§è¡Œ LLM ä»»åŠ¡ã€‚\n",
    "\"\"\"\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self Ask With Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\"\"\"\n",
    "è¿™æ®µä»£ç å¯¼å…¥äº† OpenAI å’Œ SerpAPIWrapper æ¨¡å—ï¼Œä»¥åŠ initialize_agentã€Tool å’Œ AgentType ç±»ã€‚\n",
    "ç„¶åï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º llm çš„ OpenAI å¯¹è±¡ï¼Œç”¨äºæ‰§è¡Œ LLM ä»»åŠ¡ã€‚æ¥ç€ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º search çš„ SerpAPIWrapper å¯¹è±¡ï¼Œç”¨äºæœç´¢ç­”æ¡ˆã€‚\n",
    "æ¥ä¸‹æ¥ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º tools çš„åˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªåä¸º Intermediate Answer çš„å·¥å…·å¯¹è±¡ã€‚è¯¥å·¥å…·å¯¹è±¡å…·æœ‰ func å±æ€§ï¼ŒæŒ‡å®šäº†ä½¿ç”¨\n",
    " search.run() æ–¹æ³•æ¥æœç´¢ç­”æ¡ˆã€‚\n",
    " \"\"\"\n",
    "llm = OpenAI(temperature=0)\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    )\n",
    "]\n",
    "#è°ƒç”¨ initialize_agent å‡½æ•°åˆå§‹åŒ–ä¸€ä¸ªä»£ç†å¯¹è±¡ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™ self_ask_with_search å˜é‡ã€‚\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "self_ask_with_search.run(\"What is the hometown of the reigning men's U.S. Open champion?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Toolkits\n",
    "è¿™éƒ¨åˆ†ä¸»è¦åŒ…å«ä¸€äº›æˆäº†å·¥å…·çš„agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [CSV Agent](#csv-agent)\n",
    "- [Python Agent](#python-agent)\n",
    "- [Vectorstore Agent](#vectorstore-agent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CSV Agent\n",
    "æ ¹æ®ç»™å®šçš„csvæ–‡ä»¶å†…å®¹ï¼Œå›å¤ç”¨æˆ·é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_csv_agent\n",
    "from langchain.llms import OpenAI\n",
    "#æˆ‘ä»¬æ‰¾äº†ä¸€ä¸ªtitanicç”Ÿè¿˜è€…åå•ï¼Œé‡Œé¢æ˜¯ä¸€äº›å¹¸å­˜è€…çš„ä¿¡æ¯ï¼Œä½ å¯ä»¥ä¸Šä¼ ä¸€ä¸ªcsvæ–‡ä»¶ï¼Œå¹¶å¯¹csvæ–‡ä»¶è¿›è¡ŒåŸºæœ¬çš„è¯¢é—®\n",
    "agent = create_csv_agent(OpenAI(temperature=0), 'titanic.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to count the number of rows\n",
      "Action: python_repl_ast\n",
      "Action Input: len(df)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m891\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 891 rows in the dataframe.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 891 rows in the dataframe.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to count the number of people with more than 3 siblings\n",
      "Action: python_repl_ast\n",
      "Action Input: df[df['SibSp'] > 3].shape[0]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m30\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 30 people have more than 3 siblings.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'30 people have more than 3 siblings.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"how many people have more than 3 sibligngs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to calculate the average age first\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Age'].mean()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m29.69911764705882\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now need to calculate the square root of this\n",
      "Action: python_repl_ast\n",
      "Action Input: math.sqrt(df['Age'].mean())\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mname 'math' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to import the math library\n",
      "Action: python_repl_ast\n",
      "Action Input: import math\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now need to calculate the square root of the average age\n",
      "Action: python_repl_ast\n",
      "Action Input: math.sqrt(df['Age'].mean())\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m5.449689683556195\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 5.449689683556195\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5.449689683556195'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"whats the square root of the average age?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Python Agent\n",
    "è¯¥ä»£ç†ç”¨äºæ ¹æ®ç”¨æˆ·è¦æ±‚ç”Ÿæˆæˆ–æ‰§è¡Œä¸€æ®µpythonä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.llms.openai import OpenAI\n",
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º agent_executor çš„å˜é‡ï¼Œç±»å‹ä¸º AgentExecutorã€‚è¯¥å˜é‡é€šè¿‡è°ƒç”¨ create_python_agent å‡½æ•°è¿›è¡Œåˆå§‹åŒ–ã€‚\n",
    "åœ¨æ„é€ å‡½æ•°ä¸­ï¼Œä¼ å…¥äº†ä¸‰ä¸ªå‚æ•°ï¼šllmã€tool å’Œ verboseã€‚\n",
    "å…¶ä¸­ï¼Œllm æ˜¯ä¸€ä¸ª OpenAI å¯¹è±¡ï¼Œç”¨äºæ‰§è¡Œ LLM ä»»åŠ¡ï¼›\n",
    "tool æ˜¯ä¸€ä¸ªPythonREPLTool å¯¹è±¡ï¼Œè¡¨ç¤ºç”¨äºäº¤äº’å¼è§£é‡Šçš„å·¥å…·ï¼›\n",
    "verbose æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯ã€‚\n",
    "æ¥ä¸‹æ¥ï¼Œè°ƒç”¨ create_python_agent å‡½æ•°ï¼Œå°† llmã€tool å’Œ verbose ä½œä¸ºå‚æ•°ä¼ é€’ç»™å®ƒã€‚è¯¥å‡½æ•°ä¼šè¿”å›ä¸€ä¸ªæ–°çš„ AgentExecutor å¯¹è±¡ï¼Œ\n",
    "ç”¨äºæ‰§è¡Œ LLM ä»»åŠ¡å¹¶æä¾›äº¤äº’å¼è§£é‡ŠåŠŸèƒ½ã€‚\n",
    "\"\"\"\n",
    "agent_executor = create_python_agent(\n",
    "    llm=OpenAI(temperature=0, max_tokens=1000),\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ç”ŸæˆFibonacciæ•°åˆ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate the 10th fibonacci number\n",
      "Action: Python REPL\n",
      "Action Input: def fibonacci(n):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "\n",
      "print(fibonacci(10))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m55\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 55\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'55'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"What is the 10th fibonacci number?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "è®­ç»ƒç¥ç»ç½‘ç»œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to write a neural network in PyTorch and train it on the given data.\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "import torch\n",
      "\n",
      "# Define the model\n",
      "model = torch.nn.Sequential(\n",
      "    torch.nn.Linear(1, 1)\n",
      ")\n",
      "\n",
      "# Define the loss\n",
      "loss_fn = torch.nn.MSELoss()\n",
      "\n",
      "# Define the optimizer\n",
      "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
      "\n",
      "# Define the data\n",
      "x_data = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
      "y_data = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
      "\n",
      "# Train the model\n",
      "for epoch in range(1000):\n",
      "    # Forward pass\n",
      "    y_pred = model(x_data)\n",
      "\n",
      "    # Compute and print loss\n",
      "    loss = loss_fn(y_pred, y_data)\n",
      "    if (epoch+1) % 100 == 0:\n",
      "        print(f'Epoch {epoch+1}: loss = {loss.item():.4f}')\n",
      "\n",
      "    # Zero the gradients\n",
      "    optimizer.zero_grad()\n",
      "\n",
      "    # Backward pass\n",
      "    loss.backward()\n",
      "\n",
      "    # Update the weights\n",
      "    optimizer.step()\n",
      "\n",
      "# Make a prediction\n",
      "x_pred = torch.tensor([[5.0]])\n",
      "y_pred = model(x_pred)\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mEpoch 100: loss = 0.2032\n",
      "Epoch 200: loss = 0.1116\n",
      "Epoch 300: loss = 0.0613\n",
      "Epoch 400: loss = 0.0336\n",
      "Epoch 500: loss = 0.0185\n",
      "Epoch 600: loss = 0.0101\n",
      "Epoch 700: loss = 0.0056\n",
      "Epoch 800: loss = 0.0031\n",
      "Epoch 900: loss = 0.0017\n",
      "Epoch 1000: loss = 0.0009\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The prediction for x = 5 is y = 10.00.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The prediction for x = 5 is y = 10.00.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"\"\"Understand, write a single neuron neural network in PyTorch.\n",
    "Take synthetic data for y=2x. Train for 1000 epochs and print every 100 epochs.\n",
    "Return prediction for x = 5\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorstore Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\"\"\"\n",
    "ç„¶åï¼Œæœ€åï¼Œä½¿ç”¨ Chroma.from_documents() \n",
    "æ–¹æ³•å°†æ–‡æ¡£è½¬æ¢ä¸ºè¯­è°±å›¾ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨åä¸º state_of_union_store çš„å¯¹è±¡ä¸­ã€‚\n",
    "\"\"\"\n",
    "#åŠ è½½æŒ‡å®šçš„æ–‡æœ¬æ–‡ä»¶\n",
    "loader = TextLoader('../../../state_of_the_union.txt')\n",
    "#ä»æ–‡æœ¬æ–‡ä»¶ä¸­åŠ è½½æ–‡æ¡£\n",
    "documents = loader.load()\n",
    "#å®šä¹‰äº†ä¸€ä¸ªåä¸º text_splitter çš„ CharacterTextSplitter å¯¹è±¡ï¼Œç”¨äºå°†æ–‡æ¡£åˆ†æˆ\n",
    "#å¤šä¸ªå—ã€‚å…¶ä¸­ï¼Œchunk_size å‚æ•°æŒ‡å®šæ¯ä¸ªå—çš„å¤§å°ï¼Œchunk_overlap å‚æ•°æŒ‡å®šå—ä¹‹é—´çš„é‡å å¤§å°ã€‚\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "#å®šä¹‰äº†ä¸€ä¸ªåä¸ºembeddings çš„ OpenAIEmbeddings å¯¹è±¡ï¼Œç”¨äºç”Ÿæˆæ–‡æ¡£çš„åµŒå…¥è¡¨ç¤ºã€‚\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\"\"\"\n",
    "ä¸‹é¢ä»£ç æ˜¯ä½¿ç”¨ Chroma åº“ä»æ–‡æ¡£ä¸­æå–è¯­è°±å›¾ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ä¸€ä¸ªåä¸º state_of_union_store çš„å¯¹è±¡ä¸­ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒåšäº†ä»¥ä¸‹å‡ ä»¶äº‹æƒ…ï¼š\n",
    "ä»ä¸€ä¸ªåä¸º texts çš„åˆ—è¡¨ä¸­åŠ è½½å¤šä¸ªæ–‡æœ¬æ–‡ä»¶ã€‚\n",
    "å°†æ¯ä¸ªæ–‡æœ¬æ–‡ä»¶è½¬æ¢ä¸ºä¸€ä¸ªåŒ…å«å•è¯å’Œå®ƒä»¬å¯¹åº”çš„åµŒå…¥å‘é‡çš„åˆ—è¡¨ã€‚è¿™äº›åµŒå…¥å‘é‡æ˜¯é€šè¿‡è°ƒç”¨ OpenAIEmbeddings ç±»çš„ generate() æ–¹æ³•ç”Ÿæˆçš„ã€‚\n",
    "ä½¿ç”¨ Chroma.from_documents() æ–¹æ³•å°†æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶çš„åµŒå…¥å‘é‡åˆ—è¡¨åˆå¹¶æˆä¸€ä¸ªå®Œæ•´çš„è¯­è°±å›¾ã€‚è¯¥æ–¹æ³•æ¥å—ä¸‰ä¸ªå‚æ•°ï¼štextsã€embeddings å’Œ \n",
    "collection_name,åˆ†åˆ«è¡¨ç¤ºè¦åŠ è½½çš„æ–‡æœ¬æ–‡ä»¶åˆ—è¡¨ã€æ¯ä¸ªæ–‡æœ¬æ–‡ä»¶ä¸­çš„åµŒå…¥å‘é‡åˆ—è¡¨ä»¥åŠè¯­è°±å›¾çš„é›†åˆåç§°ã€‚\n",
    "æœ€ç»ˆï¼Œè¿™æ®µä»£ç ä¼šå°†ç”Ÿæˆçš„è¯­è°±å›¾å­˜å‚¨åœ¨åä¸º state_of_union_store çš„å¯¹è±¡ä¸­ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨ã€‚\n",
    "\"\"\"\n",
    "state_of_union_store = Chroma.from_documents(texts, embeddings, collection_name=\"state-of-union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "#åˆ›å»ºä¸€ä¸ª WebBaseLoader å¯¹è±¡å¹¶æŒ‡å®šè¦åŠ è½½çš„ URL\n",
    "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")\n",
    "#è°ƒç”¨ load() æ–¹æ³•ä»æŒ‡å®šçš„ URL åŠ è½½æ–‡æ¡£ã€‚è¯¥æ–¹æ³•è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ–‡æ¡£çš„åˆ—è¡¨ã€‚\n",
    "docs = loader.load()\n",
    "#ä½¿ç”¨ text_splitter.split_documents() æ–¹æ³•å°†æ‰€æœ‰æ–‡æ¡£åˆ†å‰²æˆå¤šä¸ªæ–‡æœ¬æ®µè½ã€‚è¯¥æ–¹æ³•æ¥å—ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ–‡æ¡£çš„åˆ—è¡¨ä½œä¸ºå‚æ•°ï¼Œ\n",
    "#å¹¶è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ–‡æœ¬æ®µè½çš„åˆ—è¡¨ã€‚\n",
    "ruff_texts = text_splitter.split_documents(docs)\n",
    "\"\"\"\n",
    "ä½¿ç”¨ Chroma.from_documents() æ–¹æ³•å°†æ‰€æœ‰æ–‡æœ¬æ®µè½è½¬æ¢ä¸ºè¯­è°±å›¾ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨\n",
    "ä¸€ä¸ªåä¸º ruff_store çš„å¯¹è±¡ä¸­ã€‚è¯¥æ–¹æ³•æ¥å—ä¸‰ä¸ªå‚æ•°ï¼šruff_textsã€embeddings å’Œ collection_name,åˆ†åˆ«è¡¨ç¤ºæ‰€æœ‰æ–‡æœ¬\n",
    "æ®µè½çš„åˆ—è¡¨ã€æ¯ä¸ªæ–‡æœ¬æ®µè½å¯¹åº”çš„åµŒå…¥å‘é‡åˆ—è¡¨ä»¥åŠè¯­è°±å›¾çš„é›†åˆåç§°ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œè¯­è°±å›¾çš„é›†åˆåç§°ä¸º \"ruff\"\n",
    "\"\"\"\n",
    "ruff_store = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import (\n",
    "    create_vectorstore_agent,\n",
    "    VectorStoreToolkit,\n",
    "    VectorStoreInfo,\n",
    ")\n",
    "#é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ª VectorStoreInfo å¯¹è±¡ï¼Œå¹¶æŒ‡å®šå…¶åç§°ã€æè¿°å’ŒæŒ‡å‘è¯­è°±å›¾å­˜å‚¨å¯¹è±¡çš„vectorstore\n",
    "vectorstore_info = VectorStoreInfo(\n",
    "    name=\"state_of_union_address\",\n",
    "    description=\"the most recent state of the Union adress\",\n",
    "    vectorstore=state_of_union_store\n",
    ")\n",
    "#åˆ›å»ºä¸€ä¸ª VectorStoreToolkit å¯¹è±¡ï¼Œå°† vectorstore_info å¯¹è±¡ä½œä¸ºå‚æ•°ä¼ é€’ç»™å®ƒã€‚è¯¥å¯¹è±¡ç”¨äºç®¡ç†ä¸å‘é‡å­˜å‚¨ç›¸å…³çš„å…ƒæ•°æ®å’Œå·¥å…·ã€‚\n",
    "toolkit = VectorStoreToolkit(vectorstore_info=vectorstore_info)\n",
    "\"\"\"\n",
    "ä½¿ç”¨ create_vectorstore_agent() æ–¹æ³•åˆ›å»ºä¸€ä¸ª\n",
    "ä»£ç†ã€‚è¯¥æ–¹æ³•æ¥å—ä¸‰ä¸ªå‚æ•°ï¼šllm,è¡¨ç¤ºè¯­è¨€æ¨¡å‹ï¼›toolkit,è¡¨ç¤º VectorStoreToolkit å¯¹è±¡ï¼›verbose,è¡¨ç¤ºæ˜¯å¦å¯ç”¨è¯¦\n",
    "ç»†è¾“å‡ºæ¨¡å¼ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œä»£ç†å°†ä½¿ç”¨ llm ä½œä¸ºå…¶è¯­è¨€æ¨¡å‹ï¼Œå¹¶å°† toolkit ä½œä¸ºå…¶å·¥å…·åŒ…ã€‚æœ€ç»ˆï¼Œä»£ç†çš„æ‰§è¡Œå™¨å°†è¢«è¿”å›ï¼Œ\n",
    "å¯ä»¥å°†å…¶ç”¨äºæ‰§è¡Œç‰¹å®šçš„ä»»åŠ¡æˆ–æ“ä½œã€‚\n",
    "\"\"\"\n",
    "agent_executor = create_vectorstore_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What did biden say about ketanji brown jackson is the state of the union address?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What did biden say about ketanji brown jackson is the state of the union address? List the source.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Vectorstores\n",
    "\n",
    "å¤šä¸ªçŸ¢é‡å­˜å‚¨åº“ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å¾ˆå®¹æ˜“åœ°ä½¿ç”¨è¿™ä¸ªåˆå§‹åŒ–ä¸€ä¸ªå…·æœ‰å¤šä¸ªå‘é‡å­˜å‚¨çš„ä»£ç†ï¼Œå¹¶ä½¿ç”¨ä»£ç†åœ¨å®ƒä»¬ä¹‹é—´è¿æ¥ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ã€‚è¿™ä¸ªä»£ç†æ˜¯ä¸ºè¿æ¥å½¼æ­¤è€Œä¼˜åŒ–çš„ï¼Œæ‰€ä»¥å®ƒæ˜¯ä¸€ä¸ªä¸åŒçš„å·¥å…·åŒ…å’Œåˆå§‹åŒ–å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import (\n",
    "    create_vectorstore_router_agent,\n",
    "    VectorStoreRouterToolkit,\n",
    "    VectorStoreInfo,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VectorStoreInfoè¿™ä¸ªç±»å®ä¾‹ç”¨äºè¡¨ç¤ºå‘é‡å­˜å‚¨çš„ä¿¡æ¯ã€‚\n",
    "å®ƒæœ‰ä¸‰ä¸ªå±æ€§ï¼šnameã€descriptionå’Œvectorstore,åˆ†åˆ«è¡¨ç¤ºåç§°ã€æè¿°å’ŒæŒ‡å‘å‘é‡å­˜å‚¨å¯¹è±¡çš„å­˜å‚¨åº“ã€‚\n",
    "\"\"\"\n",
    "ruff_vectorstore_info = VectorStoreInfo(\n",
    "    name=\"ruff\",\n",
    "    description=\"Information about the Ruff python linting library\",\n",
    "    vectorstore=ruff_store\n",
    ")\n",
    "\"\"\"\n",
    "VectorStoreRouterToolkitè¿™ä¸ªç±»ç”¨äºè¡¨ç¤ºå‘é‡å­˜å‚¨è·¯ç”±å™¨å·¥å…·åŒ…ã€‚\n",
    "å®ƒæœ‰ä¸€ä¸ªå±æ€§vectorstores,è¡¨ç¤ºåŒ…å«å¤šä¸ªå‘é‡å­˜å‚¨ä¿¡æ¯çš„åˆ—è¡¨ï¼Œå‚æ•°llm,è¡¨ç¤ºè¯­è¨€æ¨¡å‹ã€‚\n",
    "\"\"\"\n",
    "router_toolkit = VectorStoreRouterToolkit(\n",
    "    vectorstores=[vectorstore_info, ruff_vectorstore_info],\n",
    "    llm=llm\n",
    ")\n",
    "\"\"\"\n",
    "create_vectorstore_router_agentè¿™ä¸ªæ–¹æ³•ç”¨äºåˆ›å»ºä¸€ä¸ªä»£ç†ï¼Œè¯¥ä»£ç†å°†ä½¿ç”¨å‘é‡å­˜å‚¨è·¯ç”±å™¨å·¥å…·åŒ…æ¥å¤„ç†æ¶ˆæ¯ã€‚\n",
    "å®ƒæœ‰ä¸‰ä¸ªå‚æ•°ï¼šllmã€toolkitå’Œverbose,åˆ†åˆ«è¡¨ç¤ºè¯­è¨€æ¨¡å‹ã€å·¥å…·åŒ…å’Œè¯¦ç»†è¾“å‡ºæ¨¡å¼ã€‚\n",
    "\"\"\"\n",
    "agent_executor = create_vectorstore_router_agent(\n",
    "    llm=llm,\n",
    "    toolkit=router_toolkit,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What did biden say about ketanji brown jackson is the state of the union address?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What tool does ruff use to run over Jupyter Notebooks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exampls\n",
    "\n",
    "- [Question answering in documents](#question-answering-in-documents)\n",
    "- [BabyAGI with Tools](#babyagi-with-tools)\n",
    "- [Auto-GPT Assistant](#auto-gpt-assistant)\n",
    "\n",
    "### Question answering in documents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é—®ç­”å¯ä»¥ä½¿ç”¨ä¸åŒçš„chainsï¼šstuffï¼Œmap_reduceï¼Œrefineå’Œmap_rerank\n",
    "\n",
    "å…¶ä¸­çš„stuffæ˜¯æœ€å¸¸ä½¿ç”¨çš„æ–¹å¼ï¼›map_reduceå¯ä»¥æŠŠè¾“å…¥çš„æ•°æ®åˆ†å‰²æˆè‹¥å¹²ä¸ªå°çš„æ•°æ®å—ï¼Œå¹¶åœ¨è¿™äº›å°çš„æ•°æ®å—ä¸Šç‹¬ç«‹åœ°æ‰§è¡Œè®¡ç®—ï¼Œç„¶åå°†è®¡ç®—ç»“æœè¿›è¡Œæ±‡æ€»ï¼Œä»è€Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºç»“æœï¼›refineæ˜¯æ ¹æ®ä¸Šä¸‹æ–‡çš„ä¿¡æ¯å’Œä¸€ä¸ªé—®é¢˜ç»™å‡ºä¸€ä¸ªåˆæ­¥çš„ç­”æ¡ˆï¼Œå¦‚æœç­”æ¡ˆä¸å¤Ÿå‡†ç¡®å°±ä¼šè¿­ä»£æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ä»¥åŠä¹‹å‰çš„å›ç­”æ¥æä¾›æ›´å¥½çš„ç­”æ¡ˆï¼Œç›´åˆ°æ‰¾åˆ°æœ€ç»ˆçš„æœ€ä½³ç­”æ¡ˆã€‚\n",
    "\n",
    "è¯¦ç»†çš„æ–‡æ¡£è¯´æ˜ç‚¹å‡»ğŸ‘‰[æ­¤å¤„](https://python.langchain.com/en/latest/use_cases/question_answering.html)ğŸ‘ˆç›´æ¥è·³è½¬ã€‚\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬é’ˆå¯¹è¿™ä¸ªç¤ºä¾‹è¿›è¡Œé€è¡Œçš„ä»£ç è§£é‡Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# è®¾ç½®HTTPä»£ç†\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:your port'\n",
    "# è®¾ç½®HTTPSä»£ç†\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:your port'\n",
    "# openaiçš„key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your OpenAI Key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#å¯¼å…¥ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡çš„æ‰€éœ€è¦çš„åº“\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "#å¯¼å…¥å°†æ–‡æœ¬åˆ†å‰²æˆå›ºå®šé•¿åº¦çš„å°å—ï¼Œæ–¹ä¾¿è¿›è¡ŒåµŒå…¥å‘é‡çš„è®¡ç®—å’Œå­˜å‚¨\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "#å¯¼å…¥å°†æ–‡æœ¬åµŒå…¥å‘é‡å­˜å‚¨åˆ°å‘é‡åº“ç§ï¼Œä»¥ä¾¿è¿›è¡Œæ–‡æœ¬æ£€ç´¢å’Œç›¸ä¼¼åº¦çš„è®¡ç®—\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores import Chroma\n",
    "#å¯¼å…¥æ–‡æ¡£å¯¹è±¡ï¼ŒåŒ…å«äº†æ–‡æ¡£çš„åç§°å’Œä½œè€…æ‘˜è¦å†…å®¹ç­‰ä¿¡æ¯\n",
    "from langchain.docstore.document import Document\n",
    "#å¯¼å…¥æ¨¡æ¿åˆ›å»ºåº“ï¼Œè¡¨ç¤ºé—®ç­”æ¨¡æ¿ï¼ŒåŒ…å«é—®é¢˜ç­”æ¡ˆæç¤ºç­‰ä¿¡æ¯æ–¹ä¾¿è¿›è¡Œé—®ç­”\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#åŠ è½½æ–‡æœ¬æ•°æ®ï¼Œå½“ç„¶è¿™ä¸€æ­¥å®Œå…¨å¯ä»¥è°ƒç”¨å¯¹åº”çš„loaderå®Œæˆï¼Œç¤ºä¾‹å¦‚ä¸‹çš„æ³¨é‡Šéƒ¨åˆ†ï¼š\n",
    "# from langchain.document_loaders import TextLoader\n",
    "# loader = TextLoader(\"./state_of_the_union.txt\")\n",
    "with open(\"./state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "#åˆ›å»ºä¸€ä¸ªcharactertextspliterå¯¹è±¡ï¼Œè¿™ä¸ªå¯¹è±¡ç”¨äºå°†æ–‡æ¡£åˆ‡åˆ†æˆå›ºå®šå¤§å°çš„æ–‡æœ¬å—ï¼Œè¿™é‡Œæ˜¯ç”¨ä¸€ä¸ªæ–‡æœ¬å—å¤§å°ä¸º1000å­—ç¬¦ä¸²çš„åˆ‡åˆ†å™¨ï¼Œå¹¶ä¸”ä¸å…è®¸æ–‡æœ¬å—ä¹‹é—´æœ‰é‡å çš„éƒ¨åˆ†\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "#æ–‡æœ¬åˆ‡åˆ†å™¨å¯¹è±¡çš„split_documentsæ–¹æ³•å°†æ–‡æ¡£æ•°æ®åˆ†å‰²æˆè‹¥å¹²ä¸ªæ–‡æœ¬ï¼Œè¿”å›ä¸€ä¸ªæ–‡æœ¬å—åˆ—è¡¨ï¼Œå¹¶å°†ç»“æœä¿å­˜å­˜å‚¨åˆ°textså˜é‡ä¸­\n",
    "texts = text_splitter.split_text(state_of_the_union)\n",
    "\n",
    "#åˆ›å»ºembeddingå¯¹è±¡ï¼Œè®¡ç®—æ–‡æœ¬æ•°æ®çš„è¯å‘é‡ï¼Œè¿™ä¸ªå¯¹è±¡ä½¿ç”¨Openaiçš„gpt-3è¿›è¡Œè®¡ç®—ï¼Œå¯ä»¥å°†ä¸€ä¸ªæ–‡æœ¬å­—ç¬¦ä¸²æ˜ å°„ä¸ºä¸€ä¸ª768ç»´åº¦çš„è¯å‘é‡\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "#ä½¿ç”¨chromaç±»çš„from_documentsæ–¹æ³•ï¼Œå°†æ–‡æœ¬å—åˆ—è¡¨å’Œè¯å‘é‡å¯¹è±¡ä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œç”Ÿæˆä¸€ä¸ªchromaå¯¹è±¡ï¼Œchromaå¯¹è±¡å¯ä»¥ç”¨äºæœç´¢æ–‡æœ¬å—ä¸­çš„ç›¸ä¼¼æ–‡æœ¬ä¿¡æ¯ï¼Œå¯ä»¥ç”¨äºæ–‡æœ¬ç›¸ä¼¼åº¦çš„è®¡ç®—å’Œæ–‡æœ¬åŒ¹é…çš„ä»»åŠ¡ã€‚\n",
    "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#å®šä¹‰æˆ‘ä»¬çš„é—®é¢˜\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "#è°ƒç”¨docsearchçš„ç›¸ä¼¼åº¦è®¡ç®—æœç´¢æ–¹å¼å¯¹é—®é¢˜è¿›è¡Œæ£€ç´¢\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#å¯¼å…¥é—®ç­”æ¨¡å‹çš„langchain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "#ä½¿ç”¨openaiæ¨¡å‹æ¥ç”Ÿæˆæ–‡æœ¬çš„åµŒå…¥å‘é‡\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \" The president thanked Justice Breyer for his service and mentioned that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to continue Justice Breyer's legacy of excellence.\\nSOURCES: 31-pl\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#æ„å»ºä¸€ä¸ªé—®ç­”æ¨¡å‹chainï¼ŒæŠŠæ¨¡å‹å‚æ•°ä¼ å…¥é‡Œé¢\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "#è¿è¡Œchainæ¨¡å‹ï¼Œä½¿ç”¨docsä½œä¸ºè¾“å…¥æ–‡æ¡£çš„åˆ—è¡¨ï¼Œqueryä½œä¸ºé—®é¢˜ï¼Œä»è€Œè¿”å›æœ€ç»ˆçš„é—®é¢˜ç­”æ¡ˆ\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': '\\nç¸½çµ±æ²’æœ‰å°å¸æ³•å¤§æ³•å®˜å¸ƒé›·è€¶ç™¼è¡¨è©•è«–ã€‚\\nSOURCES: 31, 32, 34'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "ALWAYS return a \"SOURCES\" part in your answer.\n",
    "Respond in Chinese.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "FINAL ANSWER IN ITALIAN:\"\"\"\n",
    "#å®šä¹‰äº†ä¸€ä¸ªPromptTemplateç±»ï¼Œè¯¥ç±»ç”¨äºå°†æ¨¡æ¿(template)ä¸è¾“å…¥å˜é‡(input_variables)ç»‘å®šèµ·æ¥ã€‚\n",
    "#æ¨¡æ¿åŒ…æ‹¬äº†ä¸¤ä¸ªè¾“å…¥å˜é‡ï¼š\"summaries\"å’Œ\"question\"ã€‚\n",
    "PROMPT = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
    "#åŠ è½½ä¸€ä¸ªQA with Sourcesé“¾ï¼Œè¯¥é“¾ä½¿ç”¨OpenAIä½œä¸ºå…¶è¯­è¨€æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨PromptTemplateç±»æ¥ç”Ÿæˆå›ç­”é—®é¢˜çš„æç¤º\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\", prompt=PROMPT)\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "#ä½¿ç”¨chain()æ–¹æ³•å¯¹ç»™å®šçš„æ–‡æ¡£(docs)å’Œé—®é¢˜(query)è¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶è¿”å›åªåŒ…å«è¾“å‡ºç»“æœçš„å­—å…¸ã€‚\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BabyAGI with Tools\n",
    "\n",
    "<img src=\"./aa.png\"/>\n",
    "\n",
    "BabyAGI æ˜¯ä¸€ç§è‡ªä¸»äººå·¥æ™ºèƒ½ä»£ç†ï¼Œå¯ä»¥æ ¹æ®ç»™å®šç›®æ ‡ç”Ÿæˆå¹¶å‡è£…æ‰§è¡Œä»»åŠ¡ã€‚ï¼ˆè¿™ä¸ªåŠŸèƒ½æœ‰æ²¡æœ‰ç†Ÿæ‚‰ï¼Ÿå…¶å®æœ€è¿‘å¤§ç«çš„AutoGPTå°±æ˜¯åŸºäºæ­¤è¿›è¡Œçš„è®¾è®¡ï¼‰\n",
    "\n",
    "æˆ‘ä»¬é€šè¿‡è¿™ä¸ªæ¡ˆä¾‹å°†å¸®åŠ©æ‚¨äº†è§£åˆ›å»ºè‡ªå·±çš„é€’å½’ä»£ç†çš„ç»„ä»¶ã€‚\n",
    "\n",
    "å°½ç®¡ BabyAGI ä½¿ç”¨ç‰¹å®šçš„å‘é‡å­˜å‚¨/æ¨¡å‹æä¾›ç¨‹åºï¼ˆPineconeã€OpenAIï¼‰ï¼Œä½†ä½¿ç”¨ LangChain å®ç°å®ƒçš„å¥½å¤„ä¹‹ä¸€æ˜¯æ‚¨å¯ä»¥è½»æ¾åœ°å°†å®ƒä»¬æ¢æˆä¸åŒçš„é€‰é¡¹ã€‚åœ¨æ­¤å®ç°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ FAISS vectorstoreï¼ˆå› ä¸ºå®ƒåœ¨æœ¬åœ°è¿è¡Œä¸”å…è´¹ï¼‰ã€‚\n",
    "\n",
    "å…³äºBabyAGIçš„è¯¦ç»†è¯´æ˜å¯ä»¥[ç‚¹å‡»æ­¤å¤„è®¿é—®](https://github.com/yoheinakajima/babyagi)ã€‚\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é‚£ä¹ˆæˆ‘ä»¬åœ¨è¿™ä¸ªæ¡ˆä¾‹å¼€å§‹ä¹‹å‰é¦–å…ˆå¾—çŸ¥é“ä»€ä¹ˆæ˜¯BabyAGIå¯¹å§ï¼Ÿä¸‹é¢æ˜¯ä¸€ä¸ªBabyAGIçš„ç”¨æˆ·æ“ä½œæŒ‡å—ï¼Œæˆ‘ä»¬ç†Ÿæ‚‰è¿™ä¸ªä¹‹åå†è¿›ä¸€æ­¥çœ‹ä¸Šé¢ç›¸å…³çš„ä»£ç æ¡ˆä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# è®¾ç½®HTTPä»£ç†\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:port'\n",
    "# è®¾ç½®HTTPSä»£ç†\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:port'\n",
    "# openaiçš„key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your openai key like :sk-xxxxxxxxxxxxxxxx\"\n",
    "#è°·æ­Œæœç´¢apiçš„key,ä»…åœ¨agentä¸­ä½¿ç”¨\n",
    "os.environ['SERPAPI_API_KEY']='your search API KEY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#dequeå¯ä»¥ä»é˜Ÿåˆ—ä¸¤ç«¯æ‰§è¡Œå¿«é€Ÿçš„æ·»åŠ å’Œå¼¹å‡ºæ“ä½œ\n",
    "from collections import deque\n",
    "#ç±»å‹æç¤ºåŠŸèƒ½ï¼Œå¯ä»¥è¿›è¡Œç±»å‹æ³¨é‡Šå’Œç±»å‹æ£€æŸ¥\n",
    "from typing import Dict, List, Optional, Any\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.base import Chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿æ¥åˆ°çŸ¢é‡å­˜å‚¨åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#è¿™ä¸ªç±»å¯ä»¥ç”¨äºåŸºäºå‘é‡å­˜å‚¨åº“çª’æ¯æ„Ÿè¿‘ä¼¼æœç´¢çš„ç±»ï¼Œç”±metaå¼€å‘çš„å¼‚ç§éª¨é«˜æ•ˆçš„è¿‘ä¼¼æœ€è¿‘æœç´¢åº“ï¼Œå¯ä»¥å¤„ç†é«˜ç»´å‘é‡æ•°æ®\n",
    "from langchain.vectorstores import FAISS\n",
    "#è¿™ä¸ªç±»æ˜¯ä¸€ä¸ªç”¨äºåœ¨å†…å­˜ä¸­å­˜å‚¨æ–‡æœ¬æ–‡æ¡£çš„ç±»ï¼Œæä¾›äº†æ·»åŠ ã€æ£€ç´¢å’Œåˆ é™¤æ–‡æ¡£çš„æ–¹æ³•ï¼Œæ˜¯ä¸€ä¸ªç®€å•æœ‰ç”¨çš„æ–‡æ¡£å­˜å‚¨è§£å†³æ–¹æ¡ˆ\n",
    "from langchain.docstore import InMemoryDocstore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæ²¡æœ‰å®‰è£…faissåº“ï¼Œè¯·å…è®¸ä¸‹é¢çš„ä»£ç ï¼Œå¦åˆ™è·³è¿‡ä¸‹é¢pipè¿™ä¸€æ­¥å³å¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your embedding model:text-embedding-ada-002\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "# Initialize the vectorstore as emptyï¼Œé€‰æ‹©çš„vectorstoreæ˜¯faiss\n",
    "import faiss\n",
    "#æ–‡æœ¬emmbeddingçš„ç»´æ•°ï¼Œæ¯ä¸ªæ–‡æœ¬åµŒå…¥å‘é‡ä¸­åŒ…å«çš„æ•°å­—æ•°é‡\n",
    "embedding_size = 1536\n",
    "#å‘é‡ç©ºé—´ä¸­æ‰§è¡Œè¿‘ä¼¼æœ€è¿‘æœç´¢ï¼Œä½¿ç”¨çš„æ˜¯L2è·ç¦»è¡¡é‡å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "#embeddings_model.embed_queryç”¨äºå°†æ–‡æœ¬æŸ¥è¯¢è½¬æ¢ä¸ºåµŒå…¥å‘é‡ï¼ŒInMemoryDocstoreç”¨äºåœ¨å†…å­˜ä¸­å­˜å‚¨æ–‡æ¡£ï¼Œæœ€ç»ˆå°†å…¶å­˜åœ¨vectorstoreä¸­\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰é“¾\n",
    "\n",
    "BabyAGI ä¾èµ–äºä¸‰ä¸ª LLM é“¾ï¼š\n",
    "\n",
    "ä»»åŠ¡åˆ›å»ºé“¾é€‰æ‹©æ–°ä»»åŠ¡æ·»åŠ åˆ°åˆ—è¡¨\n",
    "\n",
    "ä»»åŠ¡ä¼˜å…ˆçº§é“¾ï¼Œç”¨äºé‡æ–°ç¡®å®šä»»åŠ¡çš„ä¼˜å…ˆçº§\n",
    "\n",
    "æ‰§è¡Œä»»åŠ¡çš„æ‰§è¡Œé“¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºTaskCreationChainçš„ç±»ï¼Œå®ƒæ˜¯LLMChainç±»çš„å­ç±»ã€‚è¯¥ç±»çš„ç›®çš„æ˜¯ç”Ÿæˆä»»åŠ¡ï¼Œå¹¶è¿”å›llmchainå¯¹è±¡ã€‚\n",
    "åœ¨ç±»å®šä¹‰ä¸­ï¼Œæœ‰ä¸€ä¸ªé™æ€æ–¹æ³•from_llm(),å®ƒæ¥å—ä¸€ä¸ªBaseLLMå¯¹è±¡å’Œä¸€ä¸ªå¸ƒå°”ç±»å‹çš„verboseå‚æ•°ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªLLMChainå¯¹è±¡ã€‚\n",
    "è¯¥æ–¹æ³•ä½¿ç”¨äº†ä¸€ä¸ªtask_creation_templateå­—ç¬¦ä¸²æ¥ç”Ÿæˆä¸€ä¸ªæç¤º(prompt),è¯¥æç¤ºç”¨äºæŒ‡å¯¼AIå®Œæˆä»»åŠ¡çš„åˆ›å»ºã€‚æ¥ä¸‹æ¥ï¼Œè¯¥ä»£ç è¿˜å®š\n",
    "ä¹‰äº†ä¸€ä¸ªPromptTemplateç±»ï¼Œè¯¥ç±»ç”¨äºå°†æ¨¡æ¿(template)ä¸è¾“å…¥å˜é‡(input_variables)ç»‘å®šèµ·æ¥ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæ¨¡æ¿åŒ…æ‹¬äº†äº”ä¸ª\n",
    "è¾“å…¥å˜é‡ï¼š\"result\"ã€\"task_description\"ã€\"incomplete_tasks\"ã€\"objective\" å’Œ \"previous_task_result\"ã€‚æœ€åï¼Œ\n",
    "å®ƒä½¿ç”¨cls()æ–¹æ³•åˆ›å»ºä¸€ä¸ªLLMChainå¯¹è±¡ï¼Œå¹¶å°†å…¶ä¿å­˜åœ¨task_creation_chainå˜é‡ä¸­ã€‚\n",
    "\"\"\"\n",
    "class TaskCreationChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Get the response parser.\n",
    "        ä»”ç»†çœ‹å…³äºæ¨¡ç‰ˆçš„è®¾è®¡éƒ¨åˆ†ï¼Œæ€ä¹ˆè®¾è®¡ä¹Ÿæ¯”è¾ƒé‡è¦ï¼šæ¯ä¸€æ¬¡è®¾å®šç›®æ ‡ï¼Œä¹Ÿè¦ç»™å‡ºå®Œæˆè¿™ä¸ªç›®æ ‡çš„ç»“æœï¼Œè¿˜æœ‰\n",
    "        è¿™ä¸ªç»“æœå¯¹åº”çš„ä»»åŠ¡æè¿°ä¿¡æ¯ä¹Ÿä¼šç»™åˆ°ï¼Œæ­¤æ—¶è¿˜æ²¡æœ‰å®Œæ•´çš„ä»»åŠ¡å°±åŸºäºä¸Šé¢ç»™åˆ°çš„ç»“æœç»§ç»­ç½—åˆ—ä»»åŠ¡æ¸…å•ã€‚\n",
    "        å³ï¼šå››é¡¹å‚æ•°â€”â€”\n",
    "        1. objective ç›®æ ‡\n",
    "        2. result å‰ä¸€ä¸ªä»»åŠ¡ç»“æœ\n",
    "        3. task_description ä»»åŠ¡æè¿°\n",
    "        4. incomplete_tasks å½“å‰ä»»åŠ¡åˆ—è¡¨\n",
    "        \"\"\"\n",
    "        task_creation_template = (\n",
    "            \"You are an task creation AI that uses the result of an execution agent\"\n",
    "            \" to create new tasks with the following objective: {objective},\"\n",
    "            \" The last completed task has the result: {result}.\"\n",
    "            \" This result was based on this task description: {task_description}.\"\n",
    "            \" These are incomplete tasks: {incomplete_tasks}.\"\n",
    "            \" Based on the result, create new tasks to be completed\"\n",
    "            \" by the AI system that do not overlap with incomplete tasks.\"\n",
    "            \" Return the tasks as an array.\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_creation_template,\n",
    "            input_variables=[\n",
    "                \"result\",\n",
    "                \"task_description\",\n",
    "                \"incomplete_tasks\",\n",
    "                \"objective\",\n",
    "            ],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºTaskPrioritizationChainçš„ç±»ï¼Œå®ƒæ˜¯LLMChainç±»çš„å­ç±»ã€‚è¯¥ç±»çš„ç›®çš„æ˜¯ç¡®å®šä»»åŠ¡çš„ä¼˜å…ˆçº§ï¼Œå¹¶è¿”å›llmchainå¯¹è±¡ã€‚\n",
    "åœ¨ç±»å®šä¹‰ä¸­ï¼Œæœ‰ä¸€ä¸ªé™æ€æ–¹æ³•from_llm(),å®ƒæ¥å—ä¸€ä¸ªBaseLLMå¯¹è±¡å’Œä¸€ä¸ªå¸ƒå°”ç±»å‹çš„verboseå‚æ•°ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªLLMChainå¯¹è±¡ã€‚è¯¥æ–¹æ³•\n",
    "ä½¿ç”¨äº†ä¸€ä¸ªtask_prioritization_templateå­—ç¬¦ä¸²æ¥ç”Ÿæˆä¸€ä¸ªæç¤º(prompt),è¯¥æç¤ºç”¨äºæŒ‡å¯¼AIå®Œæˆä»»åŠ¡çš„ä¼˜å…ˆçº§æ’åºã€‚æ¥ä¸‹æ¥ï¼Œåˆå®šä¹‰äº†ä¸€ä¸ª\n",
    "PromptTemplateç±»ï¼Œè¯¥ç±»ç”¨äºå°†æ¨¡æ¿(template)ä¸è¾“å…¥å˜é‡(input_variables)ç»‘å®šèµ·æ¥ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡æ¿åŒ…æ‹¬äº†ä¸‰ä¸ªè¾“å…¥å˜é‡ï¼š\n",
    "\"task_names\"ã€\"next_task_id\"å’Œ\"objective\"ã€‚æœ€åï¼Œå®ƒä½¿ç”¨cls()æ–¹æ³•åˆ›å»ºä¸€ä¸ªLLMChainå¯¹è±¡ï¼Œå¹¶å°†å…¶ä¿å­˜åœ¨task_prioritization_chain\n",
    "è¿™ä¸ªå˜é‡ä¸­ã€‚\n",
    "\"\"\"\n",
    "class TaskPrioritizationChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        task_prioritization_template = (\n",
    "            \"You are an task prioritization AI tasked with cleaning the formatting of and reprioritizing\"\n",
    "            \" the following tasks: {task_names}.\"\n",
    "            \" Consider the ultimate objective of your team: {objective}.\"\n",
    "            \" Do not remove any tasks. Return the result as a numbered list, like:\"\n",
    "            \" #. First task\"\n",
    "            \" #. Second task\"\n",
    "            \" Start the task list with number {next_task_id}.\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_prioritization_template,\n",
    "            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºExecutionChainçš„ç±»ï¼Œå®ƒæ˜¯LLMChainç±»çš„å­ç±»ã€‚è¯¥ç±»çš„ç›®çš„æ˜¯æ‰§è¡Œä»»åŠ¡ï¼Œå¹¶è¿”å›llmchainå¯¹è±¡ã€‚åœ¨ç±»å®šä¹‰\n",
    "ä¸­ï¼Œæœ‰ä¸€ä¸ªé™æ€æ–¹æ³•from_llm(),å®ƒæ¥å—ä¸€ä¸ªBaseLLMå¯¹è±¡å’Œä¸€ä¸ªå¸ƒå°”ç±»å‹çš„verboseå‚æ•°ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªLLMChainå¯¹è±¡ã€‚è¯¥æ–¹æ³•\n",
    "ä½¿ç”¨äº†ä¸€ä¸ªexecution_templateå­—ç¬¦ä¸²æ¥ç”Ÿæˆä¸€ä¸ªæç¤º(prompt),è¯¥æç¤ºç”¨äºæŒ‡å¯¼AIå®Œæˆä»»åŠ¡çš„æ‰§è¡Œã€‚æ¥ä¸‹æ¥ï¼Œè¯¥ä»£ç è¿˜å®šä¹‰äº†ä¸€ä¸ª\n",
    "PromptTemplateç±»ï¼Œè¯¥ç±»ç”¨äºå°†æ¨¡æ¿(template)ä¸è¾“å…¥å˜é‡(input_variables)ç»‘å®šèµ·æ¥ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæ¨¡æ¿åŒ…æ‹¬äº†ä¸‰ä¸ªè¾“å…¥å˜é‡ï¼š\n",
    "\"objective\"ã€\"context\" å’Œ \"task\"ã€‚æœ€åï¼Œå®ƒä½¿ç”¨cls()æ–¹æ³•åˆ›å»ºä¸€ä¸ªLLMChainå¯¹è±¡ï¼Œå¹¶å°†å…¶ä¿å­˜åœ¨execution_chainå˜é‡ä¸­ã€‚\n",
    "\"\"\"\n",
    "class ExecutionChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Get the response parser.\"\"\"\n",
    "        execution_template = (\n",
    "            \"You are an AI who performs one task based on the following objective: {objective}.\"\n",
    "            \" Take into account these previously completed tasks: {context}.\"\n",
    "            \" Your task: {task}.\"\n",
    "            \" Response:\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=execution_template,\n",
    "            input_variables=[\"objective\", \"context\", \"task\"],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰ BabyAGI æ§åˆ¶å™¨\n",
    "\n",
    "BabyAGI å°†ä¸Šé¢å®šä¹‰çš„é“¾ç»„åˆæˆä¸€ä¸ªï¼ˆå¯èƒ½ï¼‰æ— é™å¾ªç¯çš„é—­ç¯è¿è¡Œè¿‡ç¨‹ã€‚\n",
    "\n",
    "è¿™ä¸ªè¿‡ç¨‹å¦‚ä¸‹ï¼š\n",
    "1. ä»ä»»åŠ¡åˆ—è¡¨ä¸­æå–ç¬¬ä¸€ä¸ªä»»åŠ¡.\n",
    "2. å°†ä»»åŠ¡å‘é€ç»™æ‰§è¡Œä»£ç†, è¯¥ä»£ç†ä½¿ç”¨ OpenAI API æ ¹æ®ä¸Šä¸‹æ–‡å®Œæˆä»»åŠ¡.\n",
    "3. æ¶¦è‰²ç»“æœå¹¶å°†å…¶å­˜å‚¨.\n",
    "4. åŸºäºç›®æ ‡å’Œå‰ä¸€ä¸ªä»»åŠ¡çš„ç»“æœåˆ›å»ºæ–°ä»»åŠ¡, å¹¶æ ¹æ®ä¼˜å…ˆçº§å¯¹ä»»åŠ¡åˆ—è¡¨è¿›è¡Œæ’åº."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¯¥æ–¹æ³•è¿”å›ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œä¼ å…¥çš„å‚æ•°åŒ…æ‹¬LLMchainï¼Œresultï¼Œä»»åŠ¡åˆ—è¡¨çš„task_listï¼Œè¡¨ç¤ºç›®æ ‡çš„objectiveå­—ç¬¦ä¸²ç±»å‹,\n",
    "è¿™é‡Œç”¨åˆ°çš„ä¸‰é“¾ä¸­çš„ç¬¬ä¸€é“¾task_creation_chianå»æ„å»ºä»»åŠ¡åˆ—è¡¨ï¼Œç„¶ååœ¨chain.runçš„æ–¹æ³•ä¸­å°†å˜é‡å‡ä»¥input_variables\n",
    "çš„å½¢å¼ä¼ å…¥æ¨¡ç‰ˆä¸­å®Œæˆè¡¥å…¨ï¼Œè€Œå“åº”çš„ç»“æœä»¥'\\n'åˆ†å‰²å¼€æ¥å¹¶å‚¨å­˜åˆ°new_taskså˜é‡ä¸­ï¼Œæœ€ç»ˆget_next_taskæ–¹æ³•è¿”å›ä¸€ä¸ªå°†å­—å…¸åŒ…\n",
    "è£…èµ·æ¥çš„åˆ—è¡¨\n",
    "\"\"\"\n",
    "def get_next_task(\n",
    "    task_creation_chain: LLMChain,\n",
    "    result: Dict,\n",
    "    task_description: str,\n",
    "    task_list: List[str],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Get the next task.\"\"\"\n",
    "    incomplete_tasks = \", \".join(task_list)\n",
    "\n",
    "    response = task_creation_chain.run(\n",
    "        result=result,\n",
    "        task_description=task_description,\n",
    "        incomplete_tasks=incomplete_tasks,\n",
    "        objective=objective,\n",
    "    )\n",
    "    #æœ€ç»ˆçš„å“åº”ç»“æœæ˜¯arrayç»„æˆçš„taskï¼Œç”¨æ¢è¡Œç¬¦è¿›è¡Œåˆ†å‰²\n",
    "    new_tasks = response.split(\"\\n\")\n",
    "    #è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ–°ä»»åŠ¡ä¿¡æ¯çš„åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªä»»åŠ¡ä¿¡æ¯éƒ½ç”±ä¸€ä¸ª\"task_name\"é”®ç»„æˆã€‚\n",
    "    return [{\"task_name\": task_name} for task_name in new_tasks if task_name.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºprioritize_tasksçš„å‡½æ•°ï¼Œå®ƒæ¥å—å››ä¸ªå‚æ•°ï¼štask_prioritization_chainã€this_task_idã€task_listå’Œobjectiveã€‚\n",
    "è¯¥å‡½æ•°çš„ç›®çš„æ˜¯æ ¹æ®å½“å‰ä»»åŠ¡å’Œç›®æ ‡è®¾å®šï¼Œå¯¹ä»»åŠ¡åˆ—è¡¨è¿›è¡Œä¼˜å…ˆçº§æ’åºï¼Œå¹¶è¿”å›ä¸€ä¸ªæŒ‰ç…§ä¼˜å…ˆçº§æ’åºçš„ä»»åŠ¡åˆ—è¡¨(List[Dict])ã€‚åœ¨å‡½æ•°ä¸­ï¼Œé¦–å…ˆå°†task_list\n",
    "ä¸­çš„æ¯ä¸ªä»»åŠ¡å­—å…¸(t)çš„ä»»åŠ¡åç§°(task_name)æå–å‡ºæ¥ï¼Œç”Ÿæˆä¸€ä¸ªä»»åŠ¡åç§°åˆ—è¡¨(task_names)ã€‚ç„¶åå°†å½“å‰çš„ä»»åŠ¡ID(this_task_id)è½¬æ¢æˆæ•´æ•°ï¼Œå¹¶åŠ 1,\n",
    "ç”Ÿæˆä¸‹ä¸€ä¸ªä»»åŠ¡çš„ID(next_task_id)ã€‚\n",
    "æ¥ç€ï¼Œä½¿ç”¨ä¸€ä¸ªä¸‰é“¾ä¸­çš„ä»»åŠ¡ä¼˜å…ˆçº§æ’åºé“¾å»å°†task_namesã€next_task_idå’Œobjectiveä¼ å…¥å…¶ä¸­è¡¥å…¨input_variablesã€‚\n",
    "æ¥ç€ä½¿ç”¨æ¢è¡Œç¬¦åˆ†å‰²å“åº”å†…å®¹å°†å…¶å­˜å‚¨åˆ°new_taskså­—ç¬¦ä¸²åˆ—è¡¨ä¸­ã€‚æ¥ä¸‹æ¥ï¼Œè¯¥ä»£ç åˆ›å»ºä¸€ä¸ªç©ºçš„åˆ—è¡¨ç”¨äºä¿å­˜æŒ‰ç…§ä¼˜å…ˆçº§æ’åºä¹‹åçš„ä»»åŠ¡åˆ—è¡¨(prioritized_task_list)ã€‚\n",
    "ç„¶åï¼Œä½¿ç”¨forå¾ªç¯éå†new_tasksåˆ—è¡¨ä¸­çš„æ¯ä¸ªä»»åŠ¡å­—ç¬¦ä¸²(task_string),å¦‚æœè¿™ä¸ªå­—ç¬¦ä¸²æ˜¯ç©ºçš„å­—ç¬¦ä¸²æˆ–åªåŒ…å«ç©ºæ ¼å°±è·³è¿‡è¿™æ¬¡å¾ªç¯ã€‚\n",
    "æ¥ç€ï¼Œä½¿ç”¨strip()æ–¹æ³•å»é™¤é¦–ä½ç©ºæ ¼ï¼Œå¼ºåˆ¶å°†ä»»åŠ¡å­—ç¬¦ä¸²åˆ†æˆä¸¤éƒ¨åˆ†ï¼Œåˆ†å‰²ç¬¦å·æ˜¯â€œ.â€ã€‚å¦‚æœåˆ†å‰²åå¾—åˆ°çš„åˆ—è¡¨é•¿åº¦ç­‰äº2,å³æˆåŠŸæ‹†åˆ†å‡ºtask_idå’Œtask_name,\n",
    "åˆ™å°†å®ƒä»¬æ·»åŠ åˆ°prioritized_task_liståˆ—è¡¨ä¸­ã€‚æœ€åï¼Œè¯¥å‡½æ•°è¿”å›prioritized_task_liståˆ—è¡¨ã€‚\n",
    "\"\"\"\n",
    "def prioritize_tasks(\n",
    "    task_prioritization_chain: LLMChain,\n",
    "    this_task_id: int,\n",
    "    task_list: List[Dict],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Prioritize tasks.\"\"\"\n",
    "    #å°†ä»»åŠ¡åˆ—è¡¨ä¸­çš„æ¯ä¸ªä»»åŠ¡å­—å…¸ï¼ˆtï¼‰çš„ä»»åŠ¡åç§°task_nameæå–å‡ºæ¥ï¼Œç”Ÿæˆä¸€ä¸ªä»»åŠ¡åç§°åˆ—è¡¨task_names\n",
    "    task_names = [t[\"task_name\"] for t in task_list]\n",
    "    #å°†å½“å‰çš„ä»»åŠ¡IDï¼ˆthis_task_idï¼‰è½¬æ¢æˆæ•´æ•°ï¼Œå¹¶åŠ 1ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ªä»»åŠ¡çš„idï¼ˆnext_task_idï¼‰\n",
    "    next_task_id = int(this_task_id) + 1\n",
    "    #ä½¿ç”¨ä¸€ä¸ªä¸‰é“¾ä¸­çš„ä»»åŠ¡ä¼˜å…ˆçº§æ’åºé“¾å»å°†task_names,next_task_id,objectiveä¼ å…¥å…¶ä¸­è¡¥å…¨input_variables\n",
    "    response = task_prioritization_chain.run(\n",
    "        task_names=task_names, next_task_id=next_task_id, objective=objective\n",
    "    )\n",
    "    #ä½¿ç”¨æ¢è¡Œç¬¦åˆ†å‰²å†…å®¹å°†å…¶å­˜å‚¨åˆ°new_taskså­—ç¬¦ä¸²åˆ—è¡¨ä¸­\n",
    "    new_tasks = response.split(\"\\n\")\n",
    "    #åˆ›å»ºä¸€ä¸ªç©ºçš„åˆ—è¡¨ç”¨äºä¿å­˜æŒ‰ç…§ä¼˜å…ˆçº§æ’åºä¹‹åçš„ä»»åŠ¡åˆ—è¡¨\n",
    "    prioritized_task_list = []\n",
    "    #\n",
    "    for task_string in new_tasks:\n",
    "        #å¦‚æœè¿™ä¸ªå­—ç¬¦ä¸²æ˜¯ç©ºçš„å­—ç¬¦ä¸²æˆ–åªåŒ…å«ç©ºæ ¼å°±è·³è¿‡è¿™æ¬¡å¾ªç¯\n",
    "        if not task_string.strip():\n",
    "            continue\n",
    "        #é¦–å…ˆå»é™¤é¦–ä½ç©ºæ ¼ä¹‹åå°†å…¶å¼ºåˆ¶åˆ†æˆä¸¤éƒ¨åˆ†ï¼Œåˆ†å‰²ç¬¦å·å°±æ˜¯â€œ.â€,å¾—åˆ°çš„æ˜¯ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå…ƒç´ çš„åˆ—è¡¨task_parts\n",
    "        task_parts = task_string.strip().split(\".\", 1)\n",
    "        #å¦‚æœtask_parts åˆ—è¡¨é•¿åº¦ç­‰äº2ï¼Œå³æˆåŠŸæ‹†åˆ†å‡ºtask_idå’Œtask_names\n",
    "        if len(task_parts) == 2:\n",
    "            task_id = task_parts[0].strip()\n",
    "            task_name = task_parts[1].strip()\n",
    "            prioritized_task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
    "    return prioritized_task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º_get_top_tasksçš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—ä¸‰ä¸ªå‚æ•°ï¼švectorstore(ä¸€ä¸ªå‘é‡å­˜å‚¨åº“),query(æŸ¥è¯¢è¯­å¥)å’Œk(è¦è¿”å›çš„ç»“æœæ•°é‡)ã€‚\n",
    "è¯¥å‡½æ•°çš„ç›®çš„æ˜¯æ ¹æ®æŸ¥è¯¢è¯­å¥è¿”å›ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„å‰kä¸ªå‘é‡åŠå…¶å¯¹åº”çš„ä»»åŠ¡åç§°ã€‚å‡½æ•°é¦–å…ˆè°ƒç”¨vectorstoreå¯¹è±¡çš„similarity_search_with_scoreæ–¹æ³•\n",
    "è¿›è¡Œç›¸ä¼¼åº¦æœç´¢ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨resultsä¸­ã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…é¡¹ï¼Œåˆ™å‡½æ•°è¿”å›ç©ºåˆ—è¡¨ã€‚å¦åˆ™ï¼Œå‡½æ•°ä½¿ç”¨Pythonå†…ç½®çš„sortedå‡½æ•°å¯¹resultsä¸­çš„å…ƒç´ \n",
    "æŒ‰ç…§ç›¸ä¼¼æ€§åˆ†æ•°ä»å¤§åˆ°å°è¿›è¡Œæ’åºã€‚è¯¥å‡½æ•°ä½¿ç”¨lambdaè¡¨è¾¾å¼æŒ‡å®šæŒ‰ç¬¬äºŒä¸ªå…ƒç´ (å³åˆ†æ•°)è¿›è¡Œæ’åºï¼Œå¹¶ä½¿ç”¨reverse=Trueå‚æ•°ä»¥å€’åºæ–¹å¼æ’åºã€‚ç„¶åï¼Œå‡½æ•°\n",
    "å°†æ’åºåçš„ç»“æœæ‹†åˆ†ä¸ºä¸¤ä¸ªå…ƒç»„ï¼Œå¹¶å°†æ¯ä¸ªå…ƒç»„ä¸­çš„task_namesè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œæœ€åå°†è¿™äº›å­—ç¬¦ä¸²ä½œä¸ºåˆ—è¡¨è¿”å›ã€‚\n",
    "\"\"\"\n",
    "def _get_top_tasks(vectorstore, query: str, k: int) -> List[str]:\n",
    "    \"\"\"Get the top k tasks based on the query.\"\"\"\n",
    "    #ç”±vectorstoreçš„ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°è¿›è¡Œè®¡ç®—ï¼Œè¿”å›çš„æ˜¯æœ€ç›¸ä¼¼çš„Kä¸ªå‘é‡ä»¥åŠå…¶ç›¸ä¼¼åˆ†æ•°ï¼Œå­˜å‚¨åœ¨resultsä¸­ï¼Œè¿™ä¸ªé‡Œé¢å¹¶æ²¡æœ‰æ’åºä¹‹åçš„ç»“æœ\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    if not results:\n",
    "        return []\n",
    "    #sortedå‡½æ•°æ˜¯å¯¹resultsä¸­ç»“æœå…ƒç´ æŒ‰ç…§ç›¸ä¼¼æ€§åˆ†æ•°ä»å¤§åˆ°å°è¿›è¡Œæ’åºï¼Œå¹¶å°†æ’åºå¥½çš„å‘é‡ä»¥åŠåˆ†æ•°æ‹†åˆ†ä¸ºä¸¤ä¸ªå…ƒç»„ï¼Œåˆ†åˆ«å­˜å‚¨åˆ°sorted_resultså’Œ_ä¸¤ä¸ªå˜é‡ä¸­ï¼Œå…¶ä¸­çš„\n",
    "    #key=lambda xï¼šx[1]è¡¨ç¤ºæŒ‰ç…§å…ƒç´ ä¸­çš„ç¬¬äºŒä¸ªå€¼ï¼ˆå³åˆ†æ•°ï¼‰è¿›è¡Œæ’åºï¼Œreverseè¡¨ç¤ºå€’åºæ’åº\n",
    "    sorted_results, _ = zip(*sorted(results, key=lambda x: x[1], reverse=True))\n",
    "    #å°†sorted_resultsåˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªå‘é‡å¯¹åº”çš„task_namesï¼ˆå­˜å‚¨åœ¨metadata[\"task\"]ä¸­ï¼‰è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶ä»¥åˆ—è¡¨çš„å½¢å¼è¿”å›\n",
    "    return [str(item.metadata[\"task\"]) for item in sorted_results]\n",
    "\n",
    "\"\"\"\n",
    "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºexecute_taskçš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—å››ä¸ªå‚æ•°ï¼švectorstore(ä¸€ä¸ªå‘é‡å­˜å‚¨åº“)ã€execution_chain(æ‰§è¡Œé“¾å¯¹è±¡)ã€\n",
    "objective(ç›®æ ‡å­—ç¬¦ä¸²)å’Œtask(è¦æ‰§è¡Œçš„ä»»åŠ¡å­—ç¬¦ä¸²)ã€‚è¯¥å‡½æ•°çš„ç›®çš„æ˜¯æ ¹æ®ç»™å®šçš„ç›®æ ‡å’Œä»»åŠ¡æ‰§è¡ŒæŒ‡å®šçš„å‘é‡è®¡ç®—ã€‚å‡½æ•°é¦–å…ˆè°ƒç”¨_get_top_taskså‡½æ•°\n",
    "è·å–ä¸ç›®æ ‡æœ€ç›¸å…³çš„å‰kä¸ªå‘é‡åŠå…¶å¯¹åº”çš„ä»»åŠ¡åç§°ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨contextå˜é‡ä¸­ã€‚ç„¶åï¼Œå‡½æ•°è°ƒç”¨execution_chain.run()æ–¹æ³•ï¼Œå°†ç›®æ ‡ã€ä¸Šä¸‹æ–‡å’Œ\n",
    "ä»»åŠ¡ä½œä¸ºå‚æ•°ä¼ é€’ç»™å®ƒã€‚æœ€åï¼Œå‡½æ•°è¿”å›æ‰§è¡Œç»“æœã€‚\n",
    "\"\"\"\n",
    "def execute_task(\n",
    "    vectorstore, execution_chain: LLMChain, objective: str, task: str, k: int = 5\n",
    ") -> str:\n",
    "    \"\"\"Execute a task.\"\"\"\n",
    "    context = _get_top_tasks(vectorstore, query=objective, k=k)\n",
    "    return execution_chain.run(objective=objective, context=context, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å®šä¹‰äº†ä¸€ä¸ªåä¸ºBabyAGIçš„ç±»ï¼Œç»§æ‰¿äº†Chainå’ŒBaseModelç±»ã€‚\n",
    "BabyAGIç±»ç”¨äºæ§åˆ¶æ¨¡å‹çš„æ‰§è¡Œæµç¨‹ï¼Œå…¶ä¸­å®šä¹‰äº†å¦‚ä¸‹å†…å®¹ï¼š\n",
    "task_listæ˜¯ä¸€ä¸ªdequeç±»å‹ï¼Œç”¨äºå­˜å‚¨ä»»åŠ¡åˆ—è¡¨ï¼›\n",
    "task_creation_chainã€task_prioritization_chainã€execution_chainæ˜¯ä¸‰é“¾ç±»å‹çš„å®ä¾‹ï¼Œç”¨äºåˆ›å»ºä»»åŠ¡ã€æ’åºä»»åŠ¡ä»¥åŠæ‰§è¡Œä»»åŠ¡ï¼›\n",
    "task_id_counteræ˜¯ä¸€ä¸ªæ•´å‹å˜é‡ï¼Œç”¨äºè®°å½•ä»»åŠ¡ID;\n",
    "vectorstoreæ˜¯ä¸€ä¸ªVectorStoreç±»å‹çš„å®ä¾‹ï¼Œç”¨äºå­˜å‚¨å‘é‡æ•°æ®ï¼›\n",
    "max_iterationsæ˜¯ä¸€ä¸ªæ•´å‹å˜é‡ï¼Œè¡¨ç¤ºæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼›\n",
    "add_taskæ–¹æ³•ç”¨äºæ·»åŠ ä»»åŠ¡åˆ°ä»»åŠ¡åˆ—è¡¨ä¸­ï¼›\n",
    "print_task_listæ–¹æ³•ç”¨äºæ‰“å°å½“å‰çš„ä»»åŠ¡åˆ—è¡¨ï¼›\n",
    "print_next_taskæ–¹æ³•ç”¨äºæ‰“å°ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼›\n",
    "print_task_resultæ–¹æ³•ç”¨äºæ‰“å°ä»»åŠ¡æ‰§è¡Œç»“æœï¼›\n",
    "get_next_taskæ–¹æ³•ç”¨äºè·å–ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼›\n",
    "prioritize_tasksæ–¹æ³•ç”¨äºé‡æ–°æ’åºä»»åŠ¡åˆ—è¡¨ã€‚\n",
    "åœ¨ç±»å®šä¹‰ä¸­è¿˜å®šä¹‰äº†ä¸€ä¸ªConfigç±»ï¼Œç”¨äºé…ç½®pydanticå¯¹è±¡ï¼Œå…¶ä¸­arbitrary_types_allowedå±æ€§è®¾ç½®ä¸ºTrueè¡¨ç¤ºå…è®¸ä»»æ„ç±»å‹ã€‚\n",
    "\"\"\"\n",
    "class BabyAGI(Chain, BaseModel):\n",
    "    \"\"\"Controller model for the BabyAGI agent.\"\"\"\n",
    "    #å®šä¹‰äº†task_listï¼Œç±»å‹ä¸ºdequeï¼Œä½¿ç”¨fieldä½œä¸ºå­—æ®µéªŒè¯å™¨ï¼Œè®¾ç½®äº†é»˜è®¤å·¥å‚å‡½æ•°ä¸ºdequeï¼Œä¹Ÿå°±æ˜¯åˆ›å»ºä¸€ä¸ªç©ºçš„åŒç«¯é˜Ÿåˆ—ä½œä¸ºé»˜è®¤å€¼\n",
    "    task_list: deque = Field(default_factory=deque)\n",
    "    #å®šä¹‰äº†task_creation_chainï¼Œç±»å‹ä¸ºTaskCreationChainï¼Œä½¿ç”¨fieldä½œä¸ºå­—æ®µéªŒè¯å™¨ï¼Œè®¾ç½®äº†å¿…é¡»çš„å­—æ®µæ ‡å¿—\"...\",åˆå§‹åŒ–çš„æ—¶å€™æä¾›\n",
    "    task_creation_chain: TaskCreationChain = Field(...)\n",
    "    #åŒä¸Š\n",
    "    task_prioritization_chain: TaskPrioritizationChain = Field(...)\n",
    "    execution_chain: ExecutionChain = Field(...)\n",
    "    #ç±»å‹ä¸ºintï¼Œåˆå§‹å€¼ä¸º1\n",
    "    task_id_counter: int = Field(1)\n",
    "    #åˆ›å»ºæ—¶å€™ä¸éœ€è¦åˆå§‹åŒ–\n",
    "    vectorstore: VectorStore = Field(init=False)\n",
    "    #é»˜è®¤å€¼ä¸ºNoneï¼Œè¡¨ç¤ºæ²¡æœ‰æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶\n",
    "    max_iterations: Optional[int] = None\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def add_task(self, task: Dict):\n",
    "        self.task_list.append(task)\n",
    "\n",
    "    def print_task_list(self):\n",
    "        #åˆ©ç”¨ANSIç è®¾ç½®ç»ˆç«¯çš„æ–‡æœ¬é¢œè‰²å’Œæ ·å¼ï¼Œä¸‹åŒ\n",
    "        print(\"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        for t in self.task_list:\n",
    "            print(str(t[\"task_id\"]) + \": \" + t[\"task_name\"])\n",
    "\n",
    "    def print_next_task(self, task: Dict):\n",
    "        print(\"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        print(str(task[\"task_id\"]) + \": \" + task[\"task_name\"])\n",
    "\n",
    "    def print_task_result(self, result: str):\n",
    "        print(\"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        print(result)\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        return [\"objective\"]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return []\n",
    "    \"\"\"\n",
    "    è¿™ä¸ªæ–¹æ³•ç”¨äºæ‰§è¡Œä»»åŠ¡ã€‚è¯¥æ–¹æ³•æ¥æ”¶ä¸€ä¸ªå­—å…¸å‚æ•°inputsä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›æ‰§è¡Œç»“æœã€‚åœ¨æ–¹æ³•å†…éƒ¨ï¼Œ\n",
    "    é¦–å…ˆä»inputsä¸­è·å–ä»»åŠ¡IDå’Œç¬¬ä¸€ä¸ªä»»åŠ¡ï¼Œç„¶åæ ¹æ®ç¬¬ä¸€ä¸ªä»»åŠ¡çš„åç§°åˆ›å»ºä¸€ä¸ªæ–°çš„ä»»åŠ¡ï¼Œå°†å…¶æ·»åŠ åˆ°\n",
    "    ä»»åŠ¡åˆ—è¡¨ä¸­ï¼Œå¹¶æ‰§è¡Œè¯¥ä»»åŠ¡ã€‚æ¥ç€ï¼Œæ ¹æ®æ‰§è¡Œç»“æœæ›´æ–°å‘é‡å­˜å‚¨ä¸­çš„æ–‡æœ¬å†…å®¹å’Œå…ƒæ•°æ®ï¼Œå¹¶ç”Ÿæˆæ–°ä»»åŠ¡çš„ID,\n",
    "    å°†æ–°ä»»åŠ¡æ·»åŠ åˆ°ä»»åŠ¡åˆ—è¡¨ä¸­ï¼Œæœ€åé‡æ–°æ’åºä»»åŠ¡åˆ—è¡¨ã€‚å¦‚æœè¾¾åˆ°äº†æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œåˆ™æ‰“å°ç»“æŸä¿¡æ¯å¹¶é€€å‡ºå¾ªç¯ã€‚\n",
    "    åœ¨ç±»ä¸­è¿˜å®šä¹‰äº†ä¸€äº›è¾…åŠ©æ–¹æ³•å’Œå±æ€§ï¼Œå¦‚input_keys()å±æ€§ç”¨äºè·å–è¾“å…¥é”®åˆ—è¡¨ï¼›output_keys()å±æ€§ç”¨\n",
    "    äºè·å–è¾“å‡ºé”®åˆ—è¡¨ï¼›TaskCreationChain.from_list()æ–¹æ³•ç”¨äºä»ä»»åŠ¡åˆ—è¡¨ä¸­åˆ›å»ºä»»åŠ¡åˆ›å»ºé“¾ç­‰ã€‚\n",
    "    \"\"\"\n",
    "    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Run the agent.è¿”å›ä¸€ä¸ªå­—å…¸å¯¹è±¡\"\"\"\n",
    "        #ä»è¾“å…¥å‚æ•°inputsä¸­è·å–é”®ä¸ºobjectiveçš„å€¼ï¼Œå¹¶å°†å…¶èµ‹ç»™å˜é‡objective\n",
    "        objective = inputs[\"objective\"]\n",
    "        #ä»è¾“å…¥å‚æ•°inputsä¸­è·å–é”®ä¸ºfirst_taskçš„å€¼ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™å˜é‡first_task,\n",
    "        #å¦‚æœinputsä¸­æ²¡æœ‰é”®ä¸ºfirst_taskçš„é¡¹ï¼Œæ²¡æœ‰è¿™ä¸ªé”®å°±ä½¿ç”¨é»˜è®¤çš„make a todo list\n",
    "        #èµ‹å€¼ç»™first_task,getæ–¹æ³•å¯ä»¥é¿å…å­—å…¸ä¸­ä¸å­˜åœ¨æŸä¸ªé”®æ—¶å€™æŠ¥é”™\n",
    "        first_task = inputs.get(\"first_task\", \"Make a todo list\")\n",
    "        self.add_task({\"task_id\": 1, \"task_name\": first_task})\n",
    "        num_iters = 0\n",
    "        while True:\n",
    "            if self.task_list:\n",
    "                self.print_task_list()\n",
    "\n",
    "                # Step 1: Pull the first task\n",
    "                #popleftæ˜¯ç§»é™¤é˜Ÿé¦–çš„ä»»åŠ¡ï¼Œä»é˜Ÿé¦–ç§»é™¤ä¸€ä¸ªå…ƒç´ å¹¶è¿”å›å…¶å€¼\n",
    "                task = self.task_list.popleft()\n",
    "                self.print_next_task(task)\n",
    "\n",
    "                # Step 2: Execute the task\n",
    "                result = execute_task(\n",
    "                    self.vectorstore, self.execution_chain, objective, task[\"task_name\"]\n",
    "                )\n",
    "                this_task_id = int(task[\"task_id\"])\n",
    "                self.print_task_result(result)\n",
    "\n",
    "                # Step 3: Store the result in Pinecone\n",
    "                result_id = f\"result_{task['task_id']}\"\n",
    "                self.vectorstore.add_texts(\n",
    "                    texts=[result],\n",
    "                    metadatas=[{\"task\": task[\"task_name\"]}],\n",
    "                    ids=[result_id],\n",
    "                )\n",
    "\n",
    "                # Step 4: Create new tasks and reprioritize task list\n",
    "                new_tasks = get_next_task(\n",
    "                    self.task_creation_chain,\n",
    "                    result,\n",
    "                    task[\"task_name\"],\n",
    "                    [t[\"task_name\"] for t in self.task_list],\n",
    "                    objective,\n",
    "                )\n",
    "                for new_task in new_tasks:\n",
    "                    self.task_id_counter += 1\n",
    "                    new_task.update({\"task_id\": self.task_id_counter})\n",
    "                    self.add_task(new_task)\n",
    "                self.task_list = deque(\n",
    "                    prioritize_tasks(\n",
    "                        self.task_prioritization_chain,\n",
    "                        this_task_id,\n",
    "                        list(self.task_list),\n",
    "                        objective,\n",
    "                    )\n",
    "                )\n",
    "            num_iters += 1\n",
    "            if self.max_iterations is not None and num_iters == self.max_iterations:\n",
    "                print(\n",
    "                    \"\\033[91m\\033[1m\" + \"\\n*****TASK ENDING*****\\n\" + \"\\033[0m\\033[0m\"\n",
    "                )\n",
    "                break\n",
    "        return {}\n",
    "\n",
    "    \"\"\"\n",
    "    è¿™æ˜¯ä¸€ä¸ªç±»æ–¹æ³•ï¼Œç”¨äºä»LLM(Language Model)å®ä¾‹ä¸­åˆå§‹åŒ–BabyAGIæ§åˆ¶å™¨ã€‚\n",
    "    è¯¥ç±»æ–¹æ³•æ¥å—å››ä¸ªå‚æ•°ï¼šllmã€vectorstoreã€verboseå’Œkwargsã€‚å…¶ä¸­ï¼Œllmè¡¨ç¤ºLLMå®ä¾‹ï¼Œvectorstoreè¡¨ç¤ºå‘é‡å­˜å‚¨å®ä¾‹ï¼Œ\n",
    "    verboseè¡¨ç¤ºæ˜¯å¦å¯ç”¨è¯¦ç»†è¾“å‡ºæ¨¡å¼ï¼Œkwargsè¡¨ç¤ºå…¶ä»–å¯é€‰å‚æ•°ã€‚åœ¨ç±»æ–¹æ³•ä¸­ï¼Œé¦–å…ˆè°ƒç”¨TaskCreationChain.from_llm()\n",
    "    å’ŒTaskPrioritizationChain.from_llm()æ–¹æ³•åˆ†åˆ«åˆ›å»ºä»»åŠ¡åˆ›å»ºé“¾å’Œä»»åŠ¡æ’åºé“¾ã€‚ç„¶åè°ƒç”¨ExecutionChain.from_llm()æ–¹æ³•\n",
    "    åˆ›å»ºæ‰§è¡Œé“¾ã€‚æœ€åä½¿ç”¨è¿™äº›é“¾å’Œvectorstoreä»¥åŠä¼ å…¥çš„å…¶ä»–å‚æ•°æ¥åˆ›å»ºä¸€ä¸ªBabyAGIç±»å®ä¾‹å¹¶è¿”å›ã€‚\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls, llm: BaseLLM, vectorstore: VectorStore, verbose: bool = False, **kwargs\n",
    "    ) -> \"BabyAGI\":\n",
    "        \"\"\"Initialize the BabyAGI Controller.\"\"\"\n",
    "        task_creation_chain = TaskCreationChain.from_llm(llm, verbose=verbose)\n",
    "        task_prioritization_chain = TaskPrioritizationChain.from_llm(\n",
    "            llm, verbose=verbose\n",
    "        )\n",
    "        execution_chain = ExecutionChain.from_llm(llm, verbose=verbose)\n",
    "        return cls(\n",
    "            task_creation_chain=task_creation_chain,\n",
    "            task_prioritization_chain=task_prioritization_chain,\n",
    "            execution_chain=execution_chain,\n",
    "            vectorstore=vectorstore,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œ BabyAGI \n",
    "\n",
    "ç°åœ¨æ˜¯åˆ›å»º BabyAGI æ§åˆ¶å™¨å¹¶è§‚å¯Ÿå®ƒå°è¯•å®ç°æ‚¨çš„ç›®æ ‡çš„æ—¶å€™äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTIVE = \"Make a plan to travel around the world for a month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å®šä¹‰äº†ä¸‰ä¸ªå˜é‡ï¼šverboseã€max_iterationså’Œbaby_agiã€‚\n",
    "verbose:è¿™æ˜¯ä¸€ä¸ªå¸ƒå°”ç±»å‹çš„å˜é‡ï¼Œåˆå§‹å€¼ä¸ºFalseã€‚å®ƒè¡¨ç¤ºæ˜¯å¦å¯ç”¨è¯¦ç»†è¾“å‡ºæ¨¡å¼ã€‚å¦‚æœè®¾ç½®ä¸ºTrue,åˆ™åœ¨æ‰§è¡Œä»»åŠ¡æ—¶ä¼šè¾“å‡ºæ›´å¤šçš„ä¿¡æ¯ã€‚\n",
    "max_iterations:è¿™æ˜¯ä¸€ä¸ªå¯é€‰æ•´æ•°ç±»å‹çš„å˜é‡ï¼Œåˆå§‹å€¼ä¸º3ã€‚å®ƒè¡¨ç¤ºBabyAGIæ§åˆ¶å™¨çš„æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œåˆ™é»˜è®¤ä¸º3ã€‚\n",
    "baby_agi:è¿™æ˜¯ä»LLMå®ä¾‹ä¸­åˆå§‹åŒ–BabyAGIæ§åˆ¶å™¨çš„ç»“æœã€‚å®ƒæ˜¯ä¸€ä¸ªBabyAGIç±»çš„å¯¹è±¡ï¼ŒåŒ…å«äº†ä»LLMå®ä¾‹ä¸­ç”Ÿæˆçš„ä»»åŠ¡åˆ—è¡¨ã€æ‰§è¡Œä»»åŠ¡çš„\n",
    "é“¾ä»¥åŠå‘é‡å­˜å‚¨ç­‰ä¿¡æ¯ã€‚\n",
    "\"\"\"\n",
    "verbose = False\n",
    "max_iterations: Optional[int] = 3\n",
    "baby_agi = BabyAGI.from_llm(\n",
    "    llm=llm, vectorstore=vectorstore, verbose=verbose, max_iterations=max_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "1. Research potential destinations\n",
      "2. Create a budget\n",
      "3. Book flights\n",
      "4. Book accommodations\n",
      "5. Research local attractions\n",
      "6. Pack necessary items\n",
      "7. Make copies of important documents\n",
      "8. Notify bank and credit card companies of travel plans\n",
      "9. Purchase travel insurance\n",
      "10. Make a list of emergency contacts\n",
      "11. Research visa requirements\n",
      "12. Apply for necessary visas\n",
      "13. Make a list of must-see attractions\n",
      "14. Make a list of must-do activities\n",
      "15. Make a list of must-try foods\n",
      "16. Make a list of must-visit restaurants\n",
      "17. Make a list of must-visit shops\n",
      "18. Make a list of must-visit markets\n",
      "19. Make a list of must-visit museums\n",
      "20. Make a list of must-visit galleries\n",
      "21. Make a list of must-visit parks\n",
      "22. Make a list of must-visit historical sites\n",
      "23. Make a list of must-visit religious sites\n",
      "24. Make a list of must-visit natural sites\n",
      "25. Make a list of must-visit cultural sites\n",
      "26. Make a list of must-visit nightlife spots\n",
      "\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Research local currency exchange rates\n",
      "3: Research local safety and security information\n",
      "4: Research local customs and etiquette\n",
      "5: Research local language basics\n",
      "6: Research local weather conditions\n",
      "7: Research local medical facilities\n",
      "8: Research local emergency services\n",
      "9: Research local shopping options\n",
      "10: Research local entertainment options\n",
      "11: Research local cultural events\n",
      "12: Research local outdoor activities\n",
      "13: Research local festivals\n",
      "14: Research local sports teams\n",
      "15: Research local volunteer opportunities\n",
      "16: Research local job opportunities\n",
      "17: Research local educational opportunities\n",
      "18: Research local religious services\n",
      "19: Research local political activities\n",
      "20: Research local environmental initiatives\n",
      "21: Research local community organizations\n",
      "22: Research local charities\n",
      "23: Research local art galleries\n",
      "24: Research local music venues\n",
      "25: Research local theater venues\n",
      "26: Research local libraries\n",
      "1: Research local transportation options\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Research local currency exchange rates\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "I will research local currency exchange rates for the countries I plan to visit during my month-long trip around the world. I will use online resources such as currency conversion websites and travel blogs to find the most up-to-date exchange rates. I will also research the best ways to exchange money in each country, such as using ATMs or exchanging cash at banks.\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Research local transportation costs\n",
      "4: Research local accommodation options\n",
      "5: Research local food options\n",
      "6: Research local tourist attractions\n",
      "7: Research local tourist discounts\n",
      "8: Research local tourist visas\n",
      "9: Research local tourist activities\n",
      "10: Research local tourist guides\n",
      "11: Research local tourist maps\n",
      "12: Research local tourist safety tips\n",
      "13: Research local safety and security information\n",
      "14: Research local customs and etiquette\n",
      "15: Research local language basics\n",
      "16: Research local weather conditions\n",
      "17: Research local medical facilities\n",
      "18: Research local emergency services\n",
      "19: Research local shopping options\n",
      "20: Research local entertainment options\n",
      "21: Research local cultural events\n",
      "22: Research local outdoor activities\n",
      "23: Research local festivals\n",
      "24: Research local sports teams\n",
      "25: Research local volunteer opportunities\n",
      "26: Research local job opportunities\n",
      "27: Research local educational opportunities\n",
      "28: Research local religious services\n",
      "29: Research local political activities\n",
      "30: Research local environmental initiatives\n",
      "31: Research local community organizations\n",
      "32: Research local charities\n",
      "33: Research local art galleries\n",
      "34: Research local\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Research local transportation costs\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "I will research local transportation costs by looking up the cost of flights, trains, buses, and other forms of transportation in each of the countries I plan to visit. I will also look into the cost of renting a car or taking a taxi in each country. Additionally, I will research any discounts or promotions that may be available for transportation costs.\n",
      "\u001b[91m\u001b[1m\n",
      "*****TASK ENDING*****\n",
      "\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'Make a plan to travel around the world for a month'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_agi({\"objective\": OBJECTIVE})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ï¼Œæˆ‘ä»¬ç†Ÿæ‚‰äº†BabyAGIçš„åŸºæœ¬æ“ä½œï¼Œç°åœ¨çœ‹ä¸€ä¸‹æœ‰å…³å®ƒçš„ä»£ç æ¡ˆä¾‹å§,ä¸‹é¢çš„æ¡ˆä¾‹å°†ä¼šç”¨åˆ°è°·æ­Œçš„æœç´¢APIï¼Œå¯ä»¥ä½¿agentè¿›è¡Œè”ç½‘æœç´¢å¹¶å®Œæˆä»»åŠ¡è§„åˆ’\n",
    "\n",
    "é¦–å…ˆæ˜¯å¯¼å…¥ç›¸å…³åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import deque\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.base import Chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿æ¥åˆ° Vector Store \n",
    "\n",
    "æ ¹æ®æ‚¨ä½¿ç”¨çš„çŸ¢é‡å­˜å‚¨ï¼Œæ­¤æ­¥éª¤å¯èƒ½çœ‹èµ·æ¥æœ‰æ‰€ä¸åŒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu > /dev/null\n",
    "%pip install google-search-results > /dev/null\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#embeddings_model:è¿™æ˜¯ä¸€ä¸ªOpenAIEmbeddingsç±»çš„å¯¹è±¡ï¼Œç”¨äºå°†æŸ¥è¯¢åµŒå…¥åˆ°æ¨¡å‹ä¸­ä»¥ç”Ÿæˆç›¸ä¼¼åº¦å‘é‡ã€‚\n",
    "#å®ƒåŒ…å«äº†ä¸€ä¸ªembed_query()æ–¹æ³•ï¼Œç”¨äºå°†æŸ¥è¯¢åµŒå…¥åˆ°æŒ‡å®šçš„ç»´åº¦ä¸­ã€‚\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "import faiss\n",
    "#embedding_size:è¿™æ˜¯ä¸€ä¸ªæ•´æ•°ç±»å‹çš„å˜é‡ï¼Œåˆå§‹å€¼ä¸º1536ã€‚å®ƒè¡¨ç¤ºåµŒå…¥å‘é‡çš„ç»´åº¦ã€‚\n",
    "embedding_size = 1536\n",
    "#index:è¿™æ˜¯ä¸€ä¸ªfaiss.IndexFlatL2ç±»å‹çš„å¯¹è±¡ï¼Œç”¨äºå­˜å‚¨åµŒå…¥å‘é‡ã€‚å®ƒæ˜¯ä¸€ä¸ªæ‰å¹³ç´¢å¼•ï¼Œ\n",
    "#å¯ä»¥å¿«é€ŸæŸ¥æ‰¾ç›¸ä¼¼å‘é‡ã€‚åœ¨åˆ›å»ºç´¢å¼•æ—¶ï¼Œéœ€è¦ä¼ å…¥embedding_model.embed_query()æ–¹æ³•çš„ç»“æœä½œä¸ºè¾“å…¥ã€‚\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "#vectorstore:è¿™æ˜¯ä¸€ä¸ªFAISSç±»å‹çš„å¯¹è±¡ï¼Œç”¨äºå­˜å‚¨åµŒå…¥å‘é‡ã€‚å®ƒä¸indexä¸€èµ·ä½¿ç”¨ï¼Œå¯ä»¥å°†æŸ¥è¯¢åµŒå…¥åˆ°æŒ‡å®šçš„\n",
    "#ç»´åº¦ä¸­å¹¶å­˜å‚¨åˆ°å†…å­˜ä¸­ä»¥ä¾›å¿«é€ŸæŸ¥æ‰¾ã€‚åœ¨åˆ›å»ºvectorstoreæ—¶ï¼Œéœ€è¦ä¼ å…¥embeddings_model.embed_query()æ–¹æ³•çš„ç»“æœä½œä¸ºè¾“å…¥ã€‚\"\"\"\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢çš„å®šä¹‰é“¾çš„è¿‡ç¨‹ï¼ŒåŒä¸Šï¼Œå¤§åŒå°å¼‚ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskCreationChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Get the response parser.\"\"\"\n",
    "        task_creation_template = (\n",
    "            \"You are an task creation AI that uses the result of an execution agent\"\n",
    "            \" to create new tasks with the following objective: {objective},\"\n",
    "            \" The last completed task has the result: {result}.\"\n",
    "            \" This result was based on this task description: {task_description}.\"\n",
    "            \" These are incomplete tasks: {incomplete_tasks}.\"\n",
    "            \" Based on the result, create new tasks to be completed\"\n",
    "            \" by the AI system that do not overlap with incomplete tasks.\"\n",
    "            \" Return the tasks as an array.\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_creation_template,\n",
    "            input_variables=[\n",
    "                \"result\",\n",
    "                \"task_description\",\n",
    "                \"incomplete_tasks\",\n",
    "                \"objective\",\n",
    "            ],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskPrioritizationChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Get the response parser.\"\"\"\n",
    "        task_prioritization_template = (\n",
    "            \"You are an task prioritization AI tasked with cleaning the formatting of and reprioritizing\"\n",
    "            \" the following tasks: {task_names}.\"\n",
    "            \" Consider the ultimate objective of your team: {objective}.\"\n",
    "            \" Do not remove any tasks. Return the result as a numbered list, like:\"\n",
    "            \" #. First task\"\n",
    "            \" #. Second task\"\n",
    "            \" Start the task list with number {next_task_id}.\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_prioritization_template,\n",
    "            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°·æ­Œæœç´¢apiæˆ‘ä»¬ä¼šç”¨åˆ°ï¼Œå› æ­¤åœ¨è¿™é‡Œéœ€è¦åŠ å…¥ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "\n",
    "#å®šä¹‰äº†ä¸€ä¸ªtodo_promptæ¨¡æ¿ï¼Œè¯¥æ¨¡æ¿å°†è¢«ç”¨äºç”Ÿæˆä»»åŠ¡çš„æç¤ºä¿¡æ¯\n",
    "todo_prompt = PromptTemplate.from_template(\n",
    "    \"You are a planner who is an expert at coming up with a todo list for a given objective. Come up with a todo list for this objective: {objective}\"\n",
    ")\n",
    "#å®šä¹‰äº†ä¸¤ä¸ªå·¥å…·é“¾ï¼šä¸€ä¸ªæ˜¯LLMChain(ä½¿ç”¨OpenAIåº“),å¦ä¸€ä¸ªæ˜¯SerpAPIWrapper(ç”¨äºæœç´¢)ã€‚\n",
    "todo_chain = LLMChain(llm=OpenAI(temperature=0), prompt=todo_prompt)\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "\"\"\"\n",
    "å®šä¹‰äº†ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå·¥å…·çš„å·¥å…·åˆ—è¡¨ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå·¥å…·æ˜¯â€œSearchâ€ï¼Œç”¨äºå›ç­”å½“å‰äº‹ä»¶ç›¸å…³çš„é—®é¢˜ï¼›\n",
    "ç¬¬äºŒä¸ªå·¥å…·æ˜¯â€œTODOâ€ï¼Œç”¨äºä¸ºç»™å®šçš„ç›®æ ‡ç”Ÿæˆä»»åŠ¡åˆ—è¡¨ã€‚\n",
    "\"\"\"\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"TODO\",\n",
    "        func=todo_chain.run,\n",
    "        description=\"useful for when you need to come up with todo lists. Input: an objective to create a todo list for. Output: a todo list for that objective. Please be very clear what the objective is!\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "#å®šä¹‰äº†å‰ç¼€ã€åç¼€å’Œæ¨¡æ¿ï¼Œè¿™äº›å˜é‡å°†è¢«ä¼ é€’ç»™ZeroShotAgentä»¥ç”Ÿæˆä»»åŠ¡æç¤ºä¿¡æ¯ã€‚\n",
    "prefix = \"\"\"You are an AI who performs one task based on the following objective: {objective}. Take into account these previously completed tasks: {context}.\"\"\"\n",
    "suffix = \"\"\"Question: {task}\n",
    "{agent_scratchpad}\"\"\"\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"objective\", \"task\", \"context\", \"agent_scratchpad\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰AGI controllerï¼Œ ä¸ºäº†æŠŠä¸‰ä¸ªå®šä¹‰é“¾ç»„æˆæˆä¸€ä¸ªå¾ªç¯çš„é“¾è¿›å…¥ä¸‹é¢çš„æ­¥éª¤ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡ã€‚\n",
    "å®ƒé¦–å…ˆå°†ä¹‹å‰æ‰§è¡Œè¿‡çš„ä»»åŠ¡åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶å°†å…¶ä½œä¸ºå‚æ•°ä¼ é€’ç»™ä»»åŠ¡åˆ›å»ºé“¾çš„runæ–¹æ³•ã€‚\n",
    "ç„¶åï¼Œå®ƒä»ä»»åŠ¡åˆ›å»ºé“¾çš„å“åº”ä¸­æå–å‡ºæ–°ä»»åŠ¡ï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­ã€‚æœ€åï¼Œå®ƒè¿”å›ä¸€\n",
    "ä¸ªåŒ…å«æ–°ä»»åŠ¡åç§°çš„å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸éƒ½åŒ…å«ä¸€ä¸ªåä¸ºâ€œtask_nameâ€çš„é”®å’Œå¯¹åº”çš„å€¼ã€‚\n",
    "\n",
    "task_creation_chain: LLMChainç±»å‹ï¼Œè¡¨ç¤ºä»»åŠ¡åˆ›å»ºé“¾ã€‚\n",
    "result: Dictç±»å‹ï¼Œè¡¨ç¤ºä¹‹å‰æ‰§è¡Œä»»åŠ¡çš„ç»“æœã€‚\n",
    "task_description: strç±»å‹ï¼Œè¡¨ç¤ºè¦ä¸ºæ–°ä»»åŠ¡ç”Ÿæˆçš„ä»»åŠ¡æè¿°ã€‚\n",
    "task_list: List[str]ç±»å‹ï¼Œè¡¨ç¤ºä¹‹å‰æ‰§è¡Œè¿‡çš„ä»»åŠ¡åˆ—è¡¨ã€‚\n",
    "objective: strç±»å‹ï¼Œè¡¨ç¤ºä»»åŠ¡çš„ç›®æ ‡ã€‚\n",
    "\"\"\"\n",
    "def get_next_task(\n",
    "    task_creation_chain: LLMChain,\n",
    "    result: Dict,\n",
    "    task_description: str,\n",
    "    task_list: List[str],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Get the next task.\"\"\"\n",
    "    incomplete_tasks = \", \".join(task_list)\n",
    "    response = task_creation_chain.run(\n",
    "        result=result,\n",
    "        task_description=task_description,\n",
    "        incomplete_tasks=incomplete_tasks,\n",
    "        objective=objective,\n",
    "    )\n",
    "    new_tasks = response.split(\"\\n\")\n",
    "    return [{\"task_name\": task_name} for task_name in new_tasks if task_name.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¯¥å‡½æ•°çš„ä½œç”¨æ˜¯ç¡®å®šæ¯ä¸ªä»»åŠ¡çš„ä¼˜å…ˆçº§ã€‚å®ƒé¦–å…ˆå°†ä»»åŠ¡åˆ—è¡¨ä¸­çš„æ‰€æœ‰ä»»åŠ¡åç§°æå–å‡ºæ¥ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­ã€‚\n",
    "ç„¶åï¼Œå®ƒè®¡ç®—ä¸‹ä¸€ä¸ªä»»åŠ¡çš„ID,å¹¶å°†å…¶ä½œä¸ºå‚æ•°ä¼ é€’ç»™ä»»åŠ¡ä¼˜å…ˆçº§åˆ›å»ºé“¾çš„runæ–¹æ³•ã€‚æ¥ä¸‹æ¥ï¼Œå®ƒä»ä»»åŠ¡ä¼˜å…ˆçº§åˆ›å»ºé“¾çš„\n",
    "å“åº”ä¸­æå–å‡ºæ–°ä»»åŠ¡ï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­ã€‚æœ€åï¼Œå®ƒéå†æ–°ä»»åŠ¡åˆ—è¡¨ä¸­çš„æ¯ä¸ªä»»åŠ¡å­—ç¬¦ä¸²ï¼Œå¹¶ä½¿ç”¨ç©ºæ ¼åˆ†éš”ç¬¦å°†\n",
    "å…¶æ‹†åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ã€‚å¦‚æœç¬¬äºŒä¸ªéƒ¨åˆ†ä¸ä¸ºç©ºï¼Œåˆ™è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå…·æœ‰IDå’Œåç§°çš„ä»»åŠ¡ã€‚å®ƒå°†è¯¥ä»»åŠ¡æ·»åŠ åˆ°ä¸€ä¸ªä¼˜å…ˆçº§ä»»åŠ¡åˆ—\n",
    "è¡¨ä¸­ï¼Œå¹¶è¿”å›è¯¥åˆ—è¡¨ã€‚\n",
    "task_prioritization_chain: LLMChainç±»å‹ï¼Œè¡¨ç¤ºä»»åŠ¡ä¼˜å…ˆçº§åˆ›å»ºé“¾ã€‚\n",
    "this_task_id: intç±»å‹ï¼Œè¡¨ç¤ºå½“å‰ä»»åŠ¡çš„IDã€‚\n",
    "task_list: List[Dict]ç±»å‹ï¼Œè¡¨ç¤ºæ‰€æœ‰ä»»åŠ¡çš„åˆ—è¡¨ã€‚\n",
    "objective: strç±»å‹ï¼Œè¡¨ç¤ºä»»åŠ¡çš„ç›®æ ‡ã€‚\n",
    "\"\"\"\n",
    "def prioritize_tasks(\n",
    "    task_prioritization_chain: LLMChain,\n",
    "    this_task_id: int,\n",
    "    task_list: List[Dict],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Prioritize tasks.\"\"\"\n",
    "    task_names = [t[\"task_name\"] for t in task_list]\n",
    "    next_task_id = int(this_task_id) + 1\n",
    "    response = task_prioritization_chain.run(\n",
    "        task_names=task_names, next_task_id=next_task_id, objective=objective\n",
    "    )\n",
    "    new_tasks = response.split(\"\\n\")\n",
    "    prioritized_task_list = []\n",
    "    for task_string in new_tasks:\n",
    "        if not task_string.strip():\n",
    "            continue\n",
    "        task_parts = task_string.strip().split(\".\", 1)\n",
    "        if len(task_parts) == 2:\n",
    "            task_id = task_parts[0].strip()\n",
    "            task_name = task_parts[1].strip()\n",
    "            prioritized_task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
    "    return prioritized_task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è¯¥å‡½æ•°çš„ä½œç”¨æ˜¯æ ¹æ®æŸ¥è¯¢è¯­å¥è¿”å›ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„kä¸ªä»»åŠ¡åç§°ã€‚å®ƒé¦–å…ˆè°ƒç”¨ç›¸ä¼¼å‘é‡å­˜å‚¨å¯¹è±¡çš„similarity_search_with_scoreæ–¹æ³•\n",
    "æ¥æ‰§è¡ŒæŸ¥è¯¢ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨resultså˜é‡ä¸­ã€‚å¦‚æœæ²¡æœ‰ç»“æœï¼Œåˆ™å‡½æ•°è¿”å›ç©ºåˆ—è¡¨ã€‚å¦åˆ™ï¼Œå®ƒä½¿ç”¨zipå’Œsortedå‡½æ•°æ¥æŒ‰ç›¸å…³æ€§å¯¹ç»“æœè¿›è¡Œ\n",
    "æ’åºï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨sorted_resultså˜é‡ä¸­ã€‚æœ€åï¼Œå®ƒéå†sorted_resultsä¸­çš„æ¯ä¸ªé¡¹ç›®ï¼Œå¹¶ä»å…¶å…ƒæ•°æ®ä¸­æå–ä»»åŠ¡åç§°ï¼Œå¹¶å°†å…¶å­˜\n",
    "å‚¨åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­ï¼Œæœ€ç»ˆè¿”å›è¯¥åˆ—è¡¨ã€‚\n",
    "\"\"\"\n",
    "def _get_top_tasks(vectorstore, query: str, k: int) -> List[str]:\n",
    "    \"\"\"Get the top k tasks based on the query.\"\"\"\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    if not results:\n",
    "        return []\n",
    "    sorted_results, _ = zip(*sorted(results, key=lambda x: x[1], reverse=True))\n",
    "    return [str(item.metadata[\"task\"]) for item in sorted_results]\n",
    "\n",
    "\"\"\"\n",
    "è¯¥å‡½æ•°çš„ä½œç”¨æ˜¯æ‰§è¡Œç»™å®šçš„ä»»åŠ¡ã€‚å®ƒé¦–å…ˆè°ƒç”¨åä¸ºâ€œ_get_top_tasksâ€çš„è¾…åŠ©å‡½æ•°æ¥è·å–ä¸ä»»åŠ¡ç›®æ ‡ç›¸å…³çš„å‰kä¸ªä»»åŠ¡åˆ—è¡¨ï¼Œå¹¶å°†ç»“æœå­˜å‚¨\n",
    "åœ¨contextå˜é‡ä¸­ã€‚ç„¶åï¼Œå®ƒå°†ä¸Šä¸‹æ–‡ä½œä¸ºå‚æ•°ä¼ é€’ç»™æ‰§è¡Œé“¾çš„runæ–¹æ³•ï¼Œä»¥æ‰§è¡Œä»»åŠ¡ã€‚æœ€åï¼Œè¯¥å‡½æ•°è¿”å›æ‰§è¡Œç»“æœã€‚\n",
    "\"\"\"\n",
    "def execute_task(\n",
    "    vectorstore, execution_chain: LLMChain, objective: str, task: str, k: int = 5\n",
    ") -> str:\n",
    "    \"\"\"Execute a task.\"\"\"\n",
    "    context = _get_top_tasks(vectorstore, query=objective, k=k)\n",
    "    return execution_chain.run(objective=objective, context=context, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ä¹‰äº†ä¸€ä¸ªæ§åˆ¶æ¨¡æ‹ŸAIä»£ç†è¡Œä¸ºçš„ç±»ï¼Œå¯ä»¥æ·»åŠ ä»»åŠ¡ã€æ‰§è¡Œä»»åŠ¡å¹¶è¾“å‡ºç»“æœã€‚å®ƒè¿˜æä¾›äº†ä¸€äº›é…ç½®é€‰é¡¹ï¼Œä»¥ä¾¿åœ¨è¿è¡Œæ—¶è‡ªå®šä¹‰ç±»çš„è¡Œä¸ºã€‚\n",
    "task_list: ä¸€ä¸ªåŒå‘é˜Ÿåˆ—ï¼Œå­˜å‚¨äº†ä»»åŠ¡åˆ—è¡¨ï¼›\n",
    "task_creation_chain: åˆ›å»ºä»»åŠ¡çš„é“¾æ¡ï¼›\n",
    "task_prioritization_chain: å¯¹ä»»åŠ¡è¿›è¡Œä¼˜å…ˆçº§æ’åºçš„é“¾æ¡ï¼›\n",
    "execution_chain: æ‰§è¡Œä»»åŠ¡çš„ä»£ç†ï¼›\n",
    "task_id_counter: ä»»åŠ¡IDè®¡æ•°å™¨ï¼›\n",
    "vectorstore: ä¸€ä¸ªå‘é‡å‚¨å­˜åº“ï¼›\n",
    "max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚\n",
    "ç±»å®šä¹‰ä¸­è¿˜æœ‰ä¸€äº›æ–¹æ³•å’Œå±æ€§ï¼š\n",
    "add_task(task): æ·»åŠ ä»»åŠ¡åˆ°ä»»åŠ¡åˆ—è¡¨ä¸­ï¼›\n",
    "print_task_list(): æ‰“å°ä»»åŠ¡åˆ—è¡¨ï¼›\n",
    "print_next_task(task): æ‰“å°ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼›\n",
    "print_task_result(result): æ‰“å°ä»»åŠ¡ç»“æœï¼›\n",
    "input_keys: è¾“å…¥å…³é”®å­—åˆ—è¡¨ï¼›\n",
    "output_keys: è¾“å‡ºå…³é”®å­—åˆ—è¡¨ã€‚\n",
    "\"\"\"\n",
    "class BabyAGI(Chain, BaseModel):\n",
    "    \"\"\"Controller model for the BabyAGI agent.\"\"\"\n",
    "\n",
    "    task_list: deque = Field(default_factory=deque)\n",
    "    task_creation_chain: TaskCreationChain = Field(...)\n",
    "    task_prioritization_chain: TaskPrioritizationChain = Field(...)\n",
    "    execution_chain: AgentExecutor = Field(...)\n",
    "    task_id_counter: int = Field(1)\n",
    "    vectorstore: VectorStore = Field(init=False)\n",
    "    max_iterations: Optional[int] = None\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def add_task(self, task: Dict):\n",
    "        self.task_list.append(task)\n",
    "\n",
    "    def print_task_list(self):\n",
    "        print(\"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        for t in self.task_list:\n",
    "            print(str(t[\"task_id\"]) + \": \" + t[\"task_name\"])\n",
    "\n",
    "    def print_next_task(self, task: Dict):\n",
    "        print(\"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        print(str(task[\"task_id\"]) + \": \" + task[\"task_name\"])\n",
    "\n",
    "    def print_task_result(self, result: str):\n",
    "        print(\"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        print(result)\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        return [\"objective\"]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return []\n",
    "\n",
    "    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Run the agent.\"\"\"\n",
    "        objective = inputs[\"objective\"]\n",
    "        #è¦æ‰§è¡Œçš„ç¬¬ä¸€ä¸ªä»»åŠ¡çš„åç§°\n",
    "        first_task = inputs.get(\"first_task\", \"Make a todo list\")\n",
    "        #åŠ ä¸€ä¸ªæ–°ä»»åŠ¡åˆ°ä»»åŠ¡åˆ—è¡¨ä¸­ã€‚\n",
    "        self.add_task({\"task_id\": 1, \"task_name\": first_task})\n",
    "        num_iters = 0\n",
    "        #ä¸€ä¸ªæ— é™å¾ªç¯ï¼Œç›´åˆ°é‡åˆ°æŸä¸ªé€€å‡ºæ¡ä»¶ä¸ºæ­¢ã€‚\n",
    "        while True:\n",
    "            if self.task_list:\n",
    "                self.print_task_list()\n",
    "\n",
    "                # Step 1: Pull the first task\n",
    "                task = self.task_list.popleft()\n",
    "                self.print_next_task(task)\n",
    "\n",
    "                # Step 2: Execute the task\n",
    "                result = execute_task(\n",
    "                    self.vectorstore, self.execution_chain, objective, task[\"task_name\"]\n",
    "                )\n",
    "                this_task_id = int(task[\"task_id\"])\n",
    "                self.print_task_result(result)\n",
    "\n",
    "                # Step 3: Store the result in Pinecone\n",
    "                result_id = f\"result_{task['task_id']}\"\n",
    "                self.vectorstore.add_texts(\n",
    "                    texts=[result],\n",
    "                    metadatas=[{\"task\": task[\"task_name\"]}],\n",
    "                    ids=[result_id],\n",
    "                )\n",
    "\n",
    "                # Step 4: Create new tasks and reprioritize task list\n",
    "                new_tasks = get_next_task(\n",
    "                    self.task_creation_chain,\n",
    "                    result,\n",
    "                    task[\"task_name\"],\n",
    "                    [t[\"task_name\"] for t in self.task_list],\n",
    "                    objective,\n",
    "                )\n",
    "                for new_task in new_tasks:\n",
    "                    self.task_id_counter += 1\n",
    "                    new_task.update({\"task_id\": self.task_id_counter})\n",
    "                    self.add_task(new_task)\n",
    "                self.task_list = deque(\n",
    "                    prioritize_tasks(\n",
    "                        self.task_prioritization_chain,\n",
    "                        this_task_id,\n",
    "                        list(self.task_list),\n",
    "                        objective,\n",
    "                    )\n",
    "                )\n",
    "            num_iters += 1\n",
    "            if self.max_iterations is not None and num_iters == self.max_iterations:\n",
    "                print(\n",
    "                    \"\\033[91m\\033[1m\" + \"\\n*****TASK ENDING*****\\n\" + \"\\033[0m\\033[0m\"\n",
    "                )\n",
    "                break\n",
    "        return {}\n",
    "    \"\"\"é¦–å…ˆä½¿ç”¨TaskCreationChain.from_llm()å’ŒTaskPrioritizationChain.from_llm()æ–¹æ³•\n",
    "    åˆ†åˆ«åˆ›å»ºä»»åŠ¡åˆ›å»ºé“¾å’Œä»»åŠ¡ä¼˜å…ˆçº§é“¾ã€‚ç„¶åä½¿ç”¨LLMChain()æ–¹æ³•åˆ›å»ºä¸€ä¸ªLLMé“¾ï¼Œå¹¶ä½¿ç”¨ZeroShotAgent()æ–¹æ³•\n",
    "    åˆ›å»ºä¸€ä¸ªZeroShotAgentã€‚æœ€åä½¿ç”¨AgentExecutor.from_agent_and_tools()æ–¹æ³•åˆ›å»ºä¸€ä¸ªä»£ç†æ‰§è¡Œå™¨ã€‚\n",
    "    æœ€åï¼Œè¯¥æ–¹æ³•è¿”å›ä¸€ä¸ªç”±è¿™äº›å¯¹è±¡ç»„æˆçš„BabyAGIæ§åˆ¶å™¨å¯¹è±¡ã€‚\"\"\"\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls, llm: BaseLLM, vectorstore: VectorStore, verbose: bool = False, **kwargs\n",
    "    ) -> \"BabyAGI\":\n",
    "        \"\"\"Initialize the BabyAGI Controller.\"\"\"\n",
    "        task_creation_chain = TaskCreationChain.from_llm(llm, verbose=verbose)\n",
    "        task_prioritization_chain = TaskPrioritizationChain.from_llm(\n",
    "            llm, verbose=verbose\n",
    "        )\n",
    "        llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        tool_names = [tool.name for tool in tools]\n",
    "        agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n",
    "        agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "            agent=agent, tools=tools, verbose=True\n",
    "        )\n",
    "        return cls(\n",
    "            task_creation_chain=task_creation_chain,\n",
    "            task_prioritization_chain=task_prioritization_chain,\n",
    "            execution_chain=agent_executor,\n",
    "            vectorstore=vectorstore,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œ BabyAGI \n",
    "\n",
    "ç°åœ¨æ˜¯åˆ›å»º BabyAGI æ§åˆ¶å™¨å¹¶è§‚å¯Ÿå®ƒå°è¯•å®ç°æ‚¨çš„ç›®æ ‡çš„æ—¶å€™äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTIVE = \"Write a weather report for Beijing today\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging of LLMChains\n",
    "verbose = False\n",
    "# If None, will keep on going forever\n",
    "max_iterations: Optional[int] = 3\n",
    "baby_agi = BabyAGI.from_llm(\n",
    "    llm=llm, vectorstore=vectorstore, verbose=verbose, max_iterations=max_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to come up with a todo list\n",
      "Action: TODO\n",
      "Action Input: Write a weather report for Beijing today\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "\n",
      "1. Research current weather conditions in Beijing\n",
      "2. Gather data on temperature, humidity, wind speed, and other relevant weather conditions\n",
      "3. Research historical weather patterns in Beijing\n",
      "4. Analyze current and historical data to determine any trends\n",
      "5. Write a brief introduction to the weather report\n",
      "6. Describe current weather conditions in Beijing\n",
      "7. Discuss any trends in the weather\n",
      "8. Make predictions about the weather in Beijing for the next 24 hours\n",
      "9. Conclude the report with a summary of the weather conditions\n",
      "10. Proofread and edit the report for accuracy and clarity\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: A todo list for writing a weather report for Beijing today: \n",
      "1. Research current weather conditions in Beijing\n",
      "2. Gather data on temperature, humidity, wind speed, and other relevant weather conditions\n",
      "3. Research historical weather patterns in Beijing\n",
      "4. Analyze current and historical data to determine any trends\n",
      "5. Write a brief introduction to the weather report\n",
      "6. Describe current weather conditions in Beijing\n",
      "7. Discuss any trends in the weather\n",
      "8. Make predictions about the weather in Beijing for the next 24 hours\n",
      "9. Conclude the report with a summary of the weather conditions\n",
      "10. Proofread and edit the report for accuracy and clarity\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "A todo list for writing a weather report for Beijing today: \n",
      "1. Research current weather conditions in Beijing\n",
      "2. Gather data on temperature, humidity, wind speed, and other relevant weather conditions\n",
      "3. Research historical weather patterns in Beijing\n",
      "4. Analyze current and historical data to determine any trends\n",
      "5. Write a brief introduction to the weather report\n",
      "6. Describe current weather conditions in Beijing\n",
      "7. Discuss any trends in the weather\n",
      "8. Make predictions about the weather in Beijing for the next 24 hours\n",
      "9. Conclude the report with a summary of the weather conditions\n",
      "10. Proofread and edit the report for accuracy and clarity\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Gather data on air quality, air pollution, and other relevant environmental conditions\n",
      "3: Research historical air quality patterns in Beijing\n",
      "4: Analyze current and historical data to determine any trends\n",
      "5: Compare current air quality to air quality standards\n",
      "6: Make predictions about the air quality in Beijing for the next 24 hours\n",
      "7: Discuss any trends in the air quality\n",
      "8: Write a brief summary of the air quality in Beijing\n",
      "9: Create a chart or graph to illustrate the air quality data\n",
      "10: Proofread and edit the report for accuracy and clarity\n",
      "1: Research current air quality in Beijing\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Gather data on air quality, air pollution, and other relevant environmental conditions\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for data on air quality, air pollution, and other relevant environmental conditions\n",
      "Action: Search\n",
      "Action Input: air quality, air pollution, and other relevant environmental conditions\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDespite the dramatic progress to date, air pollution continues to threaten Americans' health and welfare. The main obstacles are climate change, ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Despite the dramatic progress to date, air pollution continues to threaten Americans' health and welfare. The main obstacles are climate change, ...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "Despite the dramatic progress to date, air pollution continues to threaten Americans' health and welfare. The main obstacles are climate change, ...\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Compare current air quality to air quality standards\n",
      "4: Make predictions about the air quality in Beijing for the next 24 hours\n",
      "5: Research current air quality in Beijing\n",
      "6: Identify any sources of air pollution in Beijing and their potential impacts on air quality\n",
      "7: Investigate the effectiveness of current air quality regulations in Beijing\n",
      "8: Analyze the impact of climate change on air quality in Beijing\n",
      "9: Compare air quality in Beijing to other cities in China\n",
      "10: Examine the health effects of air pollution in Beijing\n",
      "11: Investigate the economic costs of air pollution in Beijing\n",
      "12: Research the potential solutions to improve air quality in Beijing\n",
      "13: Create a timeline of air quality in Beijing over the past decade\n",
      "14: Discuss any trends in the air quality\n",
      "15: Research historical air quality patterns in Beijing\n",
      "16: Analyze current and historical data to determine any trends\n",
      "17: Write a brief summary of the air quality in Beijing\n",
      "18: Create a chart or graph to illustrate the air quality data\n",
      "19: Proofread and edit the report for accuracy and clarity\n",
      "20: Summarize the findings of the report in a concise\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Compare current air quality to air quality standards\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for air quality standards\n",
      "Action: Search\n",
      "Action Input: air quality standards\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAQI values at or below 100 are generally thought of as satisfactory. When AQI values are above 100, air quality is unhealthy: at first for certain sensitive groups of people, then for everyone as AQI values get higher.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to search for current air quality\n",
      "Action: Search\n",
      "Action Input: current air quality\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mGet air quality data where you live. ; Air Quality Index Scale ; 0 - 50. Good ; 51 - 100. Moderate ; 101 - 150. Unhealthy for Sensitive Groups (USG) ; 151 - 200.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current air quality in Beijing is Unhealthy for Sensitive Groups (USG).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "The current air quality in Beijing is Unhealthy for Sensitive Groups (USG).\n",
      "\u001b[91m\u001b[1m\n",
      "*****TASK ENDING*****\n",
      "\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'Write a weather report for Beijing today'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_agi({\"objective\": OBJECTIVE})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-GPT Assistant "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./autogpt.png\"  height=\"20%\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆæˆ‘ä»¬å¯¹AutoGPTåŸºäºlangchainè¿›è¡Œç›¸åº”åœ°å®ç°,ä»¥ä¾¿äº†è§£å…¶åŸç†ä¸æ­¥éª¤"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆå»ºç«‹toolsï¼Œå®šä¹‰search tool, write-file tool, read-file tool\n",
    "å®‰è£…ä¸€äº›æˆ‘ä»¬è¿™ä¸ªæ ç›®ä¸­å³å°†è¦ä½¿ç”¨åˆ°çš„åº“å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install duckduckgo_search\n",
    "%pip install playwright\n",
    "%pip install bs4\n",
    "%pip install nest_asyncio\n",
    "%pip install tiktoken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é…ç½®ç¨‹åºè¿è¡Œä»£ç†ä»¥åŠç›¸å…³API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# è®¾ç½®HTTPä»£ç†\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:xxxx'\n",
    "# è®¾ç½®HTTPSä»£ç†\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:xxxx'\n",
    "\n",
    "# openaiçš„key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxx\"\n",
    "#è°·æ­Œæœç´¢apiçš„key,ä»…åœ¨agentä¸­ä½¿ç”¨\n",
    "os.environ['SERPAPI_API_KEY']='--------------Your API KEY----------------------'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹çš„ä»£ç æ³¨é‡Šç”±äºåœ¨Coding Examplesä¸­å·²ç»å‡ºç°è¿‡ï¼Œå°†å¯¹äºé‡å¤çš„éƒ¨åˆ†ä¸å†ç‰¹åˆ«æ·»åŠ æ³¨é‡Šè¯´æ˜ï¼Œå¦‚ä¾ç„¶æœ‰ç–‘é—®è¯·å‚é˜…å®Œæ•´çš„[Coding Examples](#coding-exampls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools.file_management.write import WriteFileTool\n",
    "from langchain.tools.file_management.read import ReadFileTool\n",
    "\n",
    "\"\"\"\n",
    "å®ƒåˆ›å»ºäº†ä¸€ä¸ªSerpAPIWrapperå¯¹è±¡ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™å˜é‡searchã€‚ç„¶åï¼Œå®ƒå®šä¹‰äº†ä¸€ä¸ªåä¸ºâ€œtoolsâ€çš„åˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«äº†\n",
    "ä¸‰ä¸ªå…ƒç´ ï¼šä¸€ä¸ªToolå¯¹è±¡ï¼Œè¯¥å¯¹è±¡ä»£è¡¨åç§°ä¸ºâ€œsearchâ€çš„å·¥å…·ï¼›ä¸€ä¸ªWriteFileToolå¯¹è±¡ï¼›å’Œä¸€ä¸ªReadFileToolå¯¹è±¡ã€‚\n",
    "\"\"\"\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events. You should ask targeted questions\"\n",
    "    ),\n",
    "    WriteFileTool(),\n",
    "    ReadFileTool(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings()\n",
    "import faiss\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.experimental.autonomous_agents.autogpt.agent import AutoGPT\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ä¸‹é¢æ˜¯ä½¿ç”¨AutoGPTåˆ›å»ºä¸€ä¸ªåä¸º\"agent\"çš„æ™ºèƒ½ä»£ç†ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ™ºèƒ½ä»£ç†å°†æ‰®æ¼”ä¸€ä¸ªåŠ©ç†çš„è§’è‰²ï¼Œ\n",
    "å¹¶ä½¿ç”¨æŒ‡å®šçš„å·¥å…·å’Œè¯­è¨€æ¨¡å‹(åœ¨è¿™é‡Œæ˜¯ChatOpenAI)æ¥ä¸ç”¨æˆ·è¿›è¡Œäº¤äº’ã€‚å…¶ä¸­ï¼Œå‚æ•°ai_nameæŒ‡å®šäº†æ™ºèƒ½\n",
    "ä»£ç†çš„åç§°ä¸º\"Tom\",ai_roleæŒ‡å®šäº†å…¶è§’è‰²ä¸ºåŠ©ç†ï¼›å‚æ•°toolsæŒ‡å®šäº†æ™ºèƒ½ä»£ç†å¯ä»¥ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨ï¼›å‚æ•°\n",
    "llmæŒ‡å®šäº†æ™ºèƒ½ä»£ç†çš„è¯­è¨€æ¨¡å‹ä¸ºChatOpenAI,å¹¶å°†å…¶æ¸©åº¦è®¾ç½®ä¸º0,è¿™æ„å‘³ç€å®ƒå°†å°½å¯èƒ½åœ°æä¾›å‡†ç¡®çš„å›ç­”ï¼›\n",
    "å‚æ•°memoryæŒ‡å®šäº†æ™ºèƒ½ä»£ç†ä½¿ç”¨çš„æ£€ç´¢å™¨ä¸ºvectorstore.as_retriever()ã€‚\n",
    "é€šè¿‡è¿™éƒ¨åˆ†ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªå…·æœ‰è‡ªå®šä¹‰è§’è‰²ã€å·¥å…·å’Œè¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä»£ç†ï¼Œå¹¶ä½¿ç”¨æŒ‡å®šçš„æ£€ç´¢å™¨æ¥è·\n",
    "å–ä¿¡æ¯ã€‚\n",
    "\"\"\"\n",
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"Tom\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    memory=vectorstore.as_retriever()\n",
    ")\n",
    "agent.chain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run([\"make a plan to travel around the China for a month, and give me five advices\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä»£ç æœ€ç»ˆå°†ä¼šåœ¨å½“å‰ç›®å½•ä¸‹æ–°å»ºå‡ºå¾ˆå¤šçš„txtæ–‡ä»¶ï¼ŒåŒ…æ‹¬ä¸é™äºchina_trip_plan.txt, china_info.txt, budge.txt, flight_info.txtç­‰æ–‡ä»¶ï¼Œæ‚¨å¯ä»¥é€šè¿‡è¿è¡Œè¯¥noteboookä»£ç è¿›è¡Œä½“éªŒã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”±äºè¿è¡Œè¿‡ç¨‹ä¸­éœ€è¦finishçš„ä¸­æ–­å‘½ä»¤ï¼Œå› æ­¤æˆ‘ä»¬ä¸Šé¢è¿è¡Œçš„ç¨‹åºå°†éƒ¨åˆ†è¿è¡Œç»“æœæ”¾ç½®åœ¨è¿™é‡Œï¼š\n",
    "OUTï¼š\n",
    "\n",
    "\n",
    "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
    "Prompt after formatting:\n",
    "\u001b[32;1m\u001b[1;3mSystem: You are Tom, Assistant\n",
    "Your decisions must always be made independently without seeking user assistance.\n",
    "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
    "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
    "\n",
    "GOALS:\n",
    "\n",
    "1. make a plan to travel around the China for a month, and give me five advices\n",
    "\n",
    "\n",
    "Constraints:\n",
    "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
    "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
    "3. No user assistance\n",
    "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
    "\n",
    "Commands:\n",
    "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"query\": {\"title\": \"Query\", \"type\": \"string\"}}\n",
    "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}}\n",
    "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
    "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
    "\n",
    "Resources:\n",
    "1. Internet access for searches and information gathering.\n",
    "2. Long Term memory management.\n",
    "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
    "4. File output.\n",
    "\n",
    "Performance Evaluation:\n",
    "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
    "2. Constructively self-criticize your big-picture behavior constantly.\n",
    "3. Reflect on past decisions and strategies to refine your approach.\n",
    "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
    "\n",
    "You should only respond in JSON format as described below \n",
    "Response Format: \n",
    "{\n",
    "    \"thoughts\": {\n",
    "        \"text\": \"thought\",\n",
    "        \"reasoning\": \"reasoning\",\n",
    "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
    "        \"criticism\": \"constructive self-criticism\",\n",
    "        \"speak\": \"thoughts summary to say to user\"\n",
    "    },\n",
    "    \"command\": {\n",
    "        \"name\": \"command name\",\n",
    "        \"args\": {\n",
    "            \"arg name\": \"value\"\n",
    "        }\n",
    "    }\n",
    "} \n",
    "Ensure the response can be parsed by Python json.loads\n",
    "System: The current time and date is Wed Apr 26 16:17:15 2023\n",
    "System: This reminds you of these events from your past:\n",
    "['Assistant Reply: {\"thoughts\": {\"text\": \"I will use the information I retrieved from the affordable accommodations and transportation file to create a budget for my trip. I will use the write_file command to save the budget to a file. Then, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\", \"reasoning\": \"I have retrieved the information I need to create a budget for my trip. I also need to find popular tourist attractions in China and create a packing list. I will use the write_file command to save both the budget and packing list to files.\", \"plan\": \"- Use the information from the affordable accommodations and transportation file to create a budget for my trip.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use the write_file command to save the budget to a file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use the search command to find popular tourist attractions in China and save the information to a file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use the write_file command to save a packing list to a file.\", \"criticism\": \"I need to make sure I am not spending too much time on planning and that I am making progress towards actually traveling to China.\", \"speak\": \"I am going to use the information I retrieved from the affordable accommodations and transportation file to create a budget for my trip. I will use the write_file command to save the budget to a file. Then, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\"}, \"command\": {\"name\": \"write_file\", \"args\": {\"file_path\": \"budget.txt\", \"text\": \"Budget for China Trip:\\\\\\\\nAccommodation: $80 per day\\\\\\\\nTransportation: $3 per day\\\\\\\\nFood: $30 per day\\\\\\\\nTotal: $113 per day\\\\\\\\nTotal for 30 days: $3,390\"}}} \\nResult: Command write_file returned: File written successfully to budget.txt. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"Now that I have all the necessary information saved to files, I can start planning my trip. I will use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China. Then, I will use this information to create a budget for my trip. After that, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\",\\n        \"reasoning\": \"I have all the necessary information saved to files. I can use the information I saved earlier about affordable accommodations and transportation in China to create a budget for my trip. I also need to find popular tourist attractions in China and create a packing list. I will use the write_file command to save both the budget and packing list to files.\",\\n        \"plan\": \"- Use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China.\\\\\\\\\\\\\\\\n- Use this information to create a budget for my trip.\\\\\\\\\\\\\\\\n- Use the search command to find popular tourist attractions in China and save the information to a file.\\\\\\\\\\\\\\\\n- Use the write_file command to save a packing list to a file.\",\\n        \"criticism\": \"I need to make sure I am not spending too much time on planning and that I am making progress towards actually traveling to China.\",\\n        \"speak\": \"Now that I have all the necessary information saved to files, I am going to use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China. Then, I will use this information to create a budget for my trip. After that, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\"\\n    },\\n    \"command\": {\\n        \"name\": \"read_file\",\\n        \"args\": {\\n            \"file_path\": \"china_accommodations_transportation.txt\"\\n        }\\n    }\\n} \\nResult: Command read_file returned: Accommodation: $80 per day; Transportation: $3 per day; Food: $30 per day ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I am going to use the write_file command to save the information I found earlier about affordable accommodations and transportation in China to a file. This will make it easier for me to access the information later when I need it.\", \\n        \"reasoning\": \"I have found affordable accommodations and transportation options for my trip to China. I want to make sure I have easy access to this information later when I need it.\", \\n        \"plan\": \"- Use the write_file command to save the information about affordable accommodations and transportation in China to a file\", \\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually traveling to China.\", \\n        \"speak\": \"I am going to use the write_file command to save the information I found earlier about affordable accommodations and transportation in China to a file.\"\\n    }, \\n    \"command\": {\\n        \"name\": \"write_file\", \\n        \"args\": {\\n            \"file_path\": \"china_info.txt\", \\n            \"text\": \"Accommodation: $80 per day; Transportation: $3 per day; Food: $30 per ...\"\\n        }\\n    }\\n} \\nResult: Command write_file returned: File written successfully to china_info.txt. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I will use the write_file command to save the information about affordable accommodations and transportation in China to a file. Then, I will use the search command to find affordable flights to China and use the write_file command to save the flight information to a file.\",\\n        \"reasoning\": \"I have found information about affordable accommodations and transportation in China using the search command. I need to save this information to a file so that I can refer to it later. I also need to find affordable flights to China and save this information to a file.\",\\n        \"plan\": \"- Use the write_file command to save the information about affordable accommodations and transportation in China to a file.\\\\\\\\\\\\\\\\n- Use the search command to find affordable flights to China and use the write_file command to save the flight information to a file.\",\\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually traveling to China.\",\\n        \"speak\": \"I am going to use the write_file command to save the information about affordable accommodations and transportation in China to a file. Then, I will use the search command to find affordable flights to China and use the write_file command to save the flight information to a file.\"\\n    },\\n    \"command\": {\\n        \"name\": \"write_file\",\\n        \"args\": {\\n            \"file_path\": \"china_accommodations_transportation.txt\",\\n            \"text\": \"Accommodation: $80 per day; Transportation: $3 per day; Food: $30 per day\"\\n        }\\n    }\\n} \\nResult: Command write_file returned: File written successfully to china_accommodations_transportation.txt. ']\n",
    "\n",
    "\n",
    "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n",
    "\n",
    "\u001b[1m> Finished chain.\u001b[0m\n",
    "{\n",
    "    \"thoughts\": {\n",
    "        \"text\": \"Now that I have all the necessary information saved to files, I can start planning my trip. I will use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China. Then, I will use this information to create a budget for my trip. After that, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\",\n",
    "        \"reasoning\": \"I have all the necessary information saved to files. I can use the information I saved earlier about affordable accommodations and transportation in China to create a budget for my trip. I also need to find popular tourist attractions in China and create a packing list. I will use the write_file command to save both the budget and packing list to files.\",\n",
    "        \"plan\": \"- Use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China.\\\\n- Use this information to create a budget for my trip.\\\\n- Use the search command to find popular tourist attractions in China and save the information to a file.\\\\n- Use the write_file command to save a packing list to a file.\",\n",
    "        \"criticism\": \"I need to make sure I am not spending too much time on planning and that I am making progress towards actually traveling to China.\",\n",
    "        \"speak\": \"Now that I have all the necessary information saved to files, I am going to use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China. Then, I will use this information to create a budget for my trip. After that, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\"\n",
    "    },\n",
    "    \"command\": {\n",
    "        \"name\": \"read_file\",\n",
    "        \"args\": {\n",
    "            \"file_path\": \"china_accommodations_transportation.txt\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
    "Prompt after formatting:\n",
    "\u001b[32;1m\u001b[1;3mSystem: You are Tom, Assistant\n",
    "Your decisions must always be made independently without seeking user assistance.\n",
    "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
    "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
    "\n",
    "GOALS:\n",
    "\n",
    "1. make a plan to travel around the China for a month, and give me five advices\n",
    "\n",
    "\n",
    "Constraints:\n",
    "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
    "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
    "3. No user assistance\n",
    "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
    "\n",
    "Commands:\n",
    "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"query\": {\"title\": \"Query\", \"type\": \"string\"}}\n",
    "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}}\n",
    "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
    "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
    "\n",
    "Resources:\n",
    "1. Internet access for searches and information gathering.\n",
    "2. Long Term memory management.\n",
    "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
    "4. File output.\n",
    "\n",
    "Performance Evaluation:\n",
    "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
    "2. Constructively self-criticize your big-picture behavior constantly.\n",
    "3. Reflect on past decisions and strategies to refine your approach.\n",
    "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
    "\n",
    "You should only respond in JSON format as described below \n",
    "Response Format: \n",
    "{\n",
    "    \"thoughts\": {\n",
    "        \"text\": \"thought\",\n",
    "        \"reasoning\": \"reasoning\",\n",
    "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
    "        \"criticism\": \"constructive self-criticism\",\n",
    "        \"speak\": \"thoughts summary to say to user\"\n",
    "    },\n",
    "    \"command\": {\n",
    "        \"name\": \"command name\",\n",
    "        \"args\": {\n",
    "            \"arg name\": \"value\"\n",
    "        }\n",
    "    }\n",
    "} \n",
    "Ensure the response can be parsed by Python json.loads\n",
    "System: The current time and date is Wed Apr 26 16:18:07 2023\n",
    "System: This reminds you of these events from your past:\n",
    "['Assistant Reply: {\"thoughts\": {\"text\": \"I will use the search command to find popular tourist attractions in China and save the information to a file. I should make sure to include the location, hours of operation, and admission fees for each attraction. Then, I will use the write_file command to save the information to a file.\", \"reasoning\": \"I need to find popular tourist attractions in China and save the information to a file. I will use the search command to find this information and the write_file command to save it to a file.\", \"plan\": \"- Use the search command to find popular tourist attractions in China and save the information to a file.\\\\\\\\\\\\\\\\n- Use the write_file command to save the information to a file.\", \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually traveling to China.\", \"speak\": \"I am going to use the search command to find popular tourist attractions in China and save the information to a file. Then, I will use the write_file command to save the information to a file.\"}, \"command\": {\"name\": \"search\", \"args\": {\"query\": \"popular tourist attractions in China\"}}} \\nResult: Command search returned: China, officially the People\\'s Republic of China, is a country in East Asia. It has been the world\\'s most populous country since at least 1950, with a population exceeding 1.4 billion, but is expected to be overtaken by India in mid-2023. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I will use the search command to find information about the best places to visit in China. This will help me plan my itinerary for the month.\", \\n        \"reasoning\": \"Now that I have booked my accommodations, transportation, and flights to China, I need to plan my itinerary. I will use the search command to find information about the best places to visit in China.\", \\n        \"plan\": \"- Use the search command to find information about the best places to visit in China\", \\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually traveling to China.\", \\n        \"speak\": \"I am going to use the search command to find information about the best places to visit in China.\"\\n    }, \\n    \"command\": {\\n        \"name\": \"search\", \\n        \"args\": {\\n            \"query\": \"best places to visit in China\"\\n        }\\n    }\\n} \\nResult: Command search returned: China, officially the People\\'s Republic of China, is a country in East Asia. It has been the world\\'s most populous country since at least 1950, with a population exceeding 1.4 billion, but is expected to be overtaken by India in mid-2023. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I need to find the best places to visit in China. I should search for articles or travel guides that list the top tourist destinations in China.\",\\n        \"reasoning\": \"I want to make sure I don\\'t miss any important tourist destinations in China.\",\\n        \"plan\": \"- Search for articles or travel guides that list the top tourist destinations in China\",\\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually planning my trip.\",\\n        \"speak\": \"I am going to search for articles or travel guides that list the top tourist destinations in China.\"\\n    },\\n    \"command\": {\\n        \"name\": \"search\",\\n        \"args\": {\\n            \"query\": \"best tourist destinations in China\"\\n        }\\n    }\\n} \\nResult: Command search returned: China, officially the People\\'s Republic of China, is a country in East Asia. It has been the world\\'s most populous country since at least 1950, with a population exceeding 1.4 billion, but is expected to be overtaken by India in mid-2023. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I need to start planning my trip to China. I should start by researching the best places to visit and the most efficient way to travel between them.\",\\n        \"reasoning\": \"I need to gather information to make informed decisions about my trip.\",\\n        \"plan\": \"- Research the best places to visit in China\\\\n- Research the most efficient way to travel between destinations\\\\n- Create a rough itinerary for my trip\",\\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually planning my trip.\",\\n        \"speak\": \"I am going to start by researching the best places to visit in China and the most efficient way to travel between them.\"\\n    },\\n    \"command\": {\\n        \"name\": \"search\",\\n        \"args\": {\\n            \"query\": \"best places to visit in China\"\\n        }\\n    }\\n} \\nResult: Command search returned: China, officially the People\\'s Republic of China, is a country in East Asia. It has been the world\\'s most populous country since at least 1950, with a population exceeding 1.4 billion, but is expected to be overtaken by India in mid-2023. ']\n",
    "\n",
    "\n",
    "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚ä¸‹çš„ç¤ºä¾‹æ˜¯ç”¨AutoGPTè¿›è¡ŒWinning Marathon Timesçš„æŸ¥æ‰¾ã€‚è¯¥ç¤ºä¾‹ä»£ç ä¸­ä½¿ç”¨åˆ°çš„modelæ˜¯GPT-4ï¼Œå› æ­¤éœ€è¦æå‰å‡†å¤‡å¥½GPT-4è°ƒç”¨éœ€è¦çš„ç¯å¢ƒæ¡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain.experimental.autonomous_agents.autogpt.agent import AutoGPT\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent\n",
    "from langchain.docstore.document import Document\n",
    "\"\"\"\n",
    "asyncioæ˜¯ä¸€ä¸ªPythonæ ‡å‡†åº“ï¼Œç”¨äºç¼–å†™å¼‚æ­¥ä»£ç ã€‚\n",
    "nest_asyncioæ˜¯ä¸€ä¸ªç¬¬ä¸‰æ–¹åº“ï¼Œç”¨äºåœ¨Pythonä¸­ä½¿ç”¨asyncioçš„éé˜»å¡I/Oæ“ä½œã€‚\n",
    "è°ƒç”¨nest_asyncio.apply()å‡½æ•°æ¥è¿è¡Œæ‰€æœ‰å¼‚æ­¥ä»£ç ã€‚\n",
    "\"\"\"\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import contextmanager\n",
    "from typing import Optional\n",
    "from langchain.agents import tool\n",
    "from langchain.tools.file_management.read import ReadFileTool\n",
    "from langchain.tools.file_management.write import WriteFileTool\n",
    "\n",
    "ROOT_DIR = \"./data/\"\n",
    "\"\"\"\n",
    "pushedå‡½æ•°å®šä¹‰äº†ä¸€ä¸ªåä¸ºpushdçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºæ›´æ”¹å½“å‰å·¥ä½œç›®å½•ã€‚å®ƒæ¥å—ä¸€ä¸ªå‚æ•°new_dir,è¡¨ç¤ºæ–°çš„å·¥ä½œç›®å½•è·¯å¾„ã€‚\n",
    "åœ¨è¿›å…¥pushdä¸Šä¸‹æ–‡ç®¡ç†å™¨æ—¶ï¼Œå½“å‰å·¥ä½œç›®å½•å°†è¢«ä¿å­˜ä¸ºprev_dir,ç„¶åä½¿ç”¨os.chdir()å‡½æ•°å°†å½“å‰å·¥ä½œç›®å½•æ›´æ”¹ä¸ºnew_dirã€‚åœ¨\n",
    "ç¦»å¼€ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ—¶ï¼Œprev_dirå°†è¢«æ¢å¤ä¸ºå½“å‰å·¥ä½œç›®å½•ã€‚è¿™ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨å¯ä»¥ç”¨æ¥åœ¨éœ€è¦æš‚æ—¶æ›´æ”¹å·¥ä½œç›®å½•çš„æƒ…å†µä¸‹ï¼Œä¿æŒä»£ç \n",
    "ä¸­è·¯å¾„å’Œæ–‡ä»¶åçš„æ­£ç¡®æ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ªPythonè„šæœ¬ä¸­ï¼Œå¯ä»¥ä½¿ç”¨pushdä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¥åˆ‡æ¢åˆ°æ•°æ®é›†æ‰€åœ¨çš„ç›®å½•ï¼Œç„¶åæ‰§è¡Œæ•°æ®é¢„\n",
    "å¤„ç†æˆ–æ¨¡å‹è®­ç»ƒç­‰ä»»åŠ¡ã€‚å®Œæˆä»»åŠ¡åï¼Œå¯ä»¥ä½¿ç”¨ç›¸åŒçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨å°†å·¥ä½œç›®å½•åˆ‡æ¢å›åŸå§‹ç›®å½•ã€‚\n",
    "\"\"\"\n",
    "@contextmanager\n",
    "def pushd(new_dir):\n",
    "    \"\"\"Context manager for changing the current working directory.\"\"\"\n",
    "    prev_dir = os.getcwd()\n",
    "    os.chdir(new_dir)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(prev_dir)\n",
    "\n",
    "\"\"\"\n",
    "è¯¥å‡½æ•°åä¸ºprocess_csv,ç”¨äºå¤„ç†CSVæ–‡ä»¶å¹¶æ‰§è¡Œä¸€äº›æ“ä½œ.\n",
    "æ¥å—ä¸‰ä¸ªå‚æ•°ï¼šcsv_file_path(å­—ç¬¦ä¸²ç±»å‹ï¼Œè¡¨ç¤ºCSVæ–‡ä»¶è·¯å¾„)\n",
    "instructions(å­—ç¬¦ä¸²ç±»å‹ï¼Œè¡¨ç¤ºæŒ‡ä»¤)\n",
    "output_path(å¯é€‰å­—ç¬¦ä¸²ç±»å‹ï¼Œè¡¨ç¤ºè¾“å‡ºè·¯å¾„)ã€‚\n",
    "åœ¨å‡½æ•°ä¸­ï¼Œä½¿ç”¨äº†pandasåº“æ¥è¯»å–CSVæ–‡ä»¶ï¼Œç„¶ååˆ›å»ºäº†ä¸€ä¸ªpandasæ•°æ®å¸§ä»£ç†å¯¹è±¡agentã€‚æ¥ä¸‹æ¥ï¼Œæ ¹æ®ä¼ å…¥çš„æŒ‡ä»¤å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œ\n",
    "å¹¶å°†ç»“æœä¿å­˜åˆ°æŒ‡å®šçš„è¾“å‡ºè·¯å¾„ä¸­ã€‚å¦‚æœå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼Œåˆ™è¿”å›é”™è¯¯ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè¯¥ä»£ç è¿˜åŒ…å«äº†ä¸€ä¸ªæ³¨é‡Š@tool,è¯´æ˜è¯¥å‡½æ•°çš„ä½œ\n",
    "ç”¨æ˜¯ç”¨äºåœ¨REPLç¯å¢ƒä¸­ä½¿ç”¨pandaså¤„ç†CSVæ–‡ä»¶ã€‚\n",
    "\"\"\"\n",
    "@tool\n",
    "def process_csv(\n",
    "    csv_file_path: str, instructions: str, output_path: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"Process a CSV by with pandas in a limited REPL.\\\n",
    " Only use this after writing data to disk as a csv file.\\\n",
    " Any figures must be saved to disk to be viewed by the human.\\\n",
    " Instructions should be written in natural language, not code. Assume the dataframe is already loaded.\"\"\"\n",
    "    with pushd(ROOT_DIR):\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "        agent = create_pandas_dataframe_agent(llm, df, max_iterations=30, verbose=True)\n",
    "        if output_path is not None:\n",
    "            instructions += f\" Save output to disk at {output_path}\"\n",
    "        try:\n",
    "            result = agent.run(instructions)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_load_playwright(url: str) -> str:\n",
    "    \"\"\"\n",
    "    åŠ è½½æŒ‡å®šçš„URLå¹¶ä½¿ç”¨Playwrightè§£æä¸ºBeautifulSoupå¯¹è±¡ã€‚\n",
    "    å‚æ•°ï¼š\n",
    "        url (str): è¦åŠ è½½å’Œè§£æçš„URLã€‚\n",
    "    è¿”å›å€¼ï¼š\n",
    "        str: è§£æåçš„HTMLæ–‡æœ¬ã€‚\n",
    "    \"\"\"\n",
    "    from bs4 import BeautifulSoup\n",
    "    from playwright.async_api import async_playwright\n",
    "\n",
    "    # å­˜å‚¨è§£æåçš„HTMLæ–‡æœ¬\n",
    "    results = \"\" \n",
    "    #ä½¿ç”¨async withè¯­å¥åˆ›å»ºä¸€ä¸ªä¸Šä¸‹æ–‡ç¯å¢ƒï¼Œè‡ªåŠ¨å…³é—­æµè§ˆå™¨å®ä¾‹\n",
    "    async with async_playwright() as p:\n",
    "        #åœ¨æ— å¤´æ¨¡å¼ä¸‹å¯åŠ¨Chromiumæµè§ˆå™¨å®ä¾‹\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        try:\n",
    "            #åˆ›å»ºä¸€ä¸ªæ–°çš„é¡µé¢å®ä¾‹\n",
    "            page = await browser.new_page()\n",
    "            #åŠ è½½æŒ‡å®šçš„URL\n",
    "            await page.goto(url)\n",
    "\n",
    "            #è·å–é¡µé¢æºä»£ç \n",
    "            page_source = await page.content()\n",
    "            #å°†é¡µé¢æºä»£ç è§£æä¸ºBeautifulSoupå¯¹è±¡\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "            #ä»HTMLä¸­æå–æ‰€æœ‰è„šæœ¬å’Œæ ·å¼æ ‡ç­¾çš„å†…å®¹\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.extract()\n",
    "\n",
    "            #ä»HTMLä¸­æå–çº¯æ–‡æœ¬å†…å®¹\n",
    "            text = soup.get_text()\n",
    "            #å°†æ–‡æœ¬æŒ‰è¡Œåˆ†å‰²å¹¶å»é™¤ç©ºæ ¼\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            #å°†æ–‡æœ¬æŒ‰å•è¯æˆ–ç©ºæ ¼åˆ†å‰²å¹¶å»é™¤ç©ºæ ¼\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            #å°†ç»“æœæ‹¼æ¥æˆå­—ç¬¦ä¸²å¹¶å»é™¤ç©ºæ ¼\n",
    "            results = \"\\n\".join(chunk for chunk in chunks if chunk)\n",
    "        except Exception as e:\n",
    "            #å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œå°†é”™è¯¯ä¿¡æ¯æ·»åŠ åˆ°ç»“æœå­—ç¬¦ä¸²ä¸­\n",
    "            results = f\"Error: {e}\"\n",
    "        #å…³é—­æµè§ˆå™¨å®ä¾‹\n",
    "        await browser.close()\n",
    "    #è¿”å›è§£æåçš„HTMLæ–‡æœ¬\n",
    "    return results\n",
    "#å®šä¹‰ä¸€ä¸ªå¼‚æ­¥å‡½æ•°ï¼Œç”¨äºè¿è¡Œçº¿ç¨‹\n",
    "def run_async(coro):\n",
    "    #è·å–äº‹ä»¶å¾ªç¯å¯¹è±¡\n",
    "    event_loop = asyncio.get_event_loop()\n",
    "    #è¿è¡Œåç¨‹å¹¶è¿”å›ç»“æœ\n",
    "    return event_loop.run_until_complete(coro)\n",
    "\n",
    "#å®šä¹‰ä¸€ä¸ªå·¥å…·å‡½æ•°ï¼Œç”¨äºæµè§ˆç½‘é¡µ\n",
    "#ä»¥å†—é•¿çš„æ–¹å¼æŠ“å–æ•´ä¸ªç½‘é¡µã€‚å¾ˆå¯èƒ½ä¼šå¯¼è‡´è§£æé—®é¢˜\n",
    "@tool\n",
    "def browse_web_page(url: str) -> str:\n",
    "    \"\"\"è°ƒç”¨å¼‚æ­¥å‡½æ•°ï¼ŒåŠ è½½æŒ‡å®šçš„URLå¹¶è§£æä¸ºBeautifulSoupå¯¹è±¡\"\"\"\n",
    "    return run_async(async_load_playwright(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool, DuckDuckGoSearchTool\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from pydantic import Field\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain, BaseCombineDocumentsChain\n",
    "\n",
    "\"\"\"\n",
    "å®šä¹‰äº†ä¸€ä¸ªåä¸º_get_text_splitter()çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°è¿”å›ä¸€ä¸ªRecursiveCharacterTextSplitterå¯¹è±¡ã€‚\n",
    "è¿™ä¸ªå¯¹è±¡æ˜¯ä¸€ä¸ªç”¨äºå°†æ–‡æœ¬åˆ†å‰²æˆæ›´å°éƒ¨åˆ†çš„å·¥å…·ã€‚åœ¨å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†ä¸€äº›å‚æ•°æ¥æ§åˆ¶åˆ†å‰²çš„è¡Œä¸ºï¼Œä¾‹å¦‚å—çš„å¤§å°ã€\n",
    "å—ä¹‹é—´çš„é‡å å¤§å°ä»¥åŠæŒ‡å®šé•¿åº¦å‡½æ•°ã€‚è¿™äº›å‚æ•°å¯ä»¥æ ¹æ®å…·ä½“çš„éœ€æ±‚è¿›è¡Œè°ƒæ•´ã€‚\n",
    "\"\"\"\n",
    "def _get_text_splitter():\n",
    "    return RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap  = 20,\n",
    "        length_function = len,\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "å®šä¹‰äº†ä¸€ä¸ªåä¸ºWebpageQAToolçš„ç±»ï¼Œè¯¥ç±»ç»§æ‰¿è‡ªBaseToolç±»ã€‚åœ¨ç±»ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€äº›å±æ€§å’Œæ–¹æ³•ï¼Œç”¨äºå®ç°æµè§ˆç½‘é¡µå¹¶æå–æ–‡æœ¬ä¿¡æ¯çš„åŠŸèƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œ\n",
    "æˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªåä¸ºtext_splitterçš„å±æ€§ï¼Œç”¨äºå­˜å‚¨æ–‡æœ¬åˆ†å‰²å™¨å¯¹è±¡ï¼›å®šä¹‰äº†ä¸€ä¸ªåä¸ºqa_chainçš„å±æ€§ï¼Œç”¨äºå­˜å‚¨qaé“¾å¯¹è±¡ï¼›å®ç°äº†runæ–¹æ³•å’Œå¼‚æ­¥runæ–¹\n",
    "æ³•ï¼Œåˆ†åˆ«ç”¨äºæ‰§è¡Œå…·ä½“ä»»åŠ¡çš„é€»è¾‘ã€‚åœ¨runæ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè°ƒç”¨browse_web_page.runæ–¹æ³•æµè§ˆç½‘é¡µå¹¶æå–æ–‡æœ¬ä¿¡æ¯ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æå–åˆ°çš„æ–‡æœ¬ä¿¡æ¯å­˜å‚¨\n",
    "åœ¨ä¸€ä¸ªDocumentå¯¹è±¡ä¸­ï¼Œå¹¶ä½¿ç”¨text_splitterå¯¹è±¡å¯¹å…¶è¿›è¡Œåˆ†å‰²ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨qa_chainå¯¹è±¡å¯¹åˆ†å‰²åçš„æ–‡æ¡£è¿›è¡Œå¤„ç†ï¼Œå¹¶è¿”å›ç»“æœã€‚åœ¨å¼‚æ­¥runæ–¹æ³•\n",
    "ä¸­ï¼Œæˆ‘ä»¬åŒæ ·è°ƒç”¨browse_web_page.runæ–¹æ³•æµè§ˆç½‘é¡µå¹¶æå–æ–‡æœ¬ä¿¡æ¯ã€‚ä½†æ˜¯ï¼Œç”±äºå¼‚æ­¥æ“ä½œéœ€è¦ç­‰å¾…ä»»åŠ¡å®Œæˆæ‰èƒ½ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥æ“ä½œï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦åœ¨å‡½\n",
    "æ•°ä¸­ä½¿ç”¨awaitå…³é”®å­—æ¥ç­‰å¾…ä»»åŠ¡çš„å®Œæˆã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç›®å‰åœ¨å¼‚æ­¥runæ–¹æ³•ä¸­è¿˜å­˜åœ¨ä¸€äº›æœªå®ç°çš„åŠŸèƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨å‡½æ•°æœ«å°¾ä½¿ç”¨äº†\n",
    "raise NotImplementedErrorè¯­å¥ï¼Œè¿™è¡¨ç¤ºå°šæœªå®ç°è¯¥æ–¹æ³•ã€‚å› æ­¤ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¦‚æœéœ€è¦ä½¿ç”¨å¼‚æ­¥runæ–¹æ³•ï¼Œåˆ™éœ€è¦å…ˆå®Œæˆæœªå®ç°çš„éƒ¨åˆ†ã€‚\n",
    "\"\"\"\n",
    "class WebpageQATool(BaseTool):\n",
    "    #å®šä¹‰ç±»åå’Œæè¿°ä¿¡æ¯\n",
    "    name = \"query_webpage\"\n",
    "    description = \"Browse a webpage and retrieve the information relevant to the question.\"\n",
    "    #å®šä¹‰ä¸€ä¸ªåä¸ºtext_splitterçš„å±æ€§ï¼Œç”¨äºå­˜å‚¨æ–‡æœ¬åˆ†å‰²å™¨å¯¹è±¡\n",
    "    text_splitter: RecursiveCharacterTextSplitter = Field(default_factory=_get_text_splitter)\n",
    "    #å®šä¹‰ä¸€ä¸ªåä¸ºqa_chainçš„å±æ€§ï¼Œç”¨äºå­˜å‚¨qaé“¾å¯¹è±¡\n",
    "    qa_chain: BaseCombineDocumentsChain\n",
    "\n",
    "    #å®ç°runæ–¹æ³•ï¼Œç”¨äºæ‰§è¡Œå…·ä½“ä»»åŠ¡çš„é€»è¾‘\n",
    "    def _run(self, url: str, question: str) -> str:\n",
    "        \"\"\"æµè§ˆç½‘ç«™å¹¶æå–æ–‡æœ¬ä¿¡æ¯\"\"\"\n",
    "        result = browse_web_page.run(url)\n",
    "        docs = [Document(page_content=result, metadata={\"source\": url})]\n",
    "        web_docs = self.text_splitter.split_documents(docs)\n",
    "        results = []\n",
    "        # TODO: å®ç°MapReduceChainçš„ç›¸å…³åŠŸèƒ½\n",
    "        for i in range(0, len(web_docs), 4):\n",
    "            input_docs = web_docs[i:i+4]\n",
    "            window_result = self.qa_chain({\"input_documents\": input_docs, \"question\": question}, return_only_outputs=True)\n",
    "            results.append(f\"Response from window {i} - {window_result}\")\n",
    "        results_docs = [Document(page_content=\"\\n\".join(results), metadata={\"source\": url})]\n",
    "        return self.qa_chain({\"input_documents\": results_docs, \"question\": question}, return_only_outputs=True)\n",
    "    \n",
    "    #å®ç°å¼‚æ­¥runæ–¹æ³•ï¼Œç”¨äºæ‰§è¡Œå…·ä½“ä»»åŠ¡çš„é€»è¾‘\n",
    "    async def _arun(self, url: str, question: str) -> str:\n",
    "        raise NotImplementedError\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_website_tool = WebpageQATool(qa_chain=load_qa_with_sources_chain(llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.tools.human.tool import HumanInputRun\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install duckduckgo_search\n",
    "web_search = DuckDuckGoSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    web_search,\n",
    "    WriteFileTool(root_dir=\"./data\"),\n",
    "    ReadFileTool(root_dir=\"./data\"),\n",
    "    process_csv,\n",
    "    query_website_tool,\n",
    "    # human_in_the_loop=True, # å¦‚æœè¦åœ¨æ¯ä¸ªæ­¥éª¤ä¸­æ·»åŠ åé¦ˆï¼Œè¯·å°†å…¶è®¾ç½®ä¸ºTrueã€‚\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"Tom\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=vectorstore.as_retriever(search_kwargs={\"k\": 8}),\n",
    "    # human_in_the_loop=True, # å¦‚æœè¦åœ¨æ¯ä¸ªæ­¥éª¤ä¸­æ·»åŠ åé¦ˆï¼Œè¯·å°†å…¶è®¾ç½®ä¸ºTrueã€‚\n",
    ")\n",
    "# agent.chain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run([\"What were the winning boston marathon times for the past 5 years (ending in 2022)? Generate a table of the year, name, country of origin, and times.\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ¹ ä¸Šè¿°å†…å®¹æ¥è‡ªäº[LangChainå®˜ç½‘æ•™ç¨‹](https://python.langchain.com/en/latest/index.html)å¹¶æœ‰é€‚å½“çš„æ›´æ”¹ï¼Œå¦‚æœ‰å•†ä¸šåŒ–ç­‰è¡Œä¸ºæˆ‘ä»¬ä¼šç‰¹åˆ«è¯´æ˜ã€‚è¯¥æ–‡æ¡£è¯·å‹¿éšæ„è½¬è½½ï¼Œå¦‚æœ‰ç›¸å…³å»ºè®®æˆ–è€…æ›´æ”¹éœ€æ±‚ï¼Œè¯·ä¸[æˆ‘ä»¬å–å¾—è”ç³»âœ‰ï¸](helloegoalpha@gmail.com)ï¼Œå†æ¬¡æ„Ÿè°¢ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
