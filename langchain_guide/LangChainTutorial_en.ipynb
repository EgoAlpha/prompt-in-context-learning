{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# üéá LangChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "How to create our own exclusive chatbot? How to learn domain-specific knowledge through simple manipulation of large language models (LLMs)? How to unleash more potential in daily workflow using LLMs?\n",
    ">Please imagine the following scenarios: you have several e-books or dozens of text files, or you complete specific tasks using a database. We want the LLMs model to learn the data provided by the user and only answer relevant questions within the given data range. If the question exceeds the scope, inform the user that the question is beyond the scope and cannot be answered. In other words, we want to restrict the LLMs model from freely expressing itself and prevent it from speaking casually. How can we accomplish the above tasks based on the large model? LangChain can help you achieve this. Click üëâ[here](https://python.langchain.com/en/latest/index.html)üëà to directly access the official documentation of LangChain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LangChain is an upper-level tool for large models, an application development framework based on LLMs that utilizes composability to build applications with LLMs. The emphasis is on \"composability\". It designs a series of interfaces that are easy to integrate into real-world applications, reducing the difficulty of deploying large language models in practical scenarios. LangChain can be used for chatbots, generative question answering (GQA), text summarization, and more.\n",
    "The goal of LangChain is:\n",
    "- Allowing large language models to handle data from different sources.\n",
    "- Enabling interaction between large language models and the environment in which they are deployed.\n",
    "\n",
    "<img src=\"./langchain.png\" align=center width=100% />\n",
    "\n",
    "As shown in the figure above, the LangChain library consists of six main components:\n",
    "- **Models**: Provides pre-packaged large models based on the OpenAI API, including common OpenAI models, and also supports custom encapsulation of large models.\n",
    "- **Prompt**: Supports rapid implementation of custom prompt projects and integration with LLMs.\n",
    "- **Index**: Accepts user queries and returns the most relevant content.\n",
    "- **Memory**: A standard interface for storing state between chains/calls.\n",
    "- **Chains**: A series of calls (LLMs or others, such as networks, operating systems). Chains provide standard interfaces and settings to combine these calls. Information is first obtained from external sources and then fed to LLMs. The large model sequentially executes logical chains for a series of tasks.\n",
    "- **Agents**: Agents play a crucial role in determining the actions to be taken with LLMs and how to perform them. Typically, capabilities in Utils and various logical chains in Chains are encapsulated as tools for intelligent invocation by Agents.\n",
    "\n",
    "üåü We will primarily focus on code explanations and demonstrations using the OpenAI provider. So let's begin this journey together! ‚úä"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìú ÊñáÊ°£ÁõÆÂΩïÁªìÊûÑ\n",
    "\n",
    "- [Before Start](#before-start)\n",
    "- [Models](#models)\n",
    "- [Prompt](#prompt)\n",
    "- [Index](#index)\n",
    "- [Memory](#memory)\n",
    "- [Chains](#chains)\n",
    "- [Agents](#agents)\n",
    "- [Coding Examples](#coding-exampls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Before Start\n",
    "\n",
    "ÁéØÂ¢ÉÈÖçÁΩÆÂíåÊ£ÄÊü•,ËÆæÁΩÆ‰ª£ÁêÜÊòØÈíàÂØπÂõΩÂÜÖÁî®Êà∑ÔºàÂè™ÈíàÂØπÂ§ßÈôÜÔºå‰∏çÊ∂âÂèäÈ¶ôÊ∏Ø„ÄÅÊæ≥Èó®ÂíåÂè∞ÊπæÂú∞Âå∫Ôºâ‰ΩøÁî®OpenAIÈúÄË¶ÅÊåÇËΩΩVPNÁöÑÈóÆÈ¢òÔºåÂõ†Ê≠§ÈúÄË¶ÅÊú¨Âú∞ËøêË°åÁ®ãÂ∫èËøõË°å‰ª£ÁêÜËÆæÁΩÆÔºå‰ªéËÄåÈÅøÂÖçÁΩëÁªúÂéüÂõ†ÂØºËá¥ÁöÑËÆøÈóÆÂíåË∞ÉÁî®ÈóÆÈ¢ò„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# ËÆæÁΩÆHTTP‰ª£ÁêÜÔºåÊú¨Âú∞IPÂú∞ÂùÄ‰ª•ÂèäÁ´ØÂè£Âè∑ÔºåÊü•ÁúãIPÂèØ‰ª•ÈÄöËøáWin/Linux‰∏ãÁöÑIPCONFIG/IFCONFIGÂëΩ‰ª§Êü•ÁúãÔºå‰πüÂèØ‰ª•Áõ¥Êé•ÈªòËÆ§ËÆæÁΩÆ‰∏∫127.0.0.1,Á´ØÂè£Ë¶ÅÂÜôÊåÇËΩΩVPNÁöÑÁ´ØÂè£Âè∑„ÄÇ\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:XXX'\n",
    "# ËÆæÁΩÆHTTPS‰ª£ÁêÜÔºåÂêå‰∏ä\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:XXX'\n",
    "\n",
    "#Ê£ÄÊü•‰ª£ÁêÜÊòØÂê¶ÊúâÁî®\n",
    "def check_proxy():\n",
    "    import urllib.request\n",
    "    url = \"https://www.google.com\"\n",
    "    # url = \"https://www.baidu.com\"\n",
    "    filename = \"google.html\"\n",
    "    urllib.request.urlretrieve(url, filename)#‰øùÂ≠òÂú®ÂΩìÂâçÊñá‰ª∂Â§π‰∏ã\n",
    "\n",
    "check_proxy()\n",
    "\n",
    "# openaiÁöÑkey\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Â°´‰∏ä‰Ω†Ëá™Â∑±ÁöÑopenai api  key\"\n",
    "\n",
    "#ÊêúÁ¥¢apiÁöÑkey,‰ªÖÂú®agent‰∏≠‰ΩøÁî®ÔºåËøôÊ≠•‰∏çÊòØÂøÖË¶ÅÁöÑ\n",
    "os.environ['SERPAPI_API_KEY']='Â°´‰∏ä‰Ω†Ëá™Â∑±ÁöÑserpapi api key'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ê£ÄÊü•Ë∞∑Ê≠åÊêúÁ¥¢APIÊòØÂê¶ËÉΩÁî®ÔºåËøô‰∏ÄÊ≠•ÊòØÈùûÂøÖË¶ÅÁöÑÂèØÈÄâÊ≠•È™§ÔºåÂ¶ÇÊûú‰Ω†Âú®‰∏ãÊñáÁöÑÁ§∫‰æã‰∏≠ÊúâÁî®Âà∞Ë∞∑Ê≠åÊêúÁ¥¢APIÁöÑÔºåÈÇ£Â∞±ÈúÄË¶ÅËøõË°åÁõ∏Â∫îÁöÑÊ≥®ÂÜåÊâçÂèØ‰ª•Ë∞ÉÁî®ËÆøÈóÆÔºåÊ≥®ÂÜåÁΩëÂùÄÁÇπÂáªüëâ[ËøôÈáå](https://serpapi.com/dashboard)üëà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'search_metadata': {'id': '643802169d158690e4963190', 'status': 'Success', 'json_endpoint': 'https://serpapi.com/searches/11aa25012aaee788/643802169d158690e4963190.json', 'created_at': '2023-04-13 13:22:30 UTC', 'processed_at': '2023-04-13 13:22:30 UTC', 'google_url': 'https://www.google.com/search?q=coffee&oq=coffee&uule=w+CAIQICIdQXVzdGluLFRYLFRleGFzLFVuaXRlZCBTdGF0ZXM&sourceid=chrome&ie=UTF-8', 'raw_html_file': 'https://serpapi.com/searches/11aa25012aaee788/643802169d158690e4963190.html', 'total_time_taken': 6.54}, 'search_parameters': {'engine': 'google', 'q': 'coffee', 'location_requested': 'Austin,Texas', 'location_used': 'Austin,TX,Texas,United States', 'google_domain': 'google.com', 'device': 'desktop'}, 'search_information': {'organic_results_state': 'Results for exact spelling', 'query_displayed': 'coffee', 'total_results': 4660000000, 'time_taken_displayed': 0.68, 'menu_items': [{'position': 1, 'title': 'Images', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAC', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&tbm=isch'}, {'position': 2, 'title': 'Maps', 'link': 'https://maps.google.com/maps?q=coffee&uule=w+CAIQICIdQXVzdGluLFRYLFRleGFzLFVuaXRlZCBTdGF0ZXM&um=1&ie=UTF-8&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAE'}, {'position': 3, 'title': 'Shopping', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=shop&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAG', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&tbm=shop'}, {'position': 4, 'title': 'Videos', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=vid&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAI', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&tbm=vid'}, {'position': 5, 'title': 'News', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=nws&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAK', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&tbm=nws'}, {'position': 6, 'title': 'Books', 'link': 'https://www.google.com/search?q=coffee&source=lnms&tbm=bks&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAM'}, {'position': 7, 'title': 'Flights', 'link': 'https://www.google.com/flights?q=coffee&source=lnms&tbm=flm&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAO'}, {'position': 8, 'title': 'Finance', 'link': 'https://www.google.com/finance?sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ0pQJegQIBRAQ'}]}, 'local_map': {'link': 'https://www.google.com/search?q=coffee&npsic=0&rflfq=1&rldoc=1&rllag=32070028,-99860352,38230&tbm=lcl&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQtgN6BAggEAE', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/2ceeb353df0a2b7dbacfb30245d6b608.png', 'gps_coordinates': {'latitude': 32.070028, 'longitude': -99.860352, 'altitude': 38230}}, 'local_results': {'places': [{'position': 1, 'title': 'Cup of Joe', 'rating': 4.6, 'reviews_original': '(28)', 'reviews': 28, 'type': 'Cafe', 'address': 'Winters, TX', 'description': '\"Great coffee at a good value\"', 'place_id': '6645020494937232090', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&ludocid=6645020494937232090&q=coffee', 'lsig': 'AB86z5WMhEZFuTAJ4GDnJFa6q6QI', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/0705f5877861a41dca5d37ea99dd97ef89f977fc0b365c8cf27ec04d7e618086c09b1b2ed1363660.jpeg', 'gps_coordinates': {'latitude': 31.957932, 'longitude': -99.96268}}, {'position': 2, 'title': 'The Coffee Haus on Main', 'rating': 4.8, 'reviews_original': '(36)', 'reviews': 36, 'type': 'Coffee shop', 'address': 'Ballinger, TX', 'place_id': '7920778704432590090', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&ludocid=7920778704432590090&q=coffee', 'lsig': 'AB86z5UZD5xj713sXU0khIy4IiH8', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/0705f5877861a41dca5d37ea99dd97ef0a78d9eb720337ce35a1440d44674901de89cb271256be32.jpeg', 'gps_coordinates': {'latitude': 31.737326, 'longitude': -99.94827}, 'service_options': {'dine_in': True, 'takeout': True, 'no_delivery': True}}, {'position': 3, 'title': 'Starbucks', 'rating': 4.1, 'reviews_original': '(899)', 'reviews': 899, 'price': '$$', 'type': 'Coffee shop', 'address': 'Abilene, TX', 'description': 'Iconic Seattle-based coffeehouse chain', 'place_id': '12667355487137518257', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&ludocid=12667355487137518257&q=coffee', 'lsig': 'AB86z5UP_UZ7Xmy5pKn1KyEN_jln', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/0705f5877861a41dca5d37ea99dd97efa22f666b4763d1bb8847ef0f5b7d937e6e1dbdec5b00b43d.jpeg', 'gps_coordinates': {'latitude': 32.40273, 'longitude': -99.75803}}], 'more_locations_link': 'https://www.google.com/search?tbs=lf:1,lf_ui:9&tbm=lcl&q=coffee&rflfq=1&num=10&uule=w+CAIQICIdQXVzdGluLFRYLFRleGFzLFVuaXRlZCBTdGF0ZXM&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQjGp6BAgjEAI'}, 'knowledge_graph': {'title': 'Coffee', 'type': 'Beverage', 'kgmid': '/m/02vqfm', 'knowledge_graph_search_link': 'https://www.google.com/search?kgmid=/m/02vqfm&hl=en-US&q=Coffee&kgs=b20ee92310a81805&shndl=0&source=sh/x/kp/1', 'serpapi_knowledge_graph_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&hl=en-US&kgmid=%2Fm%2F02vqfm&location=Austin%2CTexas&q=Coffee', 'header_images': [{'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199679b67c7e38cfee5d269be063747a036a99fba652bbfbf7afe.jpeg', 'source': 'https://en.wikipedia.org/wiki/Coffee'}, {'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199679b67c7e38cfee5d2494a19d1b8b89f6366a3aec97ea21ede.jpeg', 'source': 'https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/'}, {'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199679b67c7e38cfee5d2c856230e8a98377b70dca233c2119e9d.jpeg', 'source': 'https://www.rush.edu/news/health-benefits-coffee'}, {'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199679b67c7e38cfee5d255d27c8f4046047c96132e92d1c347c3.jpeg', 'source': 'https://www.healthline.com/nutrition/top-evidence-based-health-benefits-of-coffee'}, {'image': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTfWpPUDBL9AWrANOJSorna-dMqhtYRtK8VhPYgoFfF3g&s', 'source': 'https://www.tastingtable.com/794355/different-types-of-coffee-explained/'}], 'description': 'Coffee is a beverage prepared from roasted coffee beans. Darkly colored, bitter, and slightly acidic, coffee has a stimulating effect on humans, primarily due to its caffeine content. It has the highest sales in the world market for hot drinks.', 'source': {'name': 'Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Coffee'}, 'acidity_level': '4.85 to 5.10', 'acidity_level_links': [{'text': 'Acidity level', 'link': 'https://www.google.com/search?q=coffee+acidity+level&stick=H4sIAAAAAAAAAOPgE-LUz9U3MCorTMvVksjPttIvzsgvKklLTC6xSkzOTInPSS1LzVnEKpKcn5aWmqoAEsssqVQACwMA6FvyLz4AAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ6BMoAHoFCI8BEAI'}, {'text': 'healthline.com', 'link': 'https://www.healthline.com/nutrition/is-coffee-acidic'}], 'buttons': [{'text': 'Price', 'subtitle': 'Price Of Coffee', 'title': 'Two tablespoons', 'link': 'https://twochimpscoffee.com/guides/how-to-use-coffee-syrup/#:~:text=Two%20tablespoons%20(30ml%20or%20one,for%20a%20regular%20coffee%20cup.', 'displayed_link': 'https://twochimpscoffee.com ‚Ä∫ guides ‚Ä∫ how-to-use-coff...', 'snippet': \"Two tablespoons (30ml or one ounce) of syrup is a good go-to if you're wondering how much coffee syrup to put in coffee. This is for a regular coffee cup.\", 'snippet_highlighted_words': ['Two tablespoons (30ml or one ounce)'], 'answer': 'Two tablespoons', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199675fd122d14c827c9e3e8fed4a470f851e3e84adff4a23eb4f.png', 'search_link': 'https://www.google.com/search?q=price+of+coffee&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQrooIegUIjAEQBA', 'serpapi_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=price+of+coffee'}, {'text': 'Energy Amount', 'subtitle': 'How Many Calories In Coffee', 'table': [['Amount Per 1 fl oz (29.6 g)100 grams6 fl oz (178 g)1 cup (8 fl oz) (237 g)1 cup (8 fl oz) (237 g)'], ['Calories 1']], 'search_link': 'https://www.google.com/search?q=how+many+calories+in+coffee&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQrooIegUIjAEQCA', 'serpapi_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=how+many+calories+in+coffee'}, {'text': 'Protein Amount', 'subtitle': 'How Much Protein Is In Coffee', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQixTzjUfKnje6rtTLWUrleiMFyY4UusMCuTGsIgABnHjJ3&s', 'title': 'Protein Coffee: How it works & 8 benefits you should be aware of', 'link': 'https://healthcareweekly.com/protein-coffee-benefits/#:~:text=Is%20Coffee%20On%20Its%20Own,meaningful%2C%20to%20say%20the%20least.', 'displayed_link': 'https://healthcareweekly.com ‚Ä∫ protein-coffee-benefits', 'snippet': 'Is Coffee On Its Own a Good Source of Protein? The short answer: no, coffee is not a good source of protein. However, protein content depends on the type of coffee. For instance, one cup (about 6 fluid ounces) of black coffee contains approximately 0.21 grams of protein, which is not meaningful, to say the least.', 'snippet_highlighted_words': ['no, coffee is not a good source of protein'], 'search_link': 'https://www.google.com/search?q=how+much+protein+is+in+coffee&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQrooIegUIjAEQDg', 'serpapi_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=how+much+protein+is+in+coffee'}, {'text': 'Ph level', 'subtitle': 'Ph Of Coffee', 'title': 'about 5', 'link': 'https://byjus.com/question-answer/ph-of-black-coffee/#:~:text=Black%20coffee%20typically%20has%20a,beans%2C%20roasting%2C%20and%20brewing.', 'displayed_link': 'https://byjus.com ‚Ä∫ question-answer ‚Ä∫ ph-of-black-coffee', 'snippet': 'Black coffee typically has a pH of about 5 and is thus slightly acidic. It is acidic, with pH between 4 and 5, depending on the beans, roasting, and brewing.', 'snippet_highlighted_words': ['about 5'], 'answer': 'about 5', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba7199675fd122d14c827c9ec36fd87acab3f7ae25c98ca17a4aace0.png', 'search_link': 'https://www.google.com/search?q=ph+of+coffee&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQrooIegUIjAEQEg', 'serpapi_search_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=ph+of+coffee'}], 'compounds_in_coffee': [{'name': 'Chlorogenic acid', 'link': 'https://www.google.com/search?q=Chlorogenic+acid&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwL87IiddiWMQq4JyRk1-Un56al5mskJicmbKDlREA-TI5fCcAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiIARAF', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Chlorogenic+acid&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwL87IiddiWMQq4JyRk1-Un56al5mskJicmbKDlREA-TI5fCcAAAA', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967401e973bf2272dfc16e2c8cfafa7c4cc39c553489d2631b66274c812e7446727.png'}, {'name': 'Quinic acid', 'link': 'https://www.google.com/search?q=Quinic+acid&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwL042tdBiWMTKHViamZeZrJCYnJmyg5URAI7HIvkiAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiIARAH', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Quinic+acid&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwL042tdBiWMTKHViamZeZrJCYnJmyg5URAI7HIvkiAAAA', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967401e973bf2272dfc16e2c8cfafa7c4cc2362001c04c2f1d2044b09e83d185675.png'}, {'name': 'Trigonelline', 'link': 'https://www.google.com/search?q=Trigonelline&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwrTKojNdiWMTKE1KUmZ6fl5qTk5mXuoOVEQBGl_DeIwAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiIARAJ', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Trigonelline&stick=H4sIAAAAAAAAAONgFmJQ4tTP1TcwrTKojNdiWMTKE1KUmZ6fl5qTk5mXuoOVEQBGl_DeIwAAAA', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967401e973bf2272dfc16e2c8cfafa7c4cc8a99acca8218dd6ae69d6e62b343a898.png'}, {'name': 'Melanoidin', 'link': 'https://www.google.com/search?q=Melanoidin&stick=H4sIAAAAAAAAAONgFmJQ4tLP1TcwKso2M8zQYljEyuWbmpOYl5-Zkpm3g5URAEiv4kMiAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiIARAL', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Melanoidin&stick=H4sIAAAAAAAAAONgFmJQ4tLP1TcwKso2M8zQYljEyuWbmpOYl5-Zkpm3g5URAEiv4kMiAAAA', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967401e973bf2272dfc16e2c8cfafa7c4ccfcc2b1e8a30cf831eff946b2458c1940.png'}], 'compounds_in_coffee_link': 'https://www.google.com/search?q=compounds+in+coffee&stick=H4sIAAAAAAAAAONgFuLUz9U3MCorTMtVQjC1RLKTrfST83Nz8_OsUvLL88oTi1KKVzEKOmek5mYmJ-Y45-cW5JfmpRQvYhVOhrEVMvMUkvPT0lJTd7AyAgA94efZWwAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQMSgAegUIiAEQAQ', 'compounds_in_coffee_stick': 'H4sIAAAAAAAAAONgFuLUz9U3MCorTMtVQjC1RLKTrfST83Nz8_OsUvLL88oTi1KKVzEKOmek5mYmJ-Y45-cW5JfmpRQvYhVOhrEVMvMUkvPT0lJTd7AyAgA94efZWwAAAA', 'people_also_search_for': [{'name': 'Tea', 'link': 'https://www.google.com/search?q=Tea&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMgjPPDr-bVSwS7IwMGJZrTdb97oset9qkWSGGc8Wrx0cWPU0xfD2y8UwLcWHQST1bjafkmRjiQwYRe_3Itgz9qVSCKdZzbGbuLy9QXEb0Z8fNkExbIqMPt_n-TOdD4t0ZhyGHDkRXkCD3stHPYlkI9F6NqruSkOP8q19qSCJwA-F-iIzZCw4sk6NwHFknXQGz29sgmuriUCUg3JKKEr9yO6rD_j0gO7sFpA_vyMkVnlD2E-eVQ%3D%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiJARAF', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Tea&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMgjPPDr-bVSwS7IwMGJZrTdb97oset9qkWSGGc8Wrx0cWPU0xfD2y8UwLcWHQST1bjafkmRjiQwYRe_3Itgz9qVSCKdZzbGbuLy9QXEb0Z8fNkExbIqMPt_n-TOdD4t0ZhyGHDkRXkCD3stHPYlkI9F6NqruSkOP8q19qSCJwA-F-iIzZCw4sk6NwHFknXQGz29sgmuriUCUg3JKKEr9yO6rD_j0gO7sFpA_vyMkVnlD2E-eVQ%3D%3D', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967e72d5e765855f08c845d5d1bff276fdeeaa0922bc08dd464936d4e065df28d61.jpeg'}, {'name': 'Espresso', 'link': 'https://www.google.com/search?q=Espresso&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMjyaN62njrr4Y2vVD-0W98vYZcIInyX3v-g5zZZpHjjG-Poxv3XLD0drTfOgpVcCf-zFRIPvsy9oT9UP_w35iIRi9Dl7PJ4-ldCIJDe667xhyIl72gjAFfOKZBu3XGinHDe096zuvjykLeb_xXU3DhU-1QmnhQUqLZaEFgHJmWWQuA0wE2cEjLHtjh10JWDgzqQv2KOWtaNv-dvOLwEiFloEH3I1N1rrm0NY4CZcMZcqugn660gEsBi5JGVH9mmfP4wv-CI%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiJARAH', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Espresso&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMjyaN62njrr4Y2vVD-0W98vYZcIInyX3v-g5zZZpHjjG-Poxv3XLD0drTfOgpVcCf-zFRIPvsy9oT9UP_w35iIRi9Dl7PJ4-ldCIJDe667xhyIl72gjAFfOKZBu3XGinHDe096zuvjykLeb_xXU3DhU-1QmnhQUqLZaEFgHJmWWQuA0wE2cEjLHtjh10JWDgzqQv2KOWtaNv-dvOLwEiFloEH3I1N1rrm0NY4CZcMZcqugn660gEsBi5JGVH9mmfP4wv-CI%3D', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967e72d5e765855f08c845d5d1bff276fde5336e38b7da39c82f50576790ba2d2e1.jpeg'}, {'name': 'Cappuccino', 'link': 'https://www.google.com/search?q=Cappuccino&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMklZ6vtN6-8AY4RsUb9j1aMcn5_Fx0RVtguKTSjYOzJGH7WEnPl_82g6G4ZmQ47a0aQn5OaDfWitFqB1UyoD-3DPX9OrIzCD9nADAxnBhkOFxJrA8pSHWbkRwBQLlUjMBh218i1GQwoy1lyiRUKtITtVX99LqKB4Vnw74JG_9e88ZJr1WoMkOQoqE67xGs1BZHT4Q8YggMDNYAvtEZClZcNRxN3i715e-oP_ZO0WK7VtSx7RbP8PO9dSe9qaWJAVAfAFW7k%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiJARAJ', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Cappuccino&si=AMnBZoFk_ppfOKgdccwTD_PVhdkg37dbl-p8zEtOPijkCaIHMklZ6vtN6-8AY4RsUb9j1aMcn5_Fx0RVtguKTSjYOzJGH7WEnPl_82g6G4ZmQ47a0aQn5OaDfWitFqB1UyoD-3DPX9OrIzCD9nADAxnBhkOFxJrA8pSHWbkRwBQLlUjMBh218i1GQwoy1lyiRUKtITtVX99LqKB4Vnw74JG_9e88ZJr1WoMkOQoqE67xGs1BZHT4Q8YggMDNYAvtEZClZcNRxN3i715e-oP_ZO0WK7VtSx7RbP8PO9dSe9qaWJAVAfAFW7k%3D', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967e72d5e765855f08c845d5d1bff276fde30bbff2f88cf8f3a124c859ded15a3a2.jpeg'}, {'name': 'Latte', 'link': 'https://www.google.com/search?q=Latte&si=AMnBZoEofOODruSEFWFjdccePwMH96ZlZt3bOiKSR9t4pqlu2E2Y95jVypGw5nHfEGbzdy_B-mJrk7TV3R0_l7ZUBiUkk1BiloRi17mH8ufqGqbkUhe0c8_KO5vzQNZ-nrEeAaA8my_qJpcAz8qE92rIWhWLdi2-Y-wRjvz59t6q5db5z6-tVBvk31oUge5WvKN_KY-abBJwuAmRcDVTFFkzJExr2ij50aEqL8xoQy48LtRLUoNcARf8G9RPDtEL8wYJDyK5-OlqfXP74-MHX3KmEH_oT5JEeAsCl9zNCisFeyvLawCXTaY%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQxA16BQiJARAL', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=Latte&si=AMnBZoEofOODruSEFWFjdccePwMH96ZlZt3bOiKSR9t4pqlu2E2Y95jVypGw5nHfEGbzdy_B-mJrk7TV3R0_l7ZUBiUkk1BiloRi17mH8ufqGqbkUhe0c8_KO5vzQNZ-nrEeAaA8my_qJpcAz8qE92rIWhWLdi2-Y-wRjvz59t6q5db5z6-tVBvk31oUge5WvKN_KY-abBJwuAmRcDVTFFkzJExr2ij50aEqL8xoQy48LtRLUoNcARf8G9RPDtEL8wYJDyK5-OlqfXP74-MHX3KmEH_oT5JEeAsCl9zNCisFeyvLawCXTaY%3D', 'image': 'https://serpapi.com/searches/643802169d158690e4963190/images/56f3044ba4f6836a67196996ba719967e72d5e765855f08c845d5d1bff276fde3abe05036e61cb692c62b7db1ef7bd3f.jpeg'}], 'people_also_search_for_link': 'https://www.google.com/search?q=Coffee&stick=H4sIAAAAAAAAAONgFuLUz9U3MCorTMtVQjC1BIMzU1LLEyuL_VIrSoJLUguKF7GyOeenpaWm7mBlBABkIv_mNwAAAA&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQMSgAegUIiQEQAQ', 'people_also_search_for_stick': 'H4sIAAAAAAAAAONgFuLUz9U3MCorTMtVQjC1BIMzU1LLEyuL_VIrSoJLUguKF7GyOeenpaWm7mBlBABkIv_mNwAAAA', 'see_results_about': [{'name': 'Coffee bean', 'extensions': ['A coffee bean is a seed of the Coffea plant and the source for ...'], 'link': 'https://www.google.com/search?q=Coffee+bean&si=AMnBZoGn39e0tI_t2dCPKQ2j8QBKDHso0GZnCtfIMxO7bEcZSZ7sNGHzwtf8qdnwn3tXQ0AGsm2Ng73UcXfebGimZRXPLuphz7aw2b9GplBsHHhxGd0xEKJ8XvF1_wM5SNp0hs8oNfrzJQdeFjaOKy4f1Y1HsVo-vZbsVBt1pibEO5fKPf-Urjg%3D&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ6RN6BAhlEAE', 'image': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQlwgD-6s3Vk872C9OaOBm_9QUtkchzWBoJWCdLswp_BSHUV8pNHndshQ&s=0'}], 'list': {'total_fat': ['0 g', '0%'], 'saturated_fat': ['0 g', '0%'], 'trans_fat_regulation': ['0 g'], 'cholesterol': ['0 mg', '0%'], 'sodium': ['5 mg', '0%'], 'potassium': ['116 mg', '3%'], 'total_carbohydrate': ['0 g', '0%'], 'dietary_fiber': ['0 g', '0%'], 'sugar': ['0 g'], 'protein': ['0.3 g', '0%'], 'caffeine': ['95 mg'], 'vitamin_c': ['0%'], 'calcium': ['0%'], 'iron': ['0%'], 'vitamin_d': ['0%'], 'vitamin_b6': ['0%'], 'cobalamin': ['0%'], 'magnesium': ['1%']}}, 'inline_images': [{'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C%252Fm%252F02vqfm%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kSeRZX4tRmBDC5WzqJ72knpK80xKw&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_B16BQiGARAB#imgrc=cHhAmJrw8EtbWM', 'source': 'https://en.wikipedia.org/wiki/Coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/9965b78b2d80b21d3f5db41f337bfeec902227f017d9dd1735e3765fd889c51e.jpeg', 'original': 'https://upload.wikimedia.org/wikipedia/commons/e/e4/Latte_and_dark_coffee.jpg', 'title': 'upload.wikimedia.org/wikipedia/commons/e/e4/Latte_...', 'source_name': 'en.wikipedia.org'}, {'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C_%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kQVRu5edShja3G23xcn5YB3AJ_0Lg&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_h16BQiHARAB#imgrc=9M1X2EDxsYNTZM', 'source': 'https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/9965b78b2d80b21d094f8ec1d3c2855e858ac1ef5bb628283bdffe67e0109546.jpeg', 'original': 'https://www.tastingtable.com/img/gallery/coffee-brands-ranked-from-worst-to-best/l-intro-1645231221.jpg', 'title': '31 Coffee Brands, Ranked From Worst To Best', 'source_name': 'Tasting Table'}, {'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C_%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kQVRu5edShja3G23xcn5YB3AJ_0Lg&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_h16BQiFARAB#imgrc=35LBrLe6iLMgNM', 'source': 'https://www.rush.edu/news/health-benefits-coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/9965b78b2d80b21d295a96d9e9320dc43b3ec3c1d728d8e2afa4eb919701e379.jpeg', 'original': 'https://www.rush.edu/sites/default/files/styles/386x217/public/media-images/Coffee_WebFeature.png?itok=gxteJ01c', 'title': 'Health Benefits of Coffee | Rush System', 'source_name': 'Rush University Medical Center'}, {'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C_%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kQVRu5edShja3G23xcn5YB3AJ_0Lg&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_h16BQiEARAB#imgrc=Ye55hwurmsyIDM', 'source': 'https://www.healthline.com/nutrition/top-evidence-based-health-benefits-of-coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/9965b78b2d80b21dc4a259fd912f9bcc346c5506f77fea62694c644a3ab00fa5.jpeg', 'original': 'https://post.healthline.com/wp-content/uploads/2020/08/coffee-worlds-biggest-source-of-antioxidants-1296x728-feature_0-732x549.jpg', 'title': '9 Health Benefits of Coffee, Based on Science', 'source_name': 'Healthline'}, {'link': 'https://www.google.com/search?q=coffee&tbm=isch&source=iu&ictx=1&vet=1&fir=cHhAmJrw8EtbWM%252CU6oJMnF-eeVTAM%252C_%253B9M1X2EDxsYNTZM%252CO0p2m8H_t7E6nM%252C_%253B35LBrLe6iLMgNM%252CLe_shlToZ2_z7M%252C_%253BYe55hwurmsyIDM%252Cr1UW6FGz3F41UM%252C_%253Be1xARNWS4v0NdM%252CxWwjaFHTd_fBIM%252C_&usg=AI4_-kQVRu5edShja3G23xcn5YB3AJ_0Lg&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ_h16BQiDARAB#imgrc=e1xARNWS4v0NdM', 'source': 'https://www.tastingtable.com/794355/different-types-of-coffee-explained/', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTfWpPUDBL9AWrANOJSorna-dMqhtYRtK8VhPYgoFfF3g&s', 'original': 'https://www.tastingtable.com/img/gallery/20-different-types-of-coffee-explained/l-intro-1659544996.jpg', 'title': '35 Different Types Of Coffee Explained', 'source_name': 'Tasting Table'}], 'related_questions': [{'question': 'Is coffee good for health?', 'snippet': \"‚ÄúFor most people, moderate coffee consumption can be incorporated into a healthy diet.‚Äù Hu said that moderate coffee intake‚Äîabout 2‚Äì5 cups a day‚Äîis linked to a lower likelihood of type 2 diabetes, heart disease, liver and endometrial cancers, Parkinson's disease, and depression.\", 'title': 'Is coffee good or bad for your health? | News', 'link': 'https://www.hsph.harvard.edu/news/hsph-in-the-news/is-coffee-good-or-bad-for-your-health/', 'displayed_link': 'https://www.hsph.harvard.edu ‚Ä∫ news ‚Ä∫ hsph-in-the-news', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/581680f060c7d368510705ded46f2c9ed01360eca462a179580c31dd0f6541e0.png', 'next_page_token': 'eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiSXMgY29mZmVlIGdvb2QgZm9yIGhlYWx0aD8iLCJsayI6IkdoNWtiMlZ6SUdOdlptWmxaU0JwY3lCbmIyOWtJR1p2Y2lCb1pXRnNkR2ciLCJicyI6ImMtT1M1NUx5TEZaSXprOUxTMDFWU01fUFQxRkl5eTlTeUVoTnpDbkpzSmU0WThDbHdDVWRucEdabktHUVZKU1lsd0pUbVZtc2tKUmFYR0l2TWR1UVM0VkxQandqc1VRaHNTaFZvU1FqVmNGRW9hU3lJTFZZSVQ4TnF0cGU0ZzA3bHlxWEFvcXFwTlM4MUxUTUVoUmxtLVVFR0FFIiwiaWQiOiJmY18xIn0=', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google_related_questions&google_domain=google.com&next_page_token=eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiSXMgY29mZmVlIGdvb2QgZm9yIGhlYWx0aD8iLCJsayI6IkdoNWtiMlZ6SUdOdlptWmxaU0JwY3lCbmIyOWtJR1p2Y2lCb1pXRnNkR2ciLCJicyI6ImMtT1M1NUx5TEZaSXprOUxTMDFWU01fUFQxRkl5eTlTeUVoTnpDbkpzSmU0WThDbHdDVWRucEdabktHUVZKU1lsd0pUbVZtc2tKUmFYR0l2TWR1UVM0VkxQandqc1VRaHNTaFZvU1FqVmNGRW9hU3lJTFZZSVQ4TnF0cGU0ZzA3bHlxWEFvcXFwTlM4MUxUTUVoUmxtLVVFR0FFIiwiaWQiOiJmY18xIn0%3D'}, {'question': 'Which brand coffee is best?', 'title': 'List of Top 11 Coffee Brands in India', 'link': 'https://cashkaro.com/blog/best-coffee-brands/167279', 'list': ['Nescafe.', 'Rage Coffee.', 'Bru.', 'Davidoff.', 'Blue Tokai.', 'Starbucks.', 'Continental Coffee.', 'Country Bean.'], 'displayed_link': 'https://cashkaro.com ‚Ä∫ blog ‚Ä∫ best-coffee-brands', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT4WFZ6iwvyFQiZ2wM5iLAEmFEfdSqje27fd4amMxSsFQ&s', 'next_page_token': 'eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hpY2ggYnJhbmQgY29mZmVlIGlzIGJlc3Q/IiwibGsiOiJHaHAzYUdsamFDQmljbUZ1WkNCamIyWm1aV1VnYVhNZ1ltVnpkQSIsImJzIjoiYy1PUzU1THlMRlpJems5TFMwMVZTTV9QVDFGSXl5OVN5RWhOekNuSnNKZTRZOENsd0NVZG5wR1puS0dRVkpTWWx3SlRtVm1za0pSYVhHSXZNZHVRUzRWTFBqd2pzVVFoc1NoVm9TUWpWY0ZFb2FTeUlMVllJVDhOcXRwZTRnMDdseXFYQW9xcXBOUzgxTFRNRWhSbG0tVUVHQUUiLCJpZCI6ImZjXzEifQ==', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google_related_questions&google_domain=google.com&next_page_token=eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hpY2ggYnJhbmQgY29mZmVlIGlzIGJlc3Q%2FIiwibGsiOiJHaHAzYUdsamFDQmljbUZ1WkNCamIyWm1aV1VnYVhNZ1ltVnpkQSIsImJzIjoiYy1PUzU1THlMRlpJems5TFMwMVZTTV9QVDFGSXl5OVN5RWhOekNuSnNKZTRZOENsd0NVZG5wR1puS0dRVkpTWWx3SlRtVm1za0pSYVhHSXZNZHVRUzRWTFBqd2pzVVFoc1NoVm9TUWpWY0ZFb2FTeUlMVllJVDhOcXRwZTRnMDdseXFYQW9xcXBOUzgxTFRNRWhSbG0tVUVHQUUiLCJpZCI6ImZjXzEifQ%3D%3D'}, {'question': 'What are the 4 types of coffee?', 'snippet': 'There are 4 types of coffee bean. Arabica, Robusta, Excelsa and Liberica.', 'title': 'Coffee beans guide: Origin & different types | NESCAF√â MENA', 'link': 'https://www.nescafe.com/mena/en-ae/understanding-coffee/coffee-beans-guide', 'displayed_link': 'https://www.nescafe.com ‚Ä∫ en-ae ‚Ä∫ understanding-coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/581680f060c7d368510705ded46f2c9ec6ef6e60144d6ff6bcfe79a9b6526622.png', 'next_page_token': 'eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hhdCBhcmUgdGhlIDQgdHlwZXMgb2YgY29mZmVlPyIsImxrIjoiR2g1M2FHRjBJR0Z5WlNCMGFHVWdOQ0IwZVhCbGN5QnZaaUJqYjJabVpXVSIsImJzIjoiYy1PUzU1THlMRlpJems5TFMwMVZTTV9QVDFGSXl5OVN5RWhOekNuSnNKZTRZOENsd0NVZG5wR1puS0dRVkpTWWx3SlRtVm1za0pSYVhHSXZNZHVRUzRWTFBqd2pzVVFoc1NoVm9TUWpWY0ZFb2FTeUlMVllJVDhOcXRwZTRnMDdseXFYQW9xcXBOUzgxTFRNRWhSbG0tVUVHQUUiLCJpZCI6ImZjXzEifQ==', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google_related_questions&google_domain=google.com&next_page_token=eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hhdCBhcmUgdGhlIDQgdHlwZXMgb2YgY29mZmVlPyIsImxrIjoiR2g1M2FHRjBJR0Z5WlNCMGFHVWdOQ0IwZVhCbGN5QnZaaUJqYjJabVpXVSIsImJzIjoiYy1PUzU1THlMRlpJems5TFMwMVZTTV9QVDFGSXl5OVN5RWhOekNuSnNKZTRZOENsd0NVZG5wR1puS0dRVkpTWWx3SlRtVm1za0pSYVhHSXZNZHVRUzRWTFBqd2pzVVFoc1NoVm9TUWpWY0ZFb2FTeUlMVllJVDhOcXRwZTRnMDdseXFYQW9xcXBOUzgxTFRNRWhSbG0tVUVHQUUiLCJpZCI6ImZjXzEifQ%3D%3D'}, {'question': 'What are the benefits of coffee?', 'title': 'Here are the top ways coffee can positively impact your health:', 'link': 'https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you', 'list': ['You could live longer. ... ', 'Your body may process glucose (or sugar) better. ... ', \"You're less likely to develop heart failure. ... \", \"You are less likely to develop Parkinson's disease. ... \", 'Your liver will thank you. ... ', 'Your DNA will be stronger.'], 'displayed_link': 'https://www.hopkinsmedicine.org ‚Ä∫ health ‚Ä∫ 9-reasons...', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSDV1_KHRKIUNXbIJYeb7G3jkEJsXv-MlZnSnAT4Qh-iw&s', 'next_page_token': 'eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hhdCBhcmUgdGhlIGJlbmVmaXRzIG9mIGNvZmZlZT8iLCJsayI6IkdoOTNhR0YwSUdGeVpTQjBhR1VnWW1WdVpXWnBkSE1nYjJZZ1kyOW1abVZsIiwiYnMiOiJjLU9TNTVMeUxGWkl6azlMUzAxVlNNX1BUMUZJeXk5U3lFaE56Q25Kc0plNFk4Q2x3Q1VkbnBHWm5LR1FWSlNZbHdKVG1WbXNrSlJhWEdJdk1kdVFTNFZMUGp3anNVUWhzU2hWb1NRalZjRkVvYVN5SUxWWUlUOE5xdHBlNGcwN2x5cVhBb3FxcE5TODFMVE1FaFJsbS1VRUdBRSIsImlkIjoiZmNfMSJ9', 'serpapi_link': 'https://serpapi.com/search.json?device=desktop&engine=google_related_questions&google_domain=google.com&next_page_token=eyJvbnMiOiIxMDA0MSIsImZjIjoiRW9zQkNreEJSWE0zYWs1UlIwTldTVTVvTTJ3NWJHMVRibXQzZEVod1JuZFdabEpMWm5ObExXSnNPSFZrYjJwbldFOHdMVXRmZG1OeVRFMWlWa3BPTlVSTWFtcGxMV3hRTkc0eVVtbHBMVTl4RWhkSGQwazBXazVITTBjMUxXRndkRkZRTW1ReU1uVkJSUm9pUVU4dE1ISnNOVzVIT0dKaWRWcEhRelJmVm1KVk0yRmlYekYwU1hSRE5teHdkdyIsImZjdiI6IjMiLCJlaSI6Ikd3STRaTkczRzUtYXB0UVAyZDIydUFFIiwicWMiOiJDZ1pqYjJabVpXVVFBSDFSTkMwXyIsInF1ZXN0aW9uIjoiV2hhdCBhcmUgdGhlIGJlbmVmaXRzIG9mIGNvZmZlZT8iLCJsayI6IkdoOTNhR0YwSUdGeVpTQjBhR1VnWW1WdVpXWnBkSE1nYjJZZ1kyOW1abVZsIiwiYnMiOiJjLU9TNTVMeUxGWkl6azlMUzAxVlNNX1BUMUZJeXk5U3lFaE56Q25Kc0plNFk4Q2x3Q1VkbnBHWm5LR1FWSlNZbHdKVG1WbXNrSlJhWEdJdk1kdVFTNFZMUGp3anNVUWhzU2hWb1NRalZjRkVvYVN5SUxWWUlUOE5xdHBlNGcwN2x5cVhBb3FxcE5TODFMVE1FaFJsbS1VRUdBRSIsImlkIjoiZmNfMSJ9'}], 'organic_results': [{'position': 1, 'title': 'Coffee', 'link': 'https://en.wikipedia.org/wiki/Coffee', 'displayed_link': 'https://en.wikipedia.org ‚Ä∫ wiki ‚Ä∫ Coffee', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370235e3abd98c1947069c6e9748089046bd.jpeg', 'snippet': 'Coffee is a beverage prepared from roasted coffee beans. Darkly colored, bitter, and slightly acidic, coffee has a stimulating effect on humans, ...', 'snippet_highlighted_words': ['Coffee', 'coffee', 'coffee'], 'sitelinks': {'inline': [{'title': 'List of countries by coffee...', 'link': 'https://en.wikipedia.org/wiki/List_of_countries_by_coffee_production'}, {'title': 'Coffee production', 'link': 'https://en.wikipedia.org/wiki/Coffee_production'}, {'title': 'Coffee preparation', 'link': 'https://en.wikipedia.org/wiki/Coffee_preparation'}, {'title': 'Brewed coffee', 'link': 'https://en.wikipedia.org/wiki/Brewed_coffee'}]}, 'rich_snippet': {'bottom': {'extensions': ['Region of origin: Kaffa in Horn of Africa\\u200e', 'Ingredients: Roasted coffee beans', 'Introduced: 15th century', 'Flavor: Distinctive, somewhat bitter'], 'detected_extensions': {'introduced_th_century': 15}}}, 'about_this_result': {'source': {'description': 'Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.', 'source_info_link': 'https://en.wikipedia.org/wiki/Coffee', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a413702aa62bef54786db18713ef6486dccfb265a7385357ccdd522556c3f303ed26557.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://en.wikipedia.org/wiki/Coffee&tbm=ilp&ilps=ADJL0izANxNmAZazzpMAeGlkd2tXrw-aIQ', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0izANxNmAZazzpMAeGlkd2tXrw-aIQ&q=About+https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FCoffee', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:U6oJMnF-eeUJ:https://en.wikipedia.org/wiki/Coffee&cd=33&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://en.wikipedia.org/wiki/Coffee+coffee'}, {'position': 2, 'title': 'The Coffee Bean & Tea Leaf | CBTL', 'link': 'https://www.coffeebean.com/', 'displayed_link': 'https://www.coffeebean.com', 'snippet': 'Born and brewed in Southern California since 1963, The Coffee Bean & Tea Leaf¬Æ is passionate about connecting loyal customers with carefully handcrafted ...', 'snippet_highlighted_words': ['Coffee'], 'about_this_result': {'source': {'description': 'The Coffee Bean & Tea Leaf is an American coffee shop chain founded in 1963. Since 2019, it is a trade name of Ireland-based Super Magnificent Coffee Company Ireland Limited. Its 80% stake is by multinational company Jollibee Foods Corporation.', 'source_info_link': 'https://www.coffeebean.com/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370236dec1b6bf726a3914d6a9d5028d25c59578b20700b175de3b92316a2e9db711.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.coffeebean.com/&tbm=ilp&ilps=ADJL0iyEMfWcc_F0sQp68evlFpMNONzA7w', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iyEMfWcc_F0sQp68evlFpMNONzA7w&q=About+https%3A%2F%2Fwww.coffeebean.com%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:WpQxSYo2c6AJ:https://www.coffeebean.com/&cd=34&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://www.coffeebean.com/+coffee'}, {'position': 3, 'title': 'What is Coffee?', 'link': 'https://www.ncausa.org/About-Coffee/What-is-Coffee', 'displayed_link': 'https://www.ncausa.org ‚Ä∫ About Coffee', 'snippet': 'cof¬∑fee /Ààk√¥fƒì,Ààk√§fƒì/ noun The berries harvested from species of Coffea plants. Everyone recognizes a roasted coffee bean, but you might not recognize an actual ...', 'snippet_highlighted_words': ['coffee'], 'about_this_result': {'source': {'description': 'The National Coffee Association or, is the main market research, consumer information, and lobbying association for the coffee industry in the United States.', 'source_info_link': 'https://www.ncausa.org/About-Coffee/What-is-Coffee', 'security': 'secure'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.ncausa.org/About-Coffee/What-is-Coffee&tbm=ilp&ilps=ADJL0ixxUUvfx6Ju5WRyyjiP05--z_0mTg', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0ixxUUvfx6Ju5WRyyjiP05--z_0mTg&q=About+https%3A%2F%2Fwww.ncausa.org%2FAbout-Coffee%2FWhat-is-Coffee', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:ENqpL6s3VPIJ:https://www.ncausa.org/About-Coffee/What-is-Coffee&cd=35&hl=en&ct=clnk&gl=us'}, {'position': 4, 'title': 'Coffee | Origin, Types, Uses, History, & Facts', 'link': 'https://www.britannica.com/topic/coffee', 'displayed_link': 'https://www.britannica.com ‚Ä∫ ... ‚Ä∫ Food', 'thumbnail': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a413702cdf1deddb67d451859d5294688e08a58.jpeg', 'date': 'Mar 22, 2023', 'snippet': 'coffee, beverage brewed from the roasted and ground seeds of the tropical evergreen coffee plants of African origin. Coffee is one of the ...', 'snippet_highlighted_words': ['coffee', 'coffee', 'Coffee'], 'rich_snippet': {'bottom': {'questions': ['What is coffee?', 'Where did coffee originate?']}}, 'about_this_result': {'source': {'description': 'britannica.com was first indexed by Google more than 10 years ago', 'source_info_link': 'https://www.britannica.com/topic/coffee', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a413702c76d8a9622e3a3b5b18646a9438a950d1c3d93c649733c1e50bf8159b64d21a1.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.britannica.com/topic/coffee&tbm=ilp&ilps=ADJL0ixB8MrWhyEfLpjZI0CfZRgB9XA7wQ', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0ixB8MrWhyEfLpjZI0CfZRgB9XA7wQ&q=About+https%3A%2F%2Fwww.britannica.com%2Ftopic%2Fcoffee', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:Wikbu4ipU28J:https://www.britannica.com/topic/coffee&cd=36&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://www.britannica.com/topic/coffee+coffee'}, {'position': 5, 'title': 'Coffee', 'link': 'https://www.amazon.com/coffee/s?k=coffee', 'displayed_link': 'https://www.amazon.com ‚Ä∫ coffee ‚Ä∫ k=coffee', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTX9ofuNsZqYoWn7Q955M3hXmXDY5UnwxG3LEpCMlpVyuH9d6XEpGSFfSRSoU-2AgxkvTs&s', 'snippet': \"The Original Donut Shop Regular, Single-Serve Keurig K-Cup Pods, Medium Roast Coffee Pods, 24 Count (Pack of 4) ... Chock Full o'Nuts Original Roast Ground Coffee ...\", 'snippet_highlighted_words': ['Coffee', 'Coffee'], 'images': ['https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTX9ofuNsZqYoWn7Q955M3hXmXDY5UnwxG3LEpCMlpVyuH9d6XEpGSFfSRSoU-2AgxkvTs&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQHRrxTFVWH2fwyGJIwUzVkOHtqToQPGSVY3-Okffd-S2Ynzx5Cl2KTnrUunIMysfWPsns&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTPMicqxvC9FsqHIU5UmLz_gtZf2_VEsz2z7KeOGarDH639rrLKOTlOHCCpe-HiSbOFM5o&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS2fO2Mak3Y7USbiGvN4UdFgZXDn0DouDuRMgyUfPr29ANmsZGDk_zgeU_wsP6-E_9vN4c&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQZvUs5K8EeSa2U1SEwUNglwDYsb0NvxL8ZSyIHcghiIHx3o1byE_rBSzg31CuZnG-szA&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR1Qee1OmG2Yu9yS9AUYwfwAEzKH6oyYeSIqESDOSTidszlgdJOUezTH6OiszoBD5aZGBo&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTJz-mmbLw9CbQzPjj7jHU5ZZetu-XJqb5POLfDrQlpHgD3Ky9Sd65QDTyY5kJ48LUmh7A&s', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQIYAvQmQ_BbowG0CwmsnKm67ayf1kTWa0aueBTjjRzSvvLmrYoMCV6gZM30NJwMhA1mw&s'], 'rich_snippet': {'top': {'detected_extensions': {'free': 30}, 'extensions': ['Free 30', 'day returns']}}, 'about_this_result': {'source': {'description': 'Amazon.com, Inc. is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence.', 'source_info_link': 'https://www.amazon.com/coffee/s?k=coffee', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370271de3cc16a260186c3b4cb3a7fd7c1ed2f6dcfc37c91066409b0b45459219d02.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.amazon.com/coffee/s?k%3Dcoffee&tbm=ilp&ilps=ADJL0iz4yaPjFE5YbA0TnbXqmN1j8Qqr0g', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iz4yaPjFE5YbA0TnbXqmN1j8Qqr0g&q=About+https%3A%2F%2Fwww.amazon.com%2Fcoffee%2Fs%3Fk%3Dcoffee', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:wfQ5Et9Ni-kJ:https://www.amazon.com/coffee/s%3Fk%3Dcoffee&cd=37&hl=en&ct=clnk&gl=us'}, {'position': 6, 'title': 'Coffee | The Nutrition Source | Harvard T.H. Chan School of ...', 'link': 'https://www.hsph.harvard.edu/nutritionsource/food-features/coffee/', 'displayed_link': 'https://www.hsph.harvard.edu ‚Ä∫ ... ‚Ä∫ Food Features', 'snippet': 'Coffee beans are the seeds of a fruit called a coffee cherry. Coffee cherries grow on coffee trees from a genus of plants called Coffea. There are a wide ...', 'snippet_highlighted_words': ['Coffee', 'coffee', 'Coffee', 'coffee'], 'about_this_result': {'source': {'description': 'The Harvard T.H. Chan School of Public Health is the public health school of Harvard University, located in the Longwood Medical Area of Boston, Massachusetts.', 'source_info_link': 'https://www.hsph.harvard.edu/nutritionsource/food-features/coffee/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a4137026dbd26df06a2dbaf014d13f33e6a3b6a920533e702cc436894e9cb1a14359630.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.hsph.harvard.edu/nutritionsource/food-features/coffee/&tbm=ilp&ilps=ADJL0ix24UjkA35TUhg8KpNFoGqXA4X1pg', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0ix24UjkA35TUhg8KpNFoGqXA4X1pg&q=About+https%3A%2F%2Fwww.hsph.harvard.edu%2Fnutritionsource%2Ffood-features%2Fcoffee%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:aCQFR0EWgPwJ:https://www.hsph.harvard.edu/nutritionsource/food-features/coffee/&cd=38&hl=en&ct=clnk&gl=us'}, {'position': 7, 'title': \"Peet's Coffee: The Original Craft Coffee\", 'link': 'https://www.peets.com/', 'displayed_link': 'https://www.peets.com', 'snippet': \"Since 1966, Peet's Coffee has offered superior coffees and teas by sourcing the best quality coffee beans and tea leaves in the world and adhering to strict ...\", 'snippet_highlighted_words': ['Coffee', 'coffees', 'coffee'], 'about_this_result': {'source': {'description': \"Peet's Coffee is a San Francisco Bay Area-based specialty coffee roaster and retailer owned by JAB Holding Company via JDE Peet's.\", 'source_info_link': 'https://www.peets.com/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a4137024be2581d9638efd0771f573c952f60c8149f094c13f4611da3180decb846ea6a.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.peets.com/&tbm=ilp&ilps=ADJL0iyi0Ke6jkQwj42VpDqECgl1WRdfeQ', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iyi0Ke6jkQwj42VpDqECgl1WRdfeQ&q=About+https%3A%2F%2Fwww.peets.com%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:BCjzno6zP6wJ:https://www.peets.com/&cd=39&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://www.peets.com/+coffee'}, {'position': 8, 'title': '31 Coffee Brands, Ranked From Worst To Best', 'link': 'https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/', 'displayed_link': 'https://www.tastingtable.com ‚Ä∫ coffee-brands-ranked-f...', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQJbKwc_XPeJDMpYB72QQ9gDtxMu3fnuYp3dVPBKNRH58VXOyFxTPIK&usqp=CAE&s', 'date': 'Mar 2, 2023', 'snippet': \"From caf√© chains to retail roasters, we've ranked some of the most popular coffee brands from worst to first.\", 'snippet_highlighted_words': ['coffee'], 'about_this_result': {'source': {'description': \"Tasting Table is a digital media company focused on food and drink. The brand's website and email newsletter report on food and drink trends in the categories of dining, wine, cocktails, cooking and food travel.\", 'source_info_link': 'https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370255d9fd38631e86b30b8ba5a6270a8f8f8d3fdf473f4298db2e8f3de80302c3c1.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/&tbm=ilp&ilps=ADJL0iwgbb7uiNB1U30anBQOfSid1twx2w', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iwgbb7uiNB1U30anBQOfSid1twx2w&q=About+https%3A%2F%2Fwww.tastingtable.com%2F718678%2Fcoffee-brands-ranked-from-worst-to-best%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:O0p2m8H_t7EJ:https://www.tastingtable.com/718678/coffee-brands-ranked-from-worst-to-best/&cd=40&hl=en&ct=clnk&gl=us'}, {'position': 9, 'title': 'Starbucks Coffee Company', 'link': 'https://www.starbucks.com/', 'displayed_link': 'https://www.starbucks.com', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTUIjRcZRdCIqaOwWV7l1lcn8E-1M1YZNoG2_Kh_UJ8snRuD8oenfX-&usqp=CAE&s', 'snippet': 'More than just great coffee. Explore the menu, sign up for Starbucks¬Æ Rewards, manage your gift card and more.', 'snippet_highlighted_words': ['coffee'], 'about_this_result': {'source': {'description': \"Starbucks Corporation is an American multinational chain of coffeehouses and roastery reserves headquartered in Seattle, Washington. It is the world's largest coffeehouse chain.\\nAs of November 2021, the company had 33,833 stores in 80 countries, 15,444 of which were located in the United States.\", 'source_info_link': 'https://www.starbucks.com/', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a41370201fd9153a994c33cca23ce212f7b632caa714a5c58d1a195fdcc3b69b71b230c.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.starbucks.com/&tbm=ilp&ilps=ADJL0iz2L53LZLU_48M30C3XaAwABDTi8g', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0iz2L53LZLU_48M30C3XaAwABDTi8g&q=About+https%3A%2F%2Fwww.starbucks.com%2F', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:1vGXgo_FlHkJ:https://www.starbucks.com/&cd=41&hl=en&ct=clnk&gl=us', 'related_pages_link': 'https://www.google.com/search?q=related:https://www.starbucks.com/+coffee'}, {'position': 10, 'title': '9 Reasons Why (the Right Amount of) Coffee Is Good for You', 'link': 'https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you', 'displayed_link': 'https://www.hopkinsmedicine.org ‚Ä∫ health ‚Ä∫ 9-reasons...', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRsnUcaHtehFB7MvyuymVeeL7PLkII_xVLL_v6YkOtwxYZV-rzP0RBL&usqp=CAE&s', 'snippet': 'But coffee also contains antioxidants and other active substances that may reduce internal inflammation and protect against disease, say nutrition experts from ...', 'snippet_highlighted_words': ['coffee'], 'about_this_result': {'source': {'description': 'hopkinsmedicine.org was first indexed by Google more than 10 years ago', 'source_info_link': 'https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you', 'security': 'secure', 'icon': 'https://serpapi.com/searches/643802169d158690e4963190/images/f8a7b34e2b85a11c15dcd57b4a413702a84bcbfb2440423ae0a0c5fb59f87e224f8c64115e43db3dd8cb98600b9b54aa.png'}}, 'about_page_link': 'https://www.google.com/search?q=About+https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you&tbm=ilp&ilps=ADJL0izDwqyqs6boUzNyhlVyPUkW3-dJ3Q', 'about_page_serpapi_link': 'https://serpapi.com/search.json?engine=google_about_this_result&google_domain=google.com&ilps=ADJL0izDwqyqs6boUzNyhlVyPUkW3-dJ3Q&q=About+https%3A%2F%2Fwww.hopkinsmedicine.org%2Fhealth%2Fwellness-and-prevention%2F9-reasons-why-the-right-amount-of-coffee-is-good-for-you', 'cached_page_link': 'https://webcache.googleusercontent.com/search?q=cache:MdKXyZO_8uQJ:https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you&cd=42&hl=en&ct=clnk&gl=us'}], 'related_searches': [{'query': 'coffee near me', 'link': 'https://www.google.com/search?q=Coffee+near+me&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh1EAE'}, {'query': 'coffee types', 'link': 'https://www.google.com/search?q=Coffee+types&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh6EAE'}, {'query': 'coffee beans', 'link': 'https://www.google.com/search?q=Coffee+beans&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAhzEAE'}, {'query': 'coffee machine', 'link': 'https://www.google.com/search?q=Coffee+machine&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh3EAE'}, {'query': 'coffee benefits', 'link': 'https://www.google.com/search?q=Coffee+benefits&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh7EAE'}, {'query': 'coffee starbucks', 'link': 'https://www.google.com/search?q=Coffee+Starbucks&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh4EAE'}, {'query': 'coffee origin', 'link': 'https://www.google.com/search?q=Coffee+origin&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAhyEAE'}, {'query': 'coffee plant', 'link': 'https://www.google.com/search?q=Coffee+plant&sa=X&ved=2ahUKEwiRsZ3x-ab-AhUfjYkEHdmuDRcQ1QJ6BAh0EAE'}], 'pagination': {'current': 1, 'next': 'https://www.google.com/search?q=coffee&oq=coffee&start=10&sourceid=chrome&ie=UTF-8', 'other_pages': {'2': 'https://www.google.com/search?q=coffee&oq=coffee&start=10&sourceid=chrome&ie=UTF-8', '3': 'https://www.google.com/search?q=coffee&oq=coffee&start=20&sourceid=chrome&ie=UTF-8', '4': 'https://www.google.com/search?q=coffee&oq=coffee&start=30&sourceid=chrome&ie=UTF-8', '5': 'https://www.google.com/search?q=coffee&oq=coffee&start=40&sourceid=chrome&ie=UTF-8'}}, 'serpapi_pagination': {'current': 1, 'next_link': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=10', 'next': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=10', 'other_pages': {'2': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=10', '3': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=20', '4': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=30', '5': 'https://serpapi.com/search.json?device=desktop&engine=google&google_domain=google.com&location=Austin%2CTexas&q=coffee&start=40'}}}\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "search = GoogleSearch({\n",
    "    \"q\": \"coffee\",\n",
    "    \"location\": \"Austin,Texas\",\n",
    "  })\n",
    "result = search.get_dict()\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ê£ÄÊü•OpenAI KEYÊòØÂê¶ÂèØÁî®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" Kaitlin. I\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1682500219,\n",
      "  \"id\": \"cmpl-79VSFbbtZ9ekxWgW9LTDSvimSJwd3\",\n",
      "  \"model\": \"davinci\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 5,\n",
      "    \"prompt_tokens\": 5,\n",
      "    \"total_tokens\": 10\n",
      "  }\n",
      "}\n",
      "--------\n",
      " Kaitlin. I\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\"\"\"\n",
    "Ë∞ÉÁî®ChatGPT APIÔºåÂÖ∂‰∏≠ÁöÑengineÊòØ‰ΩøÁî®ÁöÑchatgptÁöÑdavinciÂºïÊìéÔºå\n",
    "ËæìÂÖ•ÊèêÁ§∫ÊòØpromptÔºåÁîüÊàêÊñáÊú¨ÁöÑÊúÄÂ§ßÈïøÂ∫¶ÈôêÂà∂‰∏∫5‰∏™tokensÔºå‰∏Ä‰∏™tokenÂèØ‰ª•\n",
    "ÊòØ‰∏Ä‰∏™ÂçïËØçÊàñËÄÖ‰∏Ä‰∏™Â≠êËØçÔºån=1ÊòØËÆæÁΩÆÁöÑÁîüÊàêÊñáÊú¨ÁöÑÊï∞ÈáèÔºåÂç≥Ë°®Á§∫ÁîüÊàê‰∏ÄÊù°ÂõûÂ§çÔºåstopÊòØ\n",
    "Êù•ÊåáÂÆöÁîüÊàêÊñáÊú¨ÁªìÊùüÁöÑÊù°‰ª∂ÁöÑÔºåËøôÈáåËÆæ‰∏∫NoneÔºåË°®Á§∫‰∏çËÆæÁΩÆÂÅúÊ≠¢ÁöÑÊù°‰ª∂ÔºåtemperatureÊòØ\n",
    "Áî®Êù•ÊéßÂà∂ÊñáÊú¨ÁîüÊàêÁöÑÈöèÊú∫ÊÄßÁöÑÔºåÊï∞ÂÄºË∂äÂ§ß‰ª£Ë°®ÁîüÊàêÁöÑÊñáÊú¨Ë∂äÈöèÊú∫ÔºåÊï∞ÂÄºË∂äÂ∞èË°®Á§∫ÁîüÊàêÁöÑÊñáÊú¨\n",
    "ÂæàÁ°ÆÂÆöÂíå‰øùÂÆà„ÄÇËøîÂõûÁöÑÂÜÖÂÆπÂ∞±ÊòØresponseÂØπË±°„ÄÇ\n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\",\n",
    "    prompt=\"Hello, my name is\",\n",
    "    max_tokens=5,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "# ËæìÂá∫ChatGPTÁöÑÂõûÂ§ç\n",
    "print(\"response : {}\".format(response))\n",
    "print(\"--------\")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Models\n",
    "\n",
    "ÈÇ£‰πàÁé∞Âú®ÂºÄÂßãÊàë‰ª¨ÁöÑÁ¨¨‰∏Ä‰∏™ÊùøÂùóÂÜÖÂÆπÔºåËØ•ÊùøÂùó‰∏≠ÁöÑ‰ª£Á†ÅÁ§∫‰æãÈÉ®ÂàÜÊù•Ê∫ê‰∫éLangChainÂÆòÁΩëÊïôÁ®ãÔºåÂÖ≥‰∫éModelsÁöÑËØ¶ÁªÜËØ¥ÊòéÊñáÊ°£‰ª•ÂèäÊåáÁ§∫ËØ∑ÁÇπÂáªüëâ[Ê≠§Â§Ñ](https://python.langchain.com/en/latest/modules/models.html)üëàËøõË°åÁõ¥Êé•ËÆøÈóÆ„ÄÇ\n",
    "\n",
    "- [LLMs](#llms)\n",
    "- [Chat Models](#chat-models)\n",
    "- [Text Embedding Models](#text-embedding-models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LLMs\n",
    "\n",
    "Êàë‰ª¨Áü•ÈÅì‚Äî‚ÄîLangChainÊú¨Ë∫´‰∏çÊèê‰æõÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåÂè™Êèê‰æõÂêÑÁßçÊé•Âè£ÂíåÊñπÂºèÁî®‰ª•Ë∞ÉÁî®ËÆøÈóÆÂ§ßËØ≠Ë®ÄÊ®°Âûã„ÄÇ\n",
    "Áé∞Âú®ÊúâÂæàÂ§öLLMÊèê‰æõÂïÜÊØîÂ¶ÇOpenAI, Cohere, Hugging FaceÁ≠â„ÄÇÂú®LLMs‰∏≠ÔºåÊèê‰æõ‰∫ÜÁªü‰∏ÄÁöÑÊé•Âè£Êù•ËÆøÈóÆËøô‰∫õÂ§ßÊ®°Âûã„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏ãÈù¢ÊòØÂ∏∏ËßÑË∞ÉÁî®Â£∞ÊòéLLMÁöÑÊñπÂºèÊñπÊ≥ïÔºåÊ®°ÂûãÈÄâÊã©ÊòØÂæàÂ§öÁöÑÔºåÂÖ∑‰ΩìË¶Å‰ΩøÁî®Âì™‰∏™Ê®°ÂûãÂèØ‰ª•ËÆøÈóÆ[Ê≠§Â§Ñ](https://platform.openai.com/docs/models/overview)ËøõË°åÊµèËßàÂíåËÆæÁΩÆ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"model_nameÊòØÈÄâÊã©ÁöÑOpenAIÁöÑÊ®°ÂûãÂêçÁß∞Ôºån=2ÊòØÁîüÊàêÁöÑÊñáÊú¨ÂÜÖÂÆπÊòØ‰∏§Êù°Ôºåbest_ofÊòØ‰ªé2‰∏™ÈáåÈù¢ÈÄâÊã©Âá∫ÊúÄ‰Ω≥ÁöÑ‰∏ÄÊù°‰Ωú‰∏∫ËæìÂá∫\"\"\"\n",
    "llm = OpenAI(model_name=\"text-ada-001\", n=2, best_of=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÈÇ£‰πàÊàë‰ª¨Áúã‰∏Ä‰∏ãËøô‰∏™llmÂÖ∑‰ΩìÁöÑÂèÇÊï∞ÊÉÖÂÜµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-ada-001', 'temperature': 0.7, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 2, 'best_of': 2, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ÁîüÊàêÊñáÊú¨ÔºöLLMÊúÄÂü∫Êú¨ÁöÑÂäüËÉΩÂ∞±ÊòØËÉΩÂ§üË∞ÉÁî®ÂÆÉÔºå‰º†ÈÄí‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤Âπ∂ËøîÂõû‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤„ÄÇÂÖ∂‰∏≠ÁöÑ\"tell me...story\"Â∞±ÊòØqueryÔºå‰º†ÈÄíËøõÊ®°Âûã‰∏≠Ë∞ÉÁî®ÈóÆÁ≠îÊ®°ÂûãÁªôÂá∫ÂõûÁ≠îÔºåqueryÁöÑÁ±ªÂûãÊòØÂ≠óÁ¨¶‰∏≤ÔºåÊ≤°ÊúâÈôêÂà∂ÂÆÉÂøÖÈ°ªÊòØÁñëÈóÆÂè•ËøòÊòØÈôàËø∞Âè•ÔºåChatGPTÁ≠âÂ§ßËØ≠Ë®ÄÊ®°Âûã‰ºöÂØπÂÖ∂ÂÜÖÂÆπËøõË°åÁõ∏Â∫îÁöÑËß£Êûê‰∏é‰∫ÜËß£ÔºåËØªËÄÖ‰∏çÂøÖÁ∫†ÁªìÂú®Ê≠§Â§Ñ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nOnce upon a time there was a princess who was very scared. She was sitting in her bedroom when she saw a scary scene in a movie. The princess was scared and started to cry. Her parents tried to soothe her and eventually she fell asleep. When she woke up, she found herself in a dark place. She couldn't make head or tail of what was going on and started to scream. A big part of her population felt sorry for her and helped her, but she wasn't alone. The people who were supposed to be helping her started to leave without her. The princess was scared and started to run around. She didn't know where she was going or what she was doing. Eventually she got her hands on a knife and started to kill people. She was scared and full of Syndicate, but she didn't care. The princess died in the dark, but her story is still shareable online.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Tell me a scared story\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "llmÂèØ‰ª•Êé•ÂèóÊñáÊú¨ÂàóË°®ÔºåÁîüÊàêÂêÑ‰∏™ËØ≠Âè•ÁöÑÂõûÁ≠îÔºåËøòÂåÖÊã¨api‰æõÂ∫îÂïÜÁöÑËøîÂõû‰ø°ÊÅØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "llm_result = llm.generate([\"How to study English\", \"How to generate a new idea\"]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='\\n\\nThere are a few ways to study English:\\n\\n1. Use online resources.\\n\\n2. Take classes from an English teacher.\\n\\n3. Use English-speaking books and articles.\\n\\n4. Take English-speaking courses at your school.', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text=' in a foreign country\\n\\nThere are a number of ways to study English in a foreign country. One way is to go to a training course offered by a English speaking teacher. Another way is to use online resources.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=\"\\n\\n1. Take a step back. What is the best idea you've heard?\\n2. Ask yourself how it would be used. Is the idea unique to you, or is it something that is commonly used?\\n3. How would you create it? This might be a difficult question to answer. Try to think of ways to create the idea that is most unique to you.\\n4. What ingredients would you need? The ingredients for the idea might be different for you, but the process will be the same.\\n5. What resources do you have? You might be able to find the idea through reading articles or Watch this video on how to generate a new idea.\\n6. How do you want to create it? The idea might be something that ismopolitan or consumer-based, so it might be a challenge to create a business around it.\\n7. What resources do you have? The resources for creating a new idea are same, but the process might be different.\", generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\n1. Create a problem\\n\\n2. rescued a kitten from a euthanasia\\n\\n3. created a Pawtucket Mystic\\n\\n4. designed a one mile run\\n\\n5. written a story for the blog\\n\\n6. created a product for a product\\n\\n7. created a company in town\\n\\n8. designed a campaign', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThere is no one-size-fits-all answer to this question, as the best way to study English will vary depending on your level of English proficientness. However, some tips on how to study English include using an online English course option, studying at a frequency that is comfortable for you, and using online resources.', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nThere are a few ways to study English:\\n\\n1. Use online resources.\\n\\n2. Use online textbooks.\\n\\n3. Use local resources.\\n\\n4. Use online lectures.\\n\\n5. Use online vocabulary.\\n\\n6. Use online grammar.\\n\\n7. Use online writing.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThere is no one way to generate a new idea. You will likely have to consider what people want, what might be appealing to them, and what you think will be a strong signal to investors. You will also need to create a plan for achieving your new idea.', generation_info={'finish_reason': None, 'logprobs': None}), Generation(text='\\n\\n1. brainstorm\\n2. create a scenario\\n3. think about what it does\\n4. come up with specific steps\\n5. test out the scenario\\n6. keep track of how it goes\\n7. Jr. Album', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=\" in a foreign country\\n\\nThere is no one-size-fits-all answer to this question, as the best way to study English in a foreign country will vary depending on the individual's individual skills and knowledge. However, some ways to study English in a foreign country include attending English-language classes, taking classes from a English-speaking tutor, or studying English content in absence-friendly websites.\", generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nThere are a few ways to study English:\\n\\n1. Online courses: There are many online courses that teach English, including some free courses and some paid courses.\\n\\n2. Meeting English-speaking people: meeting English-speaking people can help you learn more about English culture and the language.\\n\\n3. Online groups and websites: there are many online groups and websites that teach English, and they offer resources about different topics.\\n\\n4. classroom learning: classroom learning is one of the most common ways to study English, because it is a more direct way to learning the language.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThere is no one way to generate a new idea. You will need to consider what is important to you and what is comfortable for you to talk about. You also need to create a plan in how you will go about creating the idea.', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nThere is no one way to generate a new idea. You will need to have some kind of metaphor or metaphor with people, things, or something. For example, you could say that you are creating a new kind of product, but be specific about how you think this new product might be used. You could also use a metaphor with people or something to mean different things.\\n\\nFor example, you could create a new type of product that uses people as the main character. This could be a type of product that people use to find new things to do. The product might be called \"People\\'s Way.\" People use the product to find new ways to do things. The new way people are using the product is called \"People\\'s Way\\'s new way.\" People\\'s Way is different from the old way and people using the old way is called \"The old way.\"', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 1074, 'prompt_tokens': 30, 'completion_tokens': 1044}, 'model_name': 'text-ada-001'}\n"
     ]
    }
   ],
   "source": [
    "llm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llm_result.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Generation(text='\\n\\n1. Open a English course in your local university or department.\\n\\n2. Find a course on English you want to take and take it in your local university.\\n\\n3. Find a tutor or course Tutor English for you to learn from.\\n\\n4. Finish your coursework and you will have completed English studies in your local university.', generation_info={'finish_reason': 'stop', 'logprobs': None}),\n",
       " Generation(text='\\n\\nThere are a few ways to study English:\\n\\n1. Online courses: Take online courses from various English schools.\\n\\n2. Practice tests: Performance test materials and practice questions in real time so you can become comfortable with the material.\\n\\n3. Print books: Read print books and learn key concepts in the same way as if they were video lessons.\\n\\n4. Location: Take classes and workshops near you at a nearby school or organization.\\n\\n5. Online courses: Take online courses that interest you. Check out free courses beforeempying to sink in for real.', generation_info={'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.generations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Generation(text='\\n\\n\\nThere are a few ways to generate new ideas:\\n\\n1. Look at what others have done in their line of work and experiment with different ideas.\\n\\n2. Take a step back and look at the whole work process from a different perspective.\\n\\n3. Think about different ways to do a task that is popular or efficient in another job market.\\n\\n4.Solution:\\n\\nTake a step back and think about different ways to do a task that is popular or efficient in another job market. For example, think about how to automate task completion times in a specific industry.', generation_info={'finish_reason': 'stop', 'logprobs': None}),\n",
       " Generation(text=' for a game\\n\\nThere is no one definitive way to generate a new idea for a game. However, some methods you may consider include searching online forums for various ideas, creating a list of specific ideas you have, or searching Google for \" game idea\" resources. Additionally, if you have any specific ideas you would like to see included in this resource, be sure to include them in a comment!', generation_info={'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.generations[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ÁªôÂá∫Ë∞ÉÁî®apiÁöÑ‰æõÂ∫îÂïÜËøîÂõû‰ø°ÊÅØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 42,\n",
       "  'completion_tokens': 1407,\n",
       "  'total_tokens': 1449},\n",
       " 'model_name': 'text-ada-001'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.llm_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ËØÑ‰º∞Â≠óÁ¨¶‰∏≤Ëä±Ë¥πTokensÊï∞Èáè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(\"ÂÅáËÆæ‰Ω†ÊòØ‰∏™ÊïôÂ∏àÔºåÂ¶Ç‰ΩïÊïôËã±ËØ≠\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Chat Models\n",
    "ChatGPTÊé•Âè£‰ΩøÁî®ÁöÑÊòØ turbo ÁöÑÊ®°ÂûãÔºåÂØπ‰∫éËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑËÆæËÆ°ÔºåËøôÈáåÊúâÂæàÈáçË¶ÅÁöÑ‰∏â‰∏™ËßíËâ≤:system„ÄÅhuman„ÄÅAIÔºå‰∏ãÈù¢ËøôÂº†ÂõæÂ±ïÁ§∫ÁöÑÊòØËÅäÂ§©Êú∫Âô®‰∫∫Âú®ÊçïËé∑‰ø°ÊÅØÂπ∂ËøõË°åÂ§ÑÁêÜÁöÑÂõæÁîªÂ±ïÁ§∫Ôºö \n",
    "\n",
    "<img src=\"./three.png\" align=center width=100% />\n",
    "\n",
    "Â¶Ç‰∏äÂõæÊâÄÁ§∫ÔºåËøô‰∏â‰∏™ËßíËâ≤ÂàÜÂà´ÊòØÂ¶Ç‰∏ãÁöÑÂÆö‰πâÔºö\n",
    "- systemÔºöÈíàÂØπÁé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑ‰∏ÄÂàáÊèèËø∞ÔºåÊàë‰ª¨ÁöÑsystemË¶ÅÂÜ≥ÂÆöÊúÄÁªàÊÉ≥Ë¶ÅAIÂÅö‰ªÄ‰πàÔºå‰∏Ä‰∏™Áõ¥ÁôΩÁöÑËÉåÊôØÊàñËÄÖËØ¥ÊòØËßíËâ≤ÁöÑÂÆö‰ΩçÔºå‰æãÂ¶ÇÁøªËØëÂëò„ÄÅÈì∂Ë°åÂÆ∂Á≠âÔºõ \n",
    "- humanÔºöÂÖ∑‰ΩìÁöÑ‰∫ãÊÉÖÔºå‰æãÂ¶ÇÊÉ≥Ë¶ÅAIÁøªËØëÁöÑËØ≠Âè•ÊàñËÄÖÊÉ≥Ë¶ÅAIÂÜôÂá∫‰∏ÄÂè•ÈÖ∑‰ººÊñπÊñáÂ±±ÁöÑÊ≠åËØçÔºõ\n",
    "- AIÔºöÂ§ßÊ®°ÂûãÂÜ≥ÂÆöËøîÂõûÁöÑÂÜÖÂÆπ ‰ΩøÁî®langchainÂ∑•ÂÖ∑ÁÆ±ÂÆûÁé∞Ëøô‰∏™ÂäüËÉΩ„ÄÇ\n",
    "\n",
    "Âú®‰ª£Á†Å‰∏≠Êàë‰ª¨Â∞Ü‰ºöÈÄöËøálangchain.schemaÂºïÂÖ•ÁöÑSystemMessage, HumanMessage, AIMessageÊù•ÊìçÁ∫µÂÖ∑‰ΩìÁöÑÈúÄÊ±ÇÊ≠•È™§ÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ÂØºÂÖ•Êàë‰ª¨ÊâÄÈúÄË¶ÅÁöÑÁõ∏ÂÖ≥Â∫ìÂáΩÊï∞\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fad12836580>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key=None, openai_organization=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ÂÆö‰πâËÅäÂ§©Êú∫Âô®‰∫∫‰ΩøÁî®ÁöÑËÅäÂ§©ÈóÆÁ≠îÊ®°Âûã\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "chat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏äÈù¢ÁöÑËæìÂá∫chatÂ¶Ç‰∏ãÔºö\n",
    "ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fad12836580>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key=None, openai_organization=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Áî±AIÂõûÂ§çhumanÁöÑÊ∂àÊÅØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ÊàëÂñúÊ¨¢ÁºñÁ®ã„ÄÇ', additional_kwargs={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#humanÁªôÂá∫ÁöÑ‰ø°ÊÅØÊòØ‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ÂÜÖÂÆπÔºåÁªôÂà∞chat‰πãÂêé‰ºöËøîÂõû‰∏Ä‰∏™AIMessage‰ø°ÊÅØÔºåÂÖ∂‰∏≠ÁöÑÂÜÖÂÆπÂ∞ÜÊòØÁªôÂá∫ÁöÑÂèçÈ¶àÁ≠îÊ°à\n",
    "chat([HumanMessage(content=\"Translate this sentence from English to Chinese. I love programming.\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ê≠£Â¶ÇÊàë‰ª¨‰∏äÈù¢Âõæ‰∏≠Â±ïÁ§∫ÁöÑÈÇ£Ê†∑ÔºåÊàë‰ª¨‰∏ÄËà¨ÂÆö‰πâsystemmessageÁöÑÂÜÖÂÆπ‰∏∫ÁªôÂÆöÂÆÉ‰∏Ä‰∏™ËßíËâ≤‰ΩøOpenAIÊ®°ÂûãËÉΩÂ§üÂú®‰∏Ä‰∏™Áü•ËØÜÈ¢ÜÂüüÂÜÖÂõûÁ≠îÔºåËøôÊ†∑ÂÅöÁöÑÂ•ΩÂ§ÑÂ∞±ÊòØÂØπ‰∫éÁªôÂá∫ÁöÑÁ≠îÊ°à‰ºöÊõ¥Âä†ÂáÜÁ°ÆÔºåËøôÈáåÁâπÂà´ËØ¥Êòé‰∏ÄÁÇπ‚Äî‚ÄîOpenaiËÅäÂ§©Ê®°ÂûãÊîØÊåÅ‰∏ÄÊ¨°ËæìÂÖ•Â§öÊÆµ‰ø°ÊÅØÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ÊàëÂñúÊ¨¢ÁºñÁ®ã„ÄÇ', additional_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to Chinese.\"),\n",
    "    HumanMessage(content=\"Translate this sentence from English to Chinese. I love programming.\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ÂèØ‰ª•‰ΩøÁî®chat.generateÊñπÊ≥ïÂ§ÑÁêÜÂ§öÂØπÂÑøÂØπËØùÂÜÖÂÆπÔºåËøîÂõûÂÄºLLMResultÂåÖÂê´ÊúâËæìÂÖ•‰ø°ÊÅØ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text=\"J'aime programmer.\", generation_info=None, message=AIMessage(content=\"J'aime programmer.\", additional_kwargs={}))], [ChatGeneration(text='ÊàëÂñúÊ¨¢‰∫∫Â∑•Êô∫ËÉΩ„ÄÇ', generation_info=None, message=AIMessage(content='ÊàëÂñúÊ¨¢‰∫∫Â∑•Êô∫ËÉΩ„ÄÇ', additional_kwargs={}))]], llm_output={'token_usage': {'prompt_tokens': 73, 'completion_tokens': 16, 'total_tokens': 89}, 'model_name': 'gpt-3.5-turbo'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to Chinese.\"),\n",
    "        HumanMessage(content=\"Translate this sentence from English to Chinese. I love artificial intelligence.\")\n",
    "    ],\n",
    "]\n",
    "result = chat.generate(batch_messages)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏äÈù¢ÁöÑËæìÂá∫‰ø°ÊÅØÊàë‰ª¨‰∏∫‰∫ÜÊÇ®ÁöÑÁõ¥ËßÇÁúãÂà∞ÔºåÊàë‰ª¨Â∞ÜÂÖ∂ÂëàÁé∞Âú®ËøôÈáåÔºö\n",
    "\n",
    "OUTÔºö\n",
    "\n",
    "LLMResult(generations=[[ChatGeneration(text=\"J'aime programmer.\", generation_info=None, message=AIMessage(content=\"J'aime programmer.\", additional_kwargs={}))], [ChatGeneration(text='ÊàëÂñúÊ¨¢‰∫∫Â∑•Êô∫ËÉΩ„ÄÇ', generation_info=None, message=AIMessage(content='ÊàëÂñúÊ¨¢‰∫∫Â∑•Êô∫ËÉΩ„ÄÇ', additional_kwargs={}))]], llm_output={'token_usage': {'prompt_tokens': 73, 'completion_tokens': 16, 'total_tokens': 89}, 'model_name': 'gpt-3.5-turbo'})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Êàë‰ª¨ÂèØ‰ª•‰ªéresult‰∏≠ÂæóÂà∞‰∏Ä‰∫õ‰ø°ÊÅØÂ¶Ç‰∏ãÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 73,\n",
       "  'completion_tokens': 16,\n",
       "  'total_tokens': 89},\n",
       " 'model_name': 'gpt-3.5-turbo'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Âú®ËÅäÂ§©Ê®°ÂûãÔºàchatmodelÔºâ‰∏≠‰ΩøÁî®ÊèêÁ§∫Ê®°Êùø\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ãÈù¢‰ΩøÁî®Ê®°ÊùøÂåÖË£ÖSystemMessageÂíåHumanMessage„ÄÇÊñπ‰æø‰ΩøÁî®„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#È¶ñÂÖàÊûÑÂª∫Ê®°ÁâàÔºåÁî®Âá†‰∏™ÂÆåÂΩ¢ÂæÖÂ°´È°πË°®Á§∫Ë¶Å‰º†ÂÖ•ÁöÑÂÜÖÂÆπÔºåinput_variablesÂú®Ëøô‰∏™Ê®°Áâà‰∏≠ÊòØ‰∏§‰∏™\n",
    "template=\"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "#ÂÆö‰πâsystemmessageÁöÑÊèêÁ§∫Ê®°ÁâàÔºåËøõË°åÁõ∏Â∫îÁöÑÊ®°ÁâàÊ†ºÂºèÂåñ\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "#ÊûÑÂª∫humanÊ®°ÁâàÔºåÁî®Êù•‰º†ÂÖ•Êàë‰ª¨ÊÉ≥Ë¶ÅÊü•ËØ¢ÁöÑÂÜÖÂÆπ\n",
    "human_template=\"{text}\"\n",
    "#Â∞ÜhumanÊ®°ÁâàËøõË°åÊ†ºÂºèÂåñ\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Â∞Ü‰∏äÈù¢ÁöÑ‰∏§Á±ªÊ®°ÁâàÔºå‰πüÂ∞±ÊòØsystemÂíåhumanÁöÑÊ®°ÁâàÔºåÂ∞Ü‰∏§‰∏™Ê®°ÁâàÈÄöËøáÂêàÂπ∂ÁöÑÊñπÂºèÂàõÂª∫\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "# ‰ΩøÁî®ËÅäÂ§©ÊèêÁ§∫Ê®°ÁâàÊù•ÂàõÂª∫‰∏Ä‰∏™ËÅäÂ§©Ë°•ÂÖ®ÔºåÂÖ∂‰∏≠ÁöÑÂêÑÈ°πÂèÇÊï∞ÈÉΩÊòØinput_variablesÔºåÈÄöËøáto_messagesÊñπÊ≥ï‰º†ÈÄíÁªôchatÊ®°ÂûãÂÆåÊàêËÅäÂ§©ÂØπËØù\n",
    "chat(chat_prompt.format_prompt(input_language=\"English\", output_language=\"French\", text=\"I love programming.\").to_messages())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰πüÂèØ‰ª•Áî®‰∏ãÈù¢ÁöÑÊñπÊ≥ïÊõ¥Áõ¥Êé•ÁöÑÂàõÂª∫system_messageÊ®°Êùø„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input_language', 'output_language'], output_parser=None, partial_variables={}, template='You are a helpful assistant that translates {input_language} to {output_language}.', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "    input_variables=[\"input_language\", \"output_language\"],\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], output_parser=None, partial_variables={}, template='You are a helpful assistant that translates {input_language} to {output_language}.', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n",
    "system_message_prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LLMChain\n",
    "ÁªìÂêàLLMChainÂíåPrompt„ÄÅChat modelÔºåÂèØ‰ª•Êõ¥Êñπ‰æøÂú∞ÂºÄÂ±ïÂØπËØù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=None, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fad12836580>, verbose=False, prompt=ChatPromptTemplate(input_variables=['text', 'output_language', 'input_language'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], output_parser=None, partial_variables={}, template='You are a helpful assistant that translates {input_language} to {output_language}.', template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='{text}', template_format='f-string', validate_template=True), additional_kwargs={})]), llm=ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fad12836580>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key=None, openai_organization=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=None), output_key='text')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ÊàëÂñúÊ¨¢ÁºñÁ®ãÂíåÊ∏∏Ê≥≥„ÄÇ'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_language=\"English\", output_language=\"Chinese\", text=\"I love programming and swimming\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ÊµÅÂºèÂØπËØù\n",
    "ÈÄöËøáÂõûË∞ÉÂáΩÊï∞Â§ÑÁêÜÂØπËØù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‰∏ÄÂä†‰∏ÄÁ≠â‰∫é‰∫åÊòØÂõ†‰∏∫ËøôÊòØÊàë‰ª¨ÊâÄÊé•ÂèóÁöÑÂü∫Êú¨Êï∞Â≠¶ÂéüÁêÜ‰πã‰∏Ä„ÄÇÂú®ÂçÅËøõÂà∂Êï∞Á≥ªÁªü‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊï∞Â≠ó1Ë°®Á§∫‰∏∫‰∏Ä‰∏™Âçï‰ΩçÔºåÊï∞Â≠ó2Ë°®Á§∫‰∏∫‰∏§‰∏™Âçï‰Ωç„ÄÇÂΩìÊàë‰ª¨Â∞Ü‰∏Ä‰∏™Âçï‰Ωç‰∏éÂè¶‰∏Ä‰∏™Âçï‰ΩçÁõ∏Âä†Êó∂ÔºåÊàë‰ª¨ÂæóÂà∞‰∏§‰∏™Âçï‰ΩçÔºåÂç≥Êï∞Â≠ó2„ÄÇËøôÊòØÂõ†‰∏∫Âä†Ê≥ïÊòØ‰∏ÄÁßçÂü∫Êú¨ÁöÑÁÆóÊúØËøêÁÆóÔºåÂÆÉË°®Á§∫Â∞Ü‰∏§‰∏™ÊàñÂ§ö‰∏™Êï∞ÂÄºÁõ∏Âä†‰ª•ÂæóÂà∞ÂÆÉ‰ª¨ÁöÑÊÄªÂíå„ÄÇÂõ†Ê≠§Ôºå‰∏ÄÂä†‰∏ÄÁ≠â‰∫é‰∫åÊòØÊï∞Â≠¶‰∏≠ÁöÑÂü∫Êú¨ÂéüÁêÜ‰πã‰∏ÄÔºåÂÆÉË¢´ÂπøÊ≥õÊé•ÂèóÂπ∂Ë¢´Áî®‰∫éÂêÑÁßçÊï∞Â≠¶ÂíåÁßëÂ≠¶Â∫îÁî®‰∏≠„ÄÇ"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\"\"\"\n",
    "streaming=TrueÊòØÂêØÁî®‰∫ÜËÅäÂ§©ÁöÑÊµÅÂºèÊ®°ÂºèÔºå‰πüÂ∞±ÊòØÂìçÂ∫îÁöÑÂÜÖÂÆπÂ∞Ü‰ºöÂú®ÈÄêÊ≠•ÁîüÊàêÁöÑÊï∞ÊçÆÂùó‰∏≠ÈÄêÊ≠•ËøîÂõûÔºõ\n",
    "ËÄåcallback_mangerÁî®‰∫éÁÆ°ÁêÜËÅäÂ§©ËøáÁ®ã‰∏≠ÁöÑÂõûË∞ÉÂáΩÊï∞ÁöÑÂØπË±°ÔºåÊµÅÂºèÂØπË±°Â∞Ü‰ºöÈÄêÊ≠•ËøîÂõûÂÜÖÂÆπËÄå‰∏çÊòØÊï¥‰∏™\n",
    "ÂìçÂ∫îÂÆåÊàê‰πãÂêé‰∏ÄÊ¨°ÊÄßËøîÂõûÔºåÂ¶ÇÊûú‰∏ç‰º†ÈÄícallback_managerÂèÇÊï∞ÔºåÂàôËÅäÂ§©ËøáÁ®ã‰∏≠Â∞Ü‰ºö‰ª•ÈªòËÆ§ÁöÑÊñπÂºèËøêË°åÔºå‰πü\n",
    "Â∞±ÊòØÂìçÂ∫îÂÆåÊàê‰πãÂêé‰∏ÄÊ¨°ÊÄßËøîÂõûÔºõverboseÊòØËØ¶ÁªÜÊ®°ÂºèÔºåÂÜ≥ÂÆöÊòØÂê¶ÊâìÂç∞Âá∫ÂÖ∑‰ΩìÁöÑ‰ø°ÊÅØÔºõtemperatureÁöÑËÆæÁΩÆ\n",
    "ÂàôÊòØÂÜ≥ÂÆöÈöèÊú∫ÊÄß\n",
    "\"\"\"\n",
    "chat = ChatOpenAI(streaming=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True, temperature=0)\n",
    "resp = chat([HumanMessage(content=\"Â∏ÆÊàëÂàÜÊûê‰∏Ä‰∏ã‰∏∫‰ªÄ‰πà‰∏ÄÂä†‰∏ÄÁ≠â‰∫é‰∫åÔºü\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I cannot provide instructions on how to become a fictional character like Superman. However, I can suggest some ways to become a better version of yourself:\n",
      "\n",
      "1. Set goals and work towards them consistently.\n",
      "2. Exercise regularly to improve physical strength and endurance.\n",
      "3. Learn new skills and knowledge to enhance mental abilities.\n",
      "4. Practice empathy and kindness towards others.\n",
      "5. Be courageous and stand up for what is right.\n",
      "6. Develop a positive mindset and attitude towards life.\n",
      "7. Surround yourself with supportive and positive people.\n",
      "8. Take care of your health by eating a balanced diet and getting enough rest.\n",
      "9. Continuously challenge yourself to grow and improve.\n",
      "10. Believe in yourself and your abilities."
     ]
    }
   ],
   "source": [
    "resp_another = chat([HumanMessage(content=\"tell me how to become a superman?\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Text Embedding Models\n",
    "ËØçÂµåÂÖ•ÊîØÊåÅÂ∞ÜËá™ÁÑ∂ËØ≠Ë®ÄËΩ¨Âèò‰∏∫ÂêëÈáè„ÄÇLangChain‰∏≠ÊúÄÈáçË¶ÅÁöÑ‰∏§‰∏™embeddingÊñπÊ≥ï‰∏∫embed_documents Âíå embed_queryÊñπÊ≥ï„ÄÇÂõ†‰∏∫Â§ÑÁêÜÂ§ö‰∏™ÊñáÊú¨Êñá‰ª∂ÂíåÂ§ÑÁêÜ‰∏Ä‰∏™Êñá‰ª∂ÊúâÂæàÂ§ßÁöÑ‰∏çÂêåÔºåÊâÄ‰ª•LangChainÂ∞ÜÂÖ∂ÂàÜ‰∏∫‰∏§‰∏™Á±ª„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LangChain‰∏≠ÈõÜÊàê‰∫ÜÂæàÂ§öÊù•Ëá™‰∏çÂêåÂπ≥Âè∞ÁöÑAPIÂèØ‰ª•ËøõË°åËØçÂµåÂÖ•ÁºñÁ†ÅÔºåËøôÈáå‰∏æ‰∏Ä‰∏™Áî®OpenAiËøõË°åËØçÂµåÂÖ•ÁöÑÊñπÊ≥ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Êàë‰ª¨‰ΩøÁî®ËæÉÂ§öÁöÑ‰πüÊòØOpenAIÁöÑembeddingsÊñπÊ≥ï\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"This is a test document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0031265460635144116,\n",
       " 0.011133635493097378,\n",
       " -0.004037691773639618,\n",
       " -0.011746618046080886,\n",
       " -0.000993598608605281,\n",
       " 0.01080715570571065,\n",
       " -0.010440697965211392,\n",
       " -0.005253663322651083,\n",
       " -0.009874355115762394,\n",
       " -0.026171704933991537,\n",
       " 0.020348368352341755,\n",
       " 0.02257376179702522,\n",
       " -0.00752236652698065,\n",
       " 0.017230149476854816,\n",
       " -0.005986577872327018,\n",
       " 0.01914905397335298,\n",
       " 0.021254515421344024,\n",
       " -0.015644390243455687,\n",
       " 0.007642298058011785,\n",
       " -0.018402813128865346,\n",
       " -0.0006866907980891692,\n",
       " -0.006416332020722187,\n",
       " -0.010967063792870444,\n",
       " 0.0180030410483207,\n",
       " -0.022173991579125737,\n",
       " -0.0030682459684349844,\n",
       " 0.014405098842676966,\n",
       " -0.029982859474719296,\n",
       " 0.018496092535934365,\n",
       " -0.007935463505353126,\n",
       " 0.01004758949773389,\n",
       " -0.019442219420694323,\n",
       " -0.003694554583399551,\n",
       " -0.024279453027116777,\n",
       " -0.005540166088247863,\n",
       " 0.0038311432844533796,\n",
       " -0.00566676076668485,\n",
       " -0.029449831896638266,\n",
       " 0.018576046579514262,\n",
       " -0.016643818582172135,\n",
       " 0.007529029208725211,\n",
       " 0.012452880937455994,\n",
       " -0.0009711115338484352,\n",
       " -0.010693886390762786,\n",
       " 0.010034264134244767,\n",
       " -0.012566149321081278,\n",
       " 0.03358080261168561,\n",
       " -0.026957921868946542,\n",
       " -0.007935463505353126,\n",
       " 0.028970105772513726,\n",
       " 0.019735384868035666,\n",
       " -0.002010517301808462,\n",
       " -0.027397671902603716,\n",
       " -0.008768321075165222,\n",
       " -0.00623976629787841,\n",
       " 0.0019855315467744218,\n",
       " -0.007389109166799102,\n",
       " 0.027930699480684745,\n",
       " 0.00680944048819969,\n",
       " -0.009288023289757131,\n",
       " -0.022533785706557855,\n",
       " 0.010460686941767657,\n",
       " -0.013612218294654818,\n",
       " -0.011120309198285674,\n",
       " -0.004873880684323994,\n",
       " -0.008301921245852384,\n",
       " -0.0058333320012504955,\n",
       " 0.011120309198285674,\n",
       " 0.006299731830563333,\n",
       " 0.004460783240290227,\n",
       " 0.010627257710672012,\n",
       " 0.012452880937455994,\n",
       " 0.005370263512809938,\n",
       " 0.005436891727239422,\n",
       " 0.008941555457136718,\n",
       " 0.00428421751744645,\n",
       " -0.022693693793717648,\n",
       " -0.013212447145432755,\n",
       " 0.01123357851323354,\n",
       " -0.005710069129347079,\n",
       " 0.00980772643567162,\n",
       " -0.024439362976921734,\n",
       " -0.008555109671403776,\n",
       " 0.007875497507006914,\n",
       " 0.0025502087257872805,\n",
       " 0.007562343548770598,\n",
       " 0.005740052128520186,\n",
       " 0.028223864928026088,\n",
       " -0.022960208514080743,\n",
       " -0.015564436199875789,\n",
       " -0.008215303589205346,\n",
       " 0.02005520104235525,\n",
       " 0.003584617540646548,\n",
       " 0.012779361656165304,\n",
       " -0.01647058513152322,\n",
       " 0.031555295207274466,\n",
       " 0.013532264251074922,\n",
       " 0.030382631555263943,\n",
       " -0.006206451957833024,\n",
       " -0.049678266389642435,\n",
       " -0.0037212060088697317,\n",
       " -0.001316747287950374,\n",
       " -0.007055966232006522,\n",
       " 0.0035246517751309804,\n",
       " -0.03486007103425428,\n",
       " -0.009028172182461176,\n",
       " 0.021960778312719132,\n",
       " -0.007275840783173818,\n",
       " 0.015431178839694241,\n",
       " -0.008281932269296119,\n",
       " -0.016457257905388937,\n",
       " 0.005083760281551867,\n",
       " -0.006366360510654107,\n",
       " -0.03603273654890997,\n",
       " 0.01561773858515486,\n",
       " 0.00566676076668485,\n",
       " 0.006486292041685242,\n",
       " -0.021907476858762643,\n",
       " -0.010260800901495335,\n",
       " 0.0010419043318218987,\n",
       " 0.0006621215188718254,\n",
       " 0.016883680712911825,\n",
       " 0.026504848334445406,\n",
       " -0.02753092926278526,\n",
       " 0.010580618007137502,\n",
       " 0.013292401189012652,\n",
       " -0.00880829809695517,\n",
       " -0.04184274776707063,\n",
       " -0.006469634871662549,\n",
       " -0.005530172065631021,\n",
       " 0.019109076020240454,\n",
       " 0.021454401461616344,\n",
       " 0.01419188743891552,\n",
       " 0.017509989560707036,\n",
       " -0.023333328005001982,\n",
       " 0.037312004971478636,\n",
       " -0.04040357125734217,\n",
       " 0.024772504514730443,\n",
       " -0.0432286228228426,\n",
       " -0.008435177674711351,\n",
       " 0.008308583927596945,\n",
       " 0.027397671902603716,\n",
       " -0.019162379336842107,\n",
       " -0.016936984029513477,\n",
       " 0.010294115241540723,\n",
       " 0.01395202437685325,\n",
       " 0.008255280610995293,\n",
       " -0.024812482467842973,\n",
       " 0.012506184254057646,\n",
       " -0.021147910650785882,\n",
       " 0.0031082232230555777,\n",
       " 0.001852274419423519,\n",
       " 0.017763178917581012,\n",
       " 0.002528554544456166,\n",
       " 0.015551109905064087,\n",
       " 0.03144868857407117,\n",
       " 0.0038577947099235604,\n",
       " -0.009514560988330279,\n",
       " -0.018029693637944107,\n",
       " -0.01961545287134324,\n",
       " 0.0030682459684349844,\n",
       " 0.02218731694261486,\n",
       " 0.00956786337360935,\n",
       " 0.0018689315894462124,\n",
       " 0.023466585365183527,\n",
       " 0.034700162947094486,\n",
       " 0.004007708774466511,\n",
       " 0.007648960739756346,\n",
       " -0.0016307344306507275,\n",
       " -0.015404527181393415,\n",
       " -0.025039019235093538,\n",
       " 0.02475917915124132,\n",
       " -0.02537216263554741,\n",
       " 0.007655623421500907,\n",
       " -0.0201884584025368,\n",
       " 0.014271841482495417,\n",
       " 0.007202549421338483,\n",
       " 0.0034780118387658255,\n",
       " -0.0044374633885229725,\n",
       " -0.004037691773639618,\n",
       " -0.033873968059026954,\n",
       " 0.016883680712911825,\n",
       " 0.01480486999189903,\n",
       " 0.03179515547536899,\n",
       " -0.017056916026205904,\n",
       " -0.006936035166636677,\n",
       " 0.024226151573160288,\n",
       " -0.009534549033563962,\n",
       " 0.001379211559120152,\n",
       " -0.00461736045223903,\n",
       " 0.023200070644820433,\n",
       " 0.021880824269139235,\n",
       " -0.0063430406588868525,\n",
       " -0.01480486999189903,\n",
       " -0.7023184943753603,\n",
       " -0.016363978498319918,\n",
       " 0.004297543346596862,\n",
       " -0.017230149476854816,\n",
       " 0.022173991579125737,\n",
       " 0.03136873266784611,\n",
       " 0.024599271064081527,\n",
       " 0.002137111747414804,\n",
       " -0.0060098977240942725,\n",
       " 0.02185417354216099,\n",
       " -0.0226670430667394,\n",
       " -0.012706069363007388,\n",
       " -0.009201406564432673,\n",
       " -0.013212447145432755,\n",
       " -0.014111932464013044,\n",
       " -0.023160094554353066,\n",
       " -0.016963636619136885,\n",
       " -0.003323100297253163,\n",
       " -0.01761659619391034,\n",
       " 0.013085852466995769,\n",
       " 0.014924801057268873,\n",
       " 0.015457830497995068,\n",
       " -0.015711018923546458,\n",
       " -0.01672377262575203,\n",
       " 0.000518870077865774,\n",
       " 0.00890824111709133,\n",
       " 0.01309251514874033,\n",
       " -0.006133160595997688,\n",
       " 0.017483338833728792,\n",
       " 0.01689700793904611,\n",
       " -0.026211682887104064,\n",
       " -0.003571291711496135,\n",
       " -0.0009452929435963248,\n",
       " 0.008548446989659215,\n",
       " 0.033260986437366025,\n",
       " -0.0020588231414404023,\n",
       " -0.014485052886256863,\n",
       " -0.025039019235093538,\n",
       " 0.016590515265570482,\n",
       " 0.0008794972151389435,\n",
       " -0.016830379258955336,\n",
       " -0.000344802889780038,\n",
       " 0.0048205778333836324,\n",
       " -0.0017423372602551933,\n",
       " -0.004604034623088617,\n",
       " -0.0025218916298809595,\n",
       " 0.018829235936388234,\n",
       " 0.0003429289523317189,\n",
       " 0.027450973356560205,\n",
       " 0.017656572284377708,\n",
       " -0.016590515265570482,\n",
       " -0.0005492693200249316,\n",
       " 0.006656195082784458,\n",
       " -0.003491337435085593,\n",
       " 0.0010210829857088546,\n",
       " -0.010434035283466831,\n",
       " 0.021640962138399545,\n",
       " 0.007728915248997534,\n",
       " 0.010833806432688895,\n",
       " 0.016563864538592238,\n",
       " -0.0011426800707608075,\n",
       " 0.011879875406262435,\n",
       " -0.005626783279233612,\n",
       " -0.016883680712911825,\n",
       " -0.028943455045535478,\n",
       " -0.007495714868679824,\n",
       " -0.020841419839955418,\n",
       " 0.022547111070046977,\n",
       " 0.0010219158209269247,\n",
       " -0.019002471249682313,\n",
       " -0.003724537582572657,\n",
       " 0.012512846935802208,\n",
       " -0.010254138219750774,\n",
       " -0.01970873414105742,\n",
       " 0.020761463933730358,\n",
       " 0.015497807519785016,\n",
       " 0.00976108673213711,\n",
       " -0.009987623499387678,\n",
       " -0.00933466392461422,\n",
       " 0.016790401305842806,\n",
       " 0.00371454332712517,\n",
       " 0.003584617540646548,\n",
       " -0.014338470162586192,\n",
       " -0.015431178839694241,\n",
       " 0.01085379540924516,\n",
       " -0.02024176171913845,\n",
       " -0.04610697584229952,\n",
       " -0.01299923574167131,\n",
       " -0.0066761835936794325,\n",
       " 0.013385681527404252,\n",
       " 0.021547682731330526,\n",
       " 0.0014358458673481166,\n",
       " -0.007935463505353126,\n",
       " -0.0004426636181442092,\n",
       " 0.008928229162325016,\n",
       " -0.0027784116291352783,\n",
       " 0.0011585044055654307,\n",
       " 0.003967731752676563,\n",
       " 0.030142769424524252,\n",
       " -0.0019239002272380366,\n",
       " 0.0014741573351172471,\n",
       " 0.0024169515984363774,\n",
       " 0.0006317222185050064,\n",
       " 0.011733292682591764,\n",
       " 0.021161236014275005,\n",
       " 0.005247000640906522,\n",
       " 0.003637920391586909,\n",
       " 0.024452688340410856,\n",
       " 0.018256230405194675,\n",
       " -0.008488480991313004,\n",
       " -0.007169235081293096,\n",
       " -0.008988195160671227,\n",
       " -0.009554538010120227,\n",
       " 0.0015707686651351598,\n",
       " -0.016057487687489453,\n",
       " -0.034220438685615105,\n",
       " 0.008035406525489288,\n",
       " 0.011246903876722662,\n",
       " 0.0023653144179321566,\n",
       " 0.0033880630740771513,\n",
       " 0.01404530378392227,\n",
       " 0.017723200964468482,\n",
       " 0.013339040892547161,\n",
       " -0.0016365643935925412,\n",
       " 0.004580714771321362,\n",
       " -0.002518560289008679,\n",
       " 0.003941080560037028,\n",
       " -0.019415566831070916,\n",
       " -0.01719017338638745,\n",
       " -0.009707783415535458,\n",
       " -0.0194288940572052,\n",
       " -0.0017639915580016305,\n",
       " 0.03371405997186716,\n",
       " -0.01419188743891552,\n",
       " 0.007722252101591682,\n",
       " 0.002328668737014489,\n",
       " 0.0038078231998554795,\n",
       " -0.0052803149809519095,\n",
       " 0.021361122054547325,\n",
       " -0.009727772392091723,\n",
       " -0.013019223786904994,\n",
       " 0.013312390165568917,\n",
       " -0.006969349041020773,\n",
       " -0.009108126226041072,\n",
       " -0.011913189746307822,\n",
       " -0.02232057430279641,\n",
       " -0.017989715684831577,\n",
       " -0.0030299346170811763,\n",
       " 0.0009786072254340506,\n",
       " 0.00995430915934229,\n",
       " -0.022107362899034963,\n",
       " 0.0013617215538793885,\n",
       " -0.010100892814335542,\n",
       " -0.005843326489528627,\n",
       " -0.00813534954562545,\n",
       " -0.011106983834796552,\n",
       " -0.017070241389695026,\n",
       " -0.02627831156719484,\n",
       " 0.0010627257943502657,\n",
       " -0.0014475059096470666,\n",
       " -0.008601749374938286,\n",
       " 0.017549967513819566,\n",
       " -0.006196457935216181,\n",
       " 0.0011410144003246672,\n",
       " -0.02651817369793453,\n",
       " -0.018242905041705552,\n",
       " -0.03302112244398117,\n",
       " 0.033181030531140965,\n",
       " -0.009974298135898554,\n",
       " -0.0339006187860052,\n",
       " -0.018309533721796327,\n",
       " 0.005167046131665335,\n",
       " -0.013492287229284973,\n",
       " -0.0020704830673240297,\n",
       " 0.005017132067122384,\n",
       " -0.010527315621858432,\n",
       " -0.015737669650524706,\n",
       " 0.007842183166961527,\n",
       " 0.010354081239886934,\n",
       " -0.02133447132756908,\n",
       " -0.0049904804088215585,\n",
       " 0.0034580230950402063,\n",
       " 0.012279646555484499,\n",
       " 0.0020305058127034364,\n",
       " 0.01181324672617166,\n",
       " 0.015084710075751248,\n",
       " 0.013465635570984147,\n",
       " 0.007075954742901496,\n",
       " -0.012646104295983757,\n",
       " 0.0025885203099717336,\n",
       " 0.008042069207233849,\n",
       " 0.0033064431272304693,\n",
       " -0.01461831024643841,\n",
       " 0.009274697926268009,\n",
       " -0.007648960739756346,\n",
       " 0.01985531686472809,\n",
       " -0.029689694027377957,\n",
       " 0.010447360646955953,\n",
       " 0.012872641063234323,\n",
       " 0.02385303021959389,\n",
       " 0.02257376179702522,\n",
       " 0.008708355076819009,\n",
       " 0.0038544631362206344,\n",
       " -0.022720344520695893,\n",
       " 0.00016542626076378224,\n",
       " -0.03541975120195872,\n",
       " -0.01313915578359742,\n",
       " -0.0027151145227474302,\n",
       " 0.013552252296308605,\n",
       " 0.006339709318014572,\n",
       " 0.012885967358046027,\n",
       " -0.017643246920888585,\n",
       " -0.02470587583463967,\n",
       " 0.017390059426659773,\n",
       " 0.02152103014170712,\n",
       " 0.005450217556389835,\n",
       " -0.010134206223058348,\n",
       " -0.002833380383342425,\n",
       " -0.006746143614642487,\n",
       " -0.0020538258973013365,\n",
       " 0.0066895094228298455,\n",
       " 0.004837234537745035,\n",
       " 0.012559486639336717,\n",
       " -0.007282503464918379,\n",
       " -0.01624404650162749,\n",
       " 0.011493429620529494,\n",
       " 0.028596986281592487,\n",
       " 0.03259469963645829,\n",
       " 0.02300018460454811,\n",
       " -0.024159522893069513,\n",
       " -0.018362835175752816,\n",
       " 0.002605177479994427,\n",
       " 0.0008570100821744363,\n",
       " 0.0012476201022053896,\n",
       " 0.0031781832440186328,\n",
       " 0.010460686941767657,\n",
       " 0.02242717907335455,\n",
       " -0.01938891610409267,\n",
       " 0.028730243641774036,\n",
       " 0.00035979433115892995,\n",
       " 0.011486766938784932,\n",
       " 0.018829235936388234,\n",
       " 0.028650287735548976,\n",
       " -0.008501806354802126,\n",
       " 0.02290690519747909,\n",
       " -9.301974269190048e-05,\n",
       " 0.028197214201047843,\n",
       " 0.0085684350348929,\n",
       " -0.004021034603616924,\n",
       " 0.03147533930104941,\n",
       " -0.010707212685574488,\n",
       " 0.0018039686962069014,\n",
       " 0.001005258650904231,\n",
       " 0.004180943156438008,\n",
       " 0.03246144227627674,\n",
       " -0.026917945778479172,\n",
       " -0.013412332254382497,\n",
       " 0.0018822573021813028,\n",
       " 0.014338470162586192,\n",
       " 0.03123547717030972,\n",
       " 0.022227293033082227,\n",
       " 0.005023794748866945,\n",
       " -0.0026301630021978223,\n",
       " 0.0012159715490114653,\n",
       " 0.023213396008309555,\n",
       " -0.004550731772148256,\n",
       " -0.013205784463688194,\n",
       " 0.003389728977343937,\n",
       " -0.020015224951887883,\n",
       " -0.01304587544520582,\n",
       " -0.0056067947683386375,\n",
       " -0.0014141915696016796,\n",
       " 0.018082995091900596,\n",
       " 0.0024502659384817646,\n",
       " 0.0246658997441723,\n",
       " 0.010580618007137502,\n",
       " 0.02590519021362844,\n",
       " 0.012039784424744808,\n",
       " 0.01647058513152322,\n",
       " 0.001490814388724618,\n",
       " -0.009081475499062828,\n",
       " -0.022373875756752898,\n",
       " 0.0006258921973555314,\n",
       " 0.01218636714841548,\n",
       " 0.012292972850296202,\n",
       " -0.011719966387780062,\n",
       " -0.010247475538006213,\n",
       " 0.004657337474028978,\n",
       " -0.007442412017739463,\n",
       " 0.006479629359940681,\n",
       " 0.00400104609272195,\n",
       " -4.937281880562186e-05,\n",
       " 0.01709689397931843,\n",
       " -0.023160094554353066,\n",
       " -5.1793308003778376e-05,\n",
       " 0.01596420641777527,\n",
       " 0.008888252140535067,\n",
       " -0.0055368347473755825,\n",
       " -0.010147532517870051,\n",
       " -0.007815532439983282,\n",
       " 0.011180275196631888,\n",
       " -0.0075756693779210115,\n",
       " 0.008761658393420661,\n",
       " 0.00623643495700613,\n",
       " 0.02009517899546778,\n",
       " 0.0003102393260113764,\n",
       " -0.0026085088208667078,\n",
       " -0.012959258719881362,\n",
       " -0.01341899586744964,\n",
       " -0.010300777923285284,\n",
       " 0.01804301900143323,\n",
       " 0.003874451879946254,\n",
       " -0.014005326762132321,\n",
       " -0.005956594873153911,\n",
       " 0.015604413221665737,\n",
       " -0.005650103596662157,\n",
       " 0.0015449501912983721,\n",
       " 0.0133323782108026,\n",
       " 0.016830379258955336,\n",
       " 0.012819338677955252,\n",
       " -0.01537787552309259,\n",
       " -0.006882732315696315,\n",
       " -0.01809632231803488,\n",
       " 0.010727200730808172,\n",
       " 0.0489586781347782,\n",
       " 0.04320196837057403,\n",
       " 0.0025801917249603868,\n",
       " -0.010893772431035108,\n",
       " 0.0037012174979747575,\n",
       " -0.019308962060512774,\n",
       " -0.02694459650545742,\n",
       " -0.0135189388875858,\n",
       " 0.006366360510654107,\n",
       " -0.002205405865111073,\n",
       " -0.007882161120074055,\n",
       " -0.004354177538409504,\n",
       " 0.01624404650162749,\n",
       " 0.001379211559120152,\n",
       " 0.016630493218683012,\n",
       " 0.007122594912097296,\n",
       " -0.0013892058145676392,\n",
       " -0.0024735860230796648,\n",
       " -0.009487909330029453,\n",
       " -0.012279646555484499,\n",
       " 0.002900008830602554,\n",
       " 0.007708926272441269,\n",
       " 0.007688937761546295,\n",
       " 0.003371406136885103,\n",
       " 0.01209974949176844,\n",
       " -0.02133447132756908,\n",
       " 0.007722252101591682,\n",
       " 0.0016107459197557533,\n",
       " 0.0002640157490475955,\n",
       " -0.020361693715830877,\n",
       " -0.01419188743891552,\n",
       " 0.019215682653443755,\n",
       " 0.01014086983612549,\n",
       " 0.018109647681524003,\n",
       " -0.0006242264687117299,\n",
       " 0.03288786508379963,\n",
       " -0.0044308002411171206,\n",
       " -0.015790972967126355,\n",
       " 0.007755566441637069,\n",
       " 0.004847229026023168,\n",
       " 0.009254709881034323,\n",
       " 0.004580714771321362,\n",
       " -0.003394725988652358,\n",
       " -0.008261943292739854,\n",
       " -0.007149246570398122,\n",
       " 0.00025672823716266707,\n",
       " -0.016657143945661257,\n",
       " 0.003386397403641011,\n",
       " -0.008635063714983673,\n",
       " -0.007555680867026037,\n",
       " 0.012079761446534757,\n",
       " -0.01770987560097936,\n",
       " -0.0012184701710809985,\n",
       " -0.015417852544882538,\n",
       " 0.02875689436875228,\n",
       " 0.023306677278023737,\n",
       " 0.004390823219327172,\n",
       " 0.006816103635605542,\n",
       " -0.0022070715355472135,\n",
       " -0.017536642150330444,\n",
       " -0.029876254704161154,\n",
       " -0.006792783318176996,\n",
       " -0.011373498555159648,\n",
       " -0.009301349584568833,\n",
       " -0.011413475576949597,\n",
       " -0.03043593487186559,\n",
       " -0.023506561455650898,\n",
       " -0.013345704505614304,\n",
       " -0.020161807675558554,\n",
       " 0.0037212060088697317,\n",
       " 0.010980389156359566,\n",
       " -0.01760327083042122,\n",
       " -0.024785831740864725,\n",
       " -0.016217395774649247,\n",
       " 0.02899675649949197,\n",
       " -0.013938698082041547,\n",
       " 0.0005355271896808063,\n",
       " 0.01304587544520582,\n",
       " 0.0014974773032998246,\n",
       " 0.022533785706557855,\n",
       " -0.010840470045756037,\n",
       " -0.022507133116934447,\n",
       " 0.005899960681341269,\n",
       " -0.02413287030344611,\n",
       " -0.005899960681341269,\n",
       " 0.016843704622444458,\n",
       " -0.003987720263571537,\n",
       " 0.0067761261481543026,\n",
       " -0.0027351030336424044,\n",
       " 0.01047401230525678,\n",
       " -0.006076526404185046,\n",
       " -0.002423614513011584,\n",
       " -0.004863886196045861,\n",
       " -0.02936987785305837,\n",
       " 0.016350653134830796,\n",
       " -0.008768321075165222,\n",
       " 0.0019888631204773477,\n",
       " 0.007482389505190702,\n",
       " -0.00866837805502906,\n",
       " -0.004130971646369927,\n",
       " -0.015537784541574963,\n",
       " -0.001499975808954035,\n",
       " -0.009128115202597337,\n",
       " 0.0016174087179156372,\n",
       " 0.020788116523353765,\n",
       " -0.019055772703638802,\n",
       " -0.013379018845659691,\n",
       " 0.01689700793904611,\n",
       " -0.023293350051889452,\n",
       " -0.007715589419847121,\n",
       " -0.010460686941767657,\n",
       " -0.018162950998125656,\n",
       " 0.009587852350165614,\n",
       " -0.020015224951887883,\n",
       " 0.002370311662071223,\n",
       " 0.017443360880616262,\n",
       " -0.007422423506844489,\n",
       " 0.022014081629320784,\n",
       " -0.010260800901495335,\n",
       " -0.030169420151502497,\n",
       " 6.792991963538974e-05,\n",
       " -0.009801063753927058,\n",
       " 0.011086995789562869,\n",
       " 0.03563296446836532,\n",
       " 0.022080710309411555,\n",
       " 0.029209967903253413,\n",
       " -0.008768321075165222,\n",
       " -0.0030016175211748557,\n",
       " -0.014218538165893765,\n",
       " 0.007915475460119442,\n",
       " -0.00509375476983,\n",
       " 0.0011701644478643808,\n",
       " -0.007782218099937894,\n",
       " -0.0041976003264607015,\n",
       " -0.018882539252989886,\n",
       " -0.01143346362218328,\n",
       " -0.001524128728770005,\n",
       " 0.013672184293001032,\n",
       " -0.005263657810929216,\n",
       " -0.0106605720507174,\n",
       " -0.015084710075751248,\n",
       " 0.013658857998189328,\n",
       " 0.011393486600393332,\n",
       " -0.009168092224387286,\n",
       " -0.02567865344637787,\n",
       " -0.029822951387559502,\n",
       " -0.02170759081849032,\n",
       " 0.010107555496080103,\n",
       " -0.020574905119592323,\n",
       " 0.0008586758108182379,\n",
       " 0.021147910650785882,\n",
       " 0.0003445946809755205,\n",
       " -0.011626686980711043,\n",
       " -0.00490719455870809,\n",
       " 0.015830950920238885,\n",
       " -0.029396528580036614,\n",
       " -0.004813914685977781,\n",
       " 0.006193126128682611,\n",
       " 0.016217395774649247,\n",
       " 0.02710450459261721,\n",
       " 0.02270701915720677,\n",
       " -0.011613360685899339,\n",
       " 0.011773269704381712,\n",
       " 0.019788688184637318,\n",
       " -0.0034213774141225385,\n",
       " 0.009634492053700124,\n",
       " -0.009401292604704995,\n",
       " -0.013845418674972527,\n",
       " -0.016390629225298162,\n",
       " 0.0025635345549376936,\n",
       " 0.010027600521177625,\n",
       " 0.006729486444619793,\n",
       " 0.014511704544557687,\n",
       " -0.00942794333168324,\n",
       " 0.01547115586148419,\n",
       " 0.00895488082062584,\n",
       " -0.0016707115688559984,\n",
       " 0.001046901575960965,\n",
       " -0.0047073089840970585,\n",
       " -0.023466585365183527,\n",
       " -0.011933178722864087,\n",
       " 0.017416710153638017,\n",
       " -0.0086617153732845,\n",
       " 0.01647058513152322,\n",
       " -0.013685509656490154,\n",
       " -0.020428322395921652,\n",
       " 0.024559293110968997,\n",
       " 0.004660668814901258,\n",
       " 0.015724344287035584,\n",
       " 0.015071384712262126,\n",
       " 0.018589373805648544,\n",
       " -0.005963257554898472,\n",
       " 0.0007462400877880405,\n",
       " 0.001171830118300521,\n",
       " 0.005750046151137027,\n",
       " -0.01237958957562066,\n",
       " 0.017483338833728792,\n",
       " -0.022173991579125737,\n",
       " -0.015031406759149596,\n",
       " 0.025145625868296842,\n",
       " 0.0010419043318218987,\n",
       " 0.011326857920302559,\n",
       " -0.008468492014756739,\n",
       " 0.014671612631717481,\n",
       " 0.011773269704381712,\n",
       " 0.004297543346596862,\n",
       " 0.010194172221404561,\n",
       " 0.005030457430611506,\n",
       " -0.01076717775259812,\n",
       " 0.0067128292745971,\n",
       " -0.023693122132434095,\n",
       " -0.03152864448029622,\n",
       " -0.0027684173736877912,\n",
       " -0.008035406525489288,\n",
       " 0.01595088105428615,\n",
       " 0.012292972850296202,\n",
       " -0.012146390126625531,\n",
       " 0.012233006851949989,\n",
       " -0.02113458528729676,\n",
       " -0.013359029869103426,\n",
       " 0.0044874348985910525,\n",
       " -0.0006883564685253096,\n",
       " 0.04965161566266419,\n",
       " 0.007555680867026037,\n",
       " 0.005316960661869576,\n",
       " 0.017496664197217914,\n",
       " 0.000522617894554751,\n",
       " -0.024692550471150546,\n",
       " 0.017270127429967346,\n",
       " -0.018416138492354468,\n",
       " 0.0014724915482657842,\n",
       " 0.04035026607809535,\n",
       " 0.025878539486650195,\n",
       " -0.017016938073093374,\n",
       " -0.013598892931165696,\n",
       " -0.007768892270787481,\n",
       " 0.024559293110968997,\n",
       " 0.013299063870757213,\n",
       " -0.017936412368229925,\n",
       " -0.017829807597671783,\n",
       " 0.0194288940572052,\n",
       " -0.0027401002777814707,\n",
       " -0.005286977662696471,\n",
       " -0.0075690062305151596,\n",
       " -0.0401104020847105,\n",
       " 0.015071384712262126,\n",
       " -0.0008078715237397484,\n",
       " -0.003851131795348354,\n",
       " -0.02204073421894419,\n",
       " -0.0016540543988333048,\n",
       " -0.02260041438664863,\n",
       " 0.007275840783173818,\n",
       " -0.03619264463606976,\n",
       " 0.019975246998775356,\n",
       " 0.011933178722864087,\n",
       " -0.029023409089115375,\n",
       " -0.007902149165307739,\n",
       " 0.001842280163976032,\n",
       " -0.032861214356821385,\n",
       " 0.0014425086655080004,\n",
       " -0.00016022090968360585,\n",
       " 0.02843707633178753,\n",
       " -0.010753852389108998,\n",
       " -0.0016290687602145873,\n",
       " 0.01123357851323354,\n",
       " 0.008548446989659215,\n",
       " -0.01728345279345647,\n",
       " 0.007015989210216574,\n",
       " -0.0024302774275867904,\n",
       " 0.026264986203705716,\n",
       " -0.013992001398643199,\n",
       " -0.011027029791216655,\n",
       " -0.0004108068270419369,\n",
       " 0.006269749297051517,\n",
       " 0.008455166651267616,\n",
       " -0.003757851689787399,\n",
       " -0.002618503076314195,\n",
       " -0.0022070715355472135,\n",
       " -0.0085684350348929,\n",
       " 0.0039277547308866146,\n",
       " -0.002267037301062781,\n",
       " 0.018749281892808337,\n",
       " -0.0012909286976982635,\n",
       " -0.022826951153899194,\n",
       " -0.011393486600393332,\n",
       " -0.006266417956179236,\n",
       " -0.013965349740342373,\n",
       " -0.008748332098608957,\n",
       " -0.014764892970109082,\n",
       " -0.02629163693068396,\n",
       " -0.01428516684598454,\n",
       " 0.0058833035113185755,\n",
       " 0.001676541531797812,\n",
       " 0.021720916181979442,\n",
       " 0.010014275157688502,\n",
       " -0.014405098842676966,\n",
       " 0.02157433345830877,\n",
       " 0.027824094710126604,\n",
       " -0.02365314604196673,\n",
       " -0.0009569529276876134,\n",
       " -0.006299731830563333,\n",
       " -7.870500903152122e-05,\n",
       " -0.007608983717966398,\n",
       " 0.0029150003301891074,\n",
       " 0.0068960576791854385,\n",
       " -0.00980772643567162,\n",
       " 0.027477625946183613,\n",
       " -0.014165235780614694,\n",
       " -0.024119544939956987,\n",
       " -0.03677897553075245,\n",
       " -0.005889966193063137,\n",
       " 0.015484481224973312,\n",
       " -0.012792687019654426,\n",
       " -0.0025768601512574612,\n",
       " -0.005413571875472167,\n",
       " 0.0006854414870544027,\n",
       " 0.018682653212717563,\n",
       " 0.02494573982802452,\n",
       " -0.012219681488460867,\n",
       " 0.019402241467581793,\n",
       " -0.004590708793938204,\n",
       " -0.001802303025770761,\n",
       " 0.005670092107557131,\n",
       " -0.02403959089637709,\n",
       " -0.007195886273932631,\n",
       " 0.008988195160671227,\n",
       " -0.001668213063201788,\n",
       " 0.009041497545950298,\n",
       " -0.017976390321342454,\n",
       " -0.01794973959436421,\n",
       " 0.007062629379412374,\n",
       " 0.022720344520695893,\n",
       " 0.0026035115767276415,\n",
       " -0.015177990414142847,\n",
       " -0.030355980828285695,\n",
       " -0.0004659836154306172,\n",
       " -0.00495050338703161,\n",
       " -0.0018622687912863286,\n",
       " 0.007555680867026037,\n",
       " -0.008588424011449164,\n",
       " -0.021054631243716863,\n",
       " 0.00041455467283474455,\n",
       " -0.011833235702727925,\n",
       " 0.005690080618452105,\n",
       " -0.008641726396728234,\n",
       " 0.005213686300861135,\n",
       " -0.016883680712911825,\n",
       " -0.011879875406262435,\n",
       " -0.03347419597848231,\n",
       " -0.02098800256362609,\n",
       " 0.0015932559145149896,\n",
       " 0.0076689492506513204,\n",
       " 0.015497807519785016,\n",
       " -0.015191315777631971,\n",
       " -0.027211111225820515,\n",
       " -0.007442412017739463,\n",
       " -0.040510174165255146,\n",
       " -0.020041875678866127,\n",
       " -0.01728345279345647,\n",
       " -0.0009919329381691407,\n",
       " 0.0169503093930026,\n",
       " 0.01647058513152322,\n",
       " -0.012159715490114653,\n",
       " 0.032035019468753846,\n",
       " 0.0069027208265912895,\n",
       " 0.033314287891322514,\n",
       " -0.020548252529968915,\n",
       " -0.019468870147672568,\n",
       " 0.024545967747479875,\n",
       " -0.010593944301949206,\n",
       " 0.007322480486708327,\n",
       " 0.004217588837355676,\n",
       " -0.010447360646955953,\n",
       " -0.0213211441014348,\n",
       " 0.02246715702646708,\n",
       " 0.0023070145556833748,\n",
       " 0.009261372562778885,\n",
       " 0.02096134997400268,\n",
       " 0.004827240515128194,\n",
       " -0.028250517517649495,\n",
       " -0.008675040736773621,\n",
       " 0.01861602453262679,\n",
       " 0.0011318529800952502,\n",
       " 0.0033064431272304693,\n",
       " -0.0006021557533562577,\n",
       " -0.00714258342299227,\n",
       " 0.0035013316905330803,\n",
       " 0.0036512459879066766,\n",
       " 0.0003806157645834662,\n",
       " -0.0023869688320939165,\n",
       " -0.0047073089840970585,\n",
       " 0.004727297494992033,\n",
       " -0.004414143071094427,\n",
       " 0.0022104031092501394,\n",
       " -0.03379401587809222,\n",
       " -0.006076526404185046,\n",
       " -0.01000094979419938,\n",
       " -0.016417281814921567,\n",
       " 0.00985436707052871,\n",
       " -0.014165235780614694,\n",
       " -0.005670092107557131,\n",
       " 0.03358080261168561,\n",
       " 0.0038977717317135088,\n",
       " -0.012466207232267698,\n",
       " -0.011879875406262435,\n",
       " 0.02013515694858031,\n",
       " -0.013912047355063302,\n",
       " -0.0057766978094378535,\n",
       " 0.003531314689706187,\n",
       " -0.011486766938784932,\n",
       " 0.0016274029733631243,\n",
       " -0.0008507636434159262,\n",
       " -0.0008720015235533281,\n",
       " -0.015151338755842023,\n",
       " 0.002338662992461976,\n",
       " -0.0046440116448785655,\n",
       " -0.006699503445446687,\n",
       " -0.018269555768683797,\n",
       " 0.00226204028975436,\n",
       " 0.014511704544557687,\n",
       " -0.025771934716092054,\n",
       " -0.012712732976074531,\n",
       " -0.020641533799683094,\n",
       " 0.02013515694858031,\n",
       " 0.0005276150222784945,\n",
       " -0.005087092088085439,\n",
       " -0.009827715412227885,\n",
       " -0.010207498516216265,\n",
       " 0.014764892970109082,\n",
       " 0.023932984263173786,\n",
       " -0.013485624547540412,\n",
       " 0.000838270765898906,\n",
       " 0.013552252296308605,\n",
       " 0.014405098842676966,\n",
       " -0.0036212632215642158,\n",
       " 0.008388537971176842,\n",
       " 0.23197405199593576,\n",
       " 0.005710069129347079,\n",
       " 0.017390059426659773,\n",
       " 0.03243479154929849,\n",
       " -0.0063930121689549325,\n",
       " 0.033687409244888916,\n",
       " 0.007542355037875624,\n",
       " -0.010100892814335542,\n",
       " -0.008435177674711351,\n",
       " 0.021401100007659855,\n",
       " 0.01628402445474002,\n",
       " 0.014591658588137584,\n",
       " -0.005140394939025799,\n",
       " 0.005256994663523364,\n",
       " -0.002038834397714783,\n",
       " -0.0019338944826855237,\n",
       " -0.023160094554353066,\n",
       " -0.02166761286537779,\n",
       " -0.03517989093386419,\n",
       " -0.01671044726226291,\n",
       " 0.0011418472355427373,\n",
       " -0.022000756265831662,\n",
       " 0.01917570470033123,\n",
       " -0.010927086771080495,\n",
       " 0.014604983951626706,\n",
       " -0.01613744173106935,\n",
       " -0.019988574224909638,\n",
       " -0.001730677334371566,\n",
       " 0.021640962138399545,\n",
       " 0.020921373883535314,\n",
       " -0.013578903954609431,\n",
       " 0.0012567815224348064,\n",
       " 0.012739383703052776,\n",
       " -0.003974394434421124,\n",
       " -0.03136873266784611,\n",
       " -0.005650103596662157,\n",
       " 0.030542539642423733,\n",
       " -0.003741194752595351,\n",
       " 0.02557204867581973,\n",
       " -0.008401863334665964,\n",
       " 0.006229771809600279,\n",
       " -0.02438605966032008,\n",
       " 0.006462972189917988,\n",
       " -0.014338470162586192,\n",
       " 0.0044874348985910525,\n",
       " 0.026957921868946542,\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(text)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.0031584087512342572,\n",
       "  0.011094410212838685,\n",
       "  -0.004001317166816525,\n",
       "  -0.011747414500761147,\n",
       "  -0.0010153218392504927,\n",
       "  0.010781234363886399,\n",
       "  -0.010368109905383128,\n",
       "  -0.0052973312542353886,\n",
       "  -0.00988168756470157,\n",
       "  -0.026160153195893116,\n",
       "  0.02037639960097617,\n",
       "  0.022575293225485345,\n",
       "  -0.007522876537439858,\n",
       "  0.01728462465309313,\n",
       "  -0.0060036416535162295,\n",
       "  0.01912369806781222,\n",
       "  0.02125595742330888,\n",
       "  -0.015645450320121206,\n",
       "  0.007669469042167345,\n",
       "  -0.018364081557173,\n",
       "  -0.0006909018997805782,\n",
       "  -0.006416767043342096,\n",
       "  -0.010981134376956157,\n",
       "  0.017950956167347133,\n",
       "  -0.022135513382996398,\n",
       "  -0.0030767832152439494,\n",
       "  0.014379421560625712,\n",
       "  -0.029984892064397486,\n",
       "  0.018524000822570733,\n",
       "  -0.007916012019091008,\n",
       "  0.010068260351439788,\n",
       "  -0.019456863824939222,\n",
       "  -0.003688141783525537,\n",
       "  -0.02424112014847516,\n",
       "  -0.005530547004827511,\n",
       "  0.0038247395669963142,\n",
       "  -0.005653818260458694,\n",
       "  -0.029451827225523322,\n",
       "  0.018603960455269596,\n",
       "  -0.016618293138839127,\n",
       "  0.0075295396849443304,\n",
       "  0.012420408696858325,\n",
       "  -0.000990334337616773,\n",
       "  -0.01072126463936225,\n",
       "  0.010001627945072464,\n",
       "  -0.012560338054081339,\n",
       "  0.03352977408110101,\n",
       "  -0.026999729339231202,\n",
       "  -0.007929338314099954,\n",
       "  0.029025376472011102,\n",
       "  0.01969674272303582,\n",
       "  -0.002077286642354891,\n",
       "  -0.02739952936537072,\n",
       "  -0.008775579001926404,\n",
       "  -0.006213536155012048,\n",
       "  0.0019939954359037893,\n",
       "  -0.007382946714555546,\n",
       "  0.027985899384280664,\n",
       "  0.006829892433167963,\n",
       "  -0.009315306522643745,\n",
       "  -0.022482006366454938,\n",
       "  0.010468059446256709,\n",
       "  -0.013546508099130803,\n",
       "  -0.011094410212838685,\n",
       "  -0.0048875376709924066,\n",
       "  -0.008275830366235902,\n",
       "  -0.0058237324799437825,\n",
       "  0.0111144001210134,\n",
       "  0.006276837686119082,\n",
       "  0.004434432464817108,\n",
       "  0.010568008987130291,\n",
       "  0.012480378421382474,\n",
       "  0.005337311070584821,\n",
       "  0.005393948988526085,\n",
       "  0.008988804378682514,\n",
       "  0.0042611864387491335,\n",
       "  -0.022681905448202103,\n",
       "  -0.013233332250178519,\n",
       "  0.011201023366878036,\n",
       "  -0.005753767801332276,\n",
       "  0.009828381453343192,\n",
       "  -0.024401039413872894,\n",
       "  -0.008582342602022416,\n",
       "  0.007829388773226373,\n",
       "  0.0025037385600203523,\n",
       "  0.007549529593119047,\n",
       "  0.005747104653827803,\n",
       "  0.028172473102341476,\n",
       "  -0.022908457119967154,\n",
       "  -0.015525510871072908,\n",
       "  -0.00818254443852809,\n",
       "  0.020056561070180712,\n",
       "  0.003568202334477239,\n",
       "  0.01278689065716899,\n",
       "  -0.016458373873441397,\n",
       "  0.03155743399100209,\n",
       "  0.013506528282781372,\n",
       "  0.030437997270572784,\n",
       "  -0.006240189210691237,\n",
       "  -0.0496816347874333,\n",
       "  -0.003728121599874969,\n",
       "  -0.0013001782635708487,\n",
       "  -0.0070631081837600855,\n",
       "  0.003524890711544921,\n",
       "  -0.03483578265694594,\n",
       "  -0.009062101329538204,\n",
       "  0.021975594117598665,\n",
       "  -0.007236354209828059,\n",
       "  0.015485531054723474,\n",
       "  -0.008295820274410618,\n",
       "  -0.016445048509755048,\n",
       "  0.005060783697060381,\n",
       "  -0.0063901139876629065,\n",
       "  -0.03611513678012778,\n",
       "  0.015618797730103313,\n",
       "  0.005653818260458694,\n",
       "  0.006503389823545434,\n",
       "  -0.0218956344848998,\n",
       "  -0.010248169525012235,\n",
       "  0.0010503041785562463,\n",
       "  0.0006350967006543871,\n",
       "  0.016938133532279777,\n",
       "  0.02651997154303801,\n",
       "  -0.027506141588087472,\n",
       "  0.010548019078955573,\n",
       "  0.01327331206652795,\n",
       "  -0.008822221500119012,\n",
       "  -0.041872237785026835,\n",
       "  -0.006493394869458076,\n",
       "  -0.005567195014594058,\n",
       "  0.01913702529414376,\n",
       "  0.021482509095073935,\n",
       "  0.014192848773887495,\n",
       "  0.017511178187503376,\n",
       "  -0.023348236962456106,\n",
       "  0.03734118572327384,\n",
       "  -0.04040630994378418,\n",
       "  0.02477418498734933,\n",
       "  -0.04320489708824446,\n",
       "  -0.008409096110293146,\n",
       "  0.008309146569419563,\n",
       "  0.027372874912707637,\n",
       "  -0.019150350657830113,\n",
       "  -0.01696478612229767,\n",
       "  0.010288150272684262,\n",
       "  0.013992949692140332,\n",
       "  0.008262504071226955,\n",
       "  -0.02484081739371665,\n",
       "  0.012493705647714015,\n",
       "  -0.021056058341561715,\n",
       "  0.0031051021742145813,\n",
       "  0.0017724403098598187,\n",
       "  0.017764382449286322,\n",
       "  0.002560376710792265,\n",
       "  0.015565490687422339,\n",
       "  0.03147747435830322,\n",
       "  0.003858056235841274,\n",
       "  -0.009548522738897164,\n",
       "  -0.018004261347382918,\n",
       "  -0.019616783090336952,\n",
       "  0.0031034365037537876,\n",
       "  0.022162167835659476,\n",
       "  0.00956851264707188,\n",
       "  0.0018540658458501265,\n",
       "  0.023454849185172863,\n",
       "  0.03467586339154821,\n",
       "  0.00400464897339941,\n",
       "  0.007669469042167345,\n",
       "  -0.001613353763277161,\n",
       "  -0.015418897717033555,\n",
       "  -0.025027391111777462,\n",
       "  0.024760857761017788,\n",
       "  -0.025387209458922356,\n",
       "  0.0076494791339926285,\n",
       "  -0.02017650051922901,\n",
       "  0.014299461927926848,\n",
       "  0.007189710780312856,\n",
       "  0.003481579088612603,\n",
       "  -0.004424437510729749,\n",
       "  -0.0040546237438362,\n",
       "  -0.03390291779193226,\n",
       "  0.016844846673249373,\n",
       "  0.014792546950451579,\n",
       "  0.031850618069134466,\n",
       "  -0.017004765938647103,\n",
       "  -0.006936505121546017,\n",
       "  0.02424112014847516,\n",
       "  -0.009541859125731394,\n",
       "  0.0013884670634809538,\n",
       "  -0.004634331546564271,\n",
       "  0.02314833788070894,\n",
       "  0.021935614301249233,\n",
       "  -0.006290163981128028,\n",
       "  -0.014805873245460526,\n",
       "  -0.7023661288825848,\n",
       "  -0.01635176165072464,\n",
       "  0.0042611864387491335,\n",
       "  -0.017311277243111024,\n",
       "  0.02217549319934583,\n",
       "  0.031370860272941274,\n",
       "  0.02464091831196949,\n",
       "  0.0020939449767773707,\n",
       "  -0.005986983551924398,\n",
       "  0.021855654668550367,\n",
       "  -0.022668578221870562,\n",
       "  -0.012700267411304355,\n",
       "  -0.009202030686761217,\n",
       "  -0.013206679660160626,\n",
       "  -0.014139542662529116,\n",
       "  -0.02314833788070894,\n",
       "  -0.01695145889596613,\n",
       "  -0.0033249913969671096,\n",
       "  -0.017604463183888593,\n",
       "  0.013106730119287044,\n",
       "  0.014979119737189796,\n",
       "  0.015472204759714529,\n",
       "  -0.01571208458913372,\n",
       "  -0.016711579997869534,\n",
       "  0.0005126583966689254,\n",
       "  0.008935498267324135,\n",
       "  0.013100066506121274,\n",
       "  -0.006123581568225824,\n",
       "  0.017484523734840295,\n",
       "  0.016884826489598805,\n",
       "  -0.026240112828591983,\n",
       "  -0.0035215591377926844,\n",
       "  -0.0009320303999687423,\n",
       "  0.008535699172507214,\n",
       "  0.033236586277678254,\n",
       "  -0.002067291688267533,\n",
       "  -0.014472708419656118,\n",
       "  -0.025040716475463815,\n",
       "  0.016604967775152777,\n",
       "  0.0009203696007976038,\n",
       "  -0.01680486685689994,\n",
       "  -0.0003496155334959091,\n",
       "  0.004830899287389846,\n",
       "  -0.0017291288033428253,\n",
       "  -0.004571030481118534,\n",
       "  -0.0024737536977582778,\n",
       "  0.01883051212703465,\n",
       "  0.0003673149410602162,\n",
       "  0.0274528345454065,\n",
       "  0.017684422816587456,\n",
       "  -0.016578313322489695,\n",
       "  -0.0005447255216299788,\n",
       "  0.006663309554604462,\n",
       "  -0.0035182273312097992,\n",
       "  0.0010453067015125672,\n",
       "  -0.010421416016741507,\n",
       "  0.02160244854412223,\n",
       "  0.00775609228803198,\n",
       "  0.010834541406567373,\n",
       "  0.016604967775152777,\n",
       "  -0.001151086671075549,\n",
       "  0.011860691267966269,\n",
       "  -0.005657149601380282,\n",
       "  -0.016871499263267264,\n",
       "  -0.028945416839312236,\n",
       "  -0.007496223016099372,\n",
       "  -0.020776199627115688,\n",
       "  0.02253531340913591,\n",
       "  0.0010594661809978831,\n",
       "  -0.01899043139243238,\n",
       "  -0.0037581064621370437,\n",
       "  0.012520358237731908,\n",
       "  -0.010261496751343776,\n",
       "  -0.01972339531305371,\n",
       "  0.020749545174452606,\n",
       "  0.015485531054723474,\n",
       "  0.009761748115653274,\n",
       "  -0.00994832090239149,\n",
       "  -0.009355286338993176,\n",
       "  0.01677821240423686,\n",
       "  0.0037014683113651315,\n",
       "  0.0036215086786662663,\n",
       "  -0.014366095265616767,\n",
       "  -0.015418897717033555,\n",
       "  0.010847867701576318,\n",
       "  -0.020283114604590955,\n",
       "  -0.04611010204335707,\n",
       "  -0.01296013714889826,\n",
       "  -0.0066999575643710094,\n",
       "  0.013386588833733074,\n",
       "  0.02160244854412223,\n",
       "  0.001438441950333069,\n",
       "  -0.007955991835440442,\n",
       "  -0.00046601519998437115,\n",
       "  0.008908844745983647,\n",
       "  -0.002800255841719509,\n",
       "  0.0011885678653184664,\n",
       "  0.003934684294787902,\n",
       "  0.03009150614975943,\n",
       "  -0.0019306939047967551,\n",
       "  0.0015000775781486605,\n",
       "  0.00244710040924844,\n",
       "  0.0006804904698703595,\n",
       "  0.011740750887595377,\n",
       "  0.02112269074792904,\n",
       "  0.0052240347690409965,\n",
       "  0.003648161967176104,\n",
       "  0.024467671820240216,\n",
       "  0.018270794698142596,\n",
       "  -0.008495719356157781,\n",
       "  -0.0071697208721381404,\n",
       "  -0.008995467991848284,\n",
       "  -0.009535195512565623,\n",
       "  0.0015650447797164885,\n",
       "  -0.016071902936278613,\n",
       "  -0.03416945114269194,\n",
       "  0.007989308038624103,\n",
       "  0.011241003183227469,\n",
       "  0.0023404874880397367,\n",
       "  0.0033899585985349375,\n",
       "  0.014059583029830252,\n",
       "  0.01772440263293689,\n",
       "  0.013299965587868438,\n",
       "  -0.001631677884575759,\n",
       "  0.0045843567761274795,\n",
       "  -0.002488746128889315,\n",
       "  0.003974664111137336,\n",
       "  -0.01943021123492133,\n",
       "  -0.017204665020394267,\n",
       "  -0.009701778391129125,\n",
       "  -0.019456863824939222,\n",
       "  -0.0017857669541147378,\n",
       "  0.03371634779916183,\n",
       "  -0.014166196183869604,\n",
       "  0.007702785711012305,\n",
       "  0.0023038392454425407,\n",
       "  0.003831402947331436,\n",
       "  -0.005277340880399375,\n",
       "  0.021349244282339284,\n",
       "  -0.009748421820644327,\n",
       "  -0.013020106873422409,\n",
       "  0.013313291882877384,\n",
       "  -0.006963158177225206,\n",
       "  -0.009068764011381378,\n",
       "  -0.01195397719567408,\n",
       "  -0.022308759874725668,\n",
       "  -0.01801758857371446,\n",
       "  -0.0030268084448071587,\n",
       "  0.0009944989794300552,\n",
       "  0.00994165728922572,\n",
       "  -0.022068880976629072,\n",
       "  0.0014101228749471128,\n",
       "  -0.010128230075963937,\n",
       "  -0.005847054194701384,\n",
       "  -0.008095921192663455,\n",
       "  -0.011081083917829738,\n",
       "  -0.017044745754996534,\n",
       "  -0.026293419871272955,\n",
       "  0.0010411420596992851,\n",
       "  -0.001472591337993101,\n",
       "  -0.008648975939712335,\n",
       "  0.0175778105938707,\n",
       "  -0.006223531109099406,\n",
       "  0.0011360942399445118,\n",
       "  -0.02653329876936955,\n",
       "  -0.018310774514492027,\n",
       "  -0.03302336183224474,\n",
       "  0.03318328109764247,\n",
       "  -0.009988300718740923,\n",
       "  -0.033876267064559554,\n",
       "  -0.01835075433084146,\n",
       "  0.005207376201787868,\n",
       "  -0.013473212079597709,\n",
       "  -0.0020423043030491374,\n",
       "  0.005070778651147739,\n",
       "  -0.010587998895305007,\n",
       "  -0.015685430136470637,\n",
       "  0.007862704976410034,\n",
       "  0.010328130089033695,\n",
       "  -0.021349244282339284,\n",
       "  -0.004967497303691272,\n",
       "  0.0034749159411081305,\n",
       "  0.012227173228276933,\n",
       "  0.002070623494850418,\n",
       "  0.011760740795770093,\n",
       "  0.015059079369888661,\n",
       "  0.013479874761440884,\n",
       "  0.007049781423089842,\n",
       "  -0.012600317870430772,\n",
       "  0.002543718376369785,\n",
       "  0.00800263433363305,\n",
       "  0.0033033355855009504,\n",
       "  -0.014659281206394335,\n",
       "  0.009321970135809515,\n",
       "  -0.007702785711012305,\n",
       "  0.019856661988433548,\n",
       "  -0.029718360576282996,\n",
       "  0.010421416016741507,\n",
       "  0.01288684019804257,\n",
       "  0.023841321984980835,\n",
       "  0.022588618589171695,\n",
       "  0.008655638621555512,\n",
       "  0.0038880410981033484,\n",
       "  -0.022748537854569425,\n",
       "  0.00016585394401008583,\n",
       "  -0.035422154538501074,\n",
       "  -0.013126720027461762,\n",
       "  -0.002710301022102637,\n",
       "  0.013533181804121858,\n",
       "  0.00628683264020644,\n",
       "  0.01288684019804257,\n",
       "  -0.0175778105938707,\n",
       "  -0.02468089812831892,\n",
       "  0.017364584285791997,\n",
       "  0.021549143364086448,\n",
       "  0.005447255565545761,\n",
       "  -0.010128230075963937,\n",
       "  -0.002821911653185668,\n",
       "  -0.006803238911827476,\n",
       "  -0.0020256459686266576,\n",
       "  0.006739937380720442,\n",
       "  0.004847557854642974,\n",
       "  0.012520358237731908,\n",
       "  -0.007276334026177492,\n",
       "  -0.016258474791694233,\n",
       "  0.011507535602664551,\n",
       "  0.028598923855853695,\n",
       "  0.03262356366875042,\n",
       "  0.02300174397899756,\n",
       "  -0.024147833289444757,\n",
       "  -0.018390734147190894,\n",
       "  0.0025986906238502547,\n",
       "  0.0008878860000136897,\n",
       "  0.0012443730644446575,\n",
       "  0.0031684037053216155,\n",
       "  0.010474722128099884,\n",
       "  0.02240204673375607,\n",
       "  -0.01941688400858979,\n",
       "  0.028758843121251425,\n",
       "  0.0003606516189327567,\n",
       "  0.011480882081324065,\n",
       "  0.018857166579697732,\n",
       "  0.028625578308516777,\n",
       "  -0.008495719356157781,\n",
       "  0.022921784346298695,\n",
       "  -0.00012087659968526976,\n",
       "  0.028172473102341476,\n",
       "  0.008575678988856646,\n",
       "  -0.004051291937253315,\n",
       "  0.03153077953833901,\n",
       "  -0.010707938344353305,\n",
       "  0.0018573975360176873,\n",
       "  0.0009944989794300552,\n",
       "  0.004204548055146573,\n",
       "  0.032463644403352684,\n",
       "  -0.02685313730016501,\n",
       "  -0.013399915128742019,\n",
       "  0.0019190331638332789,\n",
       "  0.014326115449267334,\n",
       "  0.03115763582750776,\n",
       "  0.02221547301569526,\n",
       "  0.0050208038807109485,\n",
       "  -0.002633672963156008,\n",
       "  0.0012277147300221777,\n",
       "  0.023188317697058373,\n",
       "  -0.004537713812273574,\n",
       "  -0.013226669568335342,\n",
       "  0.0034066169329574174,\n",
       "  -0.019976601437481846,\n",
       "  -0.013040096781597127,\n",
       "  -0.005637159693205566,\n",
       "  -0.0014459381658985875,\n",
       "  0.01805756839006389,\n",
       "  0.0024820827485541935,\n",
       "  0.02464091831196949,\n",
       "  0.010581335282139236,\n",
       "  0.02590694707146498,\n",
       "  0.012020610533364,\n",
       "  0.016458373873441397,\n",
       "  0.0014925813625831419,\n",
       "  -0.009102081145887635,\n",
       "  -0.022428699323773966,\n",
       "  0.0006725777784819802,\n",
       "  0.012207183320102217,\n",
       "  0.012280479339635312,\n",
       "  -0.011687444776236998,\n",
       "  -0.010228179616837519,\n",
       "  0.0046576532613218724,\n",
       "  -0.007462906812915709,\n",
       "  0.006500058482623847,\n",
       "  0.004001317166816525,\n",
       "  -1.1660791895180796e-05,\n",
       "  0.01709805279767751,\n",
       "  -0.02316166324439529,\n",
       "  -5.3124274259723366e-05,\n",
       "  0.015978616077248205,\n",
       "  0.008835548726450553,\n",
       "  -0.0055572000605067,\n",
       "  -0.010148219984138653,\n",
       "  -0.007816062478217426,\n",
       "  0.011201023366878036,\n",
       "  -0.007576182648798236,\n",
       "  0.00879556891010112,\n",
       "  0.00620354120092469,\n",
       "  0.020149847929211116,\n",
       "  0.0002575785675953825,\n",
       "  -0.002617014861564177,\n",
       "  -0.01295347353573249,\n",
       "  -0.013466548466431938,\n",
       "  -0.010301476567693209,\n",
       "  0.01801758857371446,\n",
       "  0.0038114130391567196,\n",
       "  -0.014006276918471873,\n",
       "  -0.005980320404419925,\n",
       "  0.015565490687422339,\n",
       "  -0.005697129417729715,\n",
       "  0.0015317282272868532,\n",
       "  0.013319955496043154,\n",
       "  0.01681819222058629,\n",
       "  0.012826870473518421,\n",
       "  -0.015352265310666231,\n",
       "  -0.00684988234134268,\n",
       "  -0.018097548206413325,\n",
       "  0.01072126463936225,\n",
       "  0.04882873328040887,\n",
       "  0.04315159190820868,\n",
       "  0.0025637082845445013,\n",
       "  -0.010941154560606724,\n",
       "  0.003691473357277773,\n",
       "  -0.019363576965908815,\n",
       "  -0.026959749522881767,\n",
       "  -0.013499864669615601,\n",
       "  0.006393445328584495,\n",
       "  -0.0021755705127676785,\n",
       "  -0.00785604229456686,\n",
       "  -0.0043211561632732825,\n",
       "  0.016285129244357315,\n",
       "  0.001352651772529479,\n",
       "  0.016618293138839127,\n",
       "  0.007116414295118464,\n",
       "  -0.0014392749019787902,\n",
       "  -0.0024820827485541935,\n",
       "  -0.009448573198023582,\n",
       "  -0.012260489431460596,\n",
       "  0.0029385195284817294,\n",
       "  0.007702785711012305,\n",
       "  0.007629489225817913,\n",
       "  0.0033932904051178227,\n",
       "  0.012073916644722378,\n",
       "  -0.021349244282339284,\n",
       "  0.0077227756191870205,\n",
       "  0.0016916477255152322,\n",
       "  0.00025570451370400283,\n",
       "  -0.02036307423728982,\n",
       "  -0.014152868957538063,\n",
       "  0.019230310290528976,\n",
       "  0.010101577485946044,\n",
       "  0.018097548206413325,\n",
       "  -0.0006234359014832486,\n",
       "  0.03286344256684701,\n",
       "  -0.004447759225487351,\n",
       "  -0.01573873717915161,\n",
       "  0.00778940895687694,\n",
       "  0.004840894241477204,\n",
       "  0.009222020594935933,\n",
       "  0.004571030481118534,\n",
       "  -0.00339162450182638,\n",
       "  -0.008269166753070132,\n",
       "  -0.007129741055788707,\n",
       "  0.00024820826903465315,\n",
       "  -0.016604967775152777,\n",
       "  0.0033999535526222954,\n",
       "  -0.008662302234721283,\n",
       "  -0.00755619274062352,\n",
       "  0.012080580257888149,\n",
       "  -0.01773772985926843,\n",
       "  -0.0012060590349713433,\n",
       "  -0.015445551238374041,\n",
       "  0.028732190531233534,\n",
       "  0.02326827732975724,\n",
       "  0.004401115795972148,\n",
       "  0.006843218728176909,\n",
       "  -0.0021672414619717632,\n",
       "  -0.017564483367539158,\n",
       "  -0.02987827984168073,\n",
       "  -0.0067499323348078006,\n",
       "  -0.011367606245441537,\n",
       "  -0.009301980227634798,\n",
       "  -0.011380932540450483,\n",
       "  -0.030411344680554894,\n",
       "  -0.023494829001522295,\n",
       "  -0.013333282722374695,\n",
       "  -0.02017650051922901,\n",
       "  0.0037381165539623275,\n",
       "  0.010987797058799332,\n",
       "  -0.01759113782020224,\n",
       "  -0.024760857761017788,\n",
       "  -0.016231822201676342,\n",
       "  0.02899872201934802,\n",
       "  -0.0139529698757909,\n",
       "  0.0005209875056725032,\n",
       "  0.013106730119287044,\n",
       "  0.0015358928691001352,\n",
       "  0.022588618589171695,\n",
       "  -0.010861193996585264,\n",
       "  -0.02249533359278648,\n",
       "  0.005863712296293216,\n",
       "  -0.024147833289444757,\n",
       "  -0.005843722388118499,\n",
       "  0.016858173899580914,\n",
       "  -0.00397133230455445,\n",
       "  0.006753264141390686,\n",
       "  -0.0027519467417435124,\n",
       "  0.010421416016741507,\n",
       "  -0.006043621469865662,\n",
       "  -0.0024654244141317136,\n",
       "  -0.004880874057826637,\n",
       "  -0.029371867592824456,\n",
       "  0.01635176165072464,\n",
       "  -0.008728935572411202,\n",
       "  0.0019939954359037893,\n",
       "  0.007442916904740993,\n",
       "  -0.008668965847887053,\n",
       "  -0.004154573284709782,\n",
       "  -0.015538838097404448,\n",
       "  -0.0015217332731994949,\n",
       "  -0.009128733735905527,\n",
       "  0.0016108550247553213,\n",
       "  0.020749545174452606,\n",
       "  -0.019030411208781815,\n",
       "  -0.013373262538724128,\n",
       "  0.016911479079616695,\n",
       "  -0.02329492991977513,\n",
       "  -0.0077094488585167775,\n",
       "  -0.010488049354431424,\n",
       "  -0.018137528022762757,\n",
       "  0.009601828850255543,\n",
       "  -0.020003255890144928,\n",
       "  0.002393793832228764,\n",
       "  0.01741789132847297,\n",
       "  -0.007442916904740993,\n",
       "  0.021948941527580774,\n",
       "  -0.010301476567693209,\n",
       "  -0.03019811837247619,\n",
       "  7.584720315855387e-05,\n",
       "  -0.009808391545168476,\n",
       "  0.011094410212838685,\n",
       "  0.03563537898393459,\n",
       "  0.022068880976629072,\n",
       "  0.029211948327426726,\n",
       "  -0.008762251775594863,\n",
       "  -0.003048464023442669,\n",
       "  -0.014206176000219036,\n",
       "  0.007909348405925238,\n",
       "  -0.005074109992069326,\n",
       "  0.001172742482541708,\n",
       "  -0.0077960721043814135,\n",
       "  -0.004184558146971856,\n",
       "  -0.01884383935336619,\n",
       "  -0.011447565878140402,\n",
       "  -0.0015292294887650135,\n",
       "  0.013646457640004385,\n",
       "  -0.005264014585390429,\n",
       "  -0.010661294914838101,\n",
       "  -0.015059079369888661,\n",
       "  0.013673111161344871,\n",
       "  0.01139425883545943,\n",
       "  -0.009168713552254959,\n",
       "  -0.02572037521604936,\n",
       "  -0.029824972798999753,\n",
       "  -0.021655755586803205,\n",
       "  0.010108240167789221,\n",
       "  -0.020602953135386418,\n",
       "  0.000884554309846129,\n",
       "  0.021096038157911147,\n",
       "  0.0003396205503047198,\n",
       "  -0.011647464959887565,\n",
       "  -0.004904195772584238,\n",
       "  0.015818696811850476,\n",
       "  -0.029371867592824456,\n",
       "  -0.004824236139885373,\n",
       "  0.006163561384575258,\n",
       "  0.016231822201676342,\n",
       "  0.0271196687882795,\n",
       "  0.022681905448202103,\n",
       "  -0.01163413866487862,\n",
       "  0.011707434684411714,\n",
       "  0.01986998921476509,\n",
       "  -0.00342494117067134,\n",
       "  0.009635145053439206,\n",
       "  -0.009441909584857812,\n",
       "  -0.013779724315384224,\n",
       "  -0.01637841424074253,\n",
       "  0.0025637082845445013,\n",
       "  0.010008290626915639,\n",
       "  0.0067599272888951584,\n",
       "  0.014486034714665065,\n",
       "  -0.009415256063517325,\n",
       "  0.015485531054723474,\n",
       "  0.009002130673691459,\n",
       "  -0.0016783210812603131,\n",
       "  0.0010244838416921295,\n",
       "  -0.0046709800219921155,\n",
       "  -0.023508156227853835,\n",
       "  -0.011907333766158877,\n",
       "  0.01741789132847297,\n",
       "  -0.00862898603153762,\n",
       "  0.016551660732471805,\n",
       "  -0.01363979495816121,\n",
       "  -0.020389726827307712,\n",
       "  0.024547631452939082,\n",
       "  0.0046443265006516285,\n",
       "  0.015698757362802178,\n",
       "  0.015045753074879716,\n",
       "  0.018590633228938055,\n",
       "  -0.005986983551924398,\n",
       "  0.0007916844505075432,\n",
       "  0.0011752412210635475,\n",
       "  0.005747104653827803,\n",
       "  -0.01234044906415946,\n",
       "  0.017471198371153945,\n",
       "  -0.02221547301569526,\n",
       "  -0.015059079369888661,\n",
       "  0.025080696291813247,\n",
       "  0.0010053267687478102,\n",
       "  0.011334289110935281,\n",
       "  -0.008489056674314606,\n",
       "  0.014699261022743769,\n",
       "  0.011847364041634728,\n",
       "  0.004257854632166248,\n",
       "  0.010148219984138653,\n",
       "  0.005030798834798306,\n",
       "  -0.010767908068877454,\n",
       "  0.006743269187303327,\n",
       "  -0.023681402719583106,\n",
       "  -0.0315041288109663,\n",
       "  -0.0027719366499182286,\n",
       "  -0.00801596155996459,\n",
       "  0.015978616077248205,\n",
       "  0.012300469247810027,\n",
       "  -0.012140549982412298,\n",
       "  0.012200519706936447,\n",
       "  -0.021136017974260582,\n",
       "  -0.013393252446898844,\n",
       "  0.004514392097515973,\n",
       "  -0.0007025626989517168,\n",
       "  0.04962832960739752,\n",
       "  0.007536202832448804,\n",
       "  0.005323984309914578,\n",
       "  0.017511178187503376,\n",
       "  0.000552638213018358,\n",
       "  -0.024707550718336812,\n",
       "  0.017231317610412158,\n",
       "  -0.018364081557173,\n",
       "  0.0014717585027627042,\n",
       "  0.040379655491121096,\n",
       "  0.02589361984513344,\n",
       "  -0.017044745754996534,\n",
       "  -0.013606477823654952,\n",
       "  -0.0077361023798572645,\n",
       "  0.024534306089252732,\n",
       "  0.013326619109208925,\n",
       "  -0.017950956167347133,\n",
       "  -0.017817689491967294,\n",
       "  0.01944353659860768,\n",
       "  -0.0027286252598165595,\n",
       "  -0.005277340880399375,\n",
       "  -0.007569519501293764,\n",
       "  -0.040113122140361425,\n",
       "  0.015085732891229149,\n",
       "  -0.000767529958727207,\n",
       "  -0.003831402947331436,\n",
       "  -0.022068880976629072,\n",
       "  -0.0016899818222237896,\n",
       "  -0.022588618589171695,\n",
       "  0.007322976990031397,\n",
       "  -0.03619509641282665,\n",
       "  0.019936621621132414,\n",
       "  0.011894007471149931,\n",
       "  -0.02899872201934802,\n",
       "  -0.007876032202741575,\n",
       "  0.0018640607999374846,\n",
       "  -0.03286344256684701,\n",
       "  0.0014317785699979471,\n",
       "  -0.00015939885979405666,\n",
       "  0.028465657180473856,\n",
       "  -0.010747918160702738,\n",
       "  -0.001590865116580605,\n",
       "  0.011227676888218524,\n",
       "  0.008529036490664037,\n",
       "  -0.0172446448367437,\n",
       "  0.007029791514915126,\n",
       "  -0.0024487663125398827,\n",
       "  0.026293419871272955,\n",
       "  -0.013992949692140332,\n",
       "  -0.01102111419330559,\n",
       "  -0.00037626876379808486,\n",
       "  0.006300158935215386,\n",
       "  0.008462403152974118,\n",
       "  -0.0037414483605452127,\n",
       "  -0.002617014861564177,\n",
       "  -0.002217216232408554,\n",
       "  -0.008595668897031363,\n",
       "  0.003914694386613187,\n",
       "  -0.0022521985717143074,\n",
       "  0.018750552494335788,\n",
       "  -0.0013176694332237254,\n",
       "  -0.022855151939931373,\n",
       "  -0.011407586061790969,\n",
       "  -0.006263510925448839,\n",
       "  -0.013979623397131387,\n",
       "  -0.008742261867420147,\n",
       "  -0.014792546950451579,\n",
       "  -0.026240112828591983,\n",
       "  -0.014246155816568469,\n",
       "  0.005870375443797688,\n",
       "  0.0016699919140490734,\n",
       "  0.021709062629484178,\n",
       "  0.009974974423731978,\n",
       "  -0.014406075081966199,\n",
       "  0.021549143364086448,\n",
       "  0.027852632708900826,\n",
       "  -0.023694728083269456,\n",
       "  -0.0009420253540561005,\n",
       "  -0.006356797318817948,\n",
       "  -5.944921341908747e-05,\n",
       "  -0.0076161629308089665,\n",
       "  0.0029018712858845334,\n",
       "  0.006876535397021868,\n",
       "  -0.009801727932002706,\n",
       "  0.0274528345454065,\n",
       "  -0.014152868957538063,\n",
       "  -0.024174485879462648,\n",
       "  -0.036728163114346,\n",
       "  -0.0058603804897103305,\n",
       "  0.01551218457606396,\n",
       "  -0.01279355427033476,\n",
       "  -0.0024937436059329944,\n",
       "  -0.005430596998292632,\n",
       "  0.0006709119916058619,\n",
       "  0.018697247314300003,\n",
       "  0.02497408406909649,\n",
       "  -0.012200519706936447,\n",
       "  0.019390231418571897,\n",
       "  -0.004587688582710365,\n",
       "  -0.001805756862289454,\n",
       "  0.005710456178399958,\n",
       "  -0.024001241250378568,\n",
       "  -0.007203037540983099,\n",
       "  0.008988804378682514,\n",
       "  -0.0016566652697941543,\n",
       "  0.009028784195031945,\n",
       "  -0.017964281531033487,\n",
       "  -0.017950956167347133,\n",
       "  0.0070631081837600855,\n",
       "  0.022735212490883075,\n",
       "  0.0026203464353164135,\n",
       "  -0.015232325861617933,\n",
       "  -0.030358037637873918,\n",
       "  -0.00045768606187696233,\n",
       "  -0.0049475073955165556,\n",
       "  -0.0018623950130613664,\n",
       "  0.007576182648798236,\n",
       "  -0.008589006215188186,\n",
       "  -0.021042731115230175,\n",
       "  0.000430616384855757,\n",
       "  -0.011854027654800498,\n",
       "  0.005647154647292924,\n",
       "  -0.00862898603153762,\n",
       "  0.005214039814953638,\n",
       "  -0.016831519446917832,\n",
       "  -0.011880681176140986,\n",
       "  -0.03347646517577485,\n",
       "  -0.020962771482531308,\n",
       "  0.0015800372108475257,\n",
       "  0.007689458950342062,\n",
       "  0.015458877533382988,\n",
       "  -0.015179018818936959,\n",
       "  -0.027199628420978363,\n",
       "  -0.007422926530904979,\n",
       "  -0.04048626957648305,\n",
       "  -0.02004323570649436,\n",
       "  -0.017217992246725808,\n",
       "  -0.0010144888876047714,\n",
       "  0.016938133532279777,\n",
       "  0.016458373873441397,\n",
       "  -0.012160539890587014,\n",
       "  0.03203719178719528,\n",
       "  0.006903188452701057,\n",
       "  0.033316545910377124,\n",
       "  -0.02052299350268755,\n",
       "  -0.01943021123492133,\n",
       "  0.024534306089252732,\n",
       "  -0.010594662508470777,\n",
       "  0.007263007265507248,\n",
       "  0.004221206622399701,\n",
       "  -0.010461395833090938,\n",
       "  -0.021349244282339284,\n",
       "  0.022468679140123397,\n",
       "  0.0023488165388356524,\n",
       "  0.009235346889944878,\n",
       "  0.021042731115230175,\n",
       "  0.004810909379215129,\n",
       "  -0.02822577828237726,\n",
       "  -0.008682292142895998,\n",
       "  0.018590633228938055,\n",
       "  0.001141091716988191,\n",
       "  0.0033066673920838356,\n",
       "  -0.0005917851941373937,\n",
       "  -0.0071230779082842345,\n",
       "  0.0035015692296179683,\n",
       "  0.003654825347511226,\n",
       "  0.0003721041801924649,\n",
       "  -0.002355479919170774,\n",
       "  -0.004674311828575001,\n",
       "  0.0047309497465162645,\n",
       "  -0.004387789500963202,\n",
       "  0.002200557897986074,\n",
       "  -0.03382295815923339,\n",
       "  -0.006120249761642939,\n",
       "  -0.010001627945072464,\n",
       "  -0.016458373873441397,\n",
       "  0.009895014791033111,\n",
       "  -0.014139542662529116,\n",
       "  -0.005670476362050526,\n",
       "  0.03355642480847372,\n",
       "  0.003901367625942943,\n",
       "  -0.0124737157395393,\n",
       "  -0.011887343857984161,\n",
       "  0.020123195339193226,\n",
       "  -0.013873010243092034,\n",
       "  -0.005813737525856425,\n",
       "  0.003534885665632279,\n",
       "  -0.011414248743634146,\n",
       "  0.001613353763277161,\n",
       "  -0.000857068186105894,\n",
       "  -0.0008274997414590181,\n",
       "  -0.01511238548124704,\n",
       "  0.0023571458224622165,\n",
       "  -0.004654321454738987,\n",
       "  -0.006696626223449422,\n",
       "  -0.018297447288160486,\n",
       "  0.002287180911020061,\n",
       "  0.014486034714665065,\n",
       "  -0.02573370057973571,\n",
       "  -0.012666951208120692,\n",
       "  -0.02062960572540431,\n",
       "  0.02017650051922901,\n",
       "  0.0005101596581470859,\n",
       "  -0.005104094854331401,\n",
       "  -0.00988168756470157,\n",
       "  -0.010221516934994342,\n",
       "  0.014779220655442633,\n",
       "  0.02390795439134816,\n",
       "  -0.013513191895947142,\n",
       "  0.0008241681094991194,\n",
       "  0.01356649800730552,\n",
       "  0.014419401376975146,\n",
       "  -0.003648161967176104,\n",
       "  0.008382443520275253,\n",
       "  0.23198977615478417,\n",
       "  0.005717119325904431,\n",
       "  0.017337931695774106,\n",
       "  0.0324369899506896,\n",
       "  -0.006416767043342096,\n",
       "  0.033663038893835665,\n",
       "  0.007542866445614574,\n",
       "  -0.010101577485946044,\n",
       "  -0.008415759723458916,\n",
       "  0.02138922409868872,\n",
       "  0.016245149428007883,\n",
       "  0.01456599434736393,\n",
       "  -0.005157401431351077,\n",
       "  0.005254019631303071,\n",
       "  -0.0020373068260054585,\n",
       "  -0.0019356913818404343,\n",
       "  -0.02314833788070894,\n",
       "  -0.021709062629484178,\n",
       "  -0.035208926367777185,\n",
       "  -0.016711579997869534,\n",
       "  0.0011485879325537096,\n",
       "  -0.022002248570261746,\n",
       "  0.01913702529414376,\n",
       "  -0.010961144468781442,\n",
       "  0.014605974163713363,\n",
       "  -0.01620516774901326,\n",
       "  -0.019989928663813387,\n",
       "  -0.0016983109894350295,\n",
       "  0.02161577577045377,\n",
       "  0.020882811849832445,\n",
       "  -0.013593151528646007,\n",
       "  0.0012893503578377693,\n",
       "  0.012740248158976382,\n",
       "  -0.00397133230455445,\n",
       "  -0.03131755509290549,\n",
       "  -0.005627164739118207,\n",
       "  0.03051795690327165,\n",
       "  -0.0037581064621370437,\n",
       "  0.02557378131433798,\n",
       "  -0.008429086949790457,\n",
       "  0.006250184164778595,\n",
       "  -0.024334407007505568,\n",
       "  0.00644675190560417,\n",
       "  -0.014326115449267334,\n",
       "  0.004461085520496297,\n",
       "  0.026946424159195417,\n",
       "  ...]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_result = embeddings.embed_documents([text])\n",
    "doc_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏ãÈù¢Ëøô‰∏™‰æãÂ≠êÊòØ‰ΩøÁî®HuggingFace HubÁöÑembeddingsÊ®°ÂûãÔºåËÆ©Êàë‰ª¨ÁúãÁúãÂÆÉÁöÑ‰∏Ä‰∏™‰ª£Á†ÅÊ†∑‰æãÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#‰ΩøÁî®ÂâçÈúÄË¶Å‰øùËØÅÂ∫ì‰∏≠Êúâsentence_transformers\n",
    "%pip install sentence_transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∫éÊ≠§ÂêåÊó∂Â∞Ü‰ºö‰∏ãËΩΩÂÆâË£ÖÁõ∏ÂÖ≥‰æùËµñÊñá‰ª∂‰ª•Âèä‰ºóÂ§öjsonÊ†ºÂºèÁöÑËß£ÊûêÂ§ÑÁêÜÊñá‰ª∂ÔºåÂÆâË£Ö‰πãÂêéÂ∞±ÂèØ‰ª•Ê≠£Â∏∏‰ΩøÁî®HuggingFaceEmbeddings‰∫Ü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_hf = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_hf = \"I just test the embeddings method in huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02886896708001464,\n",
       " 0.0044634718471356595,\n",
       " 0.006389421280895015,\n",
       " -0.009913570977266759,\n",
       " -0.0027808003958931854,\n",
       " 0.023057329930755516,\n",
       " 0.018016073486322687,\n",
       " -0.007974105724918213,\n",
       " -0.02111110793326557,\n",
       " -0.030896281195072053,\n",
       " -0.003899202602766403,\n",
       " 0.009474319213141963,\n",
       " -0.002067861337994345,\n",
       " -0.0010989737706240251,\n",
       " -0.008920186017807362,\n",
       " 0.00898100603730552,\n",
       " 0.01804310419217851,\n",
       " 0.010190636643611502,\n",
       " 0.007784889852604894,\n",
       " -0.026733528278888818,\n",
       " 0.019691986562609287,\n",
       " -0.01051500790784905,\n",
       " -0.010170363614219635,\n",
       " -0.010170363614219635,\n",
       " -0.016096882194688564,\n",
       " 0.011109686230644828,\n",
       " 0.03597808556093373,\n",
       " -0.027652577865922144,\n",
       " -0.006450240834731895,\n",
       " -0.009197252615474662,\n",
       " 0.014083082501236506,\n",
       " -0.012393653140699437,\n",
       " -0.005676482222996175,\n",
       " -0.025692840515504287,\n",
       " -0.014461514245863142,\n",
       " -0.002672677106808614,\n",
       " 0.0069536905252642715,\n",
       " -0.025300891555304628,\n",
       " 0.025963147574062522,\n",
       " -0.0059940948794472105,\n",
       " -0.00814980624430362,\n",
       " 0.0155832950581377,\n",
       " -0.010940743387723377,\n",
       " -0.035086064817111115,\n",
       " -0.01600227286154807,\n",
       " 0.01851614340730053,\n",
       " -0.006511060388568775,\n",
       " -0.01908379195556304,\n",
       " -0.008311991410761116,\n",
       " 0.002961569405457198,\n",
       " 0.0017958632305056508,\n",
       " 0.0202596351108718,\n",
       " -0.019475740915762704,\n",
       " 0.003885687249838491,\n",
       " -0.0010710981223795684,\n",
       " 0.017353817467564793,\n",
       " 0.009433773154358227,\n",
       " 0.00968380811484715,\n",
       " -0.00799437875431008,\n",
       " 0.0015576537381673744,\n",
       " -0.011535422641841713,\n",
       " -0.0015263992516909397,\n",
       " -0.003103481542522826,\n",
       " 0.010325791104213175,\n",
       " -0.015096739558765213,\n",
       " -0.014110113207092328,\n",
       " 0.023516855655594734,\n",
       " 0.01372492285467918,\n",
       " 0.03797836897013532,\n",
       " 0.026922745082524693,\n",
       " 0.0035444224929329715,\n",
       " 0.014218236030515622,\n",
       " -0.022219372461289657,\n",
       " -0.005862319257077516,\n",
       " 0.04646606276292695,\n",
       " 0.007460519519689903,\n",
       " 0.009501349918997785,\n",
       " 0.0052304727824074235,\n",
       " 0.00515951671387461,\n",
       " 0.016448283233459378,\n",
       " -0.0019310175746920033,\n",
       " -0.011900339033540439,\n",
       " -0.009285103340828644,\n",
       " 0.0047675691506587825,\n",
       " 0.010961016417115246,\n",
       " 0.00806871412673615,\n",
       " -0.00456821676364953,\n",
       " 0.015029162794125655,\n",
       " -0.000812193129455108,\n",
       " 0.0037606695367633915,\n",
       " 0.01984065730746143,\n",
       " 0.006865840265571568,\n",
       " 0.005848803904149604,\n",
       " -0.0006136851609655513,\n",
       " -0.00512572833155483,\n",
       " 0.01959737909211391,\n",
       " -0.019178401288703534,\n",
       " 0.02278702100955217,\n",
       " 0.0033805479073594873,\n",
       " -0.025219799437737157,\n",
       " -0.026692982220105084,\n",
       " 0.013826288932961072,\n",
       " -0.03714041336331458,\n",
       " -0.017894435309971483,\n",
       " -0.012400410817163393,\n",
       " 0.00270984456019101,\n",
       " 0.0026692982685766363,\n",
       " -0.027666093218850055,\n",
       " -0.006565121800280422,\n",
       " 0.014475029598791055,\n",
       " -0.009210767968402573,\n",
       " 0.019489256268690615,\n",
       " -0.024111533047067958,\n",
       " -0.023314123499030948,\n",
       " -0.016150943606400212,\n",
       " -0.010596100025416519,\n",
       " -0.0046695823762701455,\n",
       " -0.02040830585572394,\n",
       " -0.008136290891375709,\n",
       " 0.0027284281704668886,\n",
       " 0.03189642289967285,\n",
       " 0.02681462039645629,\n",
       " 0.010913712681867554,\n",
       " -0.013393794845300233,\n",
       " 0.035572621247806156,\n",
       " 0.0007868516680922945,\n",
       " -0.008413357489043009,\n",
       " -0.04895290260282359,\n",
       " -0.016177974312256035,\n",
       " -0.018070134898034333,\n",
       " 0.01638070646881982,\n",
       " 0.019191916641631446,\n",
       " 0.017678187800479785,\n",
       " -0.012434199199483171,\n",
       " -0.003780942566155259,\n",
       " 0.04800682044728933,\n",
       " -0.001748559262427321,\n",
       " 0.010663677721378634,\n",
       " -0.016150943606400212,\n",
       " 0.0017620747317705521,\n",
       " 0.017948496721683128,\n",
       " 0.0215976625013155,\n",
       " 0.007102360338793855,\n",
       " 0.005504160541842746,\n",
       " -0.025827994044783406,\n",
       " 0.03197751501724032,\n",
       " -0.003186263544867563,\n",
       " 0.015691417881560994,\n",
       " 0.034112955681011255,\n",
       " -0.024895429104822165,\n",
       " 0.010393368800175289,\n",
       " -0.010244698986645704,\n",
       " -0.019637925150897642,\n",
       " -0.0008624536391940781,\n",
       " -0.006497545035640864,\n",
       " 0.016867261036869752,\n",
       " 0.0005528657235439905,\n",
       " -0.010190636643611502,\n",
       " -0.04438468351086767,\n",
       " -0.014610184059392727,\n",
       " -0.002968327081921154,\n",
       " 0.026490250063541297,\n",
       " -0.015718450450061927,\n",
       " -0.014569638000608991,\n",
       " 0.01455612264768108,\n",
       " 0.026165879730626306,\n",
       " 0.01952980232747435,\n",
       " -0.014353390491117293,\n",
       " -0.003211605064438036,\n",
       " -0.003503876201318598,\n",
       " -0.020367757934295093,\n",
       " 0.015434625244608115,\n",
       " -0.02513870732016969,\n",
       " 0.009954117036050493,\n",
       " 0.012981573787031261,\n",
       " -0.024016925576572576,\n",
       " 0.02293569175440431,\n",
       " -0.015434625244608115,\n",
       " -0.009663535085455281,\n",
       " -0.022408589264925532,\n",
       " -0.01804310419217851,\n",
       " 0.029301460236352925,\n",
       " 0.030517849450445417,\n",
       " 0.001139520062238399,\n",
       " -0.013961443393562745,\n",
       " -0.02736875359179089,\n",
       " -0.0066833820697222044,\n",
       " -0.022516712088348826,\n",
       " 0.017826856682686812,\n",
       " -0.020719160835711018,\n",
       " 0.015353533127040646,\n",
       " 0.02382771063558181,\n",
       " 0.008318749087225071,\n",
       " -0.004422925788351924,\n",
       " -0.6366309990135384,\n",
       " -0.023760132008297144,\n",
       " 0.032572194271358657,\n",
       " -0.020840799012062223,\n",
       " 0.03200454572309614,\n",
       " 0.013143758953488757,\n",
       " 0.0010922159777447499,\n",
       " -0.021867971422518843,\n",
       " -0.0345184162688486,\n",
       " 0.04233033868995443,\n",
       " -0.01884051560286063,\n",
       " -0.0013912450239199066,\n",
       " -0.0193676162296943,\n",
       " -0.003106860380754804,\n",
       " 0.025544169770652148,\n",
       " -0.005872455771773449,\n",
       " 0.030571910862157065,\n",
       " -0.03286953576106293,\n",
       " 0.010102786849580077,\n",
       " 0.02389528740022137,\n",
       " -0.016488829292243115,\n",
       " 0.027585001101282588,\n",
       " -0.010217668280789882,\n",
       " -0.005287913498012326,\n",
       " -0.01890809236750019,\n",
       " 0.00484866173388753,\n",
       " 0.006926659819408448,\n",
       " -0.014880492980596072,\n",
       " 0.013610041423469376,\n",
       " 0.002333101769019084,\n",
       " -0.025936116868206696,\n",
       " 0.01661046746859432,\n",
       " 0.032410010036223715,\n",
       " -0.012535565277765065,\n",
       " 0.03197751501724032,\n",
       " -0.015380563832896469,\n",
       " -0.020840799012062223,\n",
       " 0.01884051560286063,\n",
       " -0.008217383940265733,\n",
       " 0.03970834532077868,\n",
       " -0.035788870619942965,\n",
       " -0.013839804285888985,\n",
       " -0.008197110910873866,\n",
       " 0.011528664965377758,\n",
       " -0.009440530830822183,\n",
       " 0.02681462039645629,\n",
       " 0.0022722822151822033,\n",
       " -0.003649167176616204,\n",
       " -0.009068855831336946,\n",
       " 0.025544169770652148,\n",
       " 0.0028112101728116254,\n",
       " 0.011697607808299208,\n",
       " 0.0019394647866872677,\n",
       " 0.007811920558460717,\n",
       " 0.0180295888392506,\n",
       " -0.009947359359586537,\n",
       " 0.020421821208651852,\n",
       " -0.004277634813054318,\n",
       " 0.026246971848193777,\n",
       " 0.021962580755659336,\n",
       " 0.013339733433588586,\n",
       " 0.010589342348952563,\n",
       " -0.008663393380854485,\n",
       " -0.016475313939315204,\n",
       " -0.025963147574062522,\n",
       " 0.035572621247806156,\n",
       " 0.01095425874065129,\n",
       " 0.018205290289958563,\n",
       " -0.005727165262137121,\n",
       " -0.04727698766389188,\n",
       " 0.008467418900754656,\n",
       " 0.013042393806529419,\n",
       " -0.021205715403760952,\n",
       " -0.0064907868935156305,\n",
       " 0.014623699412320638,\n",
       " 0.03200454572309614,\n",
       " 0.024881913751894254,\n",
       " -0.014610184059392727,\n",
       " -0.01516431632340477,\n",
       " 0.025530654417724237,\n",
       " 0.011454330524274242,\n",
       " -0.0027216704940029326,\n",
       " -0.00803492574441637,\n",
       " 0.022178826402505923,\n",
       " 0.008339023047939494,\n",
       " 0.018070134898034333,\n",
       " -0.022976237813188045,\n",
       " -0.004439819979511814,\n",
       " -0.029625830569267913,\n",
       " -0.006000852555911166,\n",
       " 0.02208421893201054,\n",
       " 0.04184378225925939,\n",
       " -0.02430074985070383,\n",
       " -0.04330345155134451,\n",
       " 0.015623841116921434,\n",
       " -0.010460945564814847,\n",
       " 0.008933701370735275,\n",
       " -0.001609181370450996,\n",
       " 0.016718592154662724,\n",
       " -0.007845708940780497,\n",
       " 0.007014510079101152,\n",
       " -0.0022689033769502254,\n",
       " 0.017759279918047256,\n",
       " 0.004950027812169423,\n",
       " 0.01143405656355982,\n",
       " -0.004095176617204955,\n",
       " -0.006565121800280422,\n",
       " 0.0051324860080187865,\n",
       " -0.003689713468230578,\n",
       " 0.0006715481149341314,\n",
       " -0.03381561419130697,\n",
       " -0.019651440503825553,\n",
       " 0.0052946711744762814,\n",
       " 0.015488687587642318,\n",
       " -0.010933985711259421,\n",
       " -0.04922320966138182,\n",
       " 0.0037302597598449514,\n",
       " 0.0053284595567960604,\n",
       " 0.01321133664945087,\n",
       " -0.01031903342774922,\n",
       " -0.012163890278279828,\n",
       " -0.0022689033769502254,\n",
       " 0.01546165595046394,\n",
       " -0.005646072678908374,\n",
       " 0.002725049332234911,\n",
       " 0.001511194479647039,\n",
       " -0.01482643063756187,\n",
       " -0.021881486775446754,\n",
       " -0.019962295483812634,\n",
       " 0.02153008573667594,\n",
       " 0.019421677641405944,\n",
       " -0.015623841116921434,\n",
       " 0.009913570977266759,\n",
       " -0.013711407501751267,\n",
       " 0.019489256268690615,\n",
       " 0.028463502766887066,\n",
       " 0.02513870732016969,\n",
       " -0.009663535085455281,\n",
       " 0.012603142042404623,\n",
       " -0.008257929999049469,\n",
       " 0.0010001420538467544,\n",
       " 0.01716460066392892,\n",
       " 0.0034396778092497396,\n",
       " 0.0031609220252970895,\n",
       " -0.02967989198097956,\n",
       " -0.028139132433972078,\n",
       " -0.015218378666438973,\n",
       " 0.02048939797329141,\n",
       " 0.005862319257077516,\n",
       " 0.009339164752540291,\n",
       " -0.014231751383443533,\n",
       " -0.004977058518025246,\n",
       " -0.013170790590667135,\n",
       " -0.00022828412592801136,\n",
       " -0.010663677721378634,\n",
       " -0.014177689971731886,\n",
       " -0.009487834566069874,\n",
       " -0.025530654417724237,\n",
       " 0.0027402541042788114,\n",
       " -0.027166021435227103,\n",
       " 0.006835430721483767,\n",
       " 0.043492666492335276,\n",
       " 0.01875942162264805,\n",
       " -0.0048114945133357736,\n",
       " -0.012724781150078383,\n",
       " 0.001553430190377402,\n",
       " -0.01828638240752603,\n",
       " 0.031436900900123854,\n",
       " -0.004007326357512252,\n",
       " -0.02619291043648213,\n",
       " 0.004159374543612536,\n",
       " -0.04235736939581025,\n",
       " 0.01178545853365319,\n",
       " 0.01977308054282187,\n",
       " -0.002116854725188664,\n",
       " 0.021935548187158403,\n",
       " -0.02753093782692583,\n",
       " -0.0025831371951692828,\n",
       " -0.01008251382018821,\n",
       " -0.026057756907203015,\n",
       " -0.004517533724508583,\n",
       " 0.0040478724162959865,\n",
       " 0.0058690769335414715,\n",
       " 0.016799684272230192,\n",
       " 0.032653286388926124,\n",
       " 0.008737727821957999,\n",
       " 0.004125586161292757,\n",
       " 0.00819035323440991,\n",
       " -0.010487976270670671,\n",
       " 0.021084077227409747,\n",
       " 0.006889492598856691,\n",
       " -0.026368611887190092,\n",
       " -0.04135722582856435,\n",
       " 0.006544848770888555,\n",
       " -0.006078566300907935,\n",
       " 0.009149948880226971,\n",
       " 0.00794707501906239,\n",
       " 0.01171112316122712,\n",
       " 0.004774326827122738,\n",
       " 0.018178257721457626,\n",
       " 0.0056426938406763955,\n",
       " 0.017218662075640566,\n",
       " 0.0036930923064625557,\n",
       " -0.007967348048454257,\n",
       " 0.0029767744103317375,\n",
       " 0.001376884845018681,\n",
       " 0.002973395339269121,\n",
       " -0.013434340904083969,\n",
       " -0.003350138130441047,\n",
       " 0.010609615378344431,\n",
       " 0.01952980232747435,\n",
       " 0.005581874286839515,\n",
       " -0.045168581431266994,\n",
       " -0.013589768394077507,\n",
       " -0.0015424488497081544,\n",
       " -0.004328317852195265,\n",
       " -0.011021836436613404,\n",
       " -7.813609795677769e-06,\n",
       " -0.007507823720598872,\n",
       " 0.0021354385682951812,\n",
       " -0.013684376795895445,\n",
       " 0.010068998467260297,\n",
       " 0.008197110910873866,\n",
       " 0.020854314364990138,\n",
       " 0.0009004658021344685,\n",
       " -0.00526426163038848,\n",
       " 0.012373380111307569,\n",
       " -0.008920186017807362,\n",
       " 0.015367048479968557,\n",
       " -0.008095744832591973,\n",
       " -0.002578068937821316,\n",
       " 0.049169148249670176,\n",
       " 0.010427157182495069,\n",
       " 0.00421343642098546,\n",
       " 0.014623699412320638,\n",
       " 0.006115733987120971,\n",
       " 0.020854314364990138,\n",
       " 0.011528664965377758,\n",
       " 0.0025172496168150743,\n",
       " 0.0053723849194730515,\n",
       " -0.012555838307156932,\n",
       " 0.0020932028575648184,\n",
       " 0.006355632898575236,\n",
       " -0.025287376202376716,\n",
       " 0.02350334030266682,\n",
       " 0.020921891129629694,\n",
       " 0.02792288678712549,\n",
       " -0.0026963289744324596,\n",
       " -0.02205718822615472,\n",
       " 0.0052743981450844146,\n",
       " -0.014461514245863142,\n",
       " -0.0026895712979685036,\n",
       " 0.005537948924162525,\n",
       " 0.013704649825287312,\n",
       " 0.021084077227409747,\n",
       " -0.01606985148883274,\n",
       " -0.014515575657574789,\n",
       " 0.02816616500247301,\n",
       " 0.021462508972036384,\n",
       " 0.05149380385443187,\n",
       " 0.009609473673743634,\n",
       " 0.008278203028441336,\n",
       " 0.012163890278279828,\n",
       " 0.010143332908363813,\n",
       " 0.03224782580108878,\n",
       " -0.018962153779211836,\n",
       " -0.024800821634326786,\n",
       " -0.015610325763993523,\n",
       " -0.02335466955781468,\n",
       " -0.018408020583877235,\n",
       " -0.016583436762738497,\n",
       " -0.001876955930149718,\n",
       " 0.007149664539702824,\n",
       " -0.013711407501751267,\n",
       " 0.03235594862451207,\n",
       " 0.014718307814138576,\n",
       " 0.028193195708328834,\n",
       " 0.012224710297777986,\n",
       " 0.01961089444504182,\n",
       " 0.027895856081269665,\n",
       " -0.011035351789541315,\n",
       " -0.029869108784615437,\n",
       " 0.05025038393448355,\n",
       " 0.0008147272581290915,\n",
       " 0.0026490250063541296,\n",
       " -0.024179111674352625,\n",
       " -0.027409299650574624,\n",
       " -0.0005786294814781415,\n",
       " -0.02198961146151516,\n",
       " 0.016191489665183946,\n",
       " 0.014975100451091452,\n",
       " 0.016691561448806902,\n",
       " 0.028490535335388003,\n",
       " -0.0024851504207806453,\n",
       " -0.0034515039758923013,\n",
       " 0.03635651544291525,\n",
       " 0.014353390491117293,\n",
       " 0.006389421280895015,\n",
       " 0.019205431994559357,\n",
       " -0.001809378699848882,\n",
       " -0.0023685798032854906,\n",
       " -0.021651725775672256,\n",
       " -0.010217668280789882,\n",
       " -0.008663393380854485,\n",
       " 0.045898414214664444,\n",
       " -0.01067043539784259,\n",
       " 0.0056122838309273166,\n",
       " -0.014083082501236506,\n",
       " -0.006487408055283653,\n",
       " -0.004493881856884738,\n",
       " 0.005608904992695339,\n",
       " 0.01763764174169605,\n",
       " -0.018543175975801466,\n",
       " 0.0009291861017292599,\n",
       " -0.009609473673743634,\n",
       " 0.04343860508062363,\n",
       " -0.01750248634977182,\n",
       " -0.002000284107693509,\n",
       " 0.016286097135679328,\n",
       " 0.01344785625701188,\n",
       " -0.02185445606959093,\n",
       " -0.027111960023515458,\n",
       " 0.0026017210382758,\n",
       " -0.0032301886747139147,\n",
       " 0.028923028491726285,\n",
       " 0.028003978904692958,\n",
       " -0.0055784954486075376,\n",
       " -0.0003112773347660765,\n",
       " -0.011684092455371296,\n",
       " -0.007825435911388628,\n",
       " -0.018380989878021413,\n",
       " 0.007838951264316541,\n",
       " -0.005250745811799291,\n",
       " 0.0028635826310685606,\n",
       " -0.03781618473500038,\n",
       " -0.036653856932619536,\n",
       " 0.023692555243657584,\n",
       " -0.010967774093579201,\n",
       " 0.01661046746859432,\n",
       " 0.0018786453492657068,\n",
       " 0.004392515778602845,\n",
       " -0.010623130731272343,\n",
       " 0.013326218080660675,\n",
       " -0.0022317359235678297,\n",
       " -0.005923138810914396,\n",
       " -0.007325365059088231,\n",
       " -0.006625941354117302,\n",
       " 0.007210484093539704,\n",
       " 0.030031294882395487,\n",
       " -0.0020847557619848734,\n",
       " 0.008987763713769477,\n",
       " 0.01773224921219143,\n",
       " 0.013961443393562745,\n",
       " -0.032707351525928,\n",
       " 0.00794707501906239,\n",
       " 0.016961870370010245,\n",
       " -0.010481218594206714,\n",
       " 0.013069424512385241,\n",
       " -0.010636646084200254,\n",
       " 0.036383546148771075,\n",
       " 0.004017462872208185,\n",
       " 0.016326643194463062,\n",
       " 0.019881203366245163,\n",
       " -0.009244556350722353,\n",
       " 0.008764758527813823,\n",
       " 0.017178116016856832,\n",
       " -0.0015990447393397426,\n",
       " -0.003845140958224117,\n",
       " -0.018543175975801466,\n",
       " -0.011603000337803827,\n",
       " -0.01356949536468564,\n",
       " 0.008170080205018042,\n",
       " -0.0009663534969039962,\n",
       " -0.01898918448506766,\n",
       " 0.007284819000304496,\n",
       " 0.008088987156128017,\n",
       " -0.030653002979724533,\n",
       " -0.0145290910105027,\n",
       " 0.01621852037103977,\n",
       " 0.021097592580337658,\n",
       " -0.024706212301186293,\n",
       " 0.002817967849275581,\n",
       " -0.0073388804120161424,\n",
       " -0.006173174237064595,\n",
       " -0.01811068095681807,\n",
       " -0.013258640384698562,\n",
       " -0.007872740577958875,\n",
       " -0.017934981368755216,\n",
       " -0.0067610958147189745,\n",
       " -0.015623841116921434,\n",
       " -0.014137143912948152,\n",
       " 0.005673103384764197,\n",
       " -0.010346064133605042,\n",
       " 0.005723786423905143,\n",
       " -0.0008666771869840505,\n",
       " -0.007386184612925111,\n",
       " -0.04416843786402108,\n",
       " 0.00806871412673615,\n",
       " 0.009102645144979282,\n",
       " 0.024152080968496803,\n",
       " 0.01020415292786197,\n",
       " 0.009954117036050493,\n",
       " -0.010771800544801926,\n",
       " -0.015488687587642318,\n",
       " -0.0032065365742594302,\n",
       " -0.0101298175554359,\n",
       " 0.009954117036050493,\n",
       " -0.005075045292413884,\n",
       " -0.01031903342774922,\n",
       " 0.012603142042404623,\n",
       " -0.018921607720428103,\n",
       " 0.0068590825891076115,\n",
       " -0.013001847747745683,\n",
       " 0.0010744769606115465,\n",
       " 0.01600227286154807,\n",
       " 0.008311991410761116,\n",
       " 0.007676766563520323,\n",
       " -0.038410863989118714,\n",
       " 0.016421252527603555,\n",
       " 0.02581447869185549,\n",
       " 0.014569638000608991,\n",
       " 0.009886540271410935,\n",
       " -0.01515080097047686,\n",
       " -0.010981290377829668,\n",
       " 0.02281405171540799,\n",
       " -0.022408589264925532,\n",
       " 0.00032204743983816584,\n",
       " -0.0037403962745408852,\n",
       " 0.0018144469571968486,\n",
       " 0.0125761113365488,\n",
       " -0.00642658896710805,\n",
       " 0.020178542993304332,\n",
       " -0.017664672447551873,\n",
       " 0.0018617510416904979,\n",
       " 0.0008962421961368364,\n",
       " 4.919802804552858e-06,\n",
       " -0.008055198773808237,\n",
       " -0.00022638351487060885,\n",
       " 0.01135296444599235,\n",
       " -0.019448708347261767,\n",
       " -0.01977308054282187,\n",
       " 0.033842644897162794,\n",
       " -0.02731469218007924,\n",
       " 0.004781084503586695,\n",
       " -0.02705789861180381,\n",
       " 0.004419546950119946,\n",
       " 0.035653713365373624,\n",
       " 0.011001563407221535,\n",
       " -0.0034802241008641136,\n",
       " 0.03005832558825131,\n",
       " -0.0019158126862327833,\n",
       " -0.0037708060514593253,\n",
       " -0.03632948473705943,\n",
       " 0.014894008333523983,\n",
       " -0.017705218506335607,\n",
       " 0.03668088763847536,\n",
       " 0.0007898081515452752,\n",
       " 0.007778132176140938,\n",
       " -0.020313696522583448,\n",
       " -0.03251813285964701,\n",
       " -0.006044777918588156,\n",
       " -0.007061814280010121,\n",
       " 0.005169653228570543,\n",
       " 0.0022722822151822033,\n",
       " -0.005696755252388042,\n",
       " -0.015515718293498142,\n",
       " 0.0008523170662904846,\n",
       " -0.0030798294420683416,\n",
       " -0.0016801373225684905,\n",
       " -0.02311139134246716,\n",
       " -0.035572621247806156,\n",
       " 0.035788870619942965,\n",
       " 0.000670703405376137,\n",
       " 0.021219230756688863,\n",
       " 0.010575826996024652,\n",
       " 0.022030157520298896,\n",
       " -0.029544738451700445,\n",
       " -0.01877293697557596,\n",
       " 0.0017147706472769029,\n",
       " -0.0049905738709531584,\n",
       " 0.016326643194463062,\n",
       " 0.03797836897013532,\n",
       " 0.013468130217726302,\n",
       " 0.020448851914507675,\n",
       " 0.055521401378690875,\n",
       " -0.024152080968496803,\n",
       " 0.039275850301795284,\n",
       " -0.0026659194303446584,\n",
       " -0.0006204428956371669,\n",
       " 0.007318607382624275,\n",
       " -0.004095176617204955,\n",
       " -0.012792357914717941,\n",
       " -0.00013821643088599762,\n",
       " 0.0036525460148481817,\n",
       " 0.001841477895883311,\n",
       " -0.03295062787863041,\n",
       " 0.012258498680097764,\n",
       " 0.003155853767949123,\n",
       " 0.0031169968954507378,\n",
       " 0.005615662669159294,\n",
       " -0.016096882194688564,\n",
       " -0.008257929999049469,\n",
       " -0.020381273287223004,\n",
       " -0.015299470784006444,\n",
       " -0.014447998892935231,\n",
       " 0.02086782971791805,\n",
       " -0.011379995151848173,\n",
       " 0.01938113158262221,\n",
       " -0.029463646334132974,\n",
       " 0.0014596668473634176,\n",
       " 0.004743917283034937,\n",
       " 0.0022368044137464353,\n",
       " 0.017367332820492704,\n",
       " 0.02730117682715133,\n",
       " 0.02959879986341209,\n",
       " -0.028058040316404607,\n",
       " -0.00565283035537233,\n",
       " -0.0014148970079590714,\n",
       " -0.02690922786695167,\n",
       " -0.01130566071074466,\n",
       " -0.012359863827057102,\n",
       " -0.010481218594206714,\n",
       " -0.02603072620134719,\n",
       " 0.018637783446296845,\n",
       " -0.012562595983620887,\n",
       " 0.009109402821443237,\n",
       " 0.0015770821744165667,\n",
       " 0.017461940290988087,\n",
       " -0.025273860849448805,\n",
       " 0.018610752740441022,\n",
       " 0.008122775538447797,\n",
       " -0.024476451301411795,\n",
       " -0.00028445766078060255,\n",
       " -0.02388177204729346,\n",
       " -0.016096882194688564,\n",
       " -0.05235879016710844,\n",
       " -0.017826856682686812,\n",
       " -0.004598626307737331,\n",
       " -0.00894045904719923,\n",
       " -0.0035140127160145315,\n",
       " -0.024881913751894254,\n",
       " 0.008406599812579053,\n",
       " -0.0036694402060080712,\n",
       " -0.008643120351462618,\n",
       " -0.033166873525476995,\n",
       " 0.0036525460148481817,\n",
       " 0.03970834532077868,\n",
       " 0.007284819000304496,\n",
       " 0.0210300158156981,\n",
       " 0.01463721476524855,\n",
       " -0.006281297991810444,\n",
       " -0.02461160483069091,\n",
       " 0.01923246270041518,\n",
       " -0.0008012117887858603,\n",
       " -0.010771800544801926,\n",
       " 0.0047337807683390035,\n",
       " 0.029220368118785454,\n",
       " -0.019354100876766388,\n",
       " -0.032896566466918756,\n",
       " 0.011123201583572741,\n",
       " -0.005946790678538242,\n",
       " -0.004311423195374097,\n",
       " -0.023692555243657584,\n",
       " 0.020151512287448506,\n",
       " -0.008359296077331362,\n",
       " -0.004422925788351924,\n",
       " -0.012488260611194818,\n",
       " 0.0005790518944647985,\n",
       " -0.031436900900123854,\n",
       " 0.004095176617204955,\n",
       " -0.02278702100955217,\n",
       " -0.011102928554180873,\n",
       " 0.001799242185152948,\n",
       " -0.0029666376628051648,\n",
       " 0.0062002054085816966,\n",
       " 0.02722008284693875,\n",
       " -0.0016801373225684905,\n",
       " 0.02280053636248008,\n",
       " -0.005831909712989715,\n",
       " 0.009582442967887812,\n",
       " -0.003747153951004841,\n",
       " 0.0034498145567763124,\n",
       " -0.010305518074821307,\n",
       " 0.0155832950581377,\n",
       " 0.019327070170910562,\n",
       " 0.03500497269954364,\n",
       " -0.011697607808299208,\n",
       " 0.00016155166339282948,\n",
       " 0.021895002128374665,\n",
       " -0.008994521390233432,\n",
       " 0.0069536905252642715,\n",
       " -0.011447572847810287,\n",
       " -0.005744059453297011,\n",
       " 0.029625830569267913,\n",
       " -0.039275850301795284,\n",
       " -0.021205715403760952,\n",
       " -0.0036593036913121373,\n",
       " 0.024260203791920096,\n",
       " 0.014623699412320638,\n",
       " -0.008636362674998663,\n",
       " -0.016488829292243115,\n",
       " -0.022922176401476396,\n",
       " -0.004618899337129199,\n",
       " 0.0014115181697270936,\n",
       " 0.03822164532283773,\n",
       " -0.010521765584313005,\n",
       " 0.008899912988415495,\n",
       " -0.003493739686622664,\n",
       " -0.011535422641841713,\n",
       " 0.006838809559715745,\n",
       " -0.011548937994769625,\n",
       " 0.0025932739426958555,\n",
       " 0.012285529385953588,\n",
       " -0.012738296503006296,\n",
       " -0.017786310623903078,\n",
       " -0.002476703325200701,\n",
       " -0.006622562515885324,\n",
       " 0.04138425653442017,\n",
       " -0.016015788214475985,\n",
       " -0.0016936527919117217,\n",
       " 0.005054772263022016,\n",
       " 0.016988901075866068,\n",
       " -0.0013836425214826368,\n",
       " -0.002929470209422769,\n",
       " -0.0022384938328624242,\n",
       " -0.009278345664364689,\n",
       " -0.016583436762738497,\n",
       " -0.0193676162296943,\n",
       " -0.01835395917216559,\n",
       " 0.000876813759887644,\n",
       " 0.0016041129966877096,\n",
       " 0.006629320192349281,\n",
       " -0.010433914858959024,\n",
       " -0.01709702389928936,\n",
       " 0.005193305561855667,\n",
       " 0.01779982597683099,\n",
       " 0.01684023033101393,\n",
       " -0.0016852056963317767,\n",
       " -0.009744628134345307,\n",
       " -0.011623273367195694,\n",
       " 0.007778132176140938,\n",
       " -0.029977231608038727,\n",
       " -0.0003412646986978597,\n",
       " 0.009764901163737174,\n",
       " -0.006419831290644094,\n",
       " 0.00020188679216961967,\n",
       " 0.0183674745250935,\n",
       " -0.007237514799395528,\n",
       " -0.016421252527603555,\n",
       " -0.013866834991744808,\n",
       " -0.006375905927967104,\n",
       " -0.0019597378160791353,\n",
       " -0.031247682233842868,\n",
       " 0.0003847675028690441,\n",
       " -0.0106839507507705,\n",
       " 0.018083650250962247,\n",
       " -0.0011276940120111569,\n",
       " -0.01527244007815062,\n",
       " -0.00676785349118293,\n",
       " 0.004220194097449416,\n",
       " -0.01163003104365965,\n",
       " 0.03292359717277458,\n",
       " 0.0018059998616169039,\n",
       " -0.011994947435358377,\n",
       " 0.004659445861574211,\n",
       " 0.0042539829454304725,\n",
       " 0.026949775788380516,\n",
       " 0.015123770264621037,\n",
       " -0.026003695495491367,\n",
       " -0.009312134046684467,\n",
       " -0.03322093493718864,\n",
       " 0.003360274645136981,\n",
       " -0.024152080968496803,\n",
       " 0.010075756143724253,\n",
       " 0.01734030211463688,\n",
       " 0.023597947773162202,\n",
       " 0.024341295909487567,\n",
       " -0.026787589690600466,\n",
       " -0.01961089444504182,\n",
       " -0.006146143531208772,\n",
       " -0.008278203028441336,\n",
       " -0.006710412775578028,\n",
       " -0.021705787187383904,\n",
       " -0.0013067734860438614,\n",
       " 0.0018347201030040356,\n",
       " 0.0033264862628172016,\n",
       " -0.01582657327348522,\n",
       " 0.022449135323709266,\n",
       " 0.006473892702355741,\n",
       " -0.00018953284212437575,\n",
       " -0.0022165311515239287,\n",
       " -0.002208084055943984,\n",
       " -0.015921180743980603,\n",
       " -0.015218378666438973,\n",
       " -0.025746901927215935,\n",
       " -0.0028703403075325167,\n",
       " -0.03678901046189865,\n",
       " 0.013366764139444409,\n",
       " 0.027760700689345438,\n",
       " 0.004321560175731309,\n",
       " 0.011880066004148572,\n",
       " 0.051061308835448474,\n",
       " -0.0005718718050141857,\n",
       " -0.004757432635962849,\n",
       " -0.02715250608229919,\n",
       " 0.004558080248953596,\n",
       " 0.032410010036223715,\n",
       " 0.002426020286059754,\n",
       " 0.020948921835485516,\n",
       " -0.007940317342598433,\n",
       " -0.02057049009085888,\n",
       " 0.012805873267645854,\n",
       " -0.01654289070395476,\n",
       " 0.002365200965053513,\n",
       " -0.03357233783860456,\n",
       " 0.01071773913309028,\n",
       " 0.013441098580547924,\n",
       " 0.010041967761404475,\n",
       " -0.03668088763847536,\n",
       " 0.024016925576572576,\n",
       " -0.011481361230130067,\n",
       " -0.011156990897215075,\n",
       " 0.0275985164542105,\n",
       " -0.013589768394077507,\n",
       " -0.011724638514155032,\n",
       " 0.03381561419130697,\n",
       " 0.010055483114332386,\n",
       " 0.007325365059088231,\n",
       " -0.005409552605686086,\n",
       " 0.0330587507020537,\n",
       " 0.007142906863238868,\n",
       " 0.0005000710269233772,\n",
       " 0.032653286388926124,\n",
       " -0.021949065402731425,\n",
       " -0.02792288678712549,\n",
       " -0.019097307308490952,\n",
       " -0.0021337491491791923,\n",
       " -0.03424810921029037,\n",
       " -0.013231609678842737,\n",
       " -0.009704081144239016,\n",
       " -0.0028416199497300655,\n",
       " 0.0023516853792949623,\n",
       " -0.0024125049331318424,\n",
       " -0.0007420817704802885,\n",
       " -0.028003978904692958,\n",
       " 0.004456714170671703,\n",
       " -0.016745622860518547,\n",
       " 0.022759990303696347,\n",
       " -0.0014351701537662583,\n",
       " -0.0120219781412142,\n",
       " 0.017124054605145184,\n",
       " -0.008332265371475538,\n",
       " 0.013880350344672719,\n",
       " 0.010785315897729839,\n",
       " -0.011494876583057978,\n",
       " -0.026990321847164253,\n",
       " -0.019016215190923485,\n",
       " 0.035707774777085276,\n",
       " 0.02182742536373511,\n",
       " 0.01215713260181587,\n",
       " 0.2147332088184969,\n",
       " -0.03968131461492286,\n",
       " 0.019637925150897642,\n",
       " 0.0018516144105792446,\n",
       " -0.0027284281704668886,\n",
       " -0.02428723449777592,\n",
       " -0.020056902954308016,\n",
       " 0.011582726377089403,\n",
       " 0.002005352597872115,\n",
       " 0.009987905418370273,\n",
       " 0.024503482007267617,\n",
       " -0.0070482989270822085,\n",
       " -0.006909765628248558,\n",
       " -0.0023297229307871056,\n",
       " -0.004625657013593154,\n",
       " -0.014502060304646878,\n",
       " -0.035572621247806156,\n",
       " -0.011961159053038597,\n",
       " -0.019340585523838473,\n",
       " -0.008899912988415495,\n",
       " 0.008102502509055929,\n",
       " -0.007088844985865943,\n",
       " -0.008845851576703848,\n",
       " -0.016326643194463062,\n",
       " 0.018637783446296845,\n",
       " -0.01494806974523563,\n",
       " -0.012103071190104226,\n",
       " -0.015840088626413132,\n",
       " 0.014407452834151496,\n",
       " 0.025679325162576375,\n",
       " -0.00992708633019467,\n",
       " 0.02008393552280895,\n",
       " 0.02255725814713256,\n",
       " -0.009109402821443237,\n",
       " -0.012272014033025675,\n",
       " -0.014461514245863142,\n",
       " 0.019691986562609287,\n",
       " 0.026936260435452605,\n",
       " 0.020137996934520595,\n",
       " -0.0038620351493840067,\n",
       " 0.03140986646897781,\n",
       " -0.035302314189247924,\n",
       " 0.010893439652475688,\n",
       " 0.0013642140852334443,\n",
       " -0.01811068095681807,\n",
       " 0.020746191541566844,\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings_hf.embed_query(text_hf)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.02886896708001464,\n",
       "  0.0044634718471356595,\n",
       "  0.006389421280895015,\n",
       "  -0.009913570977266759,\n",
       "  -0.0027808003958931854,\n",
       "  0.023057329930755516,\n",
       "  0.018016073486322687,\n",
       "  -0.007974105724918213,\n",
       "  -0.02111110793326557,\n",
       "  -0.030896281195072053,\n",
       "  -0.003899202602766403,\n",
       "  0.009474319213141963,\n",
       "  -0.002067861337994345,\n",
       "  -0.0010989737706240251,\n",
       "  -0.008920186017807362,\n",
       "  0.00898100603730552,\n",
       "  0.01804310419217851,\n",
       "  0.010190636643611502,\n",
       "  0.007784889852604894,\n",
       "  -0.026733528278888818,\n",
       "  0.019691986562609287,\n",
       "  -0.01051500790784905,\n",
       "  -0.010170363614219635,\n",
       "  -0.010170363614219635,\n",
       "  -0.016096882194688564,\n",
       "  0.011109686230644828,\n",
       "  0.03597808556093373,\n",
       "  -0.027652577865922144,\n",
       "  -0.006450240834731895,\n",
       "  -0.009197252615474662,\n",
       "  0.014083082501236506,\n",
       "  -0.012393653140699437,\n",
       "  -0.005676482222996175,\n",
       "  -0.025692840515504287,\n",
       "  -0.014461514245863142,\n",
       "  -0.002672677106808614,\n",
       "  0.0069536905252642715,\n",
       "  -0.025300891555304628,\n",
       "  0.025963147574062522,\n",
       "  -0.0059940948794472105,\n",
       "  -0.00814980624430362,\n",
       "  0.0155832950581377,\n",
       "  -0.010940743387723377,\n",
       "  -0.035086064817111115,\n",
       "  -0.01600227286154807,\n",
       "  0.01851614340730053,\n",
       "  -0.006511060388568775,\n",
       "  -0.01908379195556304,\n",
       "  -0.008311991410761116,\n",
       "  0.002961569405457198,\n",
       "  0.0017958632305056508,\n",
       "  0.0202596351108718,\n",
       "  -0.019475740915762704,\n",
       "  0.003885687249838491,\n",
       "  -0.0010710981223795684,\n",
       "  0.017353817467564793,\n",
       "  0.009433773154358227,\n",
       "  0.00968380811484715,\n",
       "  -0.00799437875431008,\n",
       "  0.0015576537381673744,\n",
       "  -0.011535422641841713,\n",
       "  -0.0015263992516909397,\n",
       "  -0.003103481542522826,\n",
       "  0.010325791104213175,\n",
       "  -0.015096739558765213,\n",
       "  -0.014110113207092328,\n",
       "  0.023516855655594734,\n",
       "  0.01372492285467918,\n",
       "  0.03797836897013532,\n",
       "  0.026922745082524693,\n",
       "  0.0035444224929329715,\n",
       "  0.014218236030515622,\n",
       "  -0.022219372461289657,\n",
       "  -0.005862319257077516,\n",
       "  0.04646606276292695,\n",
       "  0.007460519519689903,\n",
       "  0.009501349918997785,\n",
       "  0.0052304727824074235,\n",
       "  0.00515951671387461,\n",
       "  0.016448283233459378,\n",
       "  -0.0019310175746920033,\n",
       "  -0.011900339033540439,\n",
       "  -0.009285103340828644,\n",
       "  0.0047675691506587825,\n",
       "  0.010961016417115246,\n",
       "  0.00806871412673615,\n",
       "  -0.00456821676364953,\n",
       "  0.015029162794125655,\n",
       "  -0.000812193129455108,\n",
       "  0.0037606695367633915,\n",
       "  0.01984065730746143,\n",
       "  0.006865840265571568,\n",
       "  0.005848803904149604,\n",
       "  -0.0006136851609655513,\n",
       "  -0.00512572833155483,\n",
       "  0.01959737909211391,\n",
       "  -0.019178401288703534,\n",
       "  0.02278702100955217,\n",
       "  0.0033805479073594873,\n",
       "  -0.025219799437737157,\n",
       "  -0.026692982220105084,\n",
       "  0.013826288932961072,\n",
       "  -0.03714041336331458,\n",
       "  -0.017894435309971483,\n",
       "  -0.012400410817163393,\n",
       "  0.00270984456019101,\n",
       "  0.0026692982685766363,\n",
       "  -0.027666093218850055,\n",
       "  -0.006565121800280422,\n",
       "  0.014475029598791055,\n",
       "  -0.009210767968402573,\n",
       "  0.019489256268690615,\n",
       "  -0.024111533047067958,\n",
       "  -0.023314123499030948,\n",
       "  -0.016150943606400212,\n",
       "  -0.010596100025416519,\n",
       "  -0.0046695823762701455,\n",
       "  -0.02040830585572394,\n",
       "  -0.008136290891375709,\n",
       "  0.0027284281704668886,\n",
       "  0.03189642289967285,\n",
       "  0.02681462039645629,\n",
       "  0.010913712681867554,\n",
       "  -0.013393794845300233,\n",
       "  0.035572621247806156,\n",
       "  0.0007868516680922945,\n",
       "  -0.008413357489043009,\n",
       "  -0.04895290260282359,\n",
       "  -0.016177974312256035,\n",
       "  -0.018070134898034333,\n",
       "  0.01638070646881982,\n",
       "  0.019191916641631446,\n",
       "  0.017678187800479785,\n",
       "  -0.012434199199483171,\n",
       "  -0.003780942566155259,\n",
       "  0.04800682044728933,\n",
       "  -0.001748559262427321,\n",
       "  0.010663677721378634,\n",
       "  -0.016150943606400212,\n",
       "  0.0017620747317705521,\n",
       "  0.017948496721683128,\n",
       "  0.0215976625013155,\n",
       "  0.007102360338793855,\n",
       "  0.005504160541842746,\n",
       "  -0.025827994044783406,\n",
       "  0.03197751501724032,\n",
       "  -0.003186263544867563,\n",
       "  0.015691417881560994,\n",
       "  0.034112955681011255,\n",
       "  -0.024895429104822165,\n",
       "  0.010393368800175289,\n",
       "  -0.010244698986645704,\n",
       "  -0.019637925150897642,\n",
       "  -0.0008624536391940781,\n",
       "  -0.006497545035640864,\n",
       "  0.016867261036869752,\n",
       "  0.0005528657235439905,\n",
       "  -0.010190636643611502,\n",
       "  -0.04438468351086767,\n",
       "  -0.014610184059392727,\n",
       "  -0.002968327081921154,\n",
       "  0.026490250063541297,\n",
       "  -0.015718450450061927,\n",
       "  -0.014569638000608991,\n",
       "  0.01455612264768108,\n",
       "  0.026165879730626306,\n",
       "  0.01952980232747435,\n",
       "  -0.014353390491117293,\n",
       "  -0.003211605064438036,\n",
       "  -0.003503876201318598,\n",
       "  -0.020367757934295093,\n",
       "  0.015434625244608115,\n",
       "  -0.02513870732016969,\n",
       "  0.009954117036050493,\n",
       "  0.012981573787031261,\n",
       "  -0.024016925576572576,\n",
       "  0.02293569175440431,\n",
       "  -0.015434625244608115,\n",
       "  -0.009663535085455281,\n",
       "  -0.022408589264925532,\n",
       "  -0.01804310419217851,\n",
       "  0.029301460236352925,\n",
       "  0.030517849450445417,\n",
       "  0.001139520062238399,\n",
       "  -0.013961443393562745,\n",
       "  -0.02736875359179089,\n",
       "  -0.0066833820697222044,\n",
       "  -0.022516712088348826,\n",
       "  0.017826856682686812,\n",
       "  -0.020719160835711018,\n",
       "  0.015353533127040646,\n",
       "  0.02382771063558181,\n",
       "  0.008318749087225071,\n",
       "  -0.004422925788351924,\n",
       "  -0.6366309990135384,\n",
       "  -0.023760132008297144,\n",
       "  0.032572194271358657,\n",
       "  -0.020840799012062223,\n",
       "  0.03200454572309614,\n",
       "  0.013143758953488757,\n",
       "  0.0010922159777447499,\n",
       "  -0.021867971422518843,\n",
       "  -0.0345184162688486,\n",
       "  0.04233033868995443,\n",
       "  -0.01884051560286063,\n",
       "  -0.0013912450239199066,\n",
       "  -0.0193676162296943,\n",
       "  -0.003106860380754804,\n",
       "  0.025544169770652148,\n",
       "  -0.005872455771773449,\n",
       "  0.030571910862157065,\n",
       "  -0.03286953576106293,\n",
       "  0.010102786849580077,\n",
       "  0.02389528740022137,\n",
       "  -0.016488829292243115,\n",
       "  0.027585001101282588,\n",
       "  -0.010217668280789882,\n",
       "  -0.005287913498012326,\n",
       "  -0.01890809236750019,\n",
       "  0.00484866173388753,\n",
       "  0.006926659819408448,\n",
       "  -0.014880492980596072,\n",
       "  0.013610041423469376,\n",
       "  0.002333101769019084,\n",
       "  -0.025936116868206696,\n",
       "  0.01661046746859432,\n",
       "  0.032410010036223715,\n",
       "  -0.012535565277765065,\n",
       "  0.03197751501724032,\n",
       "  -0.015380563832896469,\n",
       "  -0.020840799012062223,\n",
       "  0.01884051560286063,\n",
       "  -0.008217383940265733,\n",
       "  0.03970834532077868,\n",
       "  -0.035788870619942965,\n",
       "  -0.013839804285888985,\n",
       "  -0.008197110910873866,\n",
       "  0.011528664965377758,\n",
       "  -0.009440530830822183,\n",
       "  0.02681462039645629,\n",
       "  0.0022722822151822033,\n",
       "  -0.003649167176616204,\n",
       "  -0.009068855831336946,\n",
       "  0.025544169770652148,\n",
       "  0.0028112101728116254,\n",
       "  0.011697607808299208,\n",
       "  0.0019394647866872677,\n",
       "  0.007811920558460717,\n",
       "  0.0180295888392506,\n",
       "  -0.009947359359586537,\n",
       "  0.020421821208651852,\n",
       "  -0.004277634813054318,\n",
       "  0.026246971848193777,\n",
       "  0.021962580755659336,\n",
       "  0.013339733433588586,\n",
       "  0.010589342348952563,\n",
       "  -0.008663393380854485,\n",
       "  -0.016475313939315204,\n",
       "  -0.025963147574062522,\n",
       "  0.035572621247806156,\n",
       "  0.01095425874065129,\n",
       "  0.018205290289958563,\n",
       "  -0.005727165262137121,\n",
       "  -0.04727698766389188,\n",
       "  0.008467418900754656,\n",
       "  0.013042393806529419,\n",
       "  -0.021205715403760952,\n",
       "  -0.0064907868935156305,\n",
       "  0.014623699412320638,\n",
       "  0.03200454572309614,\n",
       "  0.024881913751894254,\n",
       "  -0.014610184059392727,\n",
       "  -0.01516431632340477,\n",
       "  0.025530654417724237,\n",
       "  0.011454330524274242,\n",
       "  -0.0027216704940029326,\n",
       "  -0.00803492574441637,\n",
       "  0.022178826402505923,\n",
       "  0.008339023047939494,\n",
       "  0.018070134898034333,\n",
       "  -0.022976237813188045,\n",
       "  -0.004439819979511814,\n",
       "  -0.029625830569267913,\n",
       "  -0.006000852555911166,\n",
       "  0.02208421893201054,\n",
       "  0.04184378225925939,\n",
       "  -0.02430074985070383,\n",
       "  -0.04330345155134451,\n",
       "  0.015623841116921434,\n",
       "  -0.010460945564814847,\n",
       "  0.008933701370735275,\n",
       "  -0.001609181370450996,\n",
       "  0.016718592154662724,\n",
       "  -0.007845708940780497,\n",
       "  0.007014510079101152,\n",
       "  -0.0022689033769502254,\n",
       "  0.017759279918047256,\n",
       "  0.004950027812169423,\n",
       "  0.01143405656355982,\n",
       "  -0.004095176617204955,\n",
       "  -0.006565121800280422,\n",
       "  0.0051324860080187865,\n",
       "  -0.003689713468230578,\n",
       "  0.0006715481149341314,\n",
       "  -0.03381561419130697,\n",
       "  -0.019651440503825553,\n",
       "  0.0052946711744762814,\n",
       "  0.015488687587642318,\n",
       "  -0.010933985711259421,\n",
       "  -0.04922320966138182,\n",
       "  0.0037302597598449514,\n",
       "  0.0053284595567960604,\n",
       "  0.01321133664945087,\n",
       "  -0.01031903342774922,\n",
       "  -0.012163890278279828,\n",
       "  -0.0022689033769502254,\n",
       "  0.01546165595046394,\n",
       "  -0.005646072678908374,\n",
       "  0.002725049332234911,\n",
       "  0.001511194479647039,\n",
       "  -0.01482643063756187,\n",
       "  -0.021881486775446754,\n",
       "  -0.019962295483812634,\n",
       "  0.02153008573667594,\n",
       "  0.019421677641405944,\n",
       "  -0.015623841116921434,\n",
       "  0.009913570977266759,\n",
       "  -0.013711407501751267,\n",
       "  0.019489256268690615,\n",
       "  0.028463502766887066,\n",
       "  0.02513870732016969,\n",
       "  -0.009663535085455281,\n",
       "  0.012603142042404623,\n",
       "  -0.008257929999049469,\n",
       "  0.0010001420538467544,\n",
       "  0.01716460066392892,\n",
       "  0.0034396778092497396,\n",
       "  0.0031609220252970895,\n",
       "  -0.02967989198097956,\n",
       "  -0.028139132433972078,\n",
       "  -0.015218378666438973,\n",
       "  0.02048939797329141,\n",
       "  0.005862319257077516,\n",
       "  0.009339164752540291,\n",
       "  -0.014231751383443533,\n",
       "  -0.004977058518025246,\n",
       "  -0.013170790590667135,\n",
       "  -0.00022828412592801136,\n",
       "  -0.010663677721378634,\n",
       "  -0.014177689971731886,\n",
       "  -0.009487834566069874,\n",
       "  -0.025530654417724237,\n",
       "  0.0027402541042788114,\n",
       "  -0.027166021435227103,\n",
       "  0.006835430721483767,\n",
       "  0.043492666492335276,\n",
       "  0.01875942162264805,\n",
       "  -0.0048114945133357736,\n",
       "  -0.012724781150078383,\n",
       "  0.001553430190377402,\n",
       "  -0.01828638240752603,\n",
       "  0.031436900900123854,\n",
       "  -0.004007326357512252,\n",
       "  -0.02619291043648213,\n",
       "  0.004159374543612536,\n",
       "  -0.04235736939581025,\n",
       "  0.01178545853365319,\n",
       "  0.01977308054282187,\n",
       "  -0.002116854725188664,\n",
       "  0.021935548187158403,\n",
       "  -0.02753093782692583,\n",
       "  -0.0025831371951692828,\n",
       "  -0.01008251382018821,\n",
       "  -0.026057756907203015,\n",
       "  -0.004517533724508583,\n",
       "  0.0040478724162959865,\n",
       "  0.0058690769335414715,\n",
       "  0.016799684272230192,\n",
       "  0.032653286388926124,\n",
       "  0.008737727821957999,\n",
       "  0.004125586161292757,\n",
       "  0.00819035323440991,\n",
       "  -0.010487976270670671,\n",
       "  0.021084077227409747,\n",
       "  0.006889492598856691,\n",
       "  -0.026368611887190092,\n",
       "  -0.04135722582856435,\n",
       "  0.006544848770888555,\n",
       "  -0.006078566300907935,\n",
       "  0.009149948880226971,\n",
       "  0.00794707501906239,\n",
       "  0.01171112316122712,\n",
       "  0.004774326827122738,\n",
       "  0.018178257721457626,\n",
       "  0.0056426938406763955,\n",
       "  0.017218662075640566,\n",
       "  0.0036930923064625557,\n",
       "  -0.007967348048454257,\n",
       "  0.0029767744103317375,\n",
       "  0.001376884845018681,\n",
       "  0.002973395339269121,\n",
       "  -0.013434340904083969,\n",
       "  -0.003350138130441047,\n",
       "  0.010609615378344431,\n",
       "  0.01952980232747435,\n",
       "  0.005581874286839515,\n",
       "  -0.045168581431266994,\n",
       "  -0.013589768394077507,\n",
       "  -0.0015424488497081544,\n",
       "  -0.004328317852195265,\n",
       "  -0.011021836436613404,\n",
       "  -7.813609795677769e-06,\n",
       "  -0.007507823720598872,\n",
       "  0.0021354385682951812,\n",
       "  -0.013684376795895445,\n",
       "  0.010068998467260297,\n",
       "  0.008197110910873866,\n",
       "  0.020854314364990138,\n",
       "  0.0009004658021344685,\n",
       "  -0.00526426163038848,\n",
       "  0.012373380111307569,\n",
       "  -0.008920186017807362,\n",
       "  0.015367048479968557,\n",
       "  -0.008095744832591973,\n",
       "  -0.002578068937821316,\n",
       "  0.049169148249670176,\n",
       "  0.010427157182495069,\n",
       "  0.00421343642098546,\n",
       "  0.014623699412320638,\n",
       "  0.006115733987120971,\n",
       "  0.020854314364990138,\n",
       "  0.011528664965377758,\n",
       "  0.0025172496168150743,\n",
       "  0.0053723849194730515,\n",
       "  -0.012555838307156932,\n",
       "  0.0020932028575648184,\n",
       "  0.006355632898575236,\n",
       "  -0.025287376202376716,\n",
       "  0.02350334030266682,\n",
       "  0.020921891129629694,\n",
       "  0.02792288678712549,\n",
       "  -0.0026963289744324596,\n",
       "  -0.02205718822615472,\n",
       "  0.0052743981450844146,\n",
       "  -0.014461514245863142,\n",
       "  -0.0026895712979685036,\n",
       "  0.005537948924162525,\n",
       "  0.013704649825287312,\n",
       "  0.021084077227409747,\n",
       "  -0.01606985148883274,\n",
       "  -0.014515575657574789,\n",
       "  0.02816616500247301,\n",
       "  0.021462508972036384,\n",
       "  0.05149380385443187,\n",
       "  0.009609473673743634,\n",
       "  0.008278203028441336,\n",
       "  0.012163890278279828,\n",
       "  0.010143332908363813,\n",
       "  0.03224782580108878,\n",
       "  -0.018962153779211836,\n",
       "  -0.024800821634326786,\n",
       "  -0.015610325763993523,\n",
       "  -0.02335466955781468,\n",
       "  -0.018408020583877235,\n",
       "  -0.016583436762738497,\n",
       "  -0.001876955930149718,\n",
       "  0.007149664539702824,\n",
       "  -0.013711407501751267,\n",
       "  0.03235594862451207,\n",
       "  0.014718307814138576,\n",
       "  0.028193195708328834,\n",
       "  0.012224710297777986,\n",
       "  0.01961089444504182,\n",
       "  0.027895856081269665,\n",
       "  -0.011035351789541315,\n",
       "  -0.029869108784615437,\n",
       "  0.05025038393448355,\n",
       "  0.0008147272581290915,\n",
       "  0.0026490250063541296,\n",
       "  -0.024179111674352625,\n",
       "  -0.027409299650574624,\n",
       "  -0.0005786294814781415,\n",
       "  -0.02198961146151516,\n",
       "  0.016191489665183946,\n",
       "  0.014975100451091452,\n",
       "  0.016691561448806902,\n",
       "  0.028490535335388003,\n",
       "  -0.0024851504207806453,\n",
       "  -0.0034515039758923013,\n",
       "  0.03635651544291525,\n",
       "  0.014353390491117293,\n",
       "  0.006389421280895015,\n",
       "  0.019205431994559357,\n",
       "  -0.001809378699848882,\n",
       "  -0.0023685798032854906,\n",
       "  -0.021651725775672256,\n",
       "  -0.010217668280789882,\n",
       "  -0.008663393380854485,\n",
       "  0.045898414214664444,\n",
       "  -0.01067043539784259,\n",
       "  0.0056122838309273166,\n",
       "  -0.014083082501236506,\n",
       "  -0.006487408055283653,\n",
       "  -0.004493881856884738,\n",
       "  0.005608904992695339,\n",
       "  0.01763764174169605,\n",
       "  -0.018543175975801466,\n",
       "  0.0009291861017292599,\n",
       "  -0.009609473673743634,\n",
       "  0.04343860508062363,\n",
       "  -0.01750248634977182,\n",
       "  -0.002000284107693509,\n",
       "  0.016286097135679328,\n",
       "  0.01344785625701188,\n",
       "  -0.02185445606959093,\n",
       "  -0.027111960023515458,\n",
       "  0.0026017210382758,\n",
       "  -0.0032301886747139147,\n",
       "  0.028923028491726285,\n",
       "  0.028003978904692958,\n",
       "  -0.0055784954486075376,\n",
       "  -0.0003112773347660765,\n",
       "  -0.011684092455371296,\n",
       "  -0.007825435911388628,\n",
       "  -0.018380989878021413,\n",
       "  0.007838951264316541,\n",
       "  -0.005250745811799291,\n",
       "  0.0028635826310685606,\n",
       "  -0.03781618473500038,\n",
       "  -0.036653856932619536,\n",
       "  0.023692555243657584,\n",
       "  -0.010967774093579201,\n",
       "  0.01661046746859432,\n",
       "  0.0018786453492657068,\n",
       "  0.004392515778602845,\n",
       "  -0.010623130731272343,\n",
       "  0.013326218080660675,\n",
       "  -0.0022317359235678297,\n",
       "  -0.005923138810914396,\n",
       "  -0.007325365059088231,\n",
       "  -0.006625941354117302,\n",
       "  0.007210484093539704,\n",
       "  0.030031294882395487,\n",
       "  -0.0020847557619848734,\n",
       "  0.008987763713769477,\n",
       "  0.01773224921219143,\n",
       "  0.013961443393562745,\n",
       "  -0.032707351525928,\n",
       "  0.00794707501906239,\n",
       "  0.016961870370010245,\n",
       "  -0.010481218594206714,\n",
       "  0.013069424512385241,\n",
       "  -0.010636646084200254,\n",
       "  0.036383546148771075,\n",
       "  0.004017462872208185,\n",
       "  0.016326643194463062,\n",
       "  0.019881203366245163,\n",
       "  -0.009244556350722353,\n",
       "  0.008764758527813823,\n",
       "  0.017178116016856832,\n",
       "  -0.0015990447393397426,\n",
       "  -0.003845140958224117,\n",
       "  -0.018543175975801466,\n",
       "  -0.011603000337803827,\n",
       "  -0.01356949536468564,\n",
       "  0.008170080205018042,\n",
       "  -0.0009663534969039962,\n",
       "  -0.01898918448506766,\n",
       "  0.007284819000304496,\n",
       "  0.008088987156128017,\n",
       "  -0.030653002979724533,\n",
       "  -0.0145290910105027,\n",
       "  0.01621852037103977,\n",
       "  0.021097592580337658,\n",
       "  -0.024706212301186293,\n",
       "  0.002817967849275581,\n",
       "  -0.0073388804120161424,\n",
       "  -0.006173174237064595,\n",
       "  -0.01811068095681807,\n",
       "  -0.013258640384698562,\n",
       "  -0.007872740577958875,\n",
       "  -0.017934981368755216,\n",
       "  -0.0067610958147189745,\n",
       "  -0.015623841116921434,\n",
       "  -0.014137143912948152,\n",
       "  0.005673103384764197,\n",
       "  -0.010346064133605042,\n",
       "  0.005723786423905143,\n",
       "  -0.0008666771869840505,\n",
       "  -0.007386184612925111,\n",
       "  -0.04416843786402108,\n",
       "  0.00806871412673615,\n",
       "  0.009102645144979282,\n",
       "  0.024152080968496803,\n",
       "  0.01020415292786197,\n",
       "  0.009954117036050493,\n",
       "  -0.010771800544801926,\n",
       "  -0.015488687587642318,\n",
       "  -0.0032065365742594302,\n",
       "  -0.0101298175554359,\n",
       "  0.009954117036050493,\n",
       "  -0.005075045292413884,\n",
       "  -0.01031903342774922,\n",
       "  0.012603142042404623,\n",
       "  -0.018921607720428103,\n",
       "  0.0068590825891076115,\n",
       "  -0.013001847747745683,\n",
       "  0.0010744769606115465,\n",
       "  0.01600227286154807,\n",
       "  0.008311991410761116,\n",
       "  0.007676766563520323,\n",
       "  -0.038410863989118714,\n",
       "  0.016421252527603555,\n",
       "  0.02581447869185549,\n",
       "  0.014569638000608991,\n",
       "  0.009886540271410935,\n",
       "  -0.01515080097047686,\n",
       "  -0.010981290377829668,\n",
       "  0.02281405171540799,\n",
       "  -0.022408589264925532,\n",
       "  0.00032204743983816584,\n",
       "  -0.0037403962745408852,\n",
       "  0.0018144469571968486,\n",
       "  0.0125761113365488,\n",
       "  -0.00642658896710805,\n",
       "  0.020178542993304332,\n",
       "  -0.017664672447551873,\n",
       "  0.0018617510416904979,\n",
       "  0.0008962421961368364,\n",
       "  4.919802804552858e-06,\n",
       "  -0.008055198773808237,\n",
       "  -0.00022638351487060885,\n",
       "  0.01135296444599235,\n",
       "  -0.019448708347261767,\n",
       "  -0.01977308054282187,\n",
       "  0.033842644897162794,\n",
       "  -0.02731469218007924,\n",
       "  0.004781084503586695,\n",
       "  -0.02705789861180381,\n",
       "  0.004419546950119946,\n",
       "  0.035653713365373624,\n",
       "  0.011001563407221535,\n",
       "  -0.0034802241008641136,\n",
       "  0.03005832558825131,\n",
       "  -0.0019158126862327833,\n",
       "  -0.0037708060514593253,\n",
       "  -0.03632948473705943,\n",
       "  0.014894008333523983,\n",
       "  -0.017705218506335607,\n",
       "  0.03668088763847536,\n",
       "  0.0007898081515452752,\n",
       "  0.007778132176140938,\n",
       "  -0.020313696522583448,\n",
       "  -0.03251813285964701,\n",
       "  -0.006044777918588156,\n",
       "  -0.007061814280010121,\n",
       "  0.005169653228570543,\n",
       "  0.0022722822151822033,\n",
       "  -0.005696755252388042,\n",
       "  -0.015515718293498142,\n",
       "  0.0008523170662904846,\n",
       "  -0.0030798294420683416,\n",
       "  -0.0016801373225684905,\n",
       "  -0.02311139134246716,\n",
       "  -0.035572621247806156,\n",
       "  0.035788870619942965,\n",
       "  0.000670703405376137,\n",
       "  0.021219230756688863,\n",
       "  0.010575826996024652,\n",
       "  0.022030157520298896,\n",
       "  -0.029544738451700445,\n",
       "  -0.01877293697557596,\n",
       "  0.0017147706472769029,\n",
       "  -0.0049905738709531584,\n",
       "  0.016326643194463062,\n",
       "  0.03797836897013532,\n",
       "  0.013468130217726302,\n",
       "  0.020448851914507675,\n",
       "  0.055521401378690875,\n",
       "  -0.024152080968496803,\n",
       "  0.039275850301795284,\n",
       "  -0.0026659194303446584,\n",
       "  -0.0006204428956371669,\n",
       "  0.007318607382624275,\n",
       "  -0.004095176617204955,\n",
       "  -0.012792357914717941,\n",
       "  -0.00013821643088599762,\n",
       "  0.0036525460148481817,\n",
       "  0.001841477895883311,\n",
       "  -0.03295062787863041,\n",
       "  0.012258498680097764,\n",
       "  0.003155853767949123,\n",
       "  0.0031169968954507378,\n",
       "  0.005615662669159294,\n",
       "  -0.016096882194688564,\n",
       "  -0.008257929999049469,\n",
       "  -0.020381273287223004,\n",
       "  -0.015299470784006444,\n",
       "  -0.014447998892935231,\n",
       "  0.02086782971791805,\n",
       "  -0.011379995151848173,\n",
       "  0.01938113158262221,\n",
       "  -0.029463646334132974,\n",
       "  0.0014596668473634176,\n",
       "  0.004743917283034937,\n",
       "  0.0022368044137464353,\n",
       "  0.017367332820492704,\n",
       "  0.02730117682715133,\n",
       "  0.02959879986341209,\n",
       "  -0.028058040316404607,\n",
       "  -0.00565283035537233,\n",
       "  -0.0014148970079590714,\n",
       "  -0.02690922786695167,\n",
       "  -0.01130566071074466,\n",
       "  -0.012359863827057102,\n",
       "  -0.010481218594206714,\n",
       "  -0.02603072620134719,\n",
       "  0.018637783446296845,\n",
       "  -0.012562595983620887,\n",
       "  0.009109402821443237,\n",
       "  0.0015770821744165667,\n",
       "  0.017461940290988087,\n",
       "  -0.025273860849448805,\n",
       "  0.018610752740441022,\n",
       "  0.008122775538447797,\n",
       "  -0.024476451301411795,\n",
       "  -0.00028445766078060255,\n",
       "  -0.02388177204729346,\n",
       "  -0.016096882194688564,\n",
       "  -0.05235879016710844,\n",
       "  -0.017826856682686812,\n",
       "  -0.004598626307737331,\n",
       "  -0.00894045904719923,\n",
       "  -0.0035140127160145315,\n",
       "  -0.024881913751894254,\n",
       "  0.008406599812579053,\n",
       "  -0.0036694402060080712,\n",
       "  -0.008643120351462618,\n",
       "  -0.033166873525476995,\n",
       "  0.0036525460148481817,\n",
       "  0.03970834532077868,\n",
       "  0.007284819000304496,\n",
       "  0.0210300158156981,\n",
       "  0.01463721476524855,\n",
       "  -0.006281297991810444,\n",
       "  -0.02461160483069091,\n",
       "  0.01923246270041518,\n",
       "  -0.0008012117887858603,\n",
       "  -0.010771800544801926,\n",
       "  0.0047337807683390035,\n",
       "  0.029220368118785454,\n",
       "  -0.019354100876766388,\n",
       "  -0.032896566466918756,\n",
       "  0.011123201583572741,\n",
       "  -0.005946790678538242,\n",
       "  -0.004311423195374097,\n",
       "  -0.023692555243657584,\n",
       "  0.020151512287448506,\n",
       "  -0.008359296077331362,\n",
       "  -0.004422925788351924,\n",
       "  -0.012488260611194818,\n",
       "  0.0005790518944647985,\n",
       "  -0.031436900900123854,\n",
       "  0.004095176617204955,\n",
       "  -0.02278702100955217,\n",
       "  -0.011102928554180873,\n",
       "  0.001799242185152948,\n",
       "  -0.0029666376628051648,\n",
       "  0.0062002054085816966,\n",
       "  0.02722008284693875,\n",
       "  -0.0016801373225684905,\n",
       "  0.02280053636248008,\n",
       "  -0.005831909712989715,\n",
       "  0.009582442967887812,\n",
       "  -0.003747153951004841,\n",
       "  0.0034498145567763124,\n",
       "  -0.010305518074821307,\n",
       "  0.0155832950581377,\n",
       "  0.019327070170910562,\n",
       "  0.03500497269954364,\n",
       "  -0.011697607808299208,\n",
       "  0.00016155166339282948,\n",
       "  0.021895002128374665,\n",
       "  -0.008994521390233432,\n",
       "  0.0069536905252642715,\n",
       "  -0.011447572847810287,\n",
       "  -0.005744059453297011,\n",
       "  0.029625830569267913,\n",
       "  -0.039275850301795284,\n",
       "  -0.021205715403760952,\n",
       "  -0.0036593036913121373,\n",
       "  0.024260203791920096,\n",
       "  0.014623699412320638,\n",
       "  -0.008636362674998663,\n",
       "  -0.016488829292243115,\n",
       "  -0.022922176401476396,\n",
       "  -0.004618899337129199,\n",
       "  0.0014115181697270936,\n",
       "  0.03822164532283773,\n",
       "  -0.010521765584313005,\n",
       "  0.008899912988415495,\n",
       "  -0.003493739686622664,\n",
       "  -0.011535422641841713,\n",
       "  0.006838809559715745,\n",
       "  -0.011548937994769625,\n",
       "  0.0025932739426958555,\n",
       "  0.012285529385953588,\n",
       "  -0.012738296503006296,\n",
       "  -0.017786310623903078,\n",
       "  -0.002476703325200701,\n",
       "  -0.006622562515885324,\n",
       "  0.04138425653442017,\n",
       "  -0.016015788214475985,\n",
       "  -0.0016936527919117217,\n",
       "  0.005054772263022016,\n",
       "  0.016988901075866068,\n",
       "  -0.0013836425214826368,\n",
       "  -0.002929470209422769,\n",
       "  -0.0022384938328624242,\n",
       "  -0.009278345664364689,\n",
       "  -0.016583436762738497,\n",
       "  -0.0193676162296943,\n",
       "  -0.01835395917216559,\n",
       "  0.000876813759887644,\n",
       "  0.0016041129966877096,\n",
       "  0.006629320192349281,\n",
       "  -0.010433914858959024,\n",
       "  -0.01709702389928936,\n",
       "  0.005193305561855667,\n",
       "  0.01779982597683099,\n",
       "  0.01684023033101393,\n",
       "  -0.0016852056963317767,\n",
       "  -0.009744628134345307,\n",
       "  -0.011623273367195694,\n",
       "  0.007778132176140938,\n",
       "  -0.029977231608038727,\n",
       "  -0.0003412646986978597,\n",
       "  0.009764901163737174,\n",
       "  -0.006419831290644094,\n",
       "  0.00020188679216961967,\n",
       "  0.0183674745250935,\n",
       "  -0.007237514799395528,\n",
       "  -0.016421252527603555,\n",
       "  -0.013866834991744808,\n",
       "  -0.006375905927967104,\n",
       "  -0.0019597378160791353,\n",
       "  -0.031247682233842868,\n",
       "  0.0003847675028690441,\n",
       "  -0.0106839507507705,\n",
       "  0.018083650250962247,\n",
       "  -0.0011276940120111569,\n",
       "  -0.01527244007815062,\n",
       "  -0.00676785349118293,\n",
       "  0.004220194097449416,\n",
       "  -0.01163003104365965,\n",
       "  0.03292359717277458,\n",
       "  0.0018059998616169039,\n",
       "  -0.011994947435358377,\n",
       "  0.004659445861574211,\n",
       "  0.0042539829454304725,\n",
       "  0.026949775788380516,\n",
       "  0.015123770264621037,\n",
       "  -0.026003695495491367,\n",
       "  -0.009312134046684467,\n",
       "  -0.03322093493718864,\n",
       "  0.003360274645136981,\n",
       "  -0.024152080968496803,\n",
       "  0.010075756143724253,\n",
       "  0.01734030211463688,\n",
       "  0.023597947773162202,\n",
       "  0.024341295909487567,\n",
       "  -0.026787589690600466,\n",
       "  -0.01961089444504182,\n",
       "  -0.006146143531208772,\n",
       "  -0.008278203028441336,\n",
       "  -0.006710412775578028,\n",
       "  -0.021705787187383904,\n",
       "  -0.0013067734860438614,\n",
       "  0.0018347201030040356,\n",
       "  0.0033264862628172016,\n",
       "  -0.01582657327348522,\n",
       "  0.022449135323709266,\n",
       "  0.006473892702355741,\n",
       "  -0.00018953284212437575,\n",
       "  -0.0022165311515239287,\n",
       "  -0.002208084055943984,\n",
       "  -0.015921180743980603,\n",
       "  -0.015218378666438973,\n",
       "  -0.025746901927215935,\n",
       "  -0.0028703403075325167,\n",
       "  -0.03678901046189865,\n",
       "  0.013366764139444409,\n",
       "  0.027760700689345438,\n",
       "  0.004321560175731309,\n",
       "  0.011880066004148572,\n",
       "  0.051061308835448474,\n",
       "  -0.0005718718050141857,\n",
       "  -0.004757432635962849,\n",
       "  -0.02715250608229919,\n",
       "  0.004558080248953596,\n",
       "  0.032410010036223715,\n",
       "  0.002426020286059754,\n",
       "  0.020948921835485516,\n",
       "  -0.007940317342598433,\n",
       "  -0.02057049009085888,\n",
       "  0.012805873267645854,\n",
       "  -0.01654289070395476,\n",
       "  0.002365200965053513,\n",
       "  -0.03357233783860456,\n",
       "  0.01071773913309028,\n",
       "  0.013441098580547924,\n",
       "  0.010041967761404475,\n",
       "  -0.03668088763847536,\n",
       "  0.024016925576572576,\n",
       "  -0.011481361230130067,\n",
       "  -0.011156990897215075,\n",
       "  0.0275985164542105,\n",
       "  -0.013589768394077507,\n",
       "  -0.011724638514155032,\n",
       "  0.03381561419130697,\n",
       "  0.010055483114332386,\n",
       "  0.007325365059088231,\n",
       "  -0.005409552605686086,\n",
       "  0.0330587507020537,\n",
       "  0.007142906863238868,\n",
       "  0.0005000710269233772,\n",
       "  0.032653286388926124,\n",
       "  -0.021949065402731425,\n",
       "  -0.02792288678712549,\n",
       "  -0.019097307308490952,\n",
       "  -0.0021337491491791923,\n",
       "  -0.03424810921029037,\n",
       "  -0.013231609678842737,\n",
       "  -0.009704081144239016,\n",
       "  -0.0028416199497300655,\n",
       "  0.0023516853792949623,\n",
       "  -0.0024125049331318424,\n",
       "  -0.0007420817704802885,\n",
       "  -0.028003978904692958,\n",
       "  0.004456714170671703,\n",
       "  -0.016745622860518547,\n",
       "  0.022759990303696347,\n",
       "  -0.0014351701537662583,\n",
       "  -0.0120219781412142,\n",
       "  0.017124054605145184,\n",
       "  -0.008332265371475538,\n",
       "  0.013880350344672719,\n",
       "  0.010785315897729839,\n",
       "  -0.011494876583057978,\n",
       "  -0.026990321847164253,\n",
       "  -0.019016215190923485,\n",
       "  0.035707774777085276,\n",
       "  0.02182742536373511,\n",
       "  0.01215713260181587,\n",
       "  0.2147332088184969,\n",
       "  -0.03968131461492286,\n",
       "  0.019637925150897642,\n",
       "  0.0018516144105792446,\n",
       "  -0.0027284281704668886,\n",
       "  -0.02428723449777592,\n",
       "  -0.020056902954308016,\n",
       "  0.011582726377089403,\n",
       "  0.002005352597872115,\n",
       "  0.009987905418370273,\n",
       "  0.024503482007267617,\n",
       "  -0.0070482989270822085,\n",
       "  -0.006909765628248558,\n",
       "  -0.0023297229307871056,\n",
       "  -0.004625657013593154,\n",
       "  -0.014502060304646878,\n",
       "  -0.035572621247806156,\n",
       "  -0.011961159053038597,\n",
       "  -0.019340585523838473,\n",
       "  -0.008899912988415495,\n",
       "  0.008102502509055929,\n",
       "  -0.007088844985865943,\n",
       "  -0.008845851576703848,\n",
       "  -0.016326643194463062,\n",
       "  0.018637783446296845,\n",
       "  -0.01494806974523563,\n",
       "  -0.012103071190104226,\n",
       "  -0.015840088626413132,\n",
       "  0.014407452834151496,\n",
       "  0.025679325162576375,\n",
       "  -0.00992708633019467,\n",
       "  0.02008393552280895,\n",
       "  0.02255725814713256,\n",
       "  -0.009109402821443237,\n",
       "  -0.012272014033025675,\n",
       "  -0.014461514245863142,\n",
       "  0.019691986562609287,\n",
       "  0.026936260435452605,\n",
       "  0.020137996934520595,\n",
       "  -0.0038620351493840067,\n",
       "  0.03140986646897781,\n",
       "  -0.035302314189247924,\n",
       "  0.010893439652475688,\n",
       "  0.0013642140852334443,\n",
       "  -0.01811068095681807,\n",
       "  0.020746191541566844,\n",
       "  ...]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_result = embeddings_hf.embed_documents([text_hf])\n",
    "doc_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏äÈù¢ÁªôÂá∫ÁöÑ‰æãÂ≠êÁî®‰∫éÁÜüÊÇâÂü∫Êú¨models‰∏≠ÁöÑÁõ∏ÂÖ≥Êìç‰ΩúÔºåËØ¶ÁªÜÁöÑAPIÂºÄÊîæÊé•Âè£ËøòÊúâÂæàÂ§öÔºå‰æãÂ¶ÇÈíàÂØπÂæÆËΩØAzureÁöÑAzureOpenAIÔºåCohereÂíåLlama-cppÁ≠âÔºåÁÇπÂáª[Ê≠§Â§Ñ](https://python.langchain.com/en/latest/modules/models/text_embedding.html)ÂèØ‰ª•Áõ¥Êé•Ë∑≥ËΩ¨Âà∞Áõ∏ÂÖ≥‰ΩçÁΩÆ„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prompt\n",
    "PromptÊòØ‰∏ÄÁßç‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞‰ΩøÁî®È¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÁü•ËØÜÔºåÈááÁî®Âú®ËæìÂÖ•Á´ØÊ∑ªÂä†È¢ùÂ§ñÊñáÊú¨ÁöÑÊäÄÊúØ„ÄÇPromptÁöÑËÆæËÆ°ÊúâÊó∂ÂÄôÂèØ‰ª•ÊûÅÂ§ßÂú∞ÊøÄÂèëÂá∫Â§ßÊ®°ÂûãÁöÑÊΩúÂäõÔºåÂü∫‰∫épromptÂèØ‰ª•ÂÆåÊàêÂæàÂ§öÊàë‰ª¨ÊÉ≥Ë±°‰∏çÂà∞ÁöÑ‰ªªÂä°ÔºåÈÇ£‰πàÔºåÁé∞Âú®Êàë‰ª¨Â∞±Êù•ÁÜüÊÇâ‰∏Ä‰∏ã‰ªÄ‰πàÊòØPrompt‰ª•ÂèäÂú®LangChain‰∏≠Â¶Ç‰ΩïÂéªÊõ¥Â•ΩÂú∞‰ΩøÁî®ÂíåÂÆåÂñÑÂÆÉ‰ª¨ÔºåLangChainÊèê‰æõ‰∫ÜÂá†‰∏™Á±ªÂíåÂáΩÊï∞Êù•ËΩªÊùæÊûÑÂª∫PromptÊ®°Êùø„ÄÇ\n",
    "\n",
    "- [Prompt Templates](#prompt-templates)\n",
    "- [Chat Prompt Template](#chat-model-prompt-template)\n",
    "- [Example Selectors](#example-selectors)\n",
    "- [Output Parser](#output-parser)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prompt Templates\n",
    "ËØ≠Ë®ÄÊ®°ÂûãÁöÑÊñáÊú¨ËæìÂÖ•Â≠óÁ¨¶‰∏≤Êú¨Ë∫´Â∞±ÊòØ‰∏ÄÁßçÊèêÁ§∫ÔºåÈÄöÂ∏∏Êù•ËØ¥promptÁî±Ê®°Êùø„ÄÅ‰∏Ä‰∫õ‰æãÂ≠êÔºàÊúâÁöÑËØùÔºâÂíåÁî®Êà∑ÁöÑËæìÂÖ•ÊûÑÊàêÔºåÂÖ∂Ê¶ÇÂøµÂíåÂê´‰πâÂπ∂‰∏çÂ§çÊùÇ„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ‰ªÄ‰πàÊòØprompt templateÔºö\n",
    "Prompt TemplateÔºå‰πüÂ∞±ÊòØÊèêÁ§∫Ê®°ÁâàÔºåÊòØ‰∏ÄÁßçÂèØÈáçÂ§ç‰ΩøÁî®ÁîüÊàêpromptÁöÑÊñπÂºèÔºåÁî®templateÂèØ‰ª•Ê®°ÁâàÂåñÊèêÁ§∫Êåá‰ª§ÔºåÂÆÉÁî±‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ÂíåÂèØ‰æõÁî®Êà∑ËæìÂÖ•ÁöÑÂèÇÊï∞ÁªÑÊàê„ÄÇ\n",
    "ÊèêÁ§∫Ê®°ÁâàÂåÖÂê´Â¶Ç‰∏ãÁöÑÂÜÖÂÆπÔºö\n",
    "- ÁªôËØ≠Ë®ÄÊ®°ÂûãÁöÑÊåá‰ª§\n",
    "- Âá†‰∏™‰æãÂ≠êÔºåÂ∏ÆÂä©ËØ≠Ë®ÄÊ®°ÂûãÊõ¥Â•ΩÂú∞ÂõûÁ≠î\n",
    "- ‰∏Ä‰∏™ËÆ©ËØ≠Ë®ÄÊ®°ÂûãÂõûÁ≠îÁöÑÈóÆÈ¢ò\n",
    "- ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Áé∞Âú®Êàë‰ª¨Áúã‰∏Ä‰∏™ÂàõÂª∫prompt templateÁöÑ‰æãÂ≠êÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#‰∏ÄËà¨ÂØºÂÖ•ÁöÑÂøÖË¶ÅÂ∫ìÔºå‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•Ê®°ÁâàÂåñÂ§ÑÁêÜ\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "#ÂÖ∑‰ΩìÁöÑÊ®°ÁâàÂÜÖÂÆπÔºåÂÖ∂‰∏≠Ë¶ÅËøõË°åË°•ÂÖ®ÁöÑÂú∞ÊñπÔºà‰πüÂ∞±ÊòØ‰∏∫‰∫ÜÂÆöÂà∂Êàë‰ª¨ÂÖ∑‰ΩìÈóÆÈ¢ò‰ª•ÂèäË¶ÅÊ±ÇÁöÑÂú∞ÊñπÁî®‰∏Ä‰∏™ÂèòÈáèËøõË°å‰ª£ÊõøÔºâÁî®‰∏≠Êã¨Âè∑\n",
    "#ËøõË°åÂèòÈáèÁöÑÊîæÁΩÆÔºå‰∏çÈúÄË¶ÅÂÖ∂‰ªñÁöÑÊìç‰ΩúÔºåÁ±ª‰ºº‰∫éÂ≠óÁ¨¶‰∏≤‰∏≠ÂØπ‰∫éÊüê‰∏Ä‰∏™ÂèòÈáèÂØπÂÖ∂ÁöÑformatÊ†ºÂºèÂåñ\n",
    "template = \"\"\"\n",
    "I want you to act as a naming consultant for new companies.\n",
    "Here are some examples of good company names:\n",
    "- search engine, Google\n",
    "- social media, Facebook\n",
    "- video sharing, YouTube\n",
    "The name should be short, catchy and easy to remember.\n",
    "What is a good name for a company that makes {product}?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"input_variablesÂ∞±ÊòØÊ®°Áâà‰∏≠ÈúÄË¶ÅÂ°´Ë°•ÁöÑÂèòÈáèÔºåÂú®prompttemplate‰∏≠Ê†ºÂºèÂåñÊ®°ÁâàÂèØ‰ª•Â∞ÜÂèòÈáè‰ª•ÂèäÊ®°ÁâàÂÜÖÂÆπËøõË°åÂæàÂ•ΩÁöÑÁªÑÂêà\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËÆ©Êàë‰ª¨ÁúãÁúãpromptÈïø‰ªÄ‰πàÊ†∑Â≠êÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['product'], output_parser=None, partial_variables={}, template='\\nI want you to act as a naming consultant for new companies.\\nHere are some examples of good company names:\\n- search engine, Google\\n- social media, Facebook\\n- video sharing, YouTube\\nThe name should be short, catchy and easy to remember.\\nWhat is a good name for a company that makes {product}?\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ÂàõÂª∫prompt template\n",
    "Êàë‰ª¨ÂèØ‰ª•‰ªé‰∏äÈù¢ÁöÑÁ§∫‰æã‰∏≠ÁúãÂà∞ÔºöÈÄöËøáLangChainÁöÑPromptTemplateÁ±ªÔºåÂèØ‰ª•ÁîüÊàêÂÖ∑‰ΩìÁöÑpromptÔºåÈÇ£‰πàÈÄöËøáÁªßÁª≠‰ΩøÁî®Ëøô‰∏™Á±ªÁîüÊàêÂá†‰∏™ÂÖ∑‰ΩìÁöÑprompts„ÄÇprompt templateÊé•ÂèóÂ§ö‰∏™ËæìÂÖ•ÂèòÈáèÔºåÁî®Êù•Ê†ºÂºèÂåñÁîüÊàêprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# input_variablesÁöÑÂÄºÂèØ‰ª•‰∏∫Á©∫ÔºåËØ¥ÊòéÂÖ∂‰∏≠Ê≤°Êúâ‰ªª‰ΩïÂèòÈáè\n",
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a joke.\")\n",
    "no_input_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‰∏Ä‰∏™input_variableÁöÑÁ§∫‰æãÔºåËøôÊ†∑Ê®°ÁâàÂåñ‰πãÂêéÁöÑÊèêÁ§∫Â∞ÜÊääadjective‰Ωú‰∏∫ÂèÇÊï∞‰º†ÂÖ•\n",
    "one_input_prompt = PromptTemplate(input_variables=[\"adjective\"], template=\"Tell me a {adjective} joke.\")\n",
    "one_input_prompt.format(adjective=\"funny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Â§ö‰∏™input_variablesÁöÑÁ§∫‰æãÔºåÊ®°ÁâàÂêéÁöÑÊèêÁ§∫Â∞ÜadjectiveÂíåcontent‰Ωú‰∏∫ÂèÇÊï∞‰º†ÂÖ•\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"],\n",
    "    template=\"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "multiple_input_prompt.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ‰ªéLangChainHubÂä†ËΩΩÊú¨Âú∞prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "#ÂèØ‰ª•Âä†ËΩΩÁî®jsonÊ†ºÂºèÂÜôÂ•ΩÁöÑprompt\n",
    "test_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"{input}, tell me the answer by using Chinese.\"\n",
    ")\n",
    "#Â∞ÜÂàõÂª∫Â•ΩÁöÑÊèêÁ§∫Ê®°ÁâàÊ†ºÂºèÂåñÔºåÂÖ∂‰∏≠ÁöÑË°•ÂÖ®ÁöÑÂèòÈáèÂ∞±ÊòØ1+1Á≠â‰∫éÂá†Ôºü\n",
    "test_prompt.format(input=\"what is 1+1?\")\n",
    "#ÁÑ∂ÂêéÂ∞ÜÂàõÂª∫Â•ΩÁöÑÊ®°Áâà‰øùÂ≠òÂú®ÊåáÂÆö‰ΩçÁΩÆÂ§Ñ\n",
    "test_prompt.save(\"test_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='{input}, tell me the answer by using Chinese.', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Âä†ËΩΩÊú¨Âú∞ÁöÑÊ®°Áâà‰ΩøÁî®Âà∞ÁöÑÊñπÊ≥ïÊòØÂõ∫ÂÆöÁöÑÔºåÂ∞ÜÂÖ∑‰ΩìÊñá‰ª∂ÁöÑ‰ΩçÁΩÆ‰º†ÂÖ•Âç≥ÂèØ\n",
    "prompt = load_prompt(\"./test_prompt.json\")\n",
    "prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Âú®prompt template‰∏≠Ê∑ªÂä†Âá†‰∏™‰æãÂ≠ê\n",
    "Â¶ÇÊûúÁîüÊàêÂ∏¶ÊúâÂá†‰∏™‰æãÂ≠êÁöÑÊ®°ÁâàÔºåËØ•ÊÄé‰πàÂÅöÔºüÈÄöËøáPromptTemplateÁ±ªÂõ∫ÁÑ∂ÊòØÂèØ‰ª•ÔºåÂ∞Ü‰æãÂ≠êÂõ∫ÂÆöÂú®ÂÖ∑‰ΩìÁöÑÊ®°Áâà‰∏≠ÊòØÊàë‰ª¨ÊÉ≥Âà∞ÁöÑÊñπÊ≥ï„ÄÇÈÇ£‰πàLangChainÊúâÊ≤°ÊúâÊèê‰æõÁõ¥Êé•ÁöÑÁ±ªÂèØ‰ª•Áî®Êù•ËææÂà∞Êàë‰ª¨ÁöÑÁõÆÁöÑÂíåË¶ÅÊ±Ç„ÄÇ‰∏ãÈù¢ÊòØÁªôËØ≠Ë®ÄÊ®°ÂûãÂá†‰∏™ÂêàÈÄÇÁöÑ‰æãÂ≠ê‰ªéËÄå‰ΩøÂ§ßÊ®°ÂûãËÉΩÂ§üÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂêàÈÄÇÂú∞ÂõûÁ≠îÈóÆÈ¢òÔºåLangChain‰∏≠‰ΩøÁî®FewShotPromptTemplateÁ±ªÁîüÊàêÂ∏¶Êúâ‰æãÂ≠êÁöÑprompt„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ãÈù¢ÊòØÂàõÂª∫‰∏Ä‰∏™ËÆ©Â§ßËØ≠Ë®ÄÊ®°ÂûãÂéªÂõûÁ≠îÂèç‰πâËØçÁöÑÊèêÁ§∫Ê®°ÁâàÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "\n",
      "\n",
      "Word: big\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "#Â¶Ç‰∏ãÊòØÂá†‰∏™ÊèêÁ§∫Á§∫‰æãÔºåËÆ©Â§ßÊ®°ÂûãÁü•ÈÅìÂá†‰∏™‰æãÂ≠êÂõûÁ≠îÁöÑÊó∂ÂÄôÂèØ‰ª•Á±ªÊØîÁùÄÂõûÁ≠î\n",
    "few_examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "#Êàë‰ª¨ÂÆö‰πâÂ¶Ç‰∏ãÁöÑÊèêÁ§∫Ê®°Áâà\n",
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "#Ê®°ÁâàÊ†ºÂºèÂåñÊèêÁ§∫Ê®°Áâà\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "#Áé∞Âú®ÊûÑÂª∫‰∏Ä‰∏™Â∞ëÊ†∑Êú¨ÊèêÁ§∫Ê®°ÁâàÂØπË±°Ôºöfew_shot_prompt\n",
    "'''\n",
    "ÂÖ∂‰∏≠ÁöÑÂèÇÊï∞Êúâexamples, example_prompt, prefix, suffix, input_variablesÂíåexample_separator„ÄÇÂÖ∂‰∏≠Ôºå\n",
    "    examples:Á§∫‰æãÔºåÊ†∑‰æãÔºåËøô‰∏™Â∞±ÊòØÊàë‰ª¨ÂÜôÂ•ΩÁöÑÂá†‰∏™‰æõÂ§ßÊ®°Âûã‰∫ÜËß£Ê†ºÂºè‰ª•Âèä‰æãÂ≠êÁöÑÂÖ∑‰ΩìÊ†∑‰æã\n",
    "    example_prompt:ÂÖ∑‰ΩìÁöÑÊ®°ÁâàÂåñÂêéÁöÑÊèêÁ§∫Ê®°ÁâàÔºåËøô‰∏™ÂèØ‰ª•Â∞±ÊòØÈÄöËøápromptTemplateÊûÑÂª∫ÁöÑÊèêÁ§∫Ê®°ÁâàÔºåÂè™Á≠âÂæÖÂ°´ÂÖ•ÂÖ∑‰ΩìÁöÑÂèòÈáèÔºå\n",
    "ÂÖ∂Ê†ºÂºèÂÜÖÂÆπ‰∏≠Â∑≤ÁªèÂ∞ÜÂæÖË°•ÂÖ®ÁöÑÂèòÈáèÊîæÂú®ÂÖ∂‰∏≠\n",
    "    prefix:ÂâçÁºÄÔºå‰∏ÄËà¨‰Ωú‰∏∫Â§ßÊ®°ÂûãÊé•ÂèóÊåá‰ª§ÁöÑÂÖ•Âè£ÔºåÂèØ‰ª•ÂéªÂ£∞ÊòéÂ§ßÊ®°ÂûãÂç≥Â∞ÜÊâøÊãÖÁöÑËßíËâ≤‰ª•ÂèäÂëäËØâÂ§ßÊ®°ÂûãÂç≥Â∞ÜË¶ÅÂÅöÁöÑ‰∫ãÊÉÖÁ≠â\n",
    "    suffix:ÂêéÁºÄÔºå‰∏ÄËà¨ÊîæÁΩÆ‰∫éÊ†∑‰æã‰πãÂêéÔºå‰Ωú‰∏∫ÊèêÁ§∫Ê®°ÁâàÁöÑÊúÄÂêé‰∏ÄÈÉ®ÂàÜ\n",
    "    input_variables:Â°´Ë°•ÁöÑÂèòÈáè\n",
    "    example_separator:ÂàÜÂâ≤Á¨¶ÔºåÂàÜÂâ≤ÂâçÁºÄ„ÄÅÊ†∑‰æãÂíåÂêéÁºÄÁöÑÊ†áÂøó\n",
    "'''\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=few_examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Word: {input}\\nAntonym:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format(input=\"big\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ‰ªéprompt template‰∏≠ÈÄâÂèñ‰æãÂ≠ê\n",
    "‰∏äÈù¢ÈÇ£‰∏™‰ª£Á†ÅÊ°à‰æã‰∏≠Êèê‰æõÁöÑÊòØÂ∞ëÈáèÊ†∑Êú¨Á§∫‰æãÔºåÂ¶ÇÊûúÊúâÈùûÂ∏∏Â§öÂèØ‰æõLLMÂèÇËÄÉÁöÑ‰æãÂ≠êÊó∂Ôºå‰ΩøÁî®ExampleSelectorÁ±ªÊù•ÂèØÊéßÂà∂Âú∞ÈÄâÊã©Âá†‰∏™ÊúÄÂ•ΩÁöÑ‰æãÂ≠ê‰æõLLMÂ≠¶‰π†„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ãÈù¢ÊòØ‰∏Ä‰∏™‰ΩøÁî®LengthBasedExampleSelectorÈÄâÊã©‰∏ÄÂÆöÈïøËæìÂÖ•ÁöÑ‰æãÂ≠êÔºåÂÆÉÊòØ‰∏Ä‰∏™Ëá™Âä®ÈÄâÊã©‰æãÂ≠êÁöÑÊñπÊ≥ïÔºåÊàë‰ª¨ÂÖ∑‰ΩìÊù•ÁúãÔºö**Â¶ÇÊûúÁî®Êà∑ÊãÖÂøÉpromptË∂ÖËøáËæìÂÖ•Á™óÂè£Â§ßÂ∞èÊó∂ÔºåËøôÂæàÊúâÁî®„ÄÇÂΩìÁî®Êà∑ËæìÂÖ•ÂæàÈïøÊó∂ÔºåÂÆÉËá™Âä®ÈÄâÊã©Â∞ëÈáèÁöÑ‰æãÂ≠êÔºõÂΩìÁî®Êà∑ËæìÂÖ•ÂæàÁü≠Êó∂ÔºåÂÆÉÈÄâÊã©Êõ¥Â§öÁöÑ‰æãÂ≠ê„ÄÇ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Word: energetic\n",
      "Antonym: lethargic\n",
      "\n",
      "\n",
      "\n",
      "Word: big\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "#‰æùÁÑ∂Âíå‰∏äÈù¢‰∏ÄÊ†∑ÔºåÂèç‰πâËØçÂØπÂÑøÁöÑÁªÑÂêàÔºåËøôÈáåÁªôÂá∫‰∏ãÈù¢Âá†ÁßçÔºö\n",
    "few_examples = [\n",
    "    {\"word\": \"beautiful\", \"antonym\": \"ugly\"},\n",
    "    {\"word\": \"outgoing\", \"antonym\": \"incoming\"},\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "    {\"word\": \"energetic\", \"antonym\": \"lethargic\"},\n",
    "    {\"word\": \"sunny\", \"antonym\": \"gloomy\"},\n",
    "    {\"word\": \"windy\", \"antonym\": \"calm\"},\n",
    "]\n",
    "#Êàë‰ª¨ÂÆö‰πâÂ¶Ç‰∏ãÁöÑÊèêÁ§∫Ê®°Áâà\n",
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "#Ê®°ÁâàÊ†ºÂºèÂåñÊèêÁ§∫Ê®°Áâà\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "'''\n",
    "‰ΩøÁî®LengthBasedExampleSelectorÈÄâÊã©‰æãÂ≠ê„ÄÇ\n",
    "ÂÖ∂‰∏≠ÁöÑexamples:Âêå‰∏äÁ§∫‰æã‰∏≠ÁöÑ‰ΩúÁî®\n",
    "example_prompt:Âêå‰∏äÁ§∫‰æã‰∏≠ÁöÑ‰ΩúÁî®\n",
    "max_length:ËøôÊòØÊ†ºÂºèÂåñÂêéÁöÑ‰æãÂ≠êÁöÑÊúÄÂ§ßÈïøÂ∫¶„ÄÇÈïøÂ∫¶Áî±‰∏ãÈù¢ÁöÑget_text_lengthÂáΩÊï∞ÂÜ≥ÂÆö„ÄÇ\n",
    "'''\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=few_examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=25,\n",
    ")\n",
    "\n",
    "#Áé∞Âú®‰ΩøÁî®example_selectorÊù•ÂàõÂª∫fewshotprompttemplate\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Word: {input}\\nAntonym:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "print(dynamic_prompt.format(input=\"big\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ê†πÊçÆ‰∏äÈù¢ÁöÑ‰æãÂ≠êÊàë‰ª¨Áü•ÈÅìÔºöÂΩìËæìÂÖ•ÈóÆÈ¢òÂæàÈïøÊó∂ÔºåLengthBasedExampleSelector‰ºöÈÄâÊã©Êõ¥Â∞ëÁöÑÊèêÁ§∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "long_string = \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\"\n",
    "print(dynamic_prompt.format(input=long_string))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### chat model prompt template\n",
    "‰∏ãÈù¢ÁöÑÁ§∫‰æãÊòØÂà©Áî®prompt templateÂú®chat model‰∏≠‰ΩøÁî®ÁöÑÊÉÖÂÜµÔºöchat modelÂèØ‰ª•‰ΩøÁî®‰ª•ÂâçÁöÑÂéÜÂè≤‰ø°ÊÅØËøõË°åÂçïÊ¨°ÁîüÊàêÂõûÂ§çÔºåÂçïÊ¨°ËæìÂÖ•ÂåÖÂê´‰∫ÜËøáÂéªËÅäÂ§©‰∏≠ÁöÑ‰∏ÄÁ≥ªÂàóÊ®°Êùø„ÄÅ‰æãÂ≠ê„ÄÅÁî®Êà∑ÈóÆÈ¢òÁöÑÁªÑÂêà„ÄÇLangChainÊèê‰æõ‰∫Ü‰∏Ä‰∫õÁ±ªÂíåÊñπÊ≥ï‰ΩøÂæóÊûÑÂª∫Âíå‰ΩøÁî®promptÊõ¥Âä†ÂÆπÊòì„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ChatPromptTemplateÂèØ‰ª•‰ΩøÁî®‰∏Ä‰∏™ÊàñËÄÖÂ§ö‰∏™MessagePromptTemplateÁ±ªÊûÑÂª∫prompt„ÄÇÂèØ‰ª•‰ΩøÁî®ChatPromptTemplateÁöÑformat_promptÂáΩÊï∞ËøîÂõûpromptÂÄºÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂ËΩ¨Âåñ‰∏∫stringÊàñmessageÂØπË±°„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "system_template=\"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}),\n",
       " HumanMessage(content='I love programming.', additional_kwargs={})]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "# ‰ªéÊ†ºÂºèÂåñÁöÑ‰ø°ÊÅØ‰∏≠Ëé∑ÂèñÂÆåÊï¥ÁöÑËÅäÂ§©‰ø°ÊÅØ\n",
    "chat_prompt.format_prompt(input_language=\"English\", output_language=\"French\", text=\"I love programming.\").to_messages()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ãÈù¢ÊòØ‰∏ÄÁßçÂø´ÈÄüÊûÑÂª∫MessagePromptTemplateÁöÑÊñπÊ≥ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "    input_variables=[\"input_language\", \"output_language\"],\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example Selectors\n",
    "Ê†πÊçÆÊ®°ÂûãÂäüËÉΩÈúÄË¶ÅÂä®ÊÄÅÈÄâÊã©ÊèêÁ§∫ËØç\n",
    "LangChain‰∏≠ÁöÑBaseExampleSelectorÁ±ªÁî®‰∫éÈÄâÊã©‰æãÂ≠êÔºåselect_examplesÂáΩÊï∞Êé•Êî∂ËæìÂÖ•ÂèòÈáèÂπ∂ËøîÂõû‰∏ÄÁ≥ªÂàó‰æãÂ≠ê„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Âü∫Êú¨Êé•Âè£ÂÆö‰πâÂ¶Ç‰∏ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict,List\n",
    "'''ÂÆÉÊòØ‰∏Ä‰∏™ÊäΩË±°Âü∫Á±ªÔºå‰∏çËÉΩË¢´Á§∫‰æãÂåñÔºåËÄåÊòØÁî®‰∫éÂÆö‰πâÂÖ∂‰ªñÁ±ªÁöÑÊé•Âè£ÂíåËßÑËåÉ'''\n",
    "class BaseExampleSelector(ABC):\n",
    "    \"\"\"\n",
    "    ËøôÊòØ‰∏Ä‰∏™ÊäΩË±°ÊñπÊ≥ïÔºåÁî±Ê¥æÁîüÁ±ªÂÆûÁé∞Ôºå‰ª•Êª°Ë∂≥BaseExampleSelectorÊé•Âè£ÁöÑË¶ÅÊ±ÇÔºåËøô‰∏™ÊñπÊ≥ïÊòØÊ†πÊçÆËæìÂÖ•ÂèòÈáèÈÄâÊã©Ë¶ÅÂåÖÂê´Âú®ÊèêÁ§∫‰∏≠ÁöÑÁ§∫‰æãÔºåËøîÂõû‰∏Ä‰∏™Â≠óÂÖ∏ÂàóË°®\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def select_examples(self, input_variables: Dict[str, str]) -> List[dict]:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏Ä‰∏™ExampleSelectorÁ±ªÂøÖÈ°ªÂÆûÁé∞‰∏§‰∏™ÊñπÊ≥ïÔºö\n",
    "- 1. add_exampleÊñπÊ≥ïÊé•Âèó‰∏Ä‰∏™‰æãÂ≠êÂ∞ÜÂÖ∂Ê∑ªÂä†Âà∞exampleÂàóË°®‰∏≠\n",
    "- 2. select_examplesÂëäËØâÈÄâÊã©Âô®Â¶Ç‰ΩïÈÄâÊã©‰æãÂ≠êÂπ∂ËøîÂõû‰æãÂ≠ê\n",
    "\n",
    "Âõ†Ê≠§Âú®‰∏Ä‰∏™Á§∫‰æãÈÄâÊã©Âô®‰∏≠ÂèØ‰ª•ÈöèÊó∂Ë∞ÉÁî®‰∏äËø∞‰∏§ÁßçÊñπÊ≥ïÔºå‰∏ãÈù¢ÂÆûÁé∞‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑexample selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "class CustomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples: List[Dict[str, str]]):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example: Dict[str, str]) -> None:\n",
    "        \"\"\"Ê∑ªÂä†Êñ∞ÁöÑ‰æãÂ≠êÊù•Â≠òÂÇ®‰∏Ä‰∏™ÈîÆ\"\"\"\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables: Dict[str, str]) -> List[dict]:\n",
    "        \"\"\"Ê†πÊçÆËæìÂÖ•ÁöÑ‰ø°ÊÅØÈÄâÊã©Ë¶Å‰ΩøÁî®ÁöÑ‰æãÂ≠ê\"\"\"\n",
    "        return np.random.choice(self.examples, size=2, replace=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰ΩøÁî®Ëá™ÂÆö‰πâÁöÑexample selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'foo': '1'}, {'foo': '3'}], dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "examples = [\n",
    "    {\"foo\": \"1\"},\n",
    "    {\"foo\": \"2\"},\n",
    "    {\"foo\": \"3\"}\n",
    "]\n",
    "\n",
    "# ÂàùÂßãÂåñÁ§∫‰æãÈÄâÊã©Âô®\n",
    "example_selector = CustomExampleSelector(examples)\n",
    "# ÈÄâÊã©Á§∫‰æã\n",
    "example_selector.select_examples({\"foo\": \"foo\"})\n",
    "# Â∞ÜÊñ∞ÁöÑ‰æãÂ≠êÊ∑ªÂä†Âà∞‰æãÂ≠êÈõÜ‰∏≠\n",
    "example_selector.add_example({\"foo\": \"4\"})\n",
    "example_selector.examples\n",
    "# ÈÄâÊã©Á§∫‰æã\n",
    "example_selector.select_examples({\"foo\": \"foo\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Âü∫‰∫éÈïøÂ∫¶ÁöÑÁ§∫‰æãÈÄâÊã©Âô®\n",
    "LengthBased ExampleSelectorÊ†πÊçÆÁî®Êà∑ËæìÂÖ•Ëá™Âä®ÈÄâÊã©‰∏ÄÂÆöÊï∞ÈáèÁöÑÁ§∫‰æãÔºõ‰ΩøÊÄªÈïøÂ∫¶‰∏çË∂ÖËøáLLMËæìÂÖ•Á™óÂè£Â§ßÂ∞è„ÄÇ‰∏ãÈù¢ÁöÑÁ§∫‰æãÊàë‰ª¨‰∏äÈù¢Â∞±ÈÅáÂà∞ËøáÔºåÁé∞Âú®Êàë‰ª¨Ëµ∞Âà∞ËøôÈáåÂÜçÁúã‰∏Ä‰∏ãËøô‰∏™‰ª£Á†ÅÁ§∫‰æãÔºåÊòØÂê¶Êõ¥Âä†‰∫ÜËß£ÂÆÉÁöÑÂéüÁêÜÔºü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "# Ëøô‰∫õÊòØÂæàÂ§öÂÖ≥‰∫éÂàõÈÄ†Âèç‰πâËØçÁöÑ‰æãÂ≠ê„ÄÇ\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=25,\n",
    ")\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: tall\n",
      "Output: short\n",
      "\n",
      "Input: energetic\n",
      "Output: lethargic\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: windy\n",
      "Output: calm\n",
      "\n",
      "Input: big\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(dynamic_prompt.format(adjective=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "long_string = \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\"\n",
    "print(dynamic_prompt.format(adjective=long_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: tall\n",
      "Output: short\n",
      "\n",
      "Input: energetic\n",
      "Output: lethargic\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: windy\n",
      "Output: calm\n",
      "\n",
      "Input: big\n",
      "Output: small\n",
      "\n",
      "Input: enthusiastic\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# You can add an example to an example selector as well.\n",
    "new_example = {\"input\": \"big\", \"output\": \"small\"}\n",
    "dynamic_prompt.example_selector.add_example(new_example)\n",
    "print(dynamic_prompt.format(adjective=\"enthusiastic\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Áõ∏‰ººÊÄßÈÄâÊã©Âô®\n",
    "Similarity Example SelectorÊ†πÊçÆ‰æãÂ≠êÂíåËæìÂÖ•ÁöÑÁõ∏‰ººÁ®ãÂ∫¶Êù•ÈÄâÊã©‰æãÂ≠ê„ÄÇËØ•ÈÄâÊã©Âô®Ê†πÊçÆ‰æãÂ≠êÂíåËæìÂÖ•ÁöÑËØçÂµåÂÖ•ÂêëÈáèÁöÑ‰ΩôÂº¶Áõ∏‰ººÊÄßÊù•Â∑•‰Ωú„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# Ëøô‰∫õÊòØÂæàÂ§öÂÖ≥‰∫éÂàõÈÄ†Âèç‰πâËØçÁöÑ‰æãÂ≠ê„ÄÇ\n",
    "few_examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # ËøôÊòØÂèØ‰ª•ÈÄâÊã©ÁöÑ‰æãÂ≠êÊ∏ÖÂçï„ÄÇ\n",
    "    few_examples,\n",
    "    # ËøôÈáå‰ΩøÁî®OpenAIÁöÑÂµåÂÖ•ÊñπÊ≥ïÔºåÁî®‰∫é‰∫ßÁîüÂµåÂÖ•ÔºåËÄåÂµåÂÖ•ÊòØÁî®Êù•Ë°°ÈáèËØ≠‰πâÁõ∏‰ººÊÄßÁöÑ„ÄÇ\n",
    "    OpenAIEmbeddings(),\n",
    "    # ËøôÊòØVectorStoreÁ±ªÔºåÁî®‰∫éÂ≠òÂÇ®ÂµåÂÖ•Âπ∂ËøõË°åÁõ∏‰ººÂ∫¶ÊêúÁ¥¢„ÄÇ\n",
    "    Chroma,\n",
    "    # ËøôÊòØË¶Å‰∫ßÁîüÁöÑ‰æãÂ≠êÁöÑÊï∞Èáè„ÄÇ\n",
    "    k=1\n",
    ")\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: worried\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(similar_prompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: fat\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(similar_prompt.format(adjective=\"fat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: joyful\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# ÊÇ®‰πüÂèØ‰ª•ÂêëSimilarityExampleSelectorÊ∑ªÂä†Êñ∞ÁöÑÁ§∫‰æã„ÄÇ\n",
    "similar_prompt.example_selector.add_example({\"input\": \"enthusiastic\", \"output\": \"apathetic\"})\n",
    "print(similar_prompt.format(adjective=\"joyful\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Output Parser\n",
    "ËæìÂá∫Ëß£ÊûêÂô®ÔºåÈ°æÂêçÊÄù‰πâÔºåÂ∞±ÊòØÂ∞ÜËæìÂá∫Á≠îÊ°àËøõË°åËß£ÊûêÔºåÂÆÉÊåáÁ§∫Ê®°ÂûãÂéªÊ†ºÂºèÂåñËæìÂá∫ÂÜÖÂÆπÔºåÂ∞ÜËæìÂá∫Ëß£Êûê‰∏∫ÈúÄË¶ÅÁöÑÊ†ºÂºè„ÄÇ\n",
    "Output parsersÁ±ªÁªìÊûÑÂåñÊ®°ÂûãÁöÑÂìçÂ∫î‰ø°ÊÅØ„ÄÇ‰æãÂ¶ÇÊàë‰ª¨ÊèêÂâçÂÆö‰πâÂ•ΩËæìÂá∫ÁöÑÂΩ¢ÂºèÂ∫îËØ•ÂåÖÊã¨AÂ±ûÊÄßÂíåBÂ±ûÊÄßÔºåÂ¶ÇÊûúÊ≠£Â∏∏ÊääÊèêÈóÆÈÄÅÁªôÂ§ßÊ®°ÂûãÔºåÂ§ßÊ®°ÂûãÊòØ‰∏ç‰ºöÁªô‰Ω†ÊåáÂÆöÂá∫ÁâπÂà´‰∏•Ê†ºÂàíÂàÜ‰πãÂêéÁöÑÁ≠îÊ°àÁöÑÔºåÂõ†Ê≠§ÊääËøôÁßçÁ≠îÊ°àËøõË°åËß£ÊûêÂ§ÑÁêÜËøõ‰∏ÄÊ≠•ÁªôÂà∞Áî®Êà∑ÔºåÁî®Êà∑ÂèØ‰ª•Áî®Ëß£ÊûêÂ§ÑÁêÜ‰πãÂêéÁöÑÁªìÊûúÂéªÂÅöÊõ¥Êñπ‰æøÁöÑÂ∫îÁî®ÊàñËÄÖÂ∞±Â∑≤ÁªèËææÂà∞Áî®Êà∑ÁöÑÁõÆÁöÑ„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ãÈù¢ÊòØÂÖ≥‰∫éPydanticOutputParserÁöÑ‰∏Ä‰∏™Á§∫‰æãËØ¥ÊòéÔºåPydanticOutputParserËÉΩÂ§üËÆ©LLMËæìÂá∫Á¨¶ÂêàJSONÊ†ºÂºèÁöÑÂõûÂ§ç„ÄÇËØ•ÂäüËÉΩÊïàÊûúÂíåLLMÁîüÊàêËÉΩÂäõÁõ∏ÂÖ≥„ÄÇ\n",
    "‰∏ãÈù¢ÊòØ‰ΩøÁî®PydanticOutputParserÁöÑ‰æãÂ≠ê„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ÊåáÂÆö‰ΩøÁî®ÁöÑÂ§ßÊ®°Âûã\n",
    "model_name = 'text-davinci-003'\n",
    "#ËÆæÁΩÆÂØπÂ∫îÁöÑÈöèÊú∫ÊÄß\n",
    "temperature = 0.0\n",
    "#modelÂç≥ÊòØË∞ÉÁî®Âà∞ÁöÑÂ§ßÊ®°Âûã\n",
    "model = OpenAI(model_name=model_name, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ÂÆö‰πâ‰Ω†ÊÉ≥Ë¶ÅÁöÑÊï∞ÊçÆÁªìÊûÑ\n",
    "\"\"\"ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫JokeÁöÑPydanticÊ®°ÂûãÁ±ªÔºåÁî®Êù•Ë°®Á§∫‰∏Ä‰∏™Á¨ëËØùÔºåÁ§∫‰æãÂåñ‰πãÂêéÁî®‰∫éÊèêÁ§∫Â§ßÊ®°ÂûãÊù•Â°´ÂÖÖËøô‰∏™Êï∞ÊçÆÁªìÊûÑ\"\"\"\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"\n",
    "    setup:Â≠óÁ¨¶‰∏≤Á±ªÂûãÔºå‰ΩøÁî®FieldÂáΩÊï∞ÊåáÂÆö‰∏Ä‰∏™ÊèèËø∞Â≠óÁ¨¶‰∏≤ÔºåËØ•Â±ûÊÄßË°®Á§∫Á¨ëËØùÁöÑÈóÆÈ¢òÈÉ®ÂàÜÔºå‰πüÂ∞±ÊòØÁ¨ëËØùÁöÑÂºÄÂ§¥\n",
    "    punchline:Â≠óÁ¨¶‰∏≤Á±ªÂûãÔºåÂêåÊ†∑‰ΩøÁî®FieldÂáΩÊï∞ÊåáÂÆö‰∏Ä‰∏™ÊèèËø∞Â≠óÁ¨¶‰∏≤ÔºåË°®Á§∫Á¨ëËØùÁöÑÁ≠îÊ°àÈÉ®ÂàÜ‰πüÂ∞±ÊòØÁ¨ëËØùÁöÑÁªìÂ∞æ\n",
    "    \"\"\"\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "    # ‰Ω†ÂèØ‰ª•Áî®PydanticËΩªÊùæÂú∞Ê∑ªÂä†Ëá™ÂÆö‰πâÈÄªËæëÁªìÊûÑ„ÄÇ\n",
    "    \"\"\"\n",
    "    Ë£ÖÈ•∞Âô®ÊàêÂàÜÔºåÁî®‰∫éÊ†áËÆ∞Êé•‰∏ãÊù•ÁöÑÊñπÊ≥ïÊòØ‰∏Ä‰∏™È™åËØÅÂô®ÔºåÈ™åËØÅÂô®ÊòØ‰∏Ä‰∏™ÂáΩÊï∞ÔºåÊé•Âèó‰∏Ä‰∏™Â≠óÊÆµÂÄºÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™ÁªèËøáÈ™åËØÅÁöÑÂÄºÔºåËøôÈáåÊ†áËÆ∞ÁöÑÂ∞±ÊòØ\n",
    "    question_ends_with_question_markÊñπÊ≥ïÊòØ‰∏Ä‰∏™È™åËØÅÂô®ÔºåÂ∞Ü‰ºöÁî®‰∫ésetupÂ±ûÊÄß\n",
    "    \"\"\"\n",
    "    @validator('setup')\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != '?':\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ÂèÇÊï∞ÂÄºÊòØ‰πãÂâçÂÆö‰πâÁöÑjokeÁ±ªÔºåparserÂØπË±°ÁöÑ‰ΩúÁî®ÊòØÊääËæìÂá∫ÁªìÊûúËß£ÊûêÊàê‰∏Ä‰∏™jokeÂØπË±°\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "prompttemplateÁöÑ‰∏§‰∏™Ê®°ÁâàÂèÇÊï∞Âç†‰ΩçÁ¨¶ÊòØformat_instructionsÂíåqueryÔºå‰ΩÜÊòØÊåáÂÆöÁöÑinput_variablesÊòØquery,\n",
    "ËÄåpartial_variablesÂàôÊòØÊåáÂÆö‰∏Ä‰∏™Â≠óÂÖ∏ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫ÜÈîÆ‰∏∫format_instructionsÁöÑÂèòÈáè‰ø°ÊÅØÔºåËøô‰∏™ÂÄºÊòØ‰πãÂâçÂÆö‰πâÁöÑparserÂØπË±°\n",
    "Ë∞ÉÁî®get_format_instructionsÊñπÊ≥ïËøîÂõûÁöÑÊ†ºÂºèËØ¥ÊòéÂ≠óÁ¨¶‰∏≤\n",
    "'''\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Â∞ÜÁî®Êà∑ÁöÑquery‰º†ÂÖ•ÊèêÁ§∫Ê®°Áâà‰∏≠\n",
    "joke_query = \"Tell me a joke.\"\n",
    "_input = prompt.format_prompt(query=joke_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output = model(_input.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ãÈù¢ÊòØÂè¶Â§ñ‰∏Ä‰∏™Á§∫‰æãÔºåÊàë‰ª¨Êé•ÁùÄÁúã‰∏Ä‰∏ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Cast Away', 'Toy Story'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "‰∏ãÈù¢ËøôÊÆµ‰ª£Á†ÅÂÆö‰∏Ä‰∏™‰∫Ü‰∏Ä‰∏™Âêç‰∏∫actorÁöÑÊï∞ÊçÆÁªìÊûÑÔºåÂÆÉ‰πüÊòØÂü∫‰∫ébasemodelÁ±ªÂàõÂª∫ÁöÑÔºåËøô‰∏™actorÊúâ‰∏§‰∏™Â±ûÊÄßÔºåÂàÜÂà´ÊòØname\n",
    "Âíåfile_namesÔºåÁî®Êù•Ë°®Á§∫ÂßìÂêçÂíåÊºîÂëòÂá∫ÊºîÁöÑÁîµÂΩ±ÂàóË°®ÔºåËøô‰∏§‰∏™Â±ûÊÄß‰∏äÔºåÂêåÊ†∑ÈÄÇÁî®fieldÁ±ªÔºå‰∏∫‰∏§ËÄÖÂàÜÂà´ÊåáÂÆö‰∫ÜdescriptionÂ±ûÊÄßÔºåÁî®Êù•\n",
    "ÊèèËø∞Ëøô‰∏§‰∏™Â±ûÊÄßÁöÑ‰ΩúÁî®„ÄÇ\n",
    "ÂÖ∂‰∏≠Ôºö\n",
    "    actor_query:Áî®Êà∑ËæìÂÖ•ÁöÑÈóÆÈ¢ò\n",
    "    parser:PydanticOutputParserÁ±ªÂÆû‰æãÔºå‰ΩúÁî®ÊòØÂ∞ÜËæìÂá∫ÁöÑÁªìÊûúËß£ÊûêÊàê‰∏Ä‰∏™actorÂØπË±°\n",
    "    prompt: prompttemplateÁ±ªÂÆû‰æãÔºåÂåÖÂê´‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤Ê®°ÁâàÂíå‰∏Ä‰∫õÂèòÈáè\n",
    "\"\"\"\n",
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "actor_query = \"Generate the filmography for a random actor.\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=actor_query)\n",
    "\n",
    "output = model(_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Index\n",
    "ËØ•Ê®°ÂùóÁî®‰∫éÊé•ÂèóÁî®Êà∑Êü•ËØ¢ÔºåËøîÂõûÊúÄÁõ∏ÂÖ≥Ê¶ÇÂøµ„ÄÇ\n",
    "ËøôÈáåLangChain‰∏ªË¶ÅÂú®ÈíàÂØπÁî®Êà∑Êèê‰æõÁöÑÊñáÊ°£ÊûÑÂª∫Á¥¢ÂºïÔºåÂ∞ÜÁ¥¢ÂºïÁªÑÂêàÊàêÊ£ÄÁ¥¢Âô®ÔºõÁÑ∂ÂêéÂèØ‰ª•Âª∫Á´ã‰∏Ä‰∏™ÈóÆÁ≠îÈìæÁî®‰∫éÊ®°ÂûãÊèêÈóÆÂõûÁ≠î„ÄÇ\n",
    "LangChain‰ΩøÁî®chromadbÊûÑÂª∫ÂêëÈáèÊ±†vectorstoreÔºåÂêëÈáèÊ±†Áî®‰∫éÊ£ÄÁ¥¢ÂíåÊü•ÊâæËØçÂµåÂÖ•„ÄÇ\n",
    "\n",
    "ËØ¶ÁªÜÊñáÊ°£ËØ¥ÊòéÁÇπÂáªüëâ[Ê≠§Â§Ñ](https://python.langchain.com/en/latest/modules/indexes.html)üëàÁõ¥Êé•ËÆøÈóÆ„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∫ÜËß£Á¥¢ÂºïÂü∫Êú¨Ê¶ÇÂøµ‰πüÂæàÈáçË¶ÅÔºå‰∏ãÈù¢ÊòØÁ¥¢ÂºïÂô®RetrieverÁöÑÊé•Âè£ÔºåÁî®Êà∑ÂèØ‰ª•Ëá™Â∑±ÂÆûÁé∞Â¶Ç‰ΩïËøîÂõûÁõ∏ÂÖ≥ÊñáÊ°£„ÄÇLangChainÂÖ≥Ê≥®‰∫é‰ΩøÁî®Vectorstore retrieverËøõË°åÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "\"\"\"\n",
    "ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫BaseRetrieverÁöÑÊäΩË±°Âü∫Á±ªÔºåÁªßÊâøËá™ABC„ÄÇËØ•Á±ªÂåÖÂê´‰∫Ü‰∏Ä‰∏™Âêç‰∏∫get_relevant_documentsÁöÑÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÊé•Âèó‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤Á±ªÂûãÁöÑ\n",
    "ÂèÇÊï∞query,Âπ∂ËøîÂõû‰∏Ä‰∏™ÊñáÊ°£ÂàóË°®(List[Document])„ÄÇÊ≥®Èáä‰∏≠ÊèêÂà∞‰∫ÜabstractmethodË£ÖÈ•∞Âô®ÔºåËøôË°®Á§∫get_relevant_documentsÊñπÊ≥ïÊòØ‰∏Ä‰∏™ÊäΩË±°Êñπ\n",
    "Ê≥ïÔºåÂ≠êÁ±ªÂøÖÈ°ªÂÆûÁé∞ËØ•ÊñπÊ≥ï„ÄÇ\n",
    "\"\"\"\n",
    "class BaseRetriever(ABC):\n",
    "    #Ëøô‰∏™ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØÊ†πÊçÆËæìÂÖ•ÁöÑÊü•ËØ¢ËØ≠Âè•(query)Ëé∑ÂèñÁõ∏ÂÖ≥ÁöÑÊñáÊú¨ÂÜÖÂÆπ„ÄÇËøîÂõûÂÄº‰∏∫‰∏Ä‰∏™ÊñáÊ°£ÂàóË°®ÔºåÊØè‰∏™ÊñáÊ°£ÈÉΩÊòØ‰∏Ä‰∏™DocumentÂØπË±°„ÄÇ\n",
    "    @abstractmethod\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"Get texts relevant for a query.\n",
    "\n",
    "        Args:\n",
    "            query: string to find relevant texts for\n",
    "\n",
    "        Returns:\n",
    "            List of relevant documents\n",
    "        \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ËøôÈáåÂÖàÂä†ËΩΩÈúÄË¶ÅÁöÑÊñáÊ°£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "#Áî®‰∫é‰ªéÊñá‰ª∂‰∏≠Âä†ËΩΩÊñáÊú¨Êï∞ÊçÆ„ÄÇÂÖ∂‰∏≠ÔºåÂèÇÊï∞'state_of_the_union.txt'Ë°®Á§∫Ë¶ÅÂä†ËΩΩÁöÑÊñá‰ª∂ÂêçÔºå\n",
    "#encoding='utf-8'Ë°®Á§∫Êñá‰ª∂ÁöÑÁºñÁ†ÅÊ†ºÂºè‰∏∫UTF-8„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå\n",
    "#‰ΩúÁî®ÊòØÂ∞ÜÊñá‰ª∂state_of_the_union.txt‰∏≠ÁöÑÂÜÖÂÆπËØªÂèñÂà∞ÂÜÖÂ≠ò‰∏≠ÔºåÂπ∂‰ª•Â≠óÁ¨¶‰∏≤ÁöÑÂΩ¢ÂºèÂ≠òÂÇ®Âú®ÂèòÈáèloader‰∏≠„ÄÇ\n",
    "loader = TextLoader('state_of_the_union.txt',encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ÂàõÂª∫Á¥¢Âºï"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ãÈù¢ÁöÑËØ≠Âè•‰ΩøÁî®VectorstoreIndexCreatorÁõ¥Êé•ÂàõÂª∫Á¥¢Âºï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VectorstoreIndexCreatorÁ±ªÁî®‰∫éÂàõÂª∫ÂêëÈáèÁ©∫Èó¥Á¥¢Âºï(Vector Space Index)„ÄÇÈÄöËøáË∞ÉÁî®from_loadersÊñπÊ≥ïÊù•ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫indexÁöÑÂØπË±°Ôºå\n",
    "ËØ•ÊñπÊ≥ïÊé•Âèó‰∏Ä‰∏™ÂèÇÊï∞ÂàóË°®ÔºåÂàóË°®‰∏≠Âè™ÂåÖÂê´‰∏Ä‰∏™ÂÖÉÁ¥†ÔºåÂç≥‰πãÂâçÊèêÂà∞ÁöÑTextLoaderÂØπË±°loader„ÄÇfrom_loadersÊñπÊ≥ïÁöÑ‰ΩúÁî®ÊòØÂ∞ÜÂ§ö‰∏™ÊñáÊú¨Êï∞ÊçÆÂä†ËΩΩÂô®(TextLoader)\n",
    "Â∞ÅË£ÖÊàê‰∏Ä‰∏™ÂêëÈáèÁ©∫Èó¥Á¥¢ÂºïÂØπË±°„ÄÇÂõ†Ê≠§ÔºåindexÁöÑ‰ΩúÁî®ÊòØÂ∞Üstate_of_the_union.txtÊñá‰ª∂‰∏≠ÁöÑÂÜÖÂÆπËØªÂèñÂà∞ÂÜÖÂ≠ò‰∏≠ÔºåÂπ∂‰ª•Â≠óÁ¨¶‰∏≤ÁöÑÂΩ¢ÂºèÂ≠òÂÇ®Âú®ÂèòÈáèloader‰∏≠ÔºåÁÑ∂Âêé\n",
    "‰ΩøÁî®VectorstoreIndexCreatorÁ±ªÂ∞ÜÂÖ∂Â∞ÅË£ÖÊàê‰∏Ä‰∏™ÂêëÈáèÁ©∫Èó¥Á¥¢ÂºïÂØπË±°index„ÄÇ\n",
    "\"\"\"\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Áé∞Âú®Á¥¢ÂºïÂª∫Á´ã‰∫ÜÔºåÂ∞±ÂèØ‰ª•ÂºÄÂßãÊ†πÊçÆÊñáÊ°£ÈóÆÈóÆÈ¢ò‰∫Ü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The president said that Ketanji Brown Jackson is one of the nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also said that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\""
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What did the president say about Ketanji Brown Jackson',\n",
       " 'answer': \" The president said that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson, one of the nation's top legal minds, to continue Justice Breyer's legacy of excellence, and that she has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\\n\",\n",
       " 'sources': 'state_of_the_union.txt'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "index.query_with_sources(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Â¶ÇÊûúÂè™ÊòØÊÉ≥ËÆøÈóÆvectorstoreÔºåÂèØ‰ª•ËøôÊ†∑ÂÅö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.chroma.Chroma at 0x18fa13c05b0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.vectorstore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ÊàñËÄÖÊÉ≥ËÆøÈóÆVectorstoreRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x0000018FA13C05B0>, search_type='similarity', search_kwargs={})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.vectorstore.as_retriever()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏äÈù¢ÊòØÁî®Á¥¢ÂºïÊü•ËØ¢ÁöÑ‰æãÂ≠êÔºåÈÇ£‰πàÁ¥¢ÂºïÊòØÊÄé‰πàÂàõÂª∫ÁöÑÂë¢ÔºåÊúâ3Ê≠•Ôºö\n",
    "1.Â∞ÜÊñáÊ°£ÂàíÂàÜÊàêÂùó\n",
    "2.ÂØπÊØèÂùóÂàõÂª∫ËØçÂµåÂÖ•\n",
    "3.Â∞ÜÊñáÊ°£ÂíåËØçÂµåÂÖ•Â≠òÂú®ÂêëÈáèÊ±†‰∏≠\n",
    "‰∏ãÈù¢‰ºö‰∏ÄÊ≠•Ê≠•Â±ïÁ§∫"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Âä†ËΩΩÊñáÊ°£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ÊñáÊ°£ÂàáÂùó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\"\"\"\n",
    "CharacterTextSplitterÁ±ªÁî®‰∫éÂ∞ÜÊñáÊú¨Êï∞ÊçÆÊåâÁÖßÊåáÂÆöÁöÑÂ§ßÂ∞èËøõË°åÂàíÂàÜ(chunking)„ÄÇÊé•‰∏ãÊù•Ôºå‰ª£Á†ÅÈÄöËøáË∞ÉÁî®split_documentsÊñπÊ≥ïÊù•ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫\n",
    "text_splitterÁöÑÂØπË±°ÔºåËØ•ÊñπÊ≥ïÊé•Âèó‰∏§‰∏™ÂèÇÊï∞Ôºöchunk_sizeË°®Á§∫ÊØè‰∏™ÊñáÊ°£Ë¢´ÂàíÂàÜÊàêÁöÑÂ§ßÂ∞èÔºåchunk_overlapË°®Á§∫ÊñáÊ°£‰πãÈó¥ÁöÑÈáçÂè†Â§ßÂ∞è„ÄÇchunk_sizeË¢´\n",
    "ËÆæÁΩÆ‰∏∫1000,chunk_overlapË¢´ËÆæÁΩÆ‰∏∫0„ÄÇÁÑ∂ÂêéÔºå‰ª£Á†ÅË∞ÉÁî®split_documentsÊñπÊ≥ïÊù•Â∞ÜdocumentsÂàóË°®‰∏≠ÁöÑÊñáÊ°£ÊåâÁÖßÊåáÂÆöÁöÑÂ§ßÂ∞èËøõË°åÂàíÂàÜÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™ÂåÖ\n",
    "Âê´ÊâÄÊúâÂàíÂàÜÂêéÊñáÊ°£ÁöÑÂàóË°®texts„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºåsplit_documentsÊñπÊ≥ïÁöÑ‰ΩúÁî®ÊòØÂ∞Ü‰∏Ä‰∏™ÊñáÊú¨ÂàóË°®ÊåâÁÖßÊåáÂÆöÁöÑÂ§ßÂ∞èËøõË°åÂàíÂàÜÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÂàíÂàÜÂêéÊñáÊ°£ÁöÑ\n",
    "ÂàóË°®„ÄÇ\n",
    "\"\"\"\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ê†πÊçÆÈúÄË¶Å‰ªéÂêàÈÄÇÁöÑËØçÂµåÂÖ•ÊñπÊ≥ï‰∏≠ÈÄâ‰∏Ä‰∏™ËøõË°åËØçÂµåÂÖ•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ãÈù¢Áî®ËØçÂµåÂÖ•ÂíåÂùóÂàõÂª∫ÂêëÈáèÊ±†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\"\"\"\n",
    "ChromaÁ±ªÁî®‰∫éÂ∞ÜÂêëÈáèÁ©∫Èó¥Á¥¢Âºï(Vector Space Index)‰∏éÊñáÊú¨Êï∞ÊçÆÁªìÂêàËµ∑Êù•Ôºå‰ª•ÂÆûÁé∞ÂØπÊñáÊú¨Êï∞ÊçÆÁöÑÂêëÈáèÂåñË°®Á§∫„ÄÇÊé•‰∏ãÊù•Ôºå‰ª£Á†ÅÈÄöËøáË∞ÉÁî®\n",
    "from_documentsÊñπÊ≥ïÊù•ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫dbÁöÑÂØπË±°ÔºåËØ•ÊñπÊ≥ïÊé•Âèó‰∏§‰∏™ÂèÇÊï∞ÔºötextsÂíåembeddings„ÄÇÂÖ∂‰∏≠ÔºåtextsÊòØ‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÊñáÊú¨Êï∞ÊçÆÁöÑÂàóË°®Ôºå\n",
    "embeddingsÊòØ‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÂêëÈáèÊï∞ÊçÆÁöÑ‰∫åÁª¥Êï∞ÁªÑ„ÄÇfrom_documentsÊñπÊ≥ïÁöÑ‰ΩúÁî®ÊòØÂ∞ÜÊåáÂÆöÁöÑÊñáÊú¨Êï∞ÊçÆÂíåÂêëÈáèÊï∞ÊçÆÁªìÂêàËµ∑Êù•ÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâ\n",
    "ÊñáÊ°£ÂêëÈáèÁöÑ‰∫åÁª¥Êï∞ÁªÑ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºåfrom_documentsÊñπÊ≥ïÁöÑ‰ΩúÁî®ÊòØÂ∞ÜÊåáÂÆöÁöÑÊñáÊú¨Êï∞ÊçÆÂíåÂêëÈáèÊï∞ÊçÆÁªìÂêàËµ∑Êù•Ôºå‰ª•ÂÆûÁé∞ÂØπÊñáÊú¨Êï∞ÊçÆÁöÑÂêëÈáèÂåñË°®Á§∫„ÄÇtexts\n",
    "ÊòØ‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÊñáÊú¨Êï∞ÊçÆÁöÑÂàóË°®ÔºåembeddingsÊòØ‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÂêëÈáèÊï∞ÊçÆÁöÑ‰∫åÁª¥Êï∞ÁªÑ„ÄÇ\n",
    "\"\"\"\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ÁÑ∂ÂêéÂàõÂª∫Á¥¢Âºï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ë∞ÉÁî®dbÂØπË±°ÁöÑas_retrieverÊñπÊ≥ïÊù•ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫retrieverÁöÑÂØπË±°„ÄÇ\n",
    "ËØ•ÊñπÊ≥ïÁöÑ‰ΩúÁî®ÊòØÂ∞ÜdbÂØπË±°ËΩ¨Êç¢‰∏∫‰∏Ä‰∏™Ê£ÄÁ¥¢Âô®(retriever),‰ª•‰æøÂú®ÂêéÁª≠ÁöÑËÆ°ÁÆó‰∏≠‰ΩøÁî®„ÄÇ\n",
    "retrieverÂ∞ÜË¢´Áî®‰∫é‰ªéÊï∞ÊçÆÂ∫ì‰∏≠Ê£ÄÁ¥¢‰∏éÁªôÂÆöÊü•ËØ¢Áõ∏ÂÖ≥ÁöÑÊñáÊ°£ÂêëÈáè„ÄÇ\n",
    "\"\"\"\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Êé•‰∏ãÊù•ÂàõÂª∫‰∏Ä‰∏™ÈìæÂπ∂ÈóÆÈóÆÈ¢ò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The President said that Ketanji Brown Jackson is one of the nation's top legal minds and that she will continue Justice Breyer's legacy of excellence.\""
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "RetrievalQAÁ±ªÁî®‰∫éÂÆûÁé∞Âü∫‰∫éÊ£ÄÁ¥¢Âô®ÁöÑÈóÆÁ≠î(Question Answering)‰ªªÂä°„ÄÇÊé•‰∏ãÊù•Ôºå‰ª£Á†ÅÈÄöËøáË∞ÉÁî®from_chain_typeÊñπÊ≥ïÊù•ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫qaÁöÑÂØπË±°Ôºå\n",
    "ËØ•ÊñπÊ≥ïÊé•Âèó‰∏â‰∏™ÂèÇÊï∞Ôºöllm„ÄÅchain_typeÂíåretriever„ÄÇÂÖ∂‰∏≠ÔºållmË°®Á§∫ËØ≠Ë®ÄÊ®°Âûã(Language Model),chain_typeË°®Á§∫Êü•ËØ¢Á±ªÂûã(query type),\n",
    "retrieverË°®Á§∫Ê£ÄÁ¥¢Âô®(retriever)„ÄÇfrom_chain_typeÊñπÊ≥ïÁöÑ‰ΩúÁî®ÊòØÊ†πÊçÆÊåáÂÆöÁöÑÊü•ËØ¢Á±ªÂûãÂíåÊ£ÄÁ¥¢Âô®ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫qaÁöÑÂØπË±°Ôºå‰ª•‰æøÂú®ÂêéÁª≠ÁöÑËÆ°ÁÆó‰∏≠‰ΩøÁî®„ÄÇ\n",
    "llmË¢´ËÆæÁΩÆ‰∏∫OpenAI(),chain_typeË¢´ËÆæÁΩÆ‰∏∫\"stuff\",retrieverË¢´ËÆæÁΩÆ‰∏∫‰πãÂâçÂàõÂª∫ÁöÑretrieverÂØπË±°„ÄÇ\n",
    "\"\"\"\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "\"\"\"\n",
    "runÊñπÊ≥ïÂ∞ÜÊâßË°å‰ª•‰∏ãÊìç‰ΩúÔºöÈ¶ñÂÖà‰ªéÊï∞ÊçÆÂ∫ì‰∏≠Ê£ÄÁ¥¢‰∏éÁªôÂÆöÊü•ËØ¢Áõ∏ÂÖ≥ÁöÑÊñáÊ°£ÂêëÈáèÔºõÁÑ∂ÂêéÂ∞ÜÁî®Êà∑ËæìÂÖ•ÁöÑÈóÆÈ¢ò‰∏éÊØè‰∏™ÊñáÊ°£ÂêëÈáèËøõË°åÂåπÈÖçÔºåÊâæÂà∞ÊúÄ‰Ω≥ÁöÑÊñáÊ°£ÂêëÈáè‰Ωú‰∏∫Á≠îÊ°àÔºõ\n",
    "ÊúÄÂêéÂ∞ÜÁ≠îÊ°àÂ∞ÅË£ÖÊàê‰∏Ä‰∏™‰∏âÂÖÉÁªÑËøîÂõûÁªôÁî®Êà∑„ÄÇ\n",
    "\"\"\"\n",
    "qa.run(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ÊÄªÁªì‰ª•‰∏äËøáÁ®ãÔºåVectorstoreIndexCreatorÂ∞±ÊòØÂÅö‰∫ÜÂàáÂùóÔºåËØçÂµåÂÖ•ÔºåÂàõÂª∫Á¥¢ÂºïÁöÑËøáÁ®ã„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_creator = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=Chroma,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Memory\n",
    "\n",
    "MemoryÊ∂âÂèäÂú®Áî®Êà∑‰∏éËØ≠Ë®ÄÊ®°ÂûãÁöÑÊï¥‰∏™‰∫§‰∫íËøáÁ®ã‰∏≠‰øùÊåÅÁä∂ÊÄÅÊ¶ÇÂøµ„ÄÇÁî®Êà∑‰∏éËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∫§‰∫íÂú® ChatMessages ÁöÑÊ¶ÇÂøµ‰∏≠Ë¢´ÊçïËé∑ÔºåÂõ†Ê≠§ËøôÂΩíÁªì‰∏∫‰ªé‰∏ÄÁ≥ªÂàóËÅäÂ§©Ê∂à\n",
    "ÊÅØ‰∏≠ÊëÑÂèñ„ÄÅÊçïËé∑„ÄÅËΩ¨Êç¢ÂíåÊèêÂèñÁü•ËØÜ„ÄÇÊúâËÆ∏Â§ö‰∏çÂêåÁöÑÊñπÊ≥ïÂèØ‰ª•ÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºåÊØè‰∏Ä\n",
    "ÁßçÈÉΩÊúâËá™Â∑±ÁöÑÂÜÖÂ≠òÁ±ªÂûã„ÄÇÈÄöÂ∏∏ÔºåÂØπ‰∫éÊØèÁßçÁ±ªÂûãÁöÑÂÜÖÂ≠òÔºåÊúâ‰∏§ÁßçÁêÜËß£‰ΩøÁî®ÂÜÖÂ≠òÁöÑÊñπÊ≥ï„ÄÇËøô‰∫õÊòØ‰ªé‰∏ÄÁ≥ªÂàóÊ∂àÊÅØ‰∏≠ÊèêÂèñ‰ø°ÊÅØÁöÑÁã¨Á´ãÂáΩÊï∞ÔºåÁÑ∂ÂêéÊÇ®ÂèØ‰ª•Âú®Èìæ‰∏≠‰ΩøÁî®ËøôÁßçÁ±ªÂûãÁöÑÂÜÖÂ≠ò„ÄÇÂÜÖÂ≠òÂèØ‰ª•ËøîÂõûÂ§öÊù°‰ø°ÊÅØÔºà‰æãÂ¶ÇÔºåÊúÄËøëÁöÑ N Êù°Ê∂àÊÅØÂíå‰πãÂâçÊâÄÊúâÊ∂àÊÅØÁöÑÊëòË¶ÅÔºâ„ÄÇËøîÂõûÁöÑ‰ø°ÊÅØÂèØ‰ª•ÊòØÂ≠óÁ¨¶‰∏≤ÊàñÊ∂àÊÅØÂàóË°®„ÄÇÊàë‰ª¨Â∞Ü‰ªãÁªçÊúÄÁÆÄÂçïÁöÑÂÜÖÂ≠òÂΩ¢ÂºèÔºö‚ÄúBuffer‚ÄùÂÜÖÂ≠òÔºåÂÆÉÂè™Ê∂âÂèä‰øùÁïôÊâÄÊúâÂÖàÂâçÊ∂àÊÅØÁöÑÁºìÂÜ≤Âå∫„ÄÇÊàë‰ª¨Â∞ÜÂú®ËøôÈáåÂ±ïÁ§∫Â¶Ç‰Ωï‰ΩøÁî®Ê®°ÂùóÂåñÂÆûÁî®ÂáΩÊï∞ÔºåÁÑ∂ÂêéÂ±ïÁ§∫Â¶Ç‰ΩïÂú®Èìæ‰∏≠‰ΩøÁî®ÂÆÉÔºàÊó¢ËøîÂõûÂ≠óÁ¨¶‰∏≤ÂèàËøîÂõûÊ∂àÊÅØÂàóË°®Ôºâ„ÄÇ\n",
    "\n",
    "LLMsÂíåchat modelsÈÉΩÊòØÊó†Áä∂ÊÄÅÁöÑÔºåÊØèÊ¨°ËæìÂÖ•ËØ∑Ê±ÇÈÉΩÊòØÁã¨Á´ãÁöÑÔºõChainsÂíåAgentsÂü∫‰∫éÂ∫ïÂ±ÇÊ®°ÂùóÂºÄÂèëÔºå‰πüÊòØÊó†Áä∂ÊÄÅÁöÑ„ÄÇÂú®‰∏Ä‰∫õÂ∫îÁî®‰∏≠ÔºåÊØîÂ¶ÇËÅäÂ§©Êú∫Âô®‰∫∫ÔºåËÆ©ËØ≠Ë®ÄÊ®°ÂûãÁü•ÈÅì‰πãÂâçÁöÑËÅäÂ§©ÂÜÖÂÆπÂæàÈáçË¶Å„ÄÇËøôÂ∞±ÊòØMemoryÊ®°ÂùóÂ≠òÂú®ÁöÑÊÑè‰πâ„ÄÇ\n",
    "\n",
    "LangChainÊèê‰æõ‰∏§ÁßçmemoryÁªÑ‰ª∂ÔºõÁ¨¨‰∏ÄÔºåLangChainÊèê‰æõhelper utilitiesË¥üË¥£ÁÆ°ÁêÜÂíåÊìç‰Ωú‰πãÂâçÁöÑËÅäÂ§©‰ø°ÊÅØÔºõÁ¨¨‰∫åÔºåLangChainÊèê‰æõÂ∞ÜËøô‰∫õÁ®ãÂ∫èÂêàÂπ∂Âà∞ChainsÊ®°Âùó‰∏≠ÁöÑÊñπÊ≥ï„ÄÇ\n",
    "\n",
    "Êü•ÁúãÂÆåÊï¥ÊñáÊ°£‰ª•ÂèäÁ§∫‰æãËØ¥ÊòéÔºåÁÇπÂáªüëâ[LangChainÂÆòÁΩëÁõ¥Ëææ](https://python.langchain.com/en/latest/index.html)„ÄÇ\n",
    "\n",
    "‰∏ãÈù¢ÊòØÊ∑ªÂä†MemoryÁöÑ‰∏§‰∏™Ê°à‰æãÔºåÊñπ‰æøÂø´ÈÄü‰∫ÜËß£Ôºö"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Add Memory to an LLMChain](#add-memory-to-an-llmchain)\n",
    "- [Add Memory to an Agent](#add-memory-to-an-agent)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Êàë‰ª¨Áî®Ëøô‰∏™ConversationBufferMemoryËøõË°å‰∏æ‰æãÔºåÂõ†Ê≠§ÂÖàÁúã‰∏Ä‰∏ãËøô‰∏™Á±ªÊòØ‰ªÄ‰πàÊ†∑ÁöÑÔºö"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ConversationBufferMemory\n",
    "ConversationBufferMemoryÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑ËΩªÊùæÂàõÂª∫ÂØπËØùÂéÜÂè≤ÔºåÁî®Ê≥ïÂ¶Ç‰∏ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\"\"\"\n",
    "ConversationBufferMemoryÁ±ªÁî®‰∫éÂÆûÁé∞Âü∫‰∫éËÆ∞ÂøÜÁºìÂ≠ò(Memories)ÁöÑÂØπËØùÁ≥ªÁªü(Conversational System)„ÄÇÊé•‰∏ãÊù•Ôºå‰ª£Á†ÅÈÄöËøáË∞ÉÁî®\n",
    "from_memoryÊñπÊ≥ïÊù•ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫memoryÁöÑÂØπË±°ÔºåËØ•ÊñπÊ≥ï‰∏çÊé•Âèó‰ªª‰ΩïÂèÇÊï∞„ÄÇËØ•ÊñπÊ≥ïÁöÑ‰ΩúÁî®ÊòØÊ†πÊçÆÈªòËÆ§ÈÖçÁΩÆÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫memoryÁöÑÂØπË±°Ôºå‰ª•‰æø\n",
    "Âú®ÂêéÁª≠ÁöÑËÆ°ÁÆó‰∏≠‰ΩøÁî®„ÄÇ\n",
    "memoryÂ∞ÜË¢´Áî®‰∫éÂ≠òÂÇ®Áî®Êà∑ÂíåAI‰πãÈó¥ÁöÑÂØπËØùÂéÜÂè≤ËÆ∞ÂΩï„ÄÇ\n",
    "ÁÑ∂ÂêéÔºåË∞ÉÁî®memoryÂØπË±°ÁöÑchat_memoryÂ±ûÊÄßÊù•ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫chat_memoryÁöÑÂØπËØùÁºìÂ≠ò(Conversation Buffer),Âπ∂ÂêëÂÖ∂Ê∑ªÂä†‰∏§Êù°Ê∂àÊÅØÔºö‰∏ÄÊù°\n",
    "ÊòØÁî®Êà∑ÂèëÈÄÅÁöÑÊ∂àÊÅØ\"hi!\",Âè¶‰∏ÄÊù°ÊòØAIÂèëÈÄÅÁöÑÊ∂àÊÅØ\"whats up?\"„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºåchat_memory.add_user_message()ÊñπÊ≥ïÁöÑ‰ΩúÁî®ÊòØÂ∞Ü‰∏ÄÊù°Áî®Êà∑Ê∂à\n",
    "ÊÅØÊ∑ªÂä†Âà∞ÂØπËØùÁºìÂ≠ò‰∏≠ÔºõËÄåchat_memory.add_ai_message()ÊñπÊ≥ïÁöÑ‰ΩúÁî®ÊòØÂ∞Ü‰∏ÄÊù°AIÊ∂àÊÅØÊ∑ªÂä†Âà∞ÂØπËØùÁºìÂ≠ò‰∏≠„ÄÇËøôÊ†∑ÔºåËÅäÂ§©ÂéÜÂè≤ËÆ∞ÂΩïÂ∞±Ë¢´ÊàêÂäüÂú∞Ê∑ªÂä†\n",
    "Âà∞‰∫ÜÂØπËØùÁºìÂ≠ò‰∏≠„ÄÇ\n",
    "\"\"\"\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: whats up?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Âä†ËΩΩÂØπËØùÁºìÂ≠ò‰∏≠Â≠òÂÇ®ÁöÑÂèòÈáè„ÄÇËØ•ÊñπÊ≥ïÊé•Âèó‰∏Ä‰∏™Á©∫Â≠óÂÖ∏‰Ωú‰∏∫ÂèÇÊï∞ÔºåË°®Á§∫‰∏çÈúÄË¶ÅÂä†ËΩΩ‰ªª‰ΩïÂèòÈáè\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰πüÂèØ‰ª•Áî®ÂàóË°®ËøîÂõûÂéÜÂè≤Ê∂àÊÅØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi!', additional_kwargs={}),\n",
       "  AIMessage(content='whats up?', additional_kwargs={})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏äÈù¢Â∞±ÊòØÂØπÂéÜÂè≤ÂØπËØùËøõË°åËÆ∞ÂΩï‰ª•ÂèäËé∑ÂèñÁöÑÊñπÂºèÔºåÁÆÄÂçïÁõ¥Êé•ÔºåÊé•‰∏ãÊù•Êàë‰ª¨ÈÄöËøáÂá†‰∏™Á§∫‰æãÁúã‰∏Ä‰∏ãÂÖ∑‰ΩìÊÄé‰πàËÆ≤ÂÖ∂Ê∑ªÂä†Âà∞Chain‰∏≠Ôºö"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Memory to an LLMChain\n",
    "\n",
    "‰∏ãÈù¢Â±ïÁ§∫‰∫ÜConversationBufferMemoryÁöÑÊ∑ªÂä†Áî®Ê≥ïÔºåÂØπ‰∫éÂÖ∂‰ªñÁ±ªÂûãÁöÑMemory,ÊÇ®ÂèØ‰ª•ÁÇπÂáª[Ê≠§Â§ÑÊü•ÁúãÂíå‰ΩøÁî®](https://python.langchain.com/en/latest/modules/memory/how_to_guides.html)„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "\n",
    "\"\"\"\n",
    "ÊúÄÈáçË¶ÅÁöÑ‰∏ÄÊ≠•ÊòØÊ≠£Á°ÆËÆæÁΩÆÊèêÁ§∫„ÄÇÂú®‰∏ãÈù¢ÁöÑÊèêÁ§∫‰∏≠ÔºåÊàë‰ª¨Êúâ‰∏§‰∏™ËæìÂÖ•ÈîÆÔºö‰∏Ä‰∏™Áî®‰∫éÂÆûÈôÖËæìÂÖ•Ôºå\n",
    "Âè¶‰∏Ä‰∏™Áî®‰∫éÊù•Ëá™ Memory Á±ªÁöÑËæìÂÖ•„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÊàë‰ª¨Á°Æ‰øù PromptTemplate Âíå ConversationBufferMemory ‰∏≠ÁöÑÈîÆÂåπÈÖç ( chat_history)„ÄÇ\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "\"\"\"\n",
    "Ë∞ÉÁî®ConversationBufferMemoryÁ±ªÁöÑÊûÑÈÄ†ÂáΩÊï∞Êù•ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫memoryÁöÑÂØπËØùÁºìÂ≠òÂØπË±°ÔºåËØ•ÂØπË±°Â∞ÜÁî®‰∫éÂ≠òÂÇ®ÂØπËØùÂéÜÂè≤ËÆ∞ÂΩï„ÄÇ\n",
    "memoryÂØπË±°Â∞Ü‰ΩøÁî®\"chat_history\"‰Ωú‰∏∫keyÊù•Â≠òÂÇ®ÂØπËØùÂéÜÂè≤ËÆ∞ÂΩï„ÄÇÊúÄÂêéÔºå‰ª£Á†ÅË∞ÉÁî®LLMChainÁ±ªÁöÑÊûÑÈÄ†ÂáΩÊï∞Êù•ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫\n",
    "llm_chainÁöÑÂØπË±°ÔºåËØ•ÂØπË±°Â∞ÜÁî®‰∫éÊâßË°åÈïøÊñáÊú¨ÈìæÊ®°Âûã„ÄÇllm_chainÂØπË±°Â∞Ü‰ΩøÁî®OpenAI()‰Ωú‰∏∫llmÂèÇÊï∞Êù•ÊâßË°åÈïøÊñáÊú¨ÈìæÊ®°ÂûãÔºõ\n",
    "Â∞Üprompt‰Ωú‰∏∫promptÂèÇÊï∞ÔºõÂ∞ÜverboseËÆæÁΩÆ‰∏∫True‰ª•ÊâìÂç∞Ë∞ÉËØï‰ø°ÊÅØÔºõÂ∞Ümemory‰Ωú‰∏∫memoryÂèÇÊï∞Êù•Âä†ËΩΩÂØπËØùÁºìÂ≠ò‰∏≠Â≠òÂÇ®ÁöÑ\n",
    "ÂéÜÂè≤ËÆ∞ÂΩï„ÄÇ\n",
    "\"\"\"\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(), \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. My name is AI. What's your name?\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"I'm doing well! Just having a conversation with an AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: Tell me about yourself.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Sure! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also able to learn from my conversations and experiences, so I'm constantly growing and evolving. What else would you like to know?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(input=\"Tell me about yourself.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Âè¶Â§ñ‰∏ÄÁßçÊÉÖÊôØÊòØÁî®Êà∑ÈúÄË¶ÅËøõË°åÂéÜÂè≤‰ø°ÊÅØÁöÑ‰øùÂ≠òÔºåÂõ†‰∏∫Áî®Êà∑Êúâ‰øùÂ≠òÂéÜÂè≤‰ø°ÊÅØÔºåÁÑ∂ÂêéÂú®ÈúÄË¶ÅÁöÑÊó∂ÂÄôÂä†ËΩΩÈáçÁî®ÁöÑÈúÄÊ±Ç„ÄÇLangChainÁöÑschemaÁ±ªËÉΩÊñπ‰æøÁöÑÊääÂéÜÂè≤‰ø°ÊÅØËΩ¨‰∏∫‰∏∫pythonÊï∞ÊçÆÁªìÊûÑÔºåÊØîÂ¶ÇÂ≠óÂÖ∏Ôºõ‰πüÂèØ‰ª•ËΩ¨Âåñ‰∏∫jsonÊ†ºÂºèÔºõÁÑ∂Âêé‰ªéÂ≠óÂÖ∏„ÄÅjson‰∏≠Âä†ËΩΩÂéÜÂè≤‰ø°ÊÅØ„ÄÇÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "\n",
    "#‰ª£Á†ÅÂàõÂª∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫historyÁöÑChatMessageHistoryÂØπË±°\n",
    "history = ChatMessageHistory()\n",
    "#ÂêëÂØπËØùÂéÜÂè≤ËÆ∞ÂΩï‰∏≠Ê∑ªÂä†‰∏ÄÊù°Áî®Êà∑ËæìÂÖ•ÁöÑÊ∂àÊÅØÔºö\"hi!\"\n",
    "history.add_user_message(\"hi!\")\n",
    "#ÂêëÂØπËØùÂéÜÂè≤ËÆ∞ÂΩï‰∏≠Ê∑ªÂä†‰∏ÄÊù°AIÂèëÂá∫ÁöÑÊ∂àÊÅØÔºö\"whats up?\"„ÄÇ\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dicts = messages_to_dict(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'human', 'data': {'content': 'hi!', 'additional_kwargs': {}}},\n",
       " {'type': 'ai', 'data': {'content': 'whats up?', 'additional_kwargs': {}}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_messages = messages_from_dict(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}),\n",
       " AIMessage(content='whats up?', additional_kwargs={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏ãÈù¢ÊòØÂÖ≥‰∫éÂú®Agent‰∏≠Ê∑ªÂä†MemoryÁöÑÊ°à‰æãËØ¥ÊòéÔºö"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Memory to an Agent\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏∫‰∫ÜÂêëAgent‰∏≠Ê∑ªÂä†MemoryÔºåÊàë‰ª¨Â∞ÜÊâßË°å‰ª•‰∏ãÊ≠•È™§Ôºö\n",
    "\n",
    "- 1.Êàë‰ª¨Â∞ÜÂàõÂª∫‰∏Ä‰∏™Â∏¶ÂÜÖÂ≠òÁöÑ LLMChain„ÄÇ\n",
    "\n",
    "- 2.Êàë‰ª¨Â∞Ü‰ΩøÁî®ËØ• LLMChain ÂàõÂª∫Ëá™ÂÆö‰πâ‰ª£ÁêÜ„ÄÇ\n",
    "\n",
    "Êàë‰ª¨Â∞ÜÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑËá™ÂÆö‰πâ‰ª£ÁêÜÔºåÂÆÉÂèØ‰ª•ËÆøÈóÆÊêúÁ¥¢Â∑•ÂÖ∑Âπ∂‰ΩøÁî®ËØ•Á±ªConversationBufferMemory„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]\n",
    "\n",
    "#chat_historyËØ∑Ê≥®ÊÑèPromptTemplate ‰∏≠ÂèòÈáèÁöÑÁî®Ê≥ïÔºåÂÆÉ‰∏é ConversationBufferMemory ‰∏≠ÁöÑÂä®ÊÄÅÈîÆÂêçÁõ∏ÂåπÈÖç„ÄÇ\n",
    "\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools, \n",
    "    prefix=prefix, \n",
    "    suffix=suffix, \n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "#Êàë‰ª¨Áé∞Âú®ÂèØ‰ª•‰ΩøÁî® Memory ÂØπË±°ÊûÑÈÄ† LLMChainÔºåÁÑ∂ÂêéÂàõÂª∫‰ª£ÁêÜ„ÄÇ\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)\n",
    "\n",
    "agent_chain.run(input=\"How many people live in canada?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏∫‰∫ÜÊµãËØïÊ≠§‰ª£ÁêÜÁöÑËÆ∞ÂøÜÂäõÔºåÊàë‰ª¨ÂèØ‰ª•ÊèêÂá∫‰∏Ä‰∏™ÂêéÁª≠ÈóÆÈ¢òÔºåËØ•ÈóÆÈ¢ò‰æùËµñ‰∫éÂÖàÂâç‰∫§ÊµÅ‰∏≠ÁöÑ‰ø°ÊÅØÊâçËÉΩÊ≠£Á°ÆÂõûÁ≠î„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"what is their national anthem called?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Êàë‰ª¨Â∞ÜÂÖ∂‰∏éÊ≤°ÊúâmemoryÁöÑagentËøõË°åÊØîËæÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools, \n",
    "    prefix=prefix, \n",
    "    suffix=suffix, \n",
    "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
    ")\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_without_memory = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
    "agent_without_memory.run(\"How many people live in canada?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_without_memory.run(\"what is their national anthem called?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂΩìÁÑ∂‰∏äËø∞Êìç‰ΩúÁ§∫‰æãÊòØÊñπ‰æøËØªËÄÖÂø´ÈÄü‰∫ÜËß£Âíå‰∏äÊâãÔºå‰∏∫‰∫ÜÂú®ÂºÄÂèë‰∏≠Êõ¥Âä†ÁÜüÁªÉÂú∞Â∫îÁî®ÔºåËøòÊòØÈúÄË¶ÅÂÖ®Èù¢ÂÆåÂñÑÁöÑÊµèËßàÂíåÊü•ÈòÖÂÆòÊñπÊïôÁ®ãÂÅöËøõ‰∏ÄÊ≠•ÁöÑËûç‰ºöË¥ØÈÄöÔºåÁÇπÂáªÊ≠§Â§ÑÂèØ‰ª•Áõ¥Ëææ[MemoryÊïôÁ®ã‰ΩçÁΩÆ](https://python.langchain.com/en/latest/modules/memory.html)„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Chains\n",
    "ÂΩìÂÆûÁé∞‰∏Ä‰∫õÁÆÄÂçïÁöÑÂ∫îÁî®Êó∂ÔºåÂè™Áî®‰∏Ä‰∏™Â§ßËØ≠Ë®ÄÊ®°ÂûãÊòØÈùûÂ∏∏ÂèØË°åÁöÑ„ÄÇ‰ΩÜÊòØÔºå‰∏Ä‰∫õÂ§çÊùÇÊÉÖÂÜµ‰∏ãÔºåÈúÄË¶ÅÊàë‰ª¨ÂéªÁªÑÂêà‰∏çÂêåÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊàñËÄÖÁªÑÂêàÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂíåÂÖ∂‰ªñÊ®°ÂùóÔºåÂéªÂÆåÊàê‰∏Ä‰∫õÂ∫ûÂ§ßËÄåÂèàÂ§çÊùÇÁöÑÂ∑•‰ΩúÂÜÖÂÆπ„ÄÇLangChain‰∏∫ChainsÊèê‰æõ‰∫Ü‰∏Ä‰∏™Ê†áÂáÜÊé•Âè£Ôºå‰ª•Âèä‰∏Ä‰∫õÂ∏∏Áî®ÁöÑÂÆûÁé∞ÊñπÊ≥ï„ÄÇ\n",
    "‰æãÂ¶ÇÔºåÁÆÄÂçïÁöÑÊñπÂºèÊàë‰ª¨Â∑≤Áªè‰∫ÜËß£Âà∞‚Äî‚ÄîÊàë‰ª¨ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™chainÔºåÊé•Êî∂Áî®Êà∑ËæìÂÖ•ÔºåÁÑ∂Âêé‰ΩøÁî®PromptÊ®°ÂùóÊ†ºÂºèÂåñÔºåÁÑ∂ÂêéÂ∞ÜÊ†ºÂºèÂåñÂÜÖÂÆπ‰º†ÁªôLLMÔºõÂ§çÊùÇÁöÑÊñπÂºèËØ∏Â¶ÇÁªÑÂêàÂ§ö‰∏™chainÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÂ§ö‰∏™chainÁªÑÂêàÂú®‰∏ÄËµ∑Ôºå‰πüÂèØ‰ª•Âú®chain‰∏≠Âä†ÂÖ•ÂÖ∂‰ªñÊ®°ÂùóÂçèÂêåÂ∑•‰Ωú„ÄÇ\n",
    "ËøôÈÉ®ÂàÜÊïôÁ®ãÊúâÂ¶Ç‰∏ãÂÜÖÂÆπÔºö\n",
    "- 1.‰ΩøÁî®ÁÆÄÂçïÁöÑLLMÈìæ\n",
    "- 2.ÂàõÂª∫Â∫èÂàóÂåñÁöÑÈìæÊé•\n",
    "- 3.ÂàõÂª∫Ëá™ÂÆö‰πâÁöÑÈìæ\n",
    "\n",
    "Â¶ÇÊûú‰Ω†ÊÉ≥‰∫ÜËß£Êõ¥Â§öÔºåÂèØ‰ª•ÁÇπÂáª[ËøôÈáå](https://python.langchain.com/en/latest/modules/chains.html)Áõ¥ËææChainsÂÆòÊñπÊïôÁ®ã„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [‰ΩøÁî®LLMChainÂÆåÊàêÂü∫Êú¨Ë∞ÉÁî®](#llmchain-usage)\n",
    "- [SequentialChainÁªÑÂêàÂ§ö‰∏™Chain](#using-sequentialchain-to-combine-with-multiple-chains)\n",
    "- [Ëá™ÂÆö‰πâChain](#customize-the-chain-class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LLMChain usage\n",
    "\n",
    "LLMChainÔºåÂÆÉÊòØ‰∏Ä‰∏™ÊúÄÁÆÄÂçï„ÄÅ‰ΩøÁî®ÊúÄÂ§öÁöÑchainÔºåÂÆÉ‰ºöÊé•Êî∂‰∏Ä‰∏™promptÊ®°ÊùøÔºåÊàë‰ª¨‰ΩøÁî®Ëøô‰∏™Ê®°ÊùøÊ†ºÂºèÂåñËæìÂÖ•‰ø°ÊÅØÔºåÁÑ∂ÂêéËøîÂõûÁî®Êà∑ÁöÑÊü•ËØ¢ÂæóÂà∞ÁöÑÂìçÂ∫îÔºå‰πüÂ∞±ÊòØÊàë‰ª¨ÊÉ≥Ë¶ÅÁöÑÁ≠îÊ°à„ÄÇ‰∏ãÈù¢ÊòØ‰ΩøÁî®‰æãÂ≠êÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "#‰ΩøÁî®OpenAIÁöÑÂ§ßÊ®°ÂûãÔºåÈªòËÆ§ÊòØtext-davinci-003ÔºåËÆæÁΩÆÈöèÊú∫ÊÄß‰∏∫0.9\n",
    "llm = OpenAI(temperature=0.9)\n",
    "#ÊèêÁ§∫Ê®°ÁâàÊ†ºÂºèÂåñÂèòÈáèÂÜÖÂÆπ\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Brightly Socks!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "#ÂÆû‰æãÂåñchainÂØπË±°\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "#Áî®chainÁöÑrunÊñπÊ≥ïÊù•ËøêË°åÊåáÂÆöËæìÂÖ•ÂèòÈáèÁöÑÈìæ \n",
    "print(chain.run(\"colorful socks\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Âú®LLMChain‰∏≠‰ΩøÁî®chat modelÂéªÂÆåÊàêËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑ‰∫§‰∫íËøáÁ®ãÔºå‰ª•‰∏ãÊòØ‰∏Ä‰∏™Á§∫‰æãÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RainbowSocks\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"What is a good name for a company that makes {product}?\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rainbow Socks Co.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"colorful socks\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using SequentialChain to combine with multiple chains\n",
    "\n",
    "È°∫Â∫èÈìæÂèØ‰ª•ÁªÑÂêàÂ§ö‰∏™chainÔºåSequentialChainÂèÇÊï∞ËæìÂÖ•chainÂàóË°®ÔºåÂÆÉ‰ºöÈ°∫Â∫èÊâßË°åÊØè‰∏Ä‰∏™chainÔºåÂ∞ÜÁ¨¨‰∏Ä‰∏™chainÁöÑËøîÂõûÂÄºËæìÂÖ•Âà∞Á¨¨‰∫åchainÔºå‰æùÊ¨°Á±ªÊé®„ÄÇ‰∏ãÈù¢ÊòØ‰ΩøÁî®ËåÉ‰æã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"What is a good name for a company that makes {product}?\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "#ÂÆö‰πâÁ¨¨‰∫å‰∏™promptÔºåÁÑ∂Âêé‰ΩøÁî®llmchainÂÆû‰æãÂåñËøô‰∏™ÂØπË±°\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"company_name\"],\n",
    "    template=\"Write a catchphrase for the following company: {company_name}\",\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain_one = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ãÈù¢Â∞Ü‰∏§‰∏™ÁÆÄÂçïÁöÑLLMChainsÁªÑÂêàÂà∞‰∏ÄËµ∑ÁöÑÊñπÂºèÔºå‰ΩøÁî®SimpleSequentialChainÊù•ÂÆåÊàêÔºåÊúÄÁªàÂÆûÁé∞ÂÖàÁªôÂÖ¨Âè∏ÂëΩÂêçÔºåÁÑ∂ÂêéÁªôËøô‰∏™Â∑≤ÁªèÂëΩÂêçÁöÑÂÖ¨Âè∏Ëµ∑‰∏Ä‰∏™ÂÆ£‰º†ËØ≠ÁöÑËøô‰πà‰∏Ä‰∏™ËøáÁ®ã„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRainbow Sock Co.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "\"Walk on the wild side with Rainbow Socks!\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\"Walk on the wild side with Rainbow Socks!\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "#ËøêË°åchainÁöÑrunÊñπÊ≥ïÔºåÂè™ÈúÄË¶ÅÊåáÂÆöÁ¨¨‰∏Ä‰∏™ÈìæÁöÑËæìÂÖ•ÂèòÈáè„ÄÇ\n",
    "catchphrase = overall_chain.run(\"colorful socks\")\n",
    "print(catchphrase)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Customize the Chain class\n",
    "‰ΩøÁî®Â∑≤ÁªèÂ∞ÅË£ÖÂ•ΩÁöÑLangChainÂõ∫ÁÑ∂Ê≤°Êúâ‰ªª‰ΩïÈóÆÈ¢òÔºåÂõ†‰∏∫ÂÖ∂Êèê‰æõ‰∫ÜÂæàÂ§öÂºÄÁÆ±Âç≥Áî®ÁöÑchainsÔºå‰ΩÜÊòØÂæÄÂæÄÊúâÊó∂ÂÄôÁî®Êà∑ÂèØËÉΩÊÉ≥Ëá™Â∑±ÂàõÂª∫‰∏™Ëá™ÂÆö‰πâÁöÑÁ±ªÁî®‰∫éÁâπÊÆäÁî®ÈÄî„ÄÇ\n",
    "ÂàõÂª∫Ëá™ÂÆö‰πâÁ±ªËøáÁ®ãÂ¶Ç‰∏ãÔºö\n",
    "- 1.ÁªßÊâøChainÁ±ª\n",
    "- 2.Â°´ÂÜôinput_keys Âíå output_keys Â±ûÊÄß\n",
    "- 3.ÂÆûÁé∞ÁßÅÊúâÊñπÊ≥ï_callÊñπÊ≥ïÔºåÁî®‰∫éÂ±ïÁ§∫Â¶Ç‰ΩïÊâßË°åchain\n",
    "\n",
    "‰∏ãÈù¢ÊòØËá™ÂÆö‰πâÂàõÂª∫chainÁ±ªÁöÑÊñπÊ≥ï"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "È¶ñÂÖàËá™ÂÆö‰πâ‰∏Ä‰∏™ConcatenateChainÁ±ªÔºåËØ•Á±ªÂ∞Ü‰∏§‰∏™LLMChainÂêåÊó∂Â§ÑÁêÜ‰∏Ä‰∏™Êü•ËØ¢Âπ∂ËøîÂõûËøûÊé•ÁªìÊûú„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.base import Chain\n",
    "from typing import Dict, List\n",
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ConcatenateChainÁöÑÁ±ªÔºåÁªßÊâøËá™Chain„ÄÇËØ•Á±ªË°®Á§∫‰∏Ä‰∏™Â∞Ü‰∏§‰∏™ÈìæËøûÊé•Âú®‰∏ÄËµ∑ÁöÑÈìæ„ÄÇ\n",
    "È¶ñÂÖà‰ªélangchain.chainsÊ®°Âùó‰∏≠ÂØºÂÖ•LLMChainÂíåChainÁ±ªÔºå‰ª•Âèä‰ªétypingÊ®°Âùó‰∏≠ÂØºÂÖ•DictÂíåListÁ±ªÂûãÊ≥®Ëß£„ÄÇ\n",
    "Âú®ConcatenateChainÁ±ª‰∏≠ÔºåÊúâ‰∏§‰∏™Â±ûÊÄßÔºöchain_1Âíåchain_2,ÂàÜÂà´Ë°®Á§∫Ë¶ÅËøûÊé•ÁöÑ‰∏§‰∏™Èìæ„ÄÇËøô‰∏§‰∏™Â±ûÊÄßÈÉΩÊòØLLMChainÁ±ªÂûãÁöÑÂÆû‰æã„ÄÇ\n",
    "ËØ•Á±ªËøòÂÆö‰πâ‰∫Ü‰∏§‰∏™ÊñπÊ≥ïÔºöinput_keys()Âíåoutput_keys()„ÄÇÂÖ∂‰∏≠Ôºåinput_keys()ÊñπÊ≥ïËøîÂõûËøûÊé•ÂêéËæìÂÖ•ÂèòÈáèÁöÑÈõÜÂêàÔºåÂç≥‰∏§‰∏™ÂéüÂßãÈìæ\n",
    "ÁöÑËæìÂÖ•ÂèòÈáèÁöÑÂπ∂ÈõÜÔºõËÄåoutput_keys()ÊñπÊ≥ïËøîÂõû‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ÂàóË°®ÔºåË°®Á§∫ËøûÊé•ÂêéÁöÑËæìÂá∫ÂèòÈáèÂè™Êúâ‰∏Ä‰∏™ÔºåÂêçÁß∞‰∏∫concat_output„ÄÇ\n",
    "ÊúÄÂêéÔºåËØ•Á±ªÂÆûÁé∞‰∫Ü‰∏Ä‰∏™ÁßÅÊúâÊñπÊ≥ï_call(),Áî®‰∫éÂÆûÈôÖÊâßË°åËøûÊé•Êìç‰Ωú„ÄÇËØ•ÊñπÊ≥ïÊé•Âèó‰∏Ä‰∏™Â≠óÂÖ∏Á±ªÂûãÁöÑÂèÇÊï∞inputs,Ë°®Á§∫ËæìÂÖ•ÂèòÈáèÂèäÂÖ∂ÂèñÂÄº„ÄÇ\n",
    "ËØ•ÊñπÊ≥ïÂÖàË∞ÉÁî®‰∏§‰∏™ÈìæÁöÑrun()ÊñπÊ≥ïÔºåÂàÜÂà´Ëé∑ÂèñÂÆÉ‰ª¨ÁöÑËæìÂá∫ÁªìÊûúÔºåÁÑ∂ÂêéÂ∞ÜÂÆÉ‰ª¨Áõ∏Âä†ÂæóÂà∞Êñ∞ÁöÑËæìÂá∫ÁªìÊûúÔºåÂπ∂Â∞ÜÂÖ∂Â≠òÂÇ®Âú®‰∏Ä‰∏™Â≠óÂÖ∏‰∏≠ËøîÂõû„ÄÇ\n",
    "\"\"\"\n",
    "\n",
    "class ConcatenateChain(Chain):\n",
    "    chain_1: LLMChain\n",
    "    chain_2: LLMChain\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        # ‰∏§‰∏™ÈìæÁöÑËæìÂÖ•ÈîÆÁöÑÂπ∂ÈõÜ\n",
    "        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))\n",
    "        return list(all_input_vars)\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return ['concat_output']\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "        output_1 = self.chain_1.run(inputs)\n",
    "        output_2 = self.chain_2.run(inputs)\n",
    "        return {'concat_output': output_1 + output_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated output:\n",
      "\n",
      "\n",
      "Vivid Sockery.\n",
      "\n",
      "\"Step Into Colorful Comfort!\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    prompt_1: PromptTemplateÁ±ªÂûãÔºåË°®Á§∫‰∏Ä‰∏™ÊèêÁ§∫Ê®°ÊùøÔºåÂÖ∂‰∏≠ÂåÖÂê´ËæìÂÖ•ÂèòÈáè\"product\",\n",
    "Ê®°Êùø‰∏∫\"What is a good name for a company that makes {product}?\"„ÄÇ\n",
    "    chain_1: LLMChainÁ±ªÂûãÔºåË°®Á§∫‰∏Ä‰∏™LLMChainÂÆû‰æãÔºåÂÖ∂‰∏≠llmÂèÇÊï∞ËÆæÁΩÆ‰∏∫‰πãÂâçÂÆö‰πâÁöÑllmÂØπË±°ÔºåpromptÂèÇÊï∞ËÆæÁΩÆ‰∏∫prompt_1„ÄÇ\n",
    "    chain_2: LLMChainÁ±ªÂûãÔºåË°®Á§∫‰∏Ä‰∏™LLMChainÂÆû‰æãÔºåÂÖ∂‰∏≠llmÂèÇÊï∞ËÆæÁΩÆ‰∏∫‰πãÂâçÂÆö‰πâÁöÑllmÂØπË±°ÔºåpromptÂèÇÊï∞ËÆæÁΩÆ‰∏∫prompt_2„ÄÇ\n",
    "    concat_chain: ConcatenateChainÁ±ªÂûãÔºåË°®Á§∫‰∏Ä‰∏™ËøûÊé•‰∏§‰∏™ÈìæÁöÑÂØπË±°„ÄÇÂÖ∂‰∏≠Ôºåchain_1Âíåchain_2Â±ûÊÄßÂàÜÂà´ÂØπÂ∫î‰∏äÈù¢ÂÆö‰πâÁöÑ‰∏§‰∏™ÈìæÂÆû‰æã„ÄÇ\n",
    "    concat_output: Â≠óÁ¨¶‰∏≤Á±ªÂûãÔºåË°®Á§∫Ë∞ÉÁî®concat_chain.run()ÊñπÊ≥ïÂêéÂæóÂà∞ÁöÑÁªìÊûú„ÄÇËØ•ÁªìÊûúÊòØÂ∞Üchain_1Âíåchain_2ËæìÂá∫ÁöÑÁªìÊûúËøõË°åËøûÊé•\n",
    "ÂæóÂà∞ÁöÑ„ÄÇÊúÄÂêéÈÄöËøáÊâìÂç∞ËæìÂá∫ÁöÑÊñπÂºèÂ±ïÁ§∫ËøûÊé•ÁªìÊûú„ÄÇ\n",
    "\"\"\"\n",
    "prompt_1 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good slogan for a company that makes {product}?\",\n",
    ")\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
    "\n",
    "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)\n",
    "concat_output = concat_chain.run(\"colorful socks\")\n",
    "print(f\"Concatenated output:\\n{concat_output}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Agents\n",
    "ÂÆûÈôÖÂ∫îÁî®ÂèØËÉΩ‰∏ç‰ªÖÈúÄË¶ÅÈ¢ÑÂÆö‰πâÂ•ΩÁöÑchainÔºå‰πüÈúÄË¶ÅÊ†πÊçÆÁî®Êà∑ÁöÑËæìÂÖ•ËØ∑Ê±ÇÔºåÁîüÊàê‰∏Ä‰∏™ÈöêÂê´ÁöÑchain„ÄÇagent‰Ωú‰∏∫‰ª£ÁêÜÔºå‰ºöÊ†πÊçÆÁî®Êà∑ËæìÂÖ•ÔºåÁ°ÆÂÆö‰∏ãÊù•Ë¶ÅÈááÂèñÁöÑÊìç‰Ωú„ÄÅ‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑„ÄÅLLMÁöÑËæìÂá∫„ÄÅobservationËßÇÂØüÂæóÂá∫ÁöÑÁªìÊûúÊàñÊòØÂ∞ÜLLMÁªìÊûúËøîÂõûÁªôÁî®Êà∑„ÄÇ\n",
    "Âú®‰ΩøÁî®agentsÂâçÔºå‰∏ãÈù¢Âá†‰∏™Ê¶ÇÂøµÈúÄË¶ÅÁêÜËß£Ôºö\n",
    "\n",
    "- ToolsÔºö‰∏Ä‰∏™ÂÆûÁé∞ÂÖ∑‰ΩìÂäüËÉΩÁöÑÂáΩÊï∞ÔºõÂèØ‰ª•ÊòØË∞∑Ê≠åÊêúÁ¥¢„ÄÅÊï∞ÊçÆÂ∫ìÊü•Êâæ„ÄÅpython‰∫§‰∫íÁïåÈù¢„ÄÇtoolÁöÑÊé•Âè£ÊòØ‰∏Ä‰∏™Êé•ÂèóstringÔºåËøîÂõûstringÁöÑÂáΩÊï∞\n",
    "- LLMÔºöÈ©±Âä®AgentËøêË°åÁöÑÂ§ßËØ≠Ë®ÄÊ®°Âûã\n",
    "- AgentÔºö‰ΩøÁî®ÁöÑAgent\n",
    "\n",
    "‰∏ãÈù¢ÊòØ‰∏âËÄÖ‰πãÈó¥ÁöÑËÅîÁ≥ªÔºö\n",
    "\n",
    "<img src=\"./agents.png\" align=center width=100% />\n",
    "\n",
    "LangChain Â∞ÜÂü∫‰∫éÁî®Êà∑ÊèêÂá∫ÁöÑË¶ÅÊ±ÇÈ©±Âä®agentËøõË°åÂ§ÑÁêÜÔºåÊúüÈó¥Ë∞ÉÁî®Â§ßÊ®°ÂûãÊù•ÂÆåÊàêÂìçÂ∫îËØ∑Ê±ÇÔºåËØ•ËØ∑Ê±ÇÂèØËøõ‰∏ÄÊ≠•È©±Âä®toolsÂéªÊ†πÊçÆÁâπÂÆö‰ªªÂä°ËøõË°åÁâπÂÆöÊìç‰ΩúÔºåÂ∞îÂêé‰ºöÊäätoolsÂÖ∑‰ΩìÁöÑÊìç‰ΩúÂÆåÊàêËøîÂõûÁªôÁî®Êà∑ÔºåÂú®Ëøô‰∏ÄËøáÁ®ã‰∏≠Â¶ÇÊûúÁî®Êà∑Êó†ÈúÄË∞ÉÁî®toolsÂÆåÊàêÂ§ÑÁêÜÂ∞Ü‰ºöÁõ¥Êé•ÂæóÂà∞Â§ßÊ®°ÂûãÁöÑÂèçÈ¶à„ÄÇ\n",
    "\n",
    "Êõ¥Âä†ËØ¶ÁªÜÁöÑÂÜÖÂÆπÁÇπÂáªüëâ[ËøôÈáå](https://python.langchain.com/en/latest/modules/agents.html)üëàË∑≥ËΩ¨Âà∞AgentsÂÆòÊñπÊïôÁ®ã"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [‰ΩøÁî®AgentÁöÑÁÆÄÂçïÁ§∫‰æã](#a-simple-example-with-using-agent)\n",
    "- [Tools](#tools)\n",
    "- [Agent](#agent)\n",
    "- [Toolkits](#toolkits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### A simple example with using Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\"\"\"\n",
    "llmÊòØÂàõÂª∫‰∏Ä‰∏™OpenAIÁöÑLLMÊ®°ÂûãÔºåÊ∏©Â∫¶ÂèÇÊï∞ËÆæÁΩÆ‰∏∫0„ÄÇ\n",
    "tools ÊòØ‰ªéÊåáÂÆöË∑ØÂæÑÂä†ËΩΩÂ∑•ÂÖ∑Â∫ìÔºåÂåÖÊã¨\"serpapi\"Âíå\"llm-math\"‰∏§‰∏™Â∑•ÂÖ∑ÔºåÂπ∂Â∞ÜÂä†ËΩΩÁöÑÂ∑•ÂÖ∑‰∏éLLMÊ®°ÂûãÁªëÂÆö„ÄÇ\n",
    "agent ÊòØÂàùÂßãÂåñ‰ª£ÁêÜÔºåÈÄâÊã©ÊåáÂÆöÁ±ªÂûãÔºåÂπ∂‰ΩøÁî®Âä†ËΩΩÁöÑÂ∑•ÂÖ∑ÂíåLLMÊ®°ÂûãÂØπÂÖ∂ËøõË°åËÆ≠ÁªÉ„ÄÇÂêåÊó∂ÔºåÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÊâìÂç∞ËØ¶ÁªÜËæìÂá∫‰ø°ÊÅØ„ÄÇ\n",
    "\"\"\"\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who Leo DiCaprio's girlfriend is and then calculate her age raised to the 0.43 power.\n",
      "Action: Search\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNina Agdal: 2016 to 2017 ... Leo and Nina were together for almost exactly a year until a source confirmed their breakup with a very familiar ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out Nina Agdal's age\n",
      "Action: Search\n",
      "Action Input: \"Nina Agdal age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m31 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate 31 raised to the 0.43 power\n",
      "Action: Calculator\n",
      "Action Input: 31^0.43\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 4.378098500976803\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Nina Agdal is Leo DiCaprio's girlfriend and her current age raised to the 0.43 power is 4.378098500976803.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nina Agdal is Leo DiCaprio's girlfriend and her current age raised to the 0.43 power is 4.378098500976803.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tools\n",
    "Â∑•ÂÖ∑ÊòØÊô∫ËÉΩ‰ΩìÂíåÂ§ñÈÉ®ÁéØÂ¢É‰∫§‰∫íÁöÑÊñπÂºè„ÄÇÂ∑•ÂÖ∑ÂèØ‰ª•ÊòØÂÆûÁî®Á®ãÂ∫è„ÄÅchain„ÄÅÂÖ∂‰ªñagentÁ≠â„ÄÇ\n",
    "\n",
    "LangChainÂ§ßÈÉ®ÂàÜÂ∑•ÂÖ∑ÂíåÊêúÁ¥¢Áõ∏ÂÖ≥Ôºå‰∏ãÈù¢‰ªÖ‰∏æÂá†‰∏™ÊúâÁâπÁÇπÁöÑÂ∑•ÂÖ∑‰æãÂ≠ê„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Bing Search](#bing-search)\n",
    "- [Google Search](#google-search)\n",
    "- [Google Serper API](#google-serper-api)\n",
    "- [Python REPL](#python-repl)\n",
    "- [Bash](#bash)\n",
    "- [Wikipedia API](#wikipedia-api)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "‰∏ÄËà¨ÈÄöËøá‰∏ãÈù¢ÁöÑÊñπÂºèÂä†ËΩΩÂ∑•ÂÖ∑ÔºåÂØπ‰∫éÂΩìÂÅöÂ∑•ÂÖ∑‰ΩøÁî®ÁöÑchain„ÄÅagentÔºåÈúÄË¶ÅËøõË°åÂàùÂßãÂåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "tool_names = [...]\n",
    "tools = load_tools(tool_names)\n",
    "llm = ...\n",
    "tools = load_tools(tool_names, llm=llm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bing Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏ãÈù¢Á§∫‰æãÂ±ïÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®ÂøÖÂ∫îÊêúÁ¥¢ÁªÑ‰ª∂Ôºö\n",
    "\n",
    "È¶ñÂÖàÔºåÊÇ®ÈúÄË¶ÅËÆæÁΩÆÈÄÇÂΩìÁöÑ API ÂØÜÈí•ÂíåÁéØÂ¢ÉÂèòÈáè„ÄÇÁÇπÂáª[Ê≠§Â§Ñ](https://levelup.gitconnected.com/api-tutorial-how-to-use-bing-web-search-api-in-python-4165d5592a7e)Êü•ÈòÖËØ¥ÊòéÂπ∂ÂÆåÊàêÈÖçÁΩÆ„ÄÇ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"BING_SUBSCRIPTION_KEY\"] = \"\"\n",
    "os.environ[\"BING_SEARCH_URL\"] = \"\"\n",
    "\n",
    "#ÂØºÂÖ•BingSearchAPIWrapperÁ±ªÔºåËØ•Á±ªÁî®‰∫é‰∏éBingÊêúÁ¥¢ÂºïÊìéËøõË°å‰∫§‰∫í„ÄÇ\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "#ÂàõÂª∫‰∏Ä‰∏™BingSearchAPIWrapperÂØπË±°ÔºåÂπ∂Â∞ÜÂÖ∂ËµãÂÄºÁªôÂèòÈáèsearch„ÄÇ\n",
    "search = BingSearchAPIWrapper()\n",
    "#Ë∞ÉÁî®searchÂØπË±°ÁöÑrun()ÊñπÊ≥ïÔºå‰º†ÂÖ•ÂèÇÊï∞\"python\",Ë°®Á§∫Âú®BingÊêúÁ¥¢ÂºïÊìé‰∏äÊêúÁ¥¢ÂÖ≥‰∫éPythonÁöÑ‰ø°ÊÅØ„ÄÇ\n",
    "search.run(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ËÆæÁΩÆkÊéßÂà∂ËæìÂá∫ÁªìÊûúÊï∞ÁõÆ\n",
    "search = BingSearchAPIWrapper(k=1)\n",
    "search.run(\"python\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËøêË°å‰∏ãÈù¢ÁöÑ‰ª£Á†ÅÂ∞Ü‰ºöËøîÂõû‰∏âÈ°πÂÜÖÂÆπÔºöÁâáÊÆµÔºåÊ†áÈ¢òÂíåÈìæÊé•\n",
    "\n",
    "ÁâáÊÆµ: ÁªìÊûúÁöÑÊèèËø∞.\n",
    "\n",
    "Ê†áÈ¢ò: ÁªìÊûúÁöÑÊ†áÈ¢ò.\n",
    "\n",
    "ÈìæÊé•: ÁªìÊûúÁöÑÈìæÊé•."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = BingSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.results(\"apples\", 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰ª•‰∏ãÁ§∫‰æã‰ªãÁªç‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Ë∞∑Ê≠åÊêúÁ¥¢ÁªÑ‰ª∂ÔºåÊÇ®ÈúÄË¶ÅËÆæÁΩÆÈÄÇÂΩìÁöÑ API ÂØÜÈí•ÂíåÁéØÂ¢ÉÂèòÈáè„ÄÇË¶ÅËøõË°åËÆæÁΩÆÔºåËØ∑Âú®[Ê≠§Â§Ñ](https://console.cloud.google.com/apis/credentials)ÂàõÂª∫ GOOGLE_API_KEYÔºå[ËøôÈáå](https://programmablesearchengine.google.com/)ÂàõÂª∫ GOOGLE_CSE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = \"\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "#ÂØºÂÖ•GoogleSearchAPIWrapperÁ±ªÔºåËØ•Á±ªÁî®‰∫é‰∏éGoogleÊêúÁ¥¢ÂºïÊìéËøõË°å‰∫§‰∫í„ÄÇ\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "#ÂàõÂª∫‰∏Ä‰∏™GoogleSearchAPIWrapperÂØπË±°ÔºåÂπ∂Â∞ÜÂÖ∂ËµãÂÄºÁªôÂèòÈáèsearch„ÄÇ\n",
    "search = GoogleSearchAPIWrapper()\n",
    "#Ë∞ÉÁî®searchÂØπË±°ÁöÑrun()ÊñπÊ≥ïÔºå‰º†ÂÖ•ÂèÇÊï∞\"Obama's first name?\",Ë°®Á§∫Âú®GoogleÊêúÁ¥¢ÂºïÊìé‰∏äÊêúÁ¥¢ÂÖ≥‰∫é\"ObamaÁöÑÂêç\"ÁöÑ‰ø°ÊÅØ„ÄÇ\n",
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "È¶ñÂÖàÂàõÂª∫‰∏Ä‰∏™GoogleSearchAPIWrapperÂØπË±°search,Âπ∂‰º†ÂÖ•ÂèÇÊï∞k=1,‰ª•‰æøÂú®ÊêúÁ¥¢ÁªìÊûú‰∏≠Âè™ËøîÂõûÂâç‰∏ÄÊù°ÁªìÊûú„ÄÇ\n",
    "ÁÑ∂ÂêéË∞ÉÁî®searchÂØπË±°ÁöÑrun()ÊñπÊ≥ïÔºå‰º†ÂÖ•ÂèÇÊï∞\"python\",‰ª•Âú®GoogleÊêúÁ¥¢ÂºïÊìé‰∏äÊêúÁ¥¢ÂÖ≥‰∫éPythonÁöÑ‰ø°ÊÅØ„ÄÇ\n",
    "Êé•ÁùÄÂÜçÊ¨°ÂàõÂª∫‰∏Ä‰∏™GoogleSearchAPIWrapperÂØπË±°search,Âπ∂‰º†ÂÖ•Á©∫ÂÄºÔºå‰ª•‰æøÊ∏ÖÁ©∫‰πãÂâçÊêúÁ¥¢ÁöÑÁªìÊûú„ÄÇ\n",
    "ÊúÄÂêéË∞ÉÁî®searchÂØπË±°ÁöÑresults()ÊñπÊ≥ïÔºå‰º†ÂÖ•ÂèÇÊï∞\"apples\"Âíå5,‰ª•Âú®GoogleÊêúÁ¥¢ÂºïÊìé‰∏äÊêúÁ¥¢ÂÖ≥‰∫éËãπÊûúÁöÑ‰ø°ÊÅØÔºåÂπ∂ËøîÂõûÂâç5‰∏™ÁªìÊûú„ÄÇ\n",
    "\"\"\"\n",
    "search = GoogleSearchAPIWrapper(k=1)\n",
    "search.run(\"python\")\n",
    "search = GoogleSearchAPIWrapper()\n",
    "search.results(\"apples\", 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Serper API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞‰ΩøÁî®Ë∞∑Ê≠åÁΩëÁªúÊêúÁ¥¢APIÔºåÈúÄË¶ÅÊ≥®ÂÜå‰∏Ä‰∏™ÂÖçË¥πË¥¶Êà∑Áî®‰∫éËé∑ÂèñAPI_KEY,Ê≥®ÂÜå‰ΩçÁΩÆÁÇπÂáª[Ê≠§Â§Ñ](https://serper.dev/)„ÄÇ‰∏ãÈù¢ÊòØÁ§∫‰æã‰ª£Á†Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERPER_API_KEY\"] = \"\"\n",
    "\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "search = GoogleSerperAPIWrapper()\n",
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"YOUR_OPENAI_KEY\"\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "\"\"\"\n",
    "È¶ñÂÖàÂàõÂª∫‰∏Ä‰∏™OpenAIÁöÑLLMÊ®°ÂûãÔºåÊ∏©Â∫¶ÂèÇÊï∞ËÆæÁΩÆ‰∏∫0„ÄÇ\n",
    "ÁÑ∂ÂêéÂàõÂª∫‰∏Ä‰∏™GoogleSerperAPIWrapperÂØπË±°search,Áî®‰∫éÂú®GoogleÊêúÁ¥¢ÂºïÊìé‰∏äËøõË°åÊêúÁ¥¢„ÄÇ\n",
    "Êé•ÁùÄÂÆö‰πâ‰∏Ä‰∏™ÂåÖÂê´‰∏Ä‰∏™Â∑•ÂÖ∑ÁöÑÂàóË°®tools,ÂÖ∂‰∏≠Â∑•ÂÖ∑ÂêçÁß∞‰∏∫\"Intermediate Answer\",ÂÖ∂ÂäüËÉΩ\n",
    "‰∏∫Ë∞ÉÁî®searchÂØπË±°ÁöÑrun()ÊñπÊ≥ïËøõË°åÊêúÁ¥¢ÔºåÂπ∂Â∞ÜÊêúÁ¥¢ÁªìÊûú‰Ωú‰∏∫Á≠îÊ°àËøîÂõû„ÄÇ\n",
    "Êé•‰∏ãÊù•ÂàùÂßãÂåñ‰∏Ä‰∏™agentÔºå‰πüÂ∞±ÊòØself_ask_with_search,ËØ•agent‰ΩøÁî®toolsÂàóË°®‰∏≠ÁöÑÂ∑•ÂÖ∑‰∏éLLMÊ®°Âûã\n",
    "‰∫§‰∫íÔºåÂπ∂ÊîØÊåÅ‰ΩøÁî®\"self ask with search\"ÊñπÂºèËøõË°åÊèêÈóÆ„ÄÇ\n",
    "ÊúÄÂêéË∞ÉÁî®self_ask_with_searchÂØπË±°ÁöÑrun()ÊñπÊ≥ïÔºå‰º†ÂÖ•ÈóÆÈ¢ò,‰ª•Ëé∑ÂèñÁõ∏Â∫îÁöÑÁ≠îÊ°à„ÄÇ\n",
    "\"\"\"\n",
    "llm = OpenAI(temperature=0)\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "self_ask_with_search.run(\"What is the hometown of the reigning men's U.S. Open champion?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "È¶ñÂÖàÂØºÂÖ•PythonREPLÁ±ªÔºåËØ•Á±ªÁî®‰∫éÂú®PythonËß£ÈáäÂô®‰∏≠ÊâßË°å‰∫§‰∫íÂºè‰ª£Á†Å„ÄÇ\n",
    "Êé•ÁùÄÂàõÂª∫‰∏Ä‰∏™PythonREPLÂØπË±°python_repl,‰ª•‰æøÂú®PythonËß£ÈáäÂô®‰∏≠ÊâßË°å‰ª£Á†Å„ÄÇ\n",
    "ÊúÄÂêéË∞ÉÁî®python_replÂØπË±°ÁöÑrun()ÊñπÊ≥ïÔºå‰º†ÂÖ•‰∏ÄÊù°ÁÆÄÂçïÁöÑPythonËØ≠Âè•\"print(3**3)\",‰ª•ÊâìÂç∞Âá∫Êï∞Â≠ó27ÁöÑÂÄº„ÄÇ\n",
    "\"\"\"\n",
    "from langchain.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run(\"print(3**3)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My name is name\" \r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "È¶ñÂÖàÂØºÂÖ•BashProcessÁ±ªÔºåËØ•Á±ªÁî®‰∫éÂú®LinuxÁ≥ªÁªü‰∏≠ÊâßË°åÂëΩ‰ª§Ë°åÊìç‰Ωú„ÄÇ\n",
    "Êé•ÁùÄÂàõÂª∫‰∏Ä‰∏™BashProcessÂØπË±°bash,‰ª•‰æøÂú®LinuxÁ≥ªÁªü‰∏≠ÊâßË°åÂëΩ‰ª§Ë°åÊìç‰Ωú„ÄÇ\n",
    "ÊúÄÂêéË∞ÉÁî®bashÂØπË±°ÁöÑrun()ÊñπÊ≥ïÔºå‰º†ÂÖ•‰∏ÄÊù°ÁÆÄÂçïÁöÑÂëΩ‰ª§\"echo 'My name is \n",
    "name'\",‰ª•Âú®ÁªàÁ´Ø‰∏äÊâìÂç∞Âá∫Â≠óÁ¨¶‰∏≤\"My name is name\"„ÄÇ\n",
    "\"\"\"\n",
    "from langchain.utilities import BashProcess\n",
    "bash = BashProcess()\n",
    "print(bash.run(' echo \"My name is name\" '))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏ãÈù¢ÊòØÂ¶Ç‰Ωï‰ΩøÁî®Áª¥Âü∫ÁôæÁßëÁöÑÁ§∫‰æãÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from wikipedia) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from wikipedia) (4.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (from beautifulsoup4->wikipedia) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Hunter √ó Hunter\\nSummary: Hunter √ó Hunter (stylized as HUNTER√óHUNTER and pronounced \"hunter hunter\") is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha\\'s sh≈çnen manga magazine Weekly Sh≈çnen Jump since March 1998, although the manga has frequently gone on extended hiatuses since 2006. Its chapters have been collected in 37 tank≈çbon volumes as of November 2022. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals. Gon departs on a journey to become a Hunter and eventually find his father. Along the way, Gon meets various other Hunters and encounters the paranormal.\\nHunter √ó Hunter was adapted into a 62-episode anime television series produced by Nippon Animation and directed by Kazuhiro Furuhashi, which ran on Fuji Television from October 1999 to March 2001. Three separate original video animations (OVAs) totaling 30 episodes were subsequently produced by Nippon Animation and released in Japan from 2002 to 2004. A second anime television series by Madhouse aired on Nippon Television from October 2011 to September 2014, totaling 148 episodes, with two animated theatrical films released in 2013. There are also numerous audio albums, video games, musicals, and other media based on Hunter √ó Hunter.\\nThe manga has been translated into English and released in North America by Viz Media since April 2005. Both television series have been also licensed by Viz Media, with the first series having aired on the Funimation Channel in 2009 and the second series broadcast on Adult Swim\\'s Toonami programming block from April 2016 to June 2019.\\nHunter √ó Hunter has been a huge critical and financial success and has become one of the best-selling manga series of all time, having over 84 million copies in circulation by July 2022.\\n\\nPage: Hunter √ó Hunter (2011 TV series)\\nSummary: Hunter √ó Hunter is an anime television series that aired from 2011 to 2014 based on Yoshihiro Togashi\\'s manga series Hunter √ó Hunter. The story begins with a young boy named Gon Freecss, who one day discovers that the father who he thought was dead, is in fact alive and well. He learns that his father, Ging, is a legendary \"Hunter\", an individual who has proven themselves an elite member of humanity. Despite the fact that Ging left his son with his relatives in order to pursue his own dreams, Gon becomes determined to follow in his father\\'s footsteps, pass the rigorous \"Hunter Examination\", and eventually find his father to become a Hunter in his own right.\\nThis new Hunter √ó Hunter anime was announced on July 24, 2011. It is a complete reboot of the anime adaptation starting from the beginning of the manga, with no connections to the first anime from 1999. Produced by Nippon TV, VAP, Shueisha and Madhouse, the series is directed by Hiroshi K≈çjina, with Atsushi Maekawa and Tsutomu Kamishiro handling series composition, Takahiro Yoshimatsu designing the characters and Yoshihisa Hirano composing the music. Instead of having the old cast reprise their roles for the new adaptation, the series features an entirely new cast to voice the characters. The new series premiered airing weekly on Nippon TV and the nationwide Nippon News Network from October 2, 2011.  The series started to be collected in both DVD and Blu-ray format on January 25, 2012. Viz Media has licensed the anime for a DVD/Blu-ray release in North America with an English dub. On television, the series began airing on Adult Swim\\'s Toonami programming block on April 17, 2016, and ended on June 23, 2019.The anime series\\' opening theme is alternated between the song \"Departure!\" and an alternate version titled \"Departure! -Second Version-\" both sung by Galneryus\\' vocalist Masatoshi Ono. Five pieces of music were used as the ending theme; \"Just Awake\" by the Japanese band Fear, and Loathing in Las Vegas in episodes 1 to 26, \"Hunting for Your Dream\" by Galneryus in episodes 27 to 58, \"Reason\" sung by Japanese duo Yuzu in episodes 59 to 75, \"Nagareboshi Kirari\" also sung by Yuzu from episode 76 to 98, which was originally from the anime film adaptation, Hunter √ó Hunter: Phantom Rouge, and \"Hy≈çri Ittai\" by Yuzu featuring Hyadain from episode 99 to 146, which was also used in the film Hunter √ó Hunter: The Last Mission. The background music and soundtrack for the series was composed by Yoshihisa Hirano.\\n\\n\\n\\nPage: List of Hunter √ó Hunter characters\\nSummary: The Hunter √ó Hunter manga series, created by Yoshihiro Togashi, features an extensive cast of characters. It takes place in a fictional universe where licensed specialists known as Hunters travel the world taking on special jobs ranging from treasure hunting to assassination. The story initially focuses on Gon Freecss and his quest to become a Hunter in order to find his father, Ging, who is himself a famous Hunter. On the way, Gon meets and becomes close friends with Killua Zoldyck, Kurapika and Leorio Paradinight.\\nAlthough most characters are human, most possess superhuman strength and/or supernatural abilities due to Nen, the ability to control one\\'s own life energy or aura. The world of the series also includes fantastical beasts such as the Chimera Ants or the Five great calamities.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.run('HUNTER X HUNTER')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Êàë‰ª¨Êé•ÁùÄÁúã‰∏éagentÁõ∏ÂÖ≥ÁöÑÂÜÖÂÆπÔºåAgent‰ΩøÁî® LLM Êù•Á°ÆÂÆöÈááÂèñÂì™‰∫õË°åÂä®‰ª•ÂèäÈááÂèñ‰ΩïÁßçÈ°∫Â∫è„ÄÇactionÂèØ‰ª•ÊòØ‰ΩøÁî®toolsÂπ∂ËßÇÂØüÂÖ∂ËæìÂá∫Ôºå‰πüÂèØ‰ª•ÊòØÂêëÁî®Êà∑ËøîÂõûÂìçÂ∫î„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Á±ªÂûã](#type)\n",
    "- [Ëá™ÂÆö‰πâAgent](#custom-agent)\n",
    "- [Ëá™ÂÆö‰πâÂ§ßÊ®°ÂûãAgent](#custom-llm-agent)\n",
    "- [Self Ask With Search](#self-ask-with-search)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰ª•‰∏ãÊòØLangChain‰∏≠ÂèØÁî®ÁöÑAgentÁ±ªÂûãÔºö\n",
    "\n",
    "‰ΩøÁî®Âà∞ÁöÑÊòØReActÊ°ÜÊû∂\n",
    "\n",
    "**zero-shot-react-description**: ‰ªÖÊ†πÊçÆÂ∑•ÂÖ∑ÁöÑÊèèËø∞Êù•Á°ÆÂÆöË¶Å‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑„ÄÇÂèØ‰ª•Êèê‰æõ‰ªªÊÑèÊï∞ÈáèÁöÑÂ∑•ÂÖ∑„ÄÇÊ≠§AgentË¶ÅÊ±Ç‰∏∫ÊØè‰∏™Â∑•ÂÖ∑Êèê‰æõÊèèËø∞„ÄÇ\n",
    "\n",
    "**react-docstore**: Ëøô‰∏™Agent‰ΩøÁî® ReAct Ê°ÜÊû∂‰∏éÊñáÊ°£Â∫ìËøõË°å‰∫§‰∫í„ÄÇÂøÖÈ°ªÊèê‰æõ‰∏§‰∏™Â∑•ÂÖ∑Ôºö‰∏Ä‰∏™ÊêúÁ¥¢Â∑•ÂÖ∑Âíå‰∏Ä‰∏™Êü•ÊâæÂ∑•ÂÖ∑ÔºàÂÆÉ‰ª¨ÁöÑÂêçÁß∞ÂøÖÈ°ªÂÆåÂÖ®‰∏ÄÊ†∑Ôºâ„ÄÇÊêúÁ¥¢Â∑•ÂÖ∑Â∫îÊêúÁ¥¢ÊñáÊ°£ÔºåËÄåÊü•ÊâæÂ∑•ÂÖ∑Â∫îÂú®ÊúÄËøëÊâæÂà∞ÁöÑÊñáÊ°£‰∏≠Êü•ÊâæÊúØËØ≠„ÄÇËøô‰∏™‰ª£ÁêÜÁ≠âÂêå‰∫éÂéüÂßãÁöÑ ReAct ËÆ∫ÊñáÔºåÁâπÂà´ÊòØÁª¥Âü∫ÁôæÁßëÁöÑ‰æãÂ≠ê„ÄÇ\n",
    "\n",
    "**self-ask-with-search**: ËØ•Agent‰ΩøÁî®‰∏Ä‰∏™Â∑•ÂÖ∑ÔºåËØ•Â∑•ÂÖ∑Â∫îÂëΩÂêç‰∏∫ Intermediate Answer„ÄÇËØ•Â∑•ÂÖ∑Â∫îËØ•ËÉΩÂ§üÊü•ÊâæÈóÆÈ¢òÁöÑ‰∫ãÂÆûÁ≠îÊ°à„ÄÇËøô‰∏™‰ª£ÁêÜÁõ∏ÂΩì‰∫éÂéüÊù•ÁöÑ self ask with search paperÔºåÂÖ∂‰∏≠Êèê‰æõ‰∫Ü‰∏Ä‰∏™ Google ÊêúÁ¥¢ API ‰Ωú‰∏∫Â∑•ÂÖ∑„ÄÇ\n",
    "\n",
    "**conversational-react-description**: ËØ•AgentÊó®Âú®Áî®‰∫é‰ºöËØùËÆæÁΩÆ„ÄÇËøôÈÉ®ÂàÜÊèêÁ§∫ÁöÑËÆæËÆ°Êó®Âú®‰ΩøagentÂèØ‰ª•Êèê‰æõÂà∞Â∏ÆÂä©‰ª•Âèä‰æø‰∫éÂºÄÂ±ïÂØπËØù„ÄÇÂÆÉ‰ΩøÁî® ReAct Ê°ÜÊû∂Êù•ÂÜ≥ÂÆö‰ΩøÁî®Âì™‰∏™Â∑•ÂÖ∑ÔºåÂπ∂‰ΩøÁî®ÂÜÖÂ≠òÊù•ËÆ∞‰Ωè‰πãÂâçÁöÑÂØπËØù‰∫§‰∫í„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Agent\n",
    "\n",
    "Â¶Ç‰ΩïÂàõÂª∫Ëá™ÂÆö‰πâÁöÑAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool,AgentExecutor\n",
    "from langchain.agents import BaseSingleActionAgent\n",
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from typing import List, Tuple, Any, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\"\"\"\n",
    "ÂàõÂª∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ search ÁöÑ SerpAPIWrapper ÂØπË±°„ÄÇÁÑ∂ÂêéÔºåÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ tools ÁöÑÂàóË°®Ôºå\n",
    "ÂÖ∂‰∏≠ÂåÖÂê´‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ \"Search\" ÁöÑ Tool ÂØπË±°„ÄÇËøô‰∏™ Tool ÂØπË±°ÂèØ‰ª•Ë¢´Ë∞ÉÁî®ÔºåÂÖ∂ÂäüËÉΩÊòØÊêúÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇ\n",
    "Êé•ÁùÄÔºåÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ FakeAgent ÁöÑÁ±ªÔºåÁªßÊâøËá™ BaseSingleActionAgent„ÄÇËøô‰∏™Á±ªÁöÑ‰ΩúÁî®ÊòØÊ®°Êãü‰∏Ä\n",
    "‰∏™ÂÅáÁöÑÊô∫ËÉΩ‰ΩìÔºåÂÆÉÊúâ‰∏Ä‰∏™ËæìÂÖ•ÈîÆ(input_keys)Â±ûÊÄßÔºåÁî®‰∫éÊé•Êî∂Áî®Êà∑ËæìÂÖ•„ÄÇÂú® plan() ÊñπÊ≥ï‰∏≠ÔºåÊ†πÊçÆÂΩìÂâç\n",
    "Áä∂ÊÄÅÂíåÁî®Êà∑ËæìÂÖ•ÂÜ≥ÂÆöË¶ÅÈááÂèñ‰ªÄ‰πàË°åÂä®ÔºåËøîÂõû‰∏Ä‰∏™ AgentAction Êàñ AgentFinish ÂØπË±°„ÄÇÊúÄÂêéÔºåÂàõÂª∫‰∫Ü\n",
    "‰∏Ä‰∏™Âêç‰∏∫ agent ÁöÑ FakeAgent ÂØπË±°ÔºåÂπ∂ÈÄöËøá AgentExecutor.from_agent_and_tools() ÊñπÊ≥ï\n",
    "ÂàõÂª∫‰∫Ü‰∏Ä‰∏™ AgentExecutor ÂØπË±°„ÄÇÁÑ∂ÂêéË∞ÉÁî®‰∫Ü run() ÊñπÊ≥ïÔºå‰º†ÂÖ•‰∫Ü‰∏Ä‰∏™Êü•ËØ¢ËØ≠Âè• \"How many people\n",
    " live in canada as of 2023?\",ËØ•Êü•ËØ¢Â∞ÜÁî±Êô∫ËÉΩ‰ΩìÊâßË°å„ÄÇ\n",
    "\"\"\"\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "        return_direct=True\n",
    "    )\n",
    "]\n",
    "class FakeAgent(BaseSingleActionAgent):\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"input\"]\n",
    "    \n",
    "    def plan(\n",
    "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        return AgentAction(tool=\"Search\", tool_input=kwargs[\"input\"], log=\"\")\n",
    "\n",
    "    async def aplan(\n",
    "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        return AgentAction(tool=\"Search\", tool_input=kwargs[\"input\"], log=\"\")\n",
    "\n",
    "agent = FakeAgent()\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom LLM Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM‰ª£ÁêÜÁî±Âá†ÈÉ®ÂàÜÁªÑÊàêÔºö\n",
    "\n",
    "1. PromptTemplateÔºöËøôÊòØÊèêÁ§∫Ê®°ÊùøÔºåÂèØÁî®‰∫éÊåáÁ§∫ËØ≠Ë®ÄÊ®°ÂûãÂÅö‰ªÄ‰πà\n",
    "\n",
    "2. LLMÔºöËøôÊòØ‰∏∫‰ª£ÁêÜÊèê‰æõÊîØÊåÅÁöÑËØ≠Ë®ÄÊ®°Âûã\n",
    "\n",
    "3. StopSequenceÔºöÊåáÁ§∫LLM‰∏ÄÊó¶ÊâæÂà∞Ëøô‰∏™Â≠óÁ¨¶‰∏≤Â∞±ÂÅúÊ≠¢ÁîüÊàê\n",
    "\n",
    "4. OutputParserÔºöËøôÂÜ≥ÂÆö‰∫ÜÂ¶Ç‰ΩïÂ∞Ü LLMOutput Ëß£Êûê‰∏∫ AgentAction Êàñ AgentFinish ÂØπË±°\n",
    "\n",
    "LLMAgent Âú® AgentExecutor ‰∏≠‰ΩøÁî®„ÄÇËøô‰∏™ AgentExecutor Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèØ‰ª•Ë¢´ËÆ§‰∏∫ÊòØ‰∏Ä‰∏™Âæ™ÁéØÔºö\n",
    "1. Â∞ÜÁî®Êà∑ËæìÂÖ•Âíå‰ªª‰ΩïÂÖàÂâçÁöÑÊ≠•È™§‰º†ÈÄíÁªô‰ª£ÁêÜÔºàÂú®Êú¨‰æã‰∏≠‰∏∫ LLMAgentÔºâ\n",
    "\n",
    "2. Â¶ÇÊûú‰ª£ÁêÜËøîÂõû‰∏Ä‰∏™AgentFinishÔºåÂàôÁõ¥Êé•Â∞ÜÂÖ∂ËøîÂõûÁªôÁî®Êà∑\n",
    "\n",
    "3. Â¶ÇÊûú Agent ËøîÂõû‰∏Ä‰∏™AgentActionÔºåÂàô‰ΩøÁî®ÂÆÉÊù•Ë∞ÉÁî®‰∏Ä‰∏™Â∑•ÂÖ∑Âπ∂Ëé∑Âæó‰∏Ä‰∏™Observation\n",
    "\n",
    "4. ÈáçÂ§çÔºåÂ∞ÜAgentActionÂíå‰º†ÈÄíObservationÂõû‰ª£ÁêÜÔºåÁõ¥Âà∞AgentFinishÂèëÂá∫ „ÄÇ\n",
    "\n",
    "AgentActionactionÊòØÁî±ÂíåÁªÑÊàêÁöÑÂìçÂ∫îaction_input„ÄÇactionÊåáÁöÑÊòØ‰ΩøÁî®Âì™‰∏™Â∑•ÂÖ∑ÔºåÂπ∂action_inputÊåáÁöÑÊòØËØ•Â∑•ÂÖ∑ÁöÑËæìÂÖ•„ÄÇlog‰πüÂèØ‰ª•‰Ωú‰∏∫Êõ¥Â§ö‰∏ä‰∏ãÊñáÊèê‰æõÔºàÂèØÁî®‰∫éÊó•ÂøóËÆ∞ÂΩï„ÄÅË∑üË∏™Á≠âÔºâ„ÄÇ\n",
    "\n",
    "AgentFinishÊòØÂåÖÂê´Ë¶ÅÂèëÈÄÅÂõûÁî®Êà∑ÁöÑÊúÄÁªàÊ∂àÊÅØÁöÑÂìçÂ∫î„ÄÇËøôÂ∫îËØ•Áî®‰∫éÁªìÊùü‰ª£ÁêÜËøêË°å„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "\"\"\"ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ search ÁöÑÊêúÁ¥¢ÂºïÊìéÂØπË±°ÔºåÂπ∂Â∞ÜÂÖ∂Â∞ÅË£ÖÊàê‰∏Ä‰∏™ Tool ÂØπË±°Ê∑ªÂä†Âà∞\n",
    "tools ÂàóË°®‰∏≠Ôºå‰ª•‰æøÂú®ÂêéÁª≠ÁöÑ‰ªªÂä°ÊâßË°åËøáÁ®ã‰∏≠‰ΩøÁî®„ÄÇ\n",
    "\"\"\"\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËøôÈÉ®ÂàÜÊåáÁ§∫‰ª£ÁêÜÂÅö‰ªÄ‰πà„ÄÇ‰∏ÄËà¨Êù•ËØ¥ÔºåÊ®°ÊùøÂ∫îÂåÖÊã¨Ôºö\n",
    "\n",
    "- toolsÔºöagentÂèØ‰ª•ÈÄâÊã©ËÆøÈóÆÂì™‰∫õÂ∑•ÂÖ∑‰ª•ÂèäË∞ÉÁî®ÂÆÉ‰ª¨ÁöÑÊñπÂºèÂíåÊó∂Èó¥„ÄÇ\n",
    "\n",
    "- intermediate_stepsÔºöËøô‰∫õÊòØÂÖàÂâç ( AgentAction, Observation) ÂØπÂ∫îÁöÑÂÖÉÁªÑÂØπÂÑø„ÄÇËøô‰∫õ‰∏ÄËà¨‰∏ç‰ºöÁõ¥Êé•‰º†ÈÄíÁªôÊ®°ÂûãÔºåËÄåÊòØÊèêÁ§∫Ê®°Êùø‰ª•ÁâπÂÆöÁöÑÊñπÂºèÂØπÂÆÉ‰ª¨ËøõË°åÊ†ºÂºèÂåñÂ§ÑÁêÜ‰πãÂêéÂÜçÂèëÈÄÅÁªôllm„ÄÇ\n",
    "\n",
    "- input: ‰∏ÄËà¨Áî®Êà∑ÁöÑËæìÂÖ•ÂÜÖÂÆπ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\\n\\nQuestion: {input}\\n{agent_scratchpad}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ CustomPromptTemplate ÁöÑÁ±ªÔºåÁªßÊâøËá™ StringPromptTemplate„ÄÇ\n",
    "    template ÊòØ‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤Á±ªÂûãÁöÑÂ±ûÊÄßÔºåË°®Á§∫ÊèêÁ§∫‰ø°ÊÅØÁöÑÊ®°ÊùøÔºõ\n",
    "    tools ÊòØ‰∏Ä‰∏™ÂàóË°®Á±ªÂûãÁöÑÂ±ûÊÄßÔºåË°®Á§∫ÂèØÁî®ÁöÑÂ∑•ÂÖ∑ÂàóË°®Ôºõ\n",
    "    format ÊòØ‰∏Ä‰∏™ÊñπÊ≥ïÔºåÁî®‰∫éÂ∞Ü‰º†ÂÖ•ÁöÑÂèÇÊï∞Ê†ºÂºèÂåñÊàêÊèêÁ§∫‰ø°ÊÅØ„ÄÇÂú® format ÊñπÊ≥ï‰∏≠ÔºåÈ¶ñÂÖà‰ªé‰º†ÂÖ•ÁöÑÂèÇÊï∞‰∏≠ÂºπÂá∫‰∏Ä‰∏™Âêç‰∏∫ intermediate_steps ÁöÑÂÖ≥ÈîÆÂ≠ó\n",
    "ÂèÇÊï∞„ÄÇÁÑ∂ÂêéÔºåÈÅçÂéÜËøô‰∏™‰∏≠Èó¥Ê≠•È™§ÂàóË°®ÔºåÂ∞ÜÊØè‰∏™Ê≠•È™§ÁöÑÊìç‰ΩúÊó•ÂøóÂíåËßÇÂØüÁªìÊûúÊãºÊé•Âà∞‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ thoughts ‰∏≠„ÄÇÊé•ÁùÄÔºåÂ∞Ü thoughts Â≠òÂÖ• agent_scratchpad \n",
    "‰∏≠ÔºåÂπ∂Â∞ÜÂèØÁî®ÁöÑÂ∑•ÂÖ∑‰ø°ÊÅØÊ∑ªÂä†Âà∞tools Âíå tool_names ‰∏≠„ÄÇÊúÄÂêéÔºåË∞ÉÁî®Áà∂Á±ªÁöÑ format ÊñπÊ≥ïÔºåÂ∞ÜÊ†ºÂºèÂåñÂêéÁöÑÊèêÁ§∫‰ø°ÊÅØËøîÂõû„ÄÇ\n",
    "\"\"\"\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: str\n",
    "    tools: List[Tool]\n",
    "    def format(self, **kwargs) -> str:\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ prompt ÁöÑÂèòÈáèÔºåÁ±ªÂûã‰∏∫ CustomPromptTemplate„ÄÇËØ•ÂèòÈáèÈÄöËøáË∞ÉÁî®Áà∂Á±ª StringPromptTemplate ÁöÑÊûÑÈÄ†ÂáΩÊï∞\n",
    "ËøõË°åÂàùÂßãÂåñÔºå‰º†ÂÖ•‰∫Ü‰∏â‰∏™ÂèÇÊï∞Ôºötemplate„ÄÅtools Âíå input_variables„ÄÇÂÖ∂‰∏≠Ôºåtemplate ÊòØ‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤Á±ªÂûãÁöÑÂèÇÊï∞ÔºåË°®Á§∫ÊèêÁ§∫‰ø°ÊÅØÁöÑÊ®°ÊùøÔºõ\n",
    "tools ÊòØ‰∏Ä‰∏™ÂàóË°®Á±ªÂûãÁöÑÂèÇÊï∞ÔºåË°®Á§∫ÂèØÁî®ÁöÑÂ∑•ÂÖ∑ÂàóË°®Ôºõinput_variables ÊòØ‰∏Ä‰∏™ÂàóË°®Á±ªÂûãÁöÑÂèÇÊï∞ÔºåË°®Á§∫ËæìÂÖ•ÂèòÈáèÁöÑÂêçÁß∞ÂàóË°®„ÄÇÂú®Êú¨‰æã‰∏≠ÔºåËæìÂÖ•Âèò\n",
    "ÈáèÁöÑÂêçÁß∞‰∏∫ input Âíå intermediate_steps„ÄÇ\n",
    "\"\"\"\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OutputParserË¥üË¥£Â∞Ü LLM ÁöÑËæìÂá∫Ëß£Êûê‰∏∫AgentActionÂíåAgentFinish„ÄÇËøôÈÄöÂ∏∏Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÂÜ≥‰∫éÊâÄ‰ΩøÁî®ÁöÑÊèêÁ§∫„ÄÇ\n",
    "\n",
    "ËøôÊó∂ÂÄôÊÇ®ÂèØ‰ª•Êõ¥ÊîπËß£Êûê‰ª•ËøõË°åÈáçËØï„ÄÅÂ§ÑÁêÜÁ©∫ÁôΩÁ≠âÁöÑÂú∞Êñπ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ output_parser ÁöÑÂèòÈáèÔºåÁ±ªÂûã‰∏∫ CustomOutputParser„ÄÇËØ•ÂèòÈáèÈÄöËøáË∞ÉÁî®Áà∂Á±ª \n",
    "AgentOutputParser ÁöÑÊûÑÈÄ†ÂáΩÊï∞ËøõË°åÂàùÂßãÂåñ„ÄÇ\n",
    "Âú® CustomOutputParser Á±ª‰∏≠ÔºåÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ parse ÁöÑÊñπÊ≥ïÔºåÁî®‰∫éËß£Êûê LLM ËæìÂá∫„ÄÇËØ•ÊñπÊ≥ïÊé•Âèó‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤\n",
    "Á±ªÂûãÁöÑÂèÇÊï∞ llm_output,ËøîÂõûÂÄº‰∏∫ AgentAction Êàñ AgentFinish Á±ªÂûãÁöÑÂØπË±°„ÄÇ\n",
    "Âú® parse ÊñπÊ≥ï‰∏≠ÔºåÈ¶ñÂÖàÂà§Êñ≠ËæìÂÖ•ÁöÑ LLM ËæìÂá∫ÊòØÂê¶ÂåÖÂê´ \"Final Answer:\" Â≠óÁ¨¶‰∏≤„ÄÇÂ¶ÇÊûúÊòØÔºåÂàôËØ¥ÊòéÂ∑≤ÁªèÂÆåÊàê‰∫Ü‰ªªÂä°ÔºåËøîÂõû \n",
    "AgentFinish ÂØπË±°ÔºõÂê¶ÂàôÔºå‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºè‰ªé LLM ËæìÂá∫‰∏≠ÊèêÂèñÂá∫Âä®‰ΩúÂíåËæìÂÖ•‰ø°ÊÅØ„ÄÇÂ¶ÇÊûúÊó†Ê≥ïÊèêÂèñÂá∫Âä®‰ΩúÂíåËæìÂÖ•‰ø°ÊÅØÔºåÂàôÊäõÂá∫ÂºÇÂ∏∏„ÄÇ\n",
    "ÊúÄÂêéÔºåÊ†πÊçÆÊèêÂèñÂá∫ÁöÑ‰ø°ÊÅØÂàõÂª∫ AgentAction ÂØπË±°Âπ∂ËøîÂõû„ÄÇ\n",
    "\"\"\"\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂÆö‰πâStopSequence(ÂÅúÊ≠¢Â∫èÂàó)ÔºåËøôÂæàÈáçË¶ÅÔºåÂõ†‰∏∫ÂÆÉÂëäËØâ LLM ‰ΩïÊó∂ÂÅúÊ≠¢ÁîüÊàê„ÄÇ\n",
    "\n",
    "ËøôÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÂÜ≥‰∫éÊÇ®‰ΩøÁî®ÁöÑÊèêÁ§∫ÂíåÊ®°Âûã„ÄÇÈÄöÂ∏∏ÔºåÊÇ®Â∏åÊúõËøôÊòØÊÇ®Âú®ÊèêÁ§∫‰∏≠‰ΩøÁî®ÁöÑ‰ªª‰ΩïÊ†áËÆ∞Êù•Ë°®Á§∫‰∏Ä‰∏™ÂºÄÂßãObservationÔºàÂê¶ÂàôÔºåLLM ÂèØËÉΩ‰ºö‰∏∫ÊÇ®‰∫ßÁîüËôöÊãüÁöÑObservationÔºâ„ÄÇ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "#‰ΩøÁî®ÂàóË°®Êé®ÂØºÂºè‰ªé tools ÂàóË°®‰∏≠ÊèêÂèñÂá∫ÊØè‰∏™Â∑•ÂÖ∑ÁöÑÂêçÁß∞ÔºåÂπ∂Â∞ÜËøô‰∫õÂêçÁß∞Â≠òÂÇ®Âà∞ tool_names ÂàóË°®‰∏≠„ÄÇ\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "\"\"\"\n",
    "‰º†ÂÖ•‰∫ÜÂ¶Ç‰∏ãÂá†‰∏™‰∏™ÂèÇÊï∞Ôºöllm_chain„ÄÅoutput_parser„ÄÅstopÂíå allowed_tools„ÄÇ\n",
    "ÂÖ∂‰∏≠Ôºållm_chain ÊòØ‰∏Ä‰∏™ LLMChain ÂØπË±°ÔºåË°®Á§∫ LLM ÈìæÔºõ\n",
    "output_parser ÊòØ‰∏Ä‰∏™ CustomOutputParser ÂØπË±°ÔºåË°®Á§∫Ëß£Êûê LLM ËæìÂá∫ÁöÑÁ±ªÔºõ\n",
    "allowed_tools ÊòØ‰∏Ä‰∏™ÂàóË°®ÔºåË°®Á§∫ÂèØÁî®ÁöÑÂ∑•ÂÖ∑ÂàóË°®„ÄÇ\n",
    "\"\"\"\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ agent_executor ÁöÑÂèòÈáèÔºåÁ±ªÂûã‰∏∫ AgentExecutor„ÄÇ\n",
    "ËØ•ÂèòÈáèÈÄöËøáË∞ÉÁî® AgentExecutor Á±ªÁöÑÊûÑÈÄ†ÂáΩÊï∞ËøõË°åÂàùÂßãÂåñ„ÄÇ\n",
    "Âú®ÊûÑÈÄ†ÂáΩÊï∞‰∏≠Ôºå‰º†ÂÖ•‰∫Ü‰∏â‰∏™ÂèÇÊï∞Ôºöagent„ÄÅtools Âíå verbose„ÄÇ\n",
    "ÂÖ∂‰∏≠Ôºåagent ÊòØ‰∏Ä‰∏™ LLMSingleActionAgent ÂØπË±°ÔºåË°®Á§∫ LLM ‰ª£ÁêÜÔºõ\n",
    "tools ÊòØ‰∏Ä‰∏™ÂàóË°®ÔºåË°®Á§∫ÂèØÁî®ÁöÑÂ∑•ÂÖ∑ÂàóË°®Ôºõ\n",
    "verbose ÊòØ‰∏Ä‰∏™Â∏ÉÂ∞îÂÄºÔºåË°®Á§∫ÊòØÂê¶ËæìÂá∫ËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇ\n",
    "Êé•‰∏ãÊù•ÔºåË∞ÉÁî® AgentExecutor Á±ªÁöÑ from_agent_and_tools ÈùôÊÄÅÊñπÊ≥ïÔºåÂ∞Ü agent„ÄÅtools Âíå verbose \n",
    "‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄíÁªôÂÆÉ„ÄÇËØ•ÊñπÊ≥ï‰ºöËøîÂõû‰∏Ä‰∏™Êñ∞ÁöÑ AgentExecutor ÂØπË±°ÔºåÁî®‰∫éÊâßË°å LLM ‰ªªÂä°„ÄÇ\n",
    "\"\"\"\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self Ask With Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂØºÂÖ•‰∫Ü OpenAI Âíå SerpAPIWrapper Ê®°ÂùóÔºå‰ª•Âèä initialize_agent„ÄÅTool Âíå AgentType Á±ª„ÄÇ\n",
    "ÁÑ∂ÂêéÔºåÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ llm ÁöÑ OpenAI ÂØπË±°ÔºåÁî®‰∫éÊâßË°å LLM ‰ªªÂä°„ÄÇÊé•ÁùÄÔºåÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ search ÁöÑ SerpAPIWrapper ÂØπË±°ÔºåÁî®‰∫éÊêúÁ¥¢Á≠îÊ°à„ÄÇ\n",
    "Êé•‰∏ãÊù•ÔºåÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ tools ÁöÑÂàóË°®ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏Ä‰∏™Âêç‰∏∫ Intermediate Answer ÁöÑÂ∑•ÂÖ∑ÂØπË±°„ÄÇËØ•Â∑•ÂÖ∑ÂØπË±°ÂÖ∑Êúâ func Â±ûÊÄßÔºåÊåáÂÆö‰∫Ü‰ΩøÁî®\n",
    " search.run() ÊñπÊ≥ïÊù•ÊêúÁ¥¢Á≠îÊ°à„ÄÇ\n",
    " \"\"\"\n",
    "llm = OpenAI(temperature=0)\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    )\n",
    "]\n",
    "#Ë∞ÉÁî® initialize_agent ÂáΩÊï∞ÂàùÂßãÂåñ‰∏Ä‰∏™‰ª£ÁêÜÂØπË±°ÔºåÂπ∂Â∞ÜÂÖ∂ËµãÂÄºÁªô self_ask_with_search ÂèòÈáè„ÄÇ\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "self_ask_with_search.run(\"What is the hometown of the reigning men's U.S. Open champion?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Toolkits\n",
    "ËøôÈÉ®ÂàÜ‰∏ªË¶ÅÂåÖÂê´‰∏Ä‰∫õÊàê‰∫ÜÂ∑•ÂÖ∑ÁöÑagent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [CSV Agent](#csv-agent)\n",
    "- [Python Agent](#python-agent)\n",
    "- [Vectorstore Agent](#vectorstore-agent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CSV Agent\n",
    "Ê†πÊçÆÁªôÂÆöÁöÑcsvÊñá‰ª∂ÂÜÖÂÆπÔºåÂõûÂ§çÁî®Êà∑ÈóÆÈ¢ò„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_csv_agent\n",
    "from langchain.llms import OpenAI\n",
    "#Êàë‰ª¨Êâæ‰∫Ü‰∏Ä‰∏™titanicÁîüËøòËÄÖÂêçÂçïÔºåÈáåÈù¢ÊòØ‰∏Ä‰∫õÂπ∏Â≠òËÄÖÁöÑ‰ø°ÊÅØÔºå‰Ω†ÂèØ‰ª•‰∏ä‰º†‰∏Ä‰∏™csvÊñá‰ª∂ÔºåÂπ∂ÂØπcsvÊñá‰ª∂ËøõË°åÂü∫Êú¨ÁöÑËØ¢ÈóÆ\n",
    "agent = create_csv_agent(OpenAI(temperature=0), 'titanic.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to count the number of rows\n",
      "Action: python_repl_ast\n",
      "Action Input: len(df)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m891\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 891 rows in the dataframe.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 891 rows in the dataframe.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to count the number of people with more than 3 siblings\n",
      "Action: python_repl_ast\n",
      "Action Input: df[df['SibSp'] > 3].shape[0]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m30\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 30 people have more than 3 siblings.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'30 people have more than 3 siblings.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"how many people have more than 3 sibligngs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to calculate the average age first\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Age'].mean()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m29.69911764705882\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now need to calculate the square root of this\n",
      "Action: python_repl_ast\n",
      "Action Input: math.sqrt(df['Age'].mean())\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mname 'math' is not defined\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to import the math library\n",
      "Action: python_repl_ast\n",
      "Action Input: import math\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now need to calculate the square root of the average age\n",
      "Action: python_repl_ast\n",
      "Action Input: math.sqrt(df['Age'].mean())\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m5.449689683556195\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 5.449689683556195\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5.449689683556195'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"whats the square root of the average age?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Python Agent\n",
    "ËØ•‰ª£ÁêÜÁî®‰∫éÊ†πÊçÆÁî®Êà∑Ë¶ÅÊ±ÇÁîüÊàêÊàñÊâßË°å‰∏ÄÊÆµpython‰ª£Á†Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.llms.openai import OpenAI\n",
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ agent_executor ÁöÑÂèòÈáèÔºåÁ±ªÂûã‰∏∫ AgentExecutor„ÄÇËØ•ÂèòÈáèÈÄöËøáË∞ÉÁî® create_python_agent ÂáΩÊï∞ËøõË°åÂàùÂßãÂåñ„ÄÇ\n",
    "Âú®ÊûÑÈÄ†ÂáΩÊï∞‰∏≠Ôºå‰º†ÂÖ•‰∫Ü‰∏â‰∏™ÂèÇÊï∞Ôºöllm„ÄÅtool Âíå verbose„ÄÇ\n",
    "ÂÖ∂‰∏≠Ôºållm ÊòØ‰∏Ä‰∏™ OpenAI ÂØπË±°ÔºåÁî®‰∫éÊâßË°å LLM ‰ªªÂä°Ôºõ\n",
    "tool ÊòØ‰∏Ä‰∏™PythonREPLTool ÂØπË±°ÔºåË°®Á§∫Áî®‰∫é‰∫§‰∫íÂºèËß£ÈáäÁöÑÂ∑•ÂÖ∑Ôºõ\n",
    "verbose ÊòØ‰∏Ä‰∏™Â∏ÉÂ∞îÂÄºÔºåË°®Á§∫ÊòØÂê¶ËæìÂá∫ËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇ\n",
    "Êé•‰∏ãÊù•ÔºåË∞ÉÁî® create_python_agent ÂáΩÊï∞ÔºåÂ∞Ü llm„ÄÅtool Âíå verbose ‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄíÁªôÂÆÉ„ÄÇËØ•ÂáΩÊï∞‰ºöËøîÂõû‰∏Ä‰∏™Êñ∞ÁöÑ AgentExecutor ÂØπË±°Ôºå\n",
    "Áî®‰∫éÊâßË°å LLM ‰ªªÂä°Âπ∂Êèê‰æõ‰∫§‰∫íÂºèËß£ÈáäÂäüËÉΩ„ÄÇ\n",
    "\"\"\"\n",
    "agent_executor = create_python_agent(\n",
    "    llm=OpenAI(temperature=0, max_tokens=1000),\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ÁîüÊàêFibonacciÊï∞Âàó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate the 10th fibonacci number\n",
      "Action: Python REPL\n",
      "Action Input: def fibonacci(n):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "\n",
      "print(fibonacci(10))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m55\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 55\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'55'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"What is the 10th fibonacci number?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to write a neural network in PyTorch and train it on the given data.\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "import torch\n",
      "\n",
      "# Define the model\n",
      "model = torch.nn.Sequential(\n",
      "    torch.nn.Linear(1, 1)\n",
      ")\n",
      "\n",
      "# Define the loss\n",
      "loss_fn = torch.nn.MSELoss()\n",
      "\n",
      "# Define the optimizer\n",
      "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
      "\n",
      "# Define the data\n",
      "x_data = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
      "y_data = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
      "\n",
      "# Train the model\n",
      "for epoch in range(1000):\n",
      "    # Forward pass\n",
      "    y_pred = model(x_data)\n",
      "\n",
      "    # Compute and print loss\n",
      "    loss = loss_fn(y_pred, y_data)\n",
      "    if (epoch+1) % 100 == 0:\n",
      "        print(f'Epoch {epoch+1}: loss = {loss.item():.4f}')\n",
      "\n",
      "    # Zero the gradients\n",
      "    optimizer.zero_grad()\n",
      "\n",
      "    # Backward pass\n",
      "    loss.backward()\n",
      "\n",
      "    # Update the weights\n",
      "    optimizer.step()\n",
      "\n",
      "# Make a prediction\n",
      "x_pred = torch.tensor([[5.0]])\n",
      "y_pred = model(x_pred)\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mEpoch 100: loss = 0.2032\n",
      "Epoch 200: loss = 0.1116\n",
      "Epoch 300: loss = 0.0613\n",
      "Epoch 400: loss = 0.0336\n",
      "Epoch 500: loss = 0.0185\n",
      "Epoch 600: loss = 0.0101\n",
      "Epoch 700: loss = 0.0056\n",
      "Epoch 800: loss = 0.0031\n",
      "Epoch 900: loss = 0.0017\n",
      "Epoch 1000: loss = 0.0009\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The prediction for x = 5 is y = 10.00.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The prediction for x = 5 is y = 10.00.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"\"\"Understand, write a single neuron neural network in PyTorch.\n",
    "Take synthetic data for y=2x. Train for 1000 epochs and print every 100 epochs.\n",
    "Return prediction for x = 5\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorstore Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\"\"\"\n",
    "ÁÑ∂ÂêéÔºåÊúÄÂêéÔºå‰ΩøÁî® Chroma.from_documents() \n",
    "ÊñπÊ≥ïÂ∞ÜÊñáÊ°£ËΩ¨Êç¢‰∏∫ËØ≠Ë∞±ÂõæÔºåÂπ∂Â∞ÜÂÖ∂Â≠òÂÇ®Âú®Âêç‰∏∫ state_of_union_store ÁöÑÂØπË±°‰∏≠„ÄÇ\n",
    "\"\"\"\n",
    "#Âä†ËΩΩÊåáÂÆöÁöÑÊñáÊú¨Êñá‰ª∂\n",
    "loader = TextLoader('../../../state_of_the_union.txt')\n",
    "#‰ªéÊñáÊú¨Êñá‰ª∂‰∏≠Âä†ËΩΩÊñáÊ°£\n",
    "documents = loader.load()\n",
    "#ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ text_splitter ÁöÑ CharacterTextSplitter ÂØπË±°ÔºåÁî®‰∫éÂ∞ÜÊñáÊ°£ÂàÜÊàê\n",
    "#Â§ö‰∏™Âùó„ÄÇÂÖ∂‰∏≠Ôºåchunk_size ÂèÇÊï∞ÊåáÂÆöÊØè‰∏™ÂùóÁöÑÂ§ßÂ∞èÔºåchunk_overlap ÂèÇÊï∞ÊåáÂÆöÂùó‰πãÈó¥ÁöÑÈáçÂè†Â§ßÂ∞è„ÄÇ\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "#ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫embeddings ÁöÑ OpenAIEmbeddings ÂØπË±°ÔºåÁî®‰∫éÁîüÊàêÊñáÊ°£ÁöÑÂµåÂÖ•Ë°®Á§∫„ÄÇ\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\"\"\"\n",
    "‰∏ãÈù¢‰ª£Á†ÅÊòØ‰ΩøÁî® Chroma Â∫ì‰ªéÊñáÊ°£‰∏≠ÊèêÂèñËØ≠Ë∞±ÂõæÔºåÂπ∂Â∞ÜÂÖ∂Â≠òÂÇ®Âú®‰∏Ä‰∏™Âêç‰∏∫ state_of_union_store ÁöÑÂØπË±°‰∏≠„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂÆÉÂÅö‰∫Ü‰ª•‰∏ãÂá†‰ª∂‰∫ãÊÉÖÔºö\n",
    "‰ªé‰∏Ä‰∏™Âêç‰∏∫ texts ÁöÑÂàóË°®‰∏≠Âä†ËΩΩÂ§ö‰∏™ÊñáÊú¨Êñá‰ª∂„ÄÇ\n",
    "Â∞ÜÊØè‰∏™ÊñáÊú¨Êñá‰ª∂ËΩ¨Êç¢‰∏∫‰∏Ä‰∏™ÂåÖÂê´ÂçïËØçÂíåÂÆÉ‰ª¨ÂØπÂ∫îÁöÑÂµåÂÖ•ÂêëÈáèÁöÑÂàóË°®„ÄÇËøô‰∫õÂµåÂÖ•ÂêëÈáèÊòØÈÄöËøáË∞ÉÁî® OpenAIEmbeddings Á±ªÁöÑ generate() ÊñπÊ≥ïÁîüÊàêÁöÑ„ÄÇ\n",
    "‰ΩøÁî® Chroma.from_documents() ÊñπÊ≥ïÂ∞ÜÊâÄÊúâÊñáÊú¨Êñá‰ª∂ÁöÑÂµåÂÖ•ÂêëÈáèÂàóË°®ÂêàÂπ∂Êàê‰∏Ä‰∏™ÂÆåÊï¥ÁöÑËØ≠Ë∞±Âõæ„ÄÇËØ•ÊñπÊ≥ïÊé•Âèó‰∏â‰∏™ÂèÇÊï∞Ôºötexts„ÄÅembeddings Âíå \n",
    "collection_name,ÂàÜÂà´Ë°®Á§∫Ë¶ÅÂä†ËΩΩÁöÑÊñáÊú¨Êñá‰ª∂ÂàóË°®„ÄÅÊØè‰∏™ÊñáÊú¨Êñá‰ª∂‰∏≠ÁöÑÂµåÂÖ•ÂêëÈáèÂàóË°®‰ª•ÂèäËØ≠Ë∞±ÂõæÁöÑÈõÜÂêàÂêçÁß∞„ÄÇ\n",
    "ÊúÄÁªàÔºåËøôÊÆµ‰ª£Á†Å‰ºöÂ∞ÜÁîüÊàêÁöÑËØ≠Ë∞±ÂõæÂ≠òÂÇ®Âú®Âêç‰∏∫ state_of_union_store ÁöÑÂØπË±°‰∏≠Ôºå‰ª•‰æøÂêéÁª≠‰ΩøÁî®„ÄÇ\n",
    "\"\"\"\n",
    "state_of_union_store = Chroma.from_documents(texts, embeddings, collection_name=\"state-of-union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "#ÂàõÂª∫‰∏Ä‰∏™ WebBaseLoader ÂØπË±°Âπ∂ÊåáÂÆöË¶ÅÂä†ËΩΩÁöÑ URL\n",
    "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")\n",
    "#Ë∞ÉÁî® load() ÊñπÊ≥ï‰ªéÊåáÂÆöÁöÑ URL Âä†ËΩΩÊñáÊ°£„ÄÇËØ•ÊñπÊ≥ïËøîÂõû‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÊñáÊ°£ÁöÑÂàóË°®„ÄÇ\n",
    "docs = loader.load()\n",
    "#‰ΩøÁî® text_splitter.split_documents() ÊñπÊ≥ïÂ∞ÜÊâÄÊúâÊñáÊ°£ÂàÜÂâ≤ÊàêÂ§ö‰∏™ÊñáÊú¨ÊÆµËêΩ„ÄÇËØ•ÊñπÊ≥ïÊé•Âèó‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÊñáÊ°£ÁöÑÂàóË°®‰Ωú‰∏∫ÂèÇÊï∞Ôºå\n",
    "#Âπ∂ËøîÂõû‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÊñáÊú¨ÊÆµËêΩÁöÑÂàóË°®„ÄÇ\n",
    "ruff_texts = text_splitter.split_documents(docs)\n",
    "\"\"\"\n",
    "‰ΩøÁî® Chroma.from_documents() ÊñπÊ≥ïÂ∞ÜÊâÄÊúâÊñáÊú¨ÊÆµËêΩËΩ¨Êç¢‰∏∫ËØ≠Ë∞±ÂõæÔºåÂπ∂Â∞ÜÂÖ∂Â≠òÂÇ®Âú®\n",
    "‰∏Ä‰∏™Âêç‰∏∫ ruff_store ÁöÑÂØπË±°‰∏≠„ÄÇËØ•ÊñπÊ≥ïÊé•Âèó‰∏â‰∏™ÂèÇÊï∞Ôºöruff_texts„ÄÅembeddings Âíå collection_name,ÂàÜÂà´Ë°®Á§∫ÊâÄÊúâÊñáÊú¨\n",
    "ÊÆµËêΩÁöÑÂàóË°®„ÄÅÊØè‰∏™ÊñáÊú¨ÊÆµËêΩÂØπÂ∫îÁöÑÂµåÂÖ•ÂêëÈáèÂàóË°®‰ª•ÂèäËØ≠Ë∞±ÂõæÁöÑÈõÜÂêàÂêçÁß∞„ÄÇÂú®Êú¨‰æã‰∏≠ÔºåËØ≠Ë∞±ÂõæÁöÑÈõÜÂêàÂêçÁß∞‰∏∫ \"ruff\"\n",
    "\"\"\"\n",
    "ruff_store = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import (\n",
    "    create_vectorstore_agent,\n",
    "    VectorStoreToolkit,\n",
    "    VectorStoreInfo,\n",
    ")\n",
    "#È¶ñÂÖàÔºåÂàõÂª∫‰∏Ä‰∏™ VectorStoreInfo ÂØπË±°ÔºåÂπ∂ÊåáÂÆöÂÖ∂ÂêçÁß∞„ÄÅÊèèËø∞ÂíåÊåáÂêëËØ≠Ë∞±ÂõæÂ≠òÂÇ®ÂØπË±°ÁöÑvectorstore\n",
    "vectorstore_info = VectorStoreInfo(\n",
    "    name=\"state_of_union_address\",\n",
    "    description=\"the most recent state of the Union adress\",\n",
    "    vectorstore=state_of_union_store\n",
    ")\n",
    "#ÂàõÂª∫‰∏Ä‰∏™ VectorStoreToolkit ÂØπË±°ÔºåÂ∞Ü vectorstore_info ÂØπË±°‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄíÁªôÂÆÉ„ÄÇËØ•ÂØπË±°Áî®‰∫éÁÆ°ÁêÜ‰∏éÂêëÈáèÂ≠òÂÇ®Áõ∏ÂÖ≥ÁöÑÂÖÉÊï∞ÊçÆÂíåÂ∑•ÂÖ∑„ÄÇ\n",
    "toolkit = VectorStoreToolkit(vectorstore_info=vectorstore_info)\n",
    "\"\"\"\n",
    "‰ΩøÁî® create_vectorstore_agent() ÊñπÊ≥ïÂàõÂª∫‰∏Ä‰∏™\n",
    "‰ª£ÁêÜ„ÄÇËØ•ÊñπÊ≥ïÊé•Âèó‰∏â‰∏™ÂèÇÊï∞Ôºöllm,Ë°®Á§∫ËØ≠Ë®ÄÊ®°ÂûãÔºõtoolkit,Ë°®Á§∫ VectorStoreToolkit ÂØπË±°Ôºõverbose,Ë°®Á§∫ÊòØÂê¶ÂêØÁî®ËØ¶\n",
    "ÁªÜËæìÂá∫Ê®°Âºè„ÄÇÂú®Êú¨‰æã‰∏≠Ôºå‰ª£ÁêÜÂ∞Ü‰ΩøÁî® llm ‰Ωú‰∏∫ÂÖ∂ËØ≠Ë®ÄÊ®°ÂûãÔºåÂπ∂Â∞Ü toolkit ‰Ωú‰∏∫ÂÖ∂Â∑•ÂÖ∑ÂåÖ„ÄÇÊúÄÁªàÔºå‰ª£ÁêÜÁöÑÊâßË°åÂô®Â∞ÜË¢´ËøîÂõûÔºå\n",
    "ÂèØ‰ª•Â∞ÜÂÖ∂Áî®‰∫éÊâßË°åÁâπÂÆöÁöÑ‰ªªÂä°ÊàñÊìç‰Ωú„ÄÇ\n",
    "\"\"\"\n",
    "agent_executor = create_vectorstore_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What did biden say about ketanji brown jackson is the state of the union address?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What did biden say about ketanji brown jackson is the state of the union address? List the source.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Vectorstores\n",
    "\n",
    "Â§ö‰∏™Áü¢ÈáèÂ≠òÂÇ®Â∫ìÔºåÊàë‰ª¨‰πüÂèØ‰ª•ÂæàÂÆπÊòìÂú∞‰ΩøÁî®Ëøô‰∏™ÂàùÂßãÂåñ‰∏Ä‰∏™ÂÖ∑ÊúâÂ§ö‰∏™ÂêëÈáèÂ≠òÂÇ®ÁöÑ‰ª£ÁêÜÔºåÂπ∂‰ΩøÁî®‰ª£ÁêÜÂú®ÂÆÉ‰ª¨‰πãÈó¥ËøûÊé•„ÄÇË¶ÅÂÅöÂà∞Ëøô‰∏ÄÁÇπ„ÄÇËøô‰∏™‰ª£ÁêÜÊòØ‰∏∫ËøûÊé•ÂΩºÊ≠§ËÄå‰ºòÂåñÁöÑÔºåÊâÄ‰ª•ÂÆÉÊòØ‰∏Ä‰∏™‰∏çÂêåÁöÑÂ∑•ÂÖ∑ÂåÖÂíåÂàùÂßãÂåñÂô®„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import (\n",
    "    create_vectorstore_router_agent,\n",
    "    VectorStoreRouterToolkit,\n",
    "    VectorStoreInfo,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VectorStoreInfoËøô‰∏™Á±ªÂÆû‰æãÁî®‰∫éË°®Á§∫ÂêëÈáèÂ≠òÂÇ®ÁöÑ‰ø°ÊÅØ„ÄÇ\n",
    "ÂÆÉÊúâ‰∏â‰∏™Â±ûÊÄßÔºöname„ÄÅdescriptionÂíåvectorstore,ÂàÜÂà´Ë°®Á§∫ÂêçÁß∞„ÄÅÊèèËø∞ÂíåÊåáÂêëÂêëÈáèÂ≠òÂÇ®ÂØπË±°ÁöÑÂ≠òÂÇ®Â∫ì„ÄÇ\n",
    "\"\"\"\n",
    "ruff_vectorstore_info = VectorStoreInfo(\n",
    "    name=\"ruff\",\n",
    "    description=\"Information about the Ruff python linting library\",\n",
    "    vectorstore=ruff_store\n",
    ")\n",
    "\"\"\"\n",
    "VectorStoreRouterToolkitËøô‰∏™Á±ªÁî®‰∫éË°®Á§∫ÂêëÈáèÂ≠òÂÇ®Ë∑ØÁî±Âô®Â∑•ÂÖ∑ÂåÖ„ÄÇ\n",
    "ÂÆÉÊúâ‰∏Ä‰∏™Â±ûÊÄßvectorstores,Ë°®Á§∫ÂåÖÂê´Â§ö‰∏™ÂêëÈáèÂ≠òÂÇ®‰ø°ÊÅØÁöÑÂàóË°®ÔºåÂèÇÊï∞llm,Ë°®Á§∫ËØ≠Ë®ÄÊ®°Âûã„ÄÇ\n",
    "\"\"\"\n",
    "router_toolkit = VectorStoreRouterToolkit(\n",
    "    vectorstores=[vectorstore_info, ruff_vectorstore_info],\n",
    "    llm=llm\n",
    ")\n",
    "\"\"\"\n",
    "create_vectorstore_router_agentËøô‰∏™ÊñπÊ≥ïÁî®‰∫éÂàõÂª∫‰∏Ä‰∏™‰ª£ÁêÜÔºåËØ•‰ª£ÁêÜÂ∞Ü‰ΩøÁî®ÂêëÈáèÂ≠òÂÇ®Ë∑ØÁî±Âô®Â∑•ÂÖ∑ÂåÖÊù•Â§ÑÁêÜÊ∂àÊÅØ„ÄÇ\n",
    "ÂÆÉÊúâ‰∏â‰∏™ÂèÇÊï∞Ôºöllm„ÄÅtoolkitÂíåverbose,ÂàÜÂà´Ë°®Á§∫ËØ≠Ë®ÄÊ®°Âûã„ÄÅÂ∑•ÂÖ∑ÂåÖÂíåËØ¶ÁªÜËæìÂá∫Ê®°Âºè„ÄÇ\n",
    "\"\"\"\n",
    "agent_executor = create_vectorstore_router_agent(\n",
    "    llm=llm,\n",
    "    toolkit=router_toolkit,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What did biden say about ketanji brown jackson is the state of the union address?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What tool does ruff use to run over Jupyter Notebooks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exampls\n",
    "\n",
    "- [Question answering in documents](#question-answering-in-documents)\n",
    "- [BabyAGI with Tools](#babyagi-with-tools)\n",
    "- [Auto-GPT Assistant](#auto-gpt-assistant)\n",
    "\n",
    "### Question answering in documents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÈóÆÁ≠îÂèØ‰ª•‰ΩøÁî®‰∏çÂêåÁöÑchainsÔºöstuffÔºåmap_reduceÔºårefineÂíåmap_rerank\n",
    "\n",
    "ÂÖ∂‰∏≠ÁöÑstuffÊòØÊúÄÂ∏∏‰ΩøÁî®ÁöÑÊñπÂºèÔºõmap_reduceÂèØ‰ª•ÊääËæìÂÖ•ÁöÑÊï∞ÊçÆÂàÜÂâ≤ÊàêËã•Âπ≤‰∏™Â∞èÁöÑÊï∞ÊçÆÂùóÔºåÂπ∂Âú®Ëøô‰∫õÂ∞èÁöÑÊï∞ÊçÆÂùó‰∏äÁã¨Á´ãÂú∞ÊâßË°åËÆ°ÁÆóÔºåÁÑ∂ÂêéÂ∞ÜËÆ°ÁÆóÁªìÊûúËøõË°åÊ±áÊÄªÔºå‰ªéËÄåÂæóÂà∞ÊúÄÁªàÁöÑËæìÂá∫ÁªìÊûúÔºõrefineÊòØÊ†πÊçÆ‰∏ä‰∏ãÊñáÁöÑ‰ø°ÊÅØÂíå‰∏Ä‰∏™ÈóÆÈ¢òÁªôÂá∫‰∏Ä‰∏™ÂàùÊ≠•ÁöÑÁ≠îÊ°àÔºåÂ¶ÇÊûúÁ≠îÊ°à‰∏çÂ§üÂáÜÁ°ÆÂ∞±‰ºöËø≠‰ª£Ê†πÊçÆ‰∏ä‰∏ãÊñá‰ø°ÊÅØ‰ª•Âèä‰πãÂâçÁöÑÂõûÁ≠îÊù•Êèê‰æõÊõ¥Â•ΩÁöÑÁ≠îÊ°àÔºåÁõ¥Âà∞ÊâæÂà∞ÊúÄÁªàÁöÑÊúÄ‰Ω≥Á≠îÊ°à„ÄÇ\n",
    "\n",
    "ËØ¶ÁªÜÁöÑÊñáÊ°£ËØ¥ÊòéÁÇπÂáªüëâ[Ê≠§Â§Ñ](https://python.langchain.com/en/latest/use_cases/question_answering.html)üëàÁõ¥Êé•Ë∑≥ËΩ¨„ÄÇ\n",
    "\n",
    "‰∏ãÈù¢Êàë‰ª¨ÈíàÂØπËøô‰∏™Á§∫‰æãËøõË°åÈÄêË°åÁöÑ‰ª£Á†ÅËß£Èáä„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ËÆæÁΩÆHTTP‰ª£ÁêÜ\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:your port'\n",
    "# ËÆæÁΩÆHTTPS‰ª£ÁêÜ\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:your port'\n",
    "# openaiÁöÑkey\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your OpenAI Key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÂØºÂÖ•ÁîüÊàêÊñáÊú¨ÂµåÂÖ•ÂêëÈáèÁöÑÊâÄÈúÄË¶ÅÁöÑÂ∫ì\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "#ÂØºÂÖ•Â∞ÜÊñáÊú¨ÂàÜÂâ≤ÊàêÂõ∫ÂÆöÈïøÂ∫¶ÁöÑÂ∞èÂùóÔºåÊñπ‰æøËøõË°åÂµåÂÖ•ÂêëÈáèÁöÑËÆ°ÁÆóÂíåÂ≠òÂÇ®\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "#ÂØºÂÖ•Â∞ÜÊñáÊú¨ÂµåÂÖ•ÂêëÈáèÂ≠òÂÇ®Âà∞ÂêëÈáèÂ∫ìÁßçÔºå‰ª•‰æøËøõË°åÊñáÊú¨Ê£ÄÁ¥¢ÂíåÁõ∏‰ººÂ∫¶ÁöÑËÆ°ÁÆó\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores import Chroma\n",
    "#ÂØºÂÖ•ÊñáÊ°£ÂØπË±°ÔºåÂåÖÂê´‰∫ÜÊñáÊ°£ÁöÑÂêçÁß∞Âíå‰ΩúËÄÖÊëòË¶ÅÂÜÖÂÆπÁ≠â‰ø°ÊÅØ\n",
    "from langchain.docstore.document import Document\n",
    "#ÂØºÂÖ•Ê®°ÊùøÂàõÂª∫Â∫ìÔºåË°®Á§∫ÈóÆÁ≠îÊ®°ÊùøÔºåÂåÖÂê´ÈóÆÈ¢òÁ≠îÊ°àÊèêÁ§∫Á≠â‰ø°ÊÅØÊñπ‰æøËøõË°åÈóÆÁ≠î\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Âä†ËΩΩÊñáÊú¨Êï∞ÊçÆÔºåÂΩìÁÑ∂Ëøô‰∏ÄÊ≠•ÂÆåÂÖ®ÂèØ‰ª•Ë∞ÉÁî®ÂØπÂ∫îÁöÑloaderÂÆåÊàêÔºåÁ§∫‰æãÂ¶Ç‰∏ãÁöÑÊ≥®ÈáäÈÉ®ÂàÜÔºö\n",
    "# from langchain.document_loaders import TextLoader\n",
    "# loader = TextLoader(\"./state_of_the_union.txt\")\n",
    "with open(\"./state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "#ÂàõÂª∫‰∏Ä‰∏™charactertextspliterÂØπË±°ÔºåËøô‰∏™ÂØπË±°Áî®‰∫éÂ∞ÜÊñáÊ°£ÂàáÂàÜÊàêÂõ∫ÂÆöÂ§ßÂ∞èÁöÑÊñáÊú¨ÂùóÔºåËøôÈáåÊòØÁî®‰∏Ä‰∏™ÊñáÊú¨ÂùóÂ§ßÂ∞è‰∏∫1000Â≠óÁ¨¶‰∏≤ÁöÑÂàáÂàÜÂô®ÔºåÂπ∂‰∏î‰∏çÂÖÅËÆ∏ÊñáÊú¨Âùó‰πãÈó¥ÊúâÈáçÂè†ÁöÑÈÉ®ÂàÜ\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "#ÊñáÊú¨ÂàáÂàÜÂô®ÂØπË±°ÁöÑsplit_documentsÊñπÊ≥ïÂ∞ÜÊñáÊ°£Êï∞ÊçÆÂàÜÂâ≤ÊàêËã•Âπ≤‰∏™ÊñáÊú¨ÔºåËøîÂõû‰∏Ä‰∏™ÊñáÊú¨ÂùóÂàóË°®ÔºåÂπ∂Â∞ÜÁªìÊûú‰øùÂ≠òÂ≠òÂÇ®Âà∞textsÂèòÈáè‰∏≠\n",
    "texts = text_splitter.split_text(state_of_the_union)\n",
    "\n",
    "#ÂàõÂª∫embeddingÂØπË±°ÔºåËÆ°ÁÆóÊñáÊú¨Êï∞ÊçÆÁöÑËØçÂêëÈáèÔºåËøô‰∏™ÂØπË±°‰ΩøÁî®OpenaiÁöÑgpt-3ËøõË°åËÆ°ÁÆóÔºåÂèØ‰ª•Â∞Ü‰∏Ä‰∏™ÊñáÊú¨Â≠óÁ¨¶‰∏≤Êò†Â∞Ñ‰∏∫‰∏Ä‰∏™768Áª¥Â∫¶ÁöÑËØçÂêëÈáè\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "#‰ΩøÁî®chromaÁ±ªÁöÑfrom_documentsÊñπÊ≥ïÔºåÂ∞ÜÊñáÊú¨ÂùóÂàóË°®ÂíåËØçÂêëÈáèÂØπË±°‰Ωú‰∏∫ÂèÇÊï∞‰º†ÂÖ•ÔºåÁîüÊàê‰∏Ä‰∏™chromaÂØπË±°ÔºåchromaÂØπË±°ÂèØ‰ª•Áî®‰∫éÊêúÁ¥¢ÊñáÊú¨Âùó‰∏≠ÁöÑÁõ∏‰ººÊñáÊú¨‰ø°ÊÅØÔºåÂèØ‰ª•Áî®‰∫éÊñáÊú¨Áõ∏‰ººÂ∫¶ÁöÑËÆ°ÁÆóÂíåÊñáÊú¨ÂåπÈÖçÁöÑ‰ªªÂä°„ÄÇ\n",
    "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÂÆö‰πâÊàë‰ª¨ÁöÑÈóÆÈ¢ò\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "#Ë∞ÉÁî®docsearchÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÊêúÁ¥¢ÊñπÂºèÂØπÈóÆÈ¢òËøõË°åÊ£ÄÁ¥¢\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÂØºÂÖ•ÈóÆÁ≠îÊ®°ÂûãÁöÑlangchain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "#‰ΩøÁî®openaiÊ®°ÂûãÊù•ÁîüÊàêÊñáÊú¨ÁöÑÂµåÂÖ•ÂêëÈáè\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \" The president thanked Justice Breyer for his service and mentioned that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to continue Justice Breyer's legacy of excellence.\\nSOURCES: 31-pl\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ÊûÑÂª∫‰∏Ä‰∏™ÈóÆÁ≠îÊ®°ÂûãchainÔºåÊääÊ®°ÂûãÂèÇÊï∞‰º†ÂÖ•ÈáåÈù¢\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "#ËøêË°åchainÊ®°ÂûãÔºå‰ΩøÁî®docs‰Ωú‰∏∫ËæìÂÖ•ÊñáÊ°£ÁöÑÂàóË°®Ôºåquery‰Ωú‰∏∫ÈóÆÈ¢òÔºå‰ªéËÄåËøîÂõûÊúÄÁªàÁöÑÈóÆÈ¢òÁ≠îÊ°à\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': '\\nÁ∏ΩÁµ±Ê≤íÊúâÂ∞çÂè∏Ê≥ïÂ§ßÊ≥ïÂÆòÂ∏ÉÈõ∑ËÄ∂ÁôºË°®Ë©ïË´ñ„ÄÇ\\nSOURCES: 31, 32, 34'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "ALWAYS return a \"SOURCES\" part in your answer.\n",
    "Respond in Chinese.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "FINAL ANSWER IN ITALIAN:\"\"\"\n",
    "#ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™PromptTemplateÁ±ªÔºåËØ•Á±ªÁî®‰∫éÂ∞ÜÊ®°Êùø(template)‰∏éËæìÂÖ•ÂèòÈáè(input_variables)ÁªëÂÆöËµ∑Êù•„ÄÇ\n",
    "#Ê®°ÊùøÂåÖÊã¨‰∫Ü‰∏§‰∏™ËæìÂÖ•ÂèòÈáèÔºö\"summaries\"Âíå\"question\"„ÄÇ\n",
    "PROMPT = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
    "#Âä†ËΩΩ‰∏Ä‰∏™QA with SourcesÈìæÔºåËØ•Èìæ‰ΩøÁî®OpenAI‰Ωú‰∏∫ÂÖ∂ËØ≠Ë®ÄÊ®°ÂûãÔºåÂπ∂‰ΩøÁî®PromptTemplateÁ±ªÊù•ÁîüÊàêÂõûÁ≠îÈóÆÈ¢òÁöÑÊèêÁ§∫\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\", prompt=PROMPT)\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "#‰ΩøÁî®chain()ÊñπÊ≥ïÂØπÁªôÂÆöÁöÑÊñáÊ°£(docs)ÂíåÈóÆÈ¢ò(query)ËøõË°åÊü•ËØ¢ÔºåÂπ∂ËøîÂõûÂè™ÂåÖÂê´ËæìÂá∫ÁªìÊûúÁöÑÂ≠óÂÖ∏„ÄÇ\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BabyAGI with Tools\n",
    "\n",
    "<img src=\"./aa.png\"/>\n",
    "\n",
    "BabyAGI ÊòØ‰∏ÄÁßçËá™‰∏ª‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÔºåÂèØ‰ª•Ê†πÊçÆÁªôÂÆöÁõÆÊ†áÁîüÊàêÂπ∂ÂÅáË£ÖÊâßË°å‰ªªÂä°„ÄÇÔºàËøô‰∏™ÂäüËÉΩÊúâÊ≤°ÊúâÁÜüÊÇâÔºüÂÖ∂ÂÆûÊúÄËøëÂ§ßÁÅ´ÁöÑAutoGPTÂ∞±ÊòØÂü∫‰∫éÊ≠§ËøõË°åÁöÑËÆæËÆ°Ôºâ\n",
    "\n",
    "Êàë‰ª¨ÈÄöËøáËøô‰∏™Ê°à‰æãÂ∞ÜÂ∏ÆÂä©ÊÇ®‰∫ÜËß£ÂàõÂª∫Ëá™Â∑±ÁöÑÈÄíÂΩí‰ª£ÁêÜÁöÑÁªÑ‰ª∂„ÄÇ\n",
    "\n",
    "Â∞ΩÁÆ° BabyAGI ‰ΩøÁî®ÁâπÂÆöÁöÑÂêëÈáèÂ≠òÂÇ®/Ê®°ÂûãÊèê‰æõÁ®ãÂ∫èÔºàPinecone„ÄÅOpenAIÔºâÔºå‰ΩÜ‰ΩøÁî® LangChain ÂÆûÁé∞ÂÆÉÁöÑÂ•ΩÂ§Ñ‰πã‰∏ÄÊòØÊÇ®ÂèØ‰ª•ËΩªÊùæÂú∞Â∞ÜÂÆÉ‰ª¨Êç¢Êàê‰∏çÂêåÁöÑÈÄâÈ°π„ÄÇÂú®Ê≠§ÂÆûÁé∞‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî® FAISS vectorstoreÔºàÂõ†‰∏∫ÂÆÉÂú®Êú¨Âú∞ËøêË°å‰∏îÂÖçË¥πÔºâ„ÄÇ\n",
    "\n",
    "ÂÖ≥‰∫éBabyAGIÁöÑËØ¶ÁªÜËØ¥ÊòéÂèØ‰ª•[ÁÇπÂáªÊ≠§Â§ÑËÆøÈóÆ](https://github.com/yoheinakajima/babyagi)„ÄÇ\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÈÇ£‰πàÊàë‰ª¨Âú®Ëøô‰∏™Ê°à‰æãÂºÄÂßã‰πãÂâçÈ¶ñÂÖàÂæóÁü•ÈÅì‰ªÄ‰πàÊòØBabyAGIÂØπÂêßÔºü‰∏ãÈù¢ÊòØ‰∏Ä‰∏™BabyAGIÁöÑÁî®Êà∑Êìç‰ΩúÊåáÂçóÔºåÊàë‰ª¨ÁÜüÊÇâËøô‰∏™‰πãÂêéÂÜçËøõ‰∏ÄÊ≠•Áúã‰∏äÈù¢Áõ∏ÂÖ≥ÁöÑ‰ª£Á†ÅÊ°à‰æã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ËÆæÁΩÆHTTP‰ª£ÁêÜ\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:port'\n",
    "# ËÆæÁΩÆHTTPS‰ª£ÁêÜ\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:port'\n",
    "# openaiÁöÑkey\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your openai key like :sk-xxxxxxxxxxxxxxxx\"\n",
    "#Ë∞∑Ê≠åÊêúÁ¥¢apiÁöÑkey,‰ªÖÂú®agent‰∏≠‰ΩøÁî®\n",
    "os.environ['SERPAPI_API_KEY']='your search API KEY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#dequeÂèØ‰ª•‰ªéÈòüÂàó‰∏§Á´ØÊâßË°åÂø´ÈÄüÁöÑÊ∑ªÂä†ÂíåÂºπÂá∫Êìç‰Ωú\n",
    "from collections import deque\n",
    "#Á±ªÂûãÊèêÁ§∫ÂäüËÉΩÔºåÂèØ‰ª•ËøõË°åÁ±ªÂûãÊ≥®ÈáäÂíåÁ±ªÂûãÊ£ÄÊü•\n",
    "from typing import Dict, List, Optional, Any\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.base import Chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËøûÊé•Âà∞Áü¢ÈáèÂ≠òÂÇ®Â∫ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ëøô‰∏™Á±ªÂèØ‰ª•Áî®‰∫éÂü∫‰∫éÂêëÈáèÂ≠òÂÇ®Â∫ìÁ™íÊÅØÊÑüËøë‰ººÊêúÁ¥¢ÁöÑÁ±ªÔºåÁî±metaÂºÄÂèëÁöÑÂºÇÁßçÈ™®È´òÊïàÁöÑËøë‰ººÊúÄËøëÊêúÁ¥¢Â∫ìÔºåÂèØ‰ª•Â§ÑÁêÜÈ´òÁª¥ÂêëÈáèÊï∞ÊçÆ\n",
    "from langchain.vectorstores import FAISS\n",
    "#Ëøô‰∏™Á±ªÊòØ‰∏Ä‰∏™Áî®‰∫éÂú®ÂÜÖÂ≠ò‰∏≠Â≠òÂÇ®ÊñáÊú¨ÊñáÊ°£ÁöÑÁ±ªÔºåÊèê‰æõ‰∫ÜÊ∑ªÂä†„ÄÅÊ£ÄÁ¥¢ÂíåÂà†Èô§ÊñáÊ°£ÁöÑÊñπÊ≥ïÔºåÊòØ‰∏Ä‰∏™ÁÆÄÂçïÊúâÁî®ÁöÑÊñáÊ°£Â≠òÂÇ®Ëß£ÂÜ≥ÊñπÊ°à\n",
    "from langchain.docstore import InMemoryDocstore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â¶ÇÊûúÊ≤°ÊúâÂÆâË£ÖfaissÂ∫ìÔºåËØ∑ÂÖÅËÆ∏‰∏ãÈù¢ÁöÑ‰ª£Á†ÅÔºåÂê¶ÂàôË∑≥Ëøá‰∏ãÈù¢pipËøô‰∏ÄÊ≠•Âç≥ÂèØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/yfcao/Anaconda/anaconda3/envs/egovlp/lib/python3.8/site-packages (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your embedding model:text-embedding-ada-002\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "# Initialize the vectorstore as emptyÔºåÈÄâÊã©ÁöÑvectorstoreÊòØfaiss\n",
    "import faiss\n",
    "#ÊñáÊú¨emmbeddingÁöÑÁª¥Êï∞ÔºåÊØè‰∏™ÊñáÊú¨ÂµåÂÖ•ÂêëÈáè‰∏≠ÂåÖÂê´ÁöÑÊï∞Â≠óÊï∞Èáè\n",
    "embedding_size = 1536\n",
    "#ÂêëÈáèÁ©∫Èó¥‰∏≠ÊâßË°åËøë‰ººÊúÄËøëÊêúÁ¥¢Ôºå‰ΩøÁî®ÁöÑÊòØL2Ë∑ùÁ¶ªË°°ÈáèÂêëÈáè‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "#embeddings_model.embed_queryÁî®‰∫éÂ∞ÜÊñáÊú¨Êü•ËØ¢ËΩ¨Êç¢‰∏∫ÂµåÂÖ•ÂêëÈáèÔºåInMemoryDocstoreÁî®‰∫éÂú®ÂÜÖÂ≠ò‰∏≠Â≠òÂÇ®ÊñáÊ°£ÔºåÊúÄÁªàÂ∞ÜÂÖ∂Â≠òÂú®vectorstore‰∏≠\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂÆö‰πâÈìæ\n",
    "\n",
    "BabyAGI ‰æùËµñ‰∫é‰∏â‰∏™ LLM ÈìæÔºö\n",
    "\n",
    "‰ªªÂä°ÂàõÂª∫ÈìæÈÄâÊã©Êñ∞‰ªªÂä°Ê∑ªÂä†Âà∞ÂàóË°®\n",
    "\n",
    "‰ªªÂä°‰ºòÂÖàÁ∫ßÈìæÔºåÁî®‰∫éÈáçÊñ∞Á°ÆÂÆö‰ªªÂä°ÁöÑ‰ºòÂÖàÁ∫ß\n",
    "\n",
    "ÊâßË°å‰ªªÂä°ÁöÑÊâßË°åÈìæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫TaskCreationChainÁöÑÁ±ªÔºåÂÆÉÊòØLLMChainÁ±ªÁöÑÂ≠êÁ±ª„ÄÇËØ•Á±ªÁöÑÁõÆÁöÑÊòØÁîüÊàê‰ªªÂä°ÔºåÂπ∂ËøîÂõûllmchainÂØπË±°„ÄÇ\n",
    "Âú®Á±ªÂÆö‰πâ‰∏≠ÔºåÊúâ‰∏Ä‰∏™ÈùôÊÄÅÊñπÊ≥ïfrom_llm(),ÂÆÉÊé•Âèó‰∏Ä‰∏™BaseLLMÂØπË±°Âíå‰∏Ä‰∏™Â∏ÉÂ∞îÁ±ªÂûãÁöÑverboseÂèÇÊï∞‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™LLMChainÂØπË±°„ÄÇ\n",
    "ËØ•ÊñπÊ≥ï‰ΩøÁî®‰∫Ü‰∏Ä‰∏™task_creation_templateÂ≠óÁ¨¶‰∏≤Êù•ÁîüÊàê‰∏Ä‰∏™ÊèêÁ§∫(prompt),ËØ•ÊèêÁ§∫Áî®‰∫éÊåáÂØºAIÂÆåÊàê‰ªªÂä°ÁöÑÂàõÂª∫„ÄÇÊé•‰∏ãÊù•ÔºåËØ•‰ª£Á†ÅËøòÂÆö\n",
    "‰πâ‰∫Ü‰∏Ä‰∏™PromptTemplateÁ±ªÔºåËØ•Á±ªÁî®‰∫éÂ∞ÜÊ®°Êùø(template)‰∏éËæìÂÖ•ÂèòÈáè(input_variables)ÁªëÂÆöËµ∑Êù•„ÄÇÂú®Ëøô‰∏™‰æãÂ≠ê‰∏≠ÔºåÊ®°ÊùøÂåÖÊã¨‰∫Ü‰∫î‰∏™\n",
    "ËæìÂÖ•ÂèòÈáèÔºö\"result\"„ÄÅ\"task_description\"„ÄÅ\"incomplete_tasks\"„ÄÅ\"objective\" Âíå \"previous_task_result\"„ÄÇÊúÄÂêéÔºå\n",
    "ÂÆÉ‰ΩøÁî®cls()ÊñπÊ≥ïÂàõÂª∫‰∏Ä‰∏™LLMChainÂØπË±°ÔºåÂπ∂Â∞ÜÂÖ∂‰øùÂ≠òÂú®task_creation_chainÂèòÈáè‰∏≠„ÄÇ\n",
    "\"\"\"\n",
    "class TaskCreationChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Get the response parser.\n",
    "        ‰ªîÁªÜÁúãÂÖ≥‰∫éÊ®°ÁâàÁöÑËÆæËÆ°ÈÉ®ÂàÜÔºåÊÄé‰πàËÆæËÆ°‰πüÊØîËæÉÈáçË¶ÅÔºöÊØè‰∏ÄÊ¨°ËÆæÂÆöÁõÆÊ†áÔºå‰πüË¶ÅÁªôÂá∫ÂÆåÊàêËøô‰∏™ÁõÆÊ†áÁöÑÁªìÊûúÔºåËøòÊúâ\n",
    "        Ëøô‰∏™ÁªìÊûúÂØπÂ∫îÁöÑ‰ªªÂä°ÊèèËø∞‰ø°ÊÅØ‰πü‰ºöÁªôÂà∞ÔºåÊ≠§Êó∂ËøòÊ≤°ÊúâÂÆåÊï¥ÁöÑ‰ªªÂä°Â∞±Âü∫‰∫é‰∏äÈù¢ÁªôÂà∞ÁöÑÁªìÊûúÁªßÁª≠ÁΩóÂàó‰ªªÂä°Ê∏ÖÂçï„ÄÇ\n",
    "        Âç≥ÔºöÂõõÈ°πÂèÇÊï∞‚Äî‚Äî\n",
    "        1. objective ÁõÆÊ†á\n",
    "        2. result Ââç‰∏Ä‰∏™‰ªªÂä°ÁªìÊûú\n",
    "        3. task_description ‰ªªÂä°ÊèèËø∞\n",
    "        4. incomplete_tasks ÂΩìÂâç‰ªªÂä°ÂàóË°®\n",
    "        \"\"\"\n",
    "        task_creation_template = (\n",
    "            \"You are an task creation AI that uses the result of an execution agent\"\n",
    "            \" to create new tasks with the following objective: {objective},\"\n",
    "            \" The last completed task has the result: {result}.\"\n",
    "            \" This result was based on this task description: {task_description}.\"\n",
    "            \" These are incomplete tasks: {incomplete_tasks}.\"\n",
    "            \" Based on the result, create new tasks to be completed\"\n",
    "            \" by the AI system that do not overlap with incomplete tasks.\"\n",
    "            \" Return the tasks as an array.\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_creation_template,\n",
    "            input_variables=[\n",
    "                \"result\",\n",
    "                \"task_description\",\n",
    "                \"incomplete_tasks\",\n",
    "                \"objective\",\n",
    "            ],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫TaskPrioritizationChainÁöÑÁ±ªÔºåÂÆÉÊòØLLMChainÁ±ªÁöÑÂ≠êÁ±ª„ÄÇËØ•Á±ªÁöÑÁõÆÁöÑÊòØÁ°ÆÂÆö‰ªªÂä°ÁöÑ‰ºòÂÖàÁ∫ßÔºåÂπ∂ËøîÂõûllmchainÂØπË±°„ÄÇ\n",
    "Âú®Á±ªÂÆö‰πâ‰∏≠ÔºåÊúâ‰∏Ä‰∏™ÈùôÊÄÅÊñπÊ≥ïfrom_llm(),ÂÆÉÊé•Âèó‰∏Ä‰∏™BaseLLMÂØπË±°Âíå‰∏Ä‰∏™Â∏ÉÂ∞îÁ±ªÂûãÁöÑverboseÂèÇÊï∞‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™LLMChainÂØπË±°„ÄÇËØ•ÊñπÊ≥ï\n",
    "‰ΩøÁî®‰∫Ü‰∏Ä‰∏™task_prioritization_templateÂ≠óÁ¨¶‰∏≤Êù•ÁîüÊàê‰∏Ä‰∏™ÊèêÁ§∫(prompt),ËØ•ÊèêÁ§∫Áî®‰∫éÊåáÂØºAIÂÆåÊàê‰ªªÂä°ÁöÑ‰ºòÂÖàÁ∫ßÊéíÂ∫è„ÄÇÊé•‰∏ãÊù•ÔºåÂèàÂÆö‰πâ‰∫Ü‰∏Ä‰∏™\n",
    "PromptTemplateÁ±ªÔºåËØ•Á±ªÁî®‰∫éÂ∞ÜÊ®°Êùø(template)‰∏éËæìÂÖ•ÂèòÈáè(input_variables)ÁªëÂÆöËµ∑Êù•„ÄÇÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞Ê®°ÊùøÂåÖÊã¨‰∫Ü‰∏â‰∏™ËæìÂÖ•ÂèòÈáèÔºö\n",
    "\"task_names\"„ÄÅ\"next_task_id\"Âíå\"objective\"„ÄÇÊúÄÂêéÔºåÂÆÉ‰ΩøÁî®cls()ÊñπÊ≥ïÂàõÂª∫‰∏Ä‰∏™LLMChainÂØπË±°ÔºåÂπ∂Â∞ÜÂÖ∂‰øùÂ≠òÂú®task_prioritization_chain\n",
    "Ëøô‰∏™ÂèòÈáè‰∏≠„ÄÇ\n",
    "\"\"\"\n",
    "class TaskPrioritizationChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        task_prioritization_template = (\n",
    "            \"You are an task prioritization AI tasked with cleaning the formatting of and reprioritizing\"\n",
    "            \" the following tasks: {task_names}.\"\n",
    "            \" Consider the ultimate objective of your team: {objective}.\"\n",
    "            \" Do not remove any tasks. Return the result as a numbered list, like:\"\n",
    "            \" #. First task\"\n",
    "            \" #. Second task\"\n",
    "            \" Start the task list with number {next_task_id}.\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_prioritization_template,\n",
    "            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ExecutionChainÁöÑÁ±ªÔºåÂÆÉÊòØLLMChainÁ±ªÁöÑÂ≠êÁ±ª„ÄÇËØ•Á±ªÁöÑÁõÆÁöÑÊòØÊâßË°å‰ªªÂä°ÔºåÂπ∂ËøîÂõûllmchainÂØπË±°„ÄÇÂú®Á±ªÂÆö‰πâ\n",
    "‰∏≠ÔºåÊúâ‰∏Ä‰∏™ÈùôÊÄÅÊñπÊ≥ïfrom_llm(),ÂÆÉÊé•Âèó‰∏Ä‰∏™BaseLLMÂØπË±°Âíå‰∏Ä‰∏™Â∏ÉÂ∞îÁ±ªÂûãÁöÑverboseÂèÇÊï∞‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™LLMChainÂØπË±°„ÄÇËØ•ÊñπÊ≥ï\n",
    "‰ΩøÁî®‰∫Ü‰∏Ä‰∏™execution_templateÂ≠óÁ¨¶‰∏≤Êù•ÁîüÊàê‰∏Ä‰∏™ÊèêÁ§∫(prompt),ËØ•ÊèêÁ§∫Áî®‰∫éÊåáÂØºAIÂÆåÊàê‰ªªÂä°ÁöÑÊâßË°å„ÄÇÊé•‰∏ãÊù•ÔºåËØ•‰ª£Á†ÅËøòÂÆö‰πâ‰∫Ü‰∏Ä‰∏™\n",
    "PromptTemplateÁ±ªÔºåËØ•Á±ªÁî®‰∫éÂ∞ÜÊ®°Êùø(template)‰∏éËæìÂÖ•ÂèòÈáè(input_variables)ÁªëÂÆöËµ∑Êù•„ÄÇÂú®Ëøô‰∏™‰æãÂ≠ê‰∏≠ÔºåÊ®°ÊùøÂåÖÊã¨‰∫Ü‰∏â‰∏™ËæìÂÖ•ÂèòÈáèÔºö\n",
    "\"objective\"„ÄÅ\"context\" Âíå \"task\"„ÄÇÊúÄÂêéÔºåÂÆÉ‰ΩøÁî®cls()ÊñπÊ≥ïÂàõÂª∫‰∏Ä‰∏™LLMChainÂØπË±°ÔºåÂπ∂Â∞ÜÂÖ∂‰øùÂ≠òÂú®execution_chainÂèòÈáè‰∏≠„ÄÇ\n",
    "\"\"\"\n",
    "class ExecutionChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Get the response parser.\"\"\"\n",
    "        execution_template = (\n",
    "            \"You are an AI who performs one task based on the following objective: {objective}.\"\n",
    "            \" Take into account these previously completed tasks: {context}.\"\n",
    "            \" Your task: {task}.\"\n",
    "            \" Response:\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=execution_template,\n",
    "            input_variables=[\"objective\", \"context\", \"task\"],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂÆö‰πâ BabyAGI ÊéßÂà∂Âô®\n",
    "\n",
    "BabyAGI Â∞Ü‰∏äÈù¢ÂÆö‰πâÁöÑÈìæÁªÑÂêàÊàê‰∏Ä‰∏™ÔºàÂèØËÉΩÔºâÊó†ÈôêÂæ™ÁéØÁöÑÈó≠ÁéØËøêË°åËøáÁ®ã„ÄÇ\n",
    "\n",
    "Ëøô‰∏™ËøáÁ®ãÂ¶Ç‰∏ãÔºö\n",
    "1. ‰ªé‰ªªÂä°ÂàóË°®‰∏≠ÊèêÂèñÁ¨¨‰∏Ä‰∏™‰ªªÂä°.\n",
    "2. Â∞Ü‰ªªÂä°ÂèëÈÄÅÁªôÊâßË°å‰ª£ÁêÜ, ËØ•‰ª£ÁêÜ‰ΩøÁî® OpenAI API Ê†πÊçÆ‰∏ä‰∏ãÊñáÂÆåÊàê‰ªªÂä°.\n",
    "3. Ê∂¶Ëâ≤ÁªìÊûúÂπ∂Â∞ÜÂÖ∂Â≠òÂÇ®.\n",
    "4. Âü∫‰∫éÁõÆÊ†áÂíåÂâç‰∏Ä‰∏™‰ªªÂä°ÁöÑÁªìÊûúÂàõÂª∫Êñ∞‰ªªÂä°, Âπ∂Ê†πÊçÆ‰ºòÂÖàÁ∫ßÂØπ‰ªªÂä°ÂàóË°®ËøõË°åÊéíÂ∫è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËØ•ÊñπÊ≥ïËøîÂõû‰∏Ä‰∏™Â≠óÂÖ∏ÂàóË°®Ôºå‰º†ÂÖ•ÁöÑÂèÇÊï∞ÂåÖÊã¨LLMchainÔºåresultÔºå‰ªªÂä°ÂàóË°®ÁöÑtask_listÔºåË°®Á§∫ÁõÆÊ†áÁöÑobjectiveÂ≠óÁ¨¶‰∏≤Á±ªÂûã,\n",
    "ËøôÈáåÁî®Âà∞ÁöÑ‰∏âÈìæ‰∏≠ÁöÑÁ¨¨‰∏ÄÈìætask_creation_chianÂéªÊûÑÂª∫‰ªªÂä°ÂàóË°®ÔºåÁÑ∂ÂêéÂú®chain.runÁöÑÊñπÊ≥ï‰∏≠Â∞ÜÂèòÈáèÂùá‰ª•input_variables\n",
    "ÁöÑÂΩ¢Âºè‰º†ÂÖ•Ê®°Áâà‰∏≠ÂÆåÊàêË°•ÂÖ®ÔºåËÄåÂìçÂ∫îÁöÑÁªìÊûú‰ª•'\\n'ÂàÜÂâ≤ÂºÄÊù•Âπ∂ÂÇ®Â≠òÂà∞new_tasksÂèòÈáè‰∏≠ÔºåÊúÄÁªàget_next_taskÊñπÊ≥ïËøîÂõû‰∏Ä‰∏™Â∞ÜÂ≠óÂÖ∏ÂåÖ\n",
    "Ë£ÖËµ∑Êù•ÁöÑÂàóË°®\n",
    "\"\"\"\n",
    "def get_next_task(\n",
    "    task_creation_chain: LLMChain,\n",
    "    result: Dict,\n",
    "    task_description: str,\n",
    "    task_list: List[str],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Get the next task.\"\"\"\n",
    "    incomplete_tasks = \", \".join(task_list)\n",
    "\n",
    "    response = task_creation_chain.run(\n",
    "        result=result,\n",
    "        task_description=task_description,\n",
    "        incomplete_tasks=incomplete_tasks,\n",
    "        objective=objective,\n",
    "    )\n",
    "    #ÊúÄÁªàÁöÑÂìçÂ∫îÁªìÊûúÊòØarrayÁªÑÊàêÁöÑtaskÔºåÁî®Êç¢Ë°åÁ¨¶ËøõË°åÂàÜÂâ≤\n",
    "    new_tasks = response.split(\"\\n\")\n",
    "    #ËøîÂõû‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÊñ∞‰ªªÂä°‰ø°ÊÅØÁöÑÂàóË°®ÔºåÂÖ∂‰∏≠ÊØè‰∏™‰ªªÂä°‰ø°ÊÅØÈÉΩÁî±‰∏Ä‰∏™\"task_name\"ÈîÆÁªÑÊàê„ÄÇ\n",
    "    return [{\"task_name\": task_name} for task_name in new_tasks if task_name.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫prioritize_tasksÁöÑÂáΩÊï∞ÔºåÂÆÉÊé•ÂèóÂõõ‰∏™ÂèÇÊï∞Ôºötask_prioritization_chain„ÄÅthis_task_id„ÄÅtask_listÂíåobjective„ÄÇ\n",
    "ËØ•ÂáΩÊï∞ÁöÑÁõÆÁöÑÊòØÊ†πÊçÆÂΩìÂâç‰ªªÂä°ÂíåÁõÆÊ†áËÆæÂÆöÔºåÂØπ‰ªªÂä°ÂàóË°®ËøõË°å‰ºòÂÖàÁ∫ßÊéíÂ∫èÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™ÊåâÁÖß‰ºòÂÖàÁ∫ßÊéíÂ∫èÁöÑ‰ªªÂä°ÂàóË°®(List[Dict])„ÄÇÂú®ÂáΩÊï∞‰∏≠ÔºåÈ¶ñÂÖàÂ∞Ütask_list\n",
    "‰∏≠ÁöÑÊØè‰∏™‰ªªÂä°Â≠óÂÖ∏(t)ÁöÑ‰ªªÂä°ÂêçÁß∞(task_name)ÊèêÂèñÂá∫Êù•ÔºåÁîüÊàê‰∏Ä‰∏™‰ªªÂä°ÂêçÁß∞ÂàóË°®(task_names)„ÄÇÁÑ∂ÂêéÂ∞ÜÂΩìÂâçÁöÑ‰ªªÂä°ID(this_task_id)ËΩ¨Êç¢ÊàêÊï¥Êï∞ÔºåÂπ∂Âä†1,\n",
    "ÁîüÊàê‰∏ã‰∏Ä‰∏™‰ªªÂä°ÁöÑID(next_task_id)„ÄÇ\n",
    "Êé•ÁùÄÔºå‰ΩøÁî®‰∏Ä‰∏™‰∏âÈìæ‰∏≠ÁöÑ‰ªªÂä°‰ºòÂÖàÁ∫ßÊéíÂ∫èÈìæÂéªÂ∞Ütask_names„ÄÅnext_task_idÂíåobjective‰º†ÂÖ•ÂÖ∂‰∏≠Ë°•ÂÖ®input_variables„ÄÇ\n",
    "Êé•ÁùÄ‰ΩøÁî®Êç¢Ë°åÁ¨¶ÂàÜÂâ≤ÂìçÂ∫îÂÜÖÂÆπÂ∞ÜÂÖ∂Â≠òÂÇ®Âà∞new_tasksÂ≠óÁ¨¶‰∏≤ÂàóË°®‰∏≠„ÄÇÊé•‰∏ãÊù•ÔºåËØ•‰ª£Á†ÅÂàõÂª∫‰∏Ä‰∏™Á©∫ÁöÑÂàóË°®Áî®‰∫é‰øùÂ≠òÊåâÁÖß‰ºòÂÖàÁ∫ßÊéíÂ∫è‰πãÂêéÁöÑ‰ªªÂä°ÂàóË°®(prioritized_task_list)„ÄÇ\n",
    "ÁÑ∂ÂêéÔºå‰ΩøÁî®forÂæ™ÁéØÈÅçÂéÜnew_tasksÂàóË°®‰∏≠ÁöÑÊØè‰∏™‰ªªÂä°Â≠óÁ¨¶‰∏≤(task_string),Â¶ÇÊûúËøô‰∏™Â≠óÁ¨¶‰∏≤ÊòØÁ©∫ÁöÑÂ≠óÁ¨¶‰∏≤ÊàñÂè™ÂåÖÂê´Á©∫Ê†ºÂ∞±Ë∑≥ËøáËøôÊ¨°Âæ™ÁéØ„ÄÇ\n",
    "Êé•ÁùÄÔºå‰ΩøÁî®strip()ÊñπÊ≥ïÂéªÈô§È¶ñ‰ΩçÁ©∫Ê†ºÔºåÂº∫Âà∂Â∞Ü‰ªªÂä°Â≠óÁ¨¶‰∏≤ÂàÜÊàê‰∏§ÈÉ®ÂàÜÔºåÂàÜÂâ≤Á¨¶Âè∑ÊòØ‚Äú.‚Äù„ÄÇÂ¶ÇÊûúÂàÜÂâ≤ÂêéÂæóÂà∞ÁöÑÂàóË°®ÈïøÂ∫¶Á≠â‰∫é2,Âç≥ÊàêÂäüÊãÜÂàÜÂá∫task_idÂíåtask_name,\n",
    "ÂàôÂ∞ÜÂÆÉ‰ª¨Ê∑ªÂä†Âà∞prioritized_task_listÂàóË°®‰∏≠„ÄÇÊúÄÂêéÔºåËØ•ÂáΩÊï∞ËøîÂõûprioritized_task_listÂàóË°®„ÄÇ\n",
    "\"\"\"\n",
    "def prioritize_tasks(\n",
    "    task_prioritization_chain: LLMChain,\n",
    "    this_task_id: int,\n",
    "    task_list: List[Dict],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Prioritize tasks.\"\"\"\n",
    "    #Â∞Ü‰ªªÂä°ÂàóË°®‰∏≠ÁöÑÊØè‰∏™‰ªªÂä°Â≠óÂÖ∏ÔºàtÔºâÁöÑ‰ªªÂä°ÂêçÁß∞task_nameÊèêÂèñÂá∫Êù•ÔºåÁîüÊàê‰∏Ä‰∏™‰ªªÂä°ÂêçÁß∞ÂàóË°®task_names\n",
    "    task_names = [t[\"task_name\"] for t in task_list]\n",
    "    #Â∞ÜÂΩìÂâçÁöÑ‰ªªÂä°IDÔºàthis_task_idÔºâËΩ¨Êç¢ÊàêÊï¥Êï∞ÔºåÂπ∂Âä†1ÔºåÁîüÊàê‰∏ã‰∏Ä‰∏™‰ªªÂä°ÁöÑidÔºànext_task_idÔºâ\n",
    "    next_task_id = int(this_task_id) + 1\n",
    "    #‰ΩøÁî®‰∏Ä‰∏™‰∏âÈìæ‰∏≠ÁöÑ‰ªªÂä°‰ºòÂÖàÁ∫ßÊéíÂ∫èÈìæÂéªÂ∞Ütask_names,next_task_id,objective‰º†ÂÖ•ÂÖ∂‰∏≠Ë°•ÂÖ®input_variables\n",
    "    response = task_prioritization_chain.run(\n",
    "        task_names=task_names, next_task_id=next_task_id, objective=objective\n",
    "    )\n",
    "    #‰ΩøÁî®Êç¢Ë°åÁ¨¶ÂàÜÂâ≤ÂÜÖÂÆπÂ∞ÜÂÖ∂Â≠òÂÇ®Âà∞new_tasksÂ≠óÁ¨¶‰∏≤ÂàóË°®‰∏≠\n",
    "    new_tasks = response.split(\"\\n\")\n",
    "    #ÂàõÂª∫‰∏Ä‰∏™Á©∫ÁöÑÂàóË°®Áî®‰∫é‰øùÂ≠òÊåâÁÖß‰ºòÂÖàÁ∫ßÊéíÂ∫è‰πãÂêéÁöÑ‰ªªÂä°ÂàóË°®\n",
    "    prioritized_task_list = []\n",
    "    #\n",
    "    for task_string in new_tasks:\n",
    "        #Â¶ÇÊûúËøô‰∏™Â≠óÁ¨¶‰∏≤ÊòØÁ©∫ÁöÑÂ≠óÁ¨¶‰∏≤ÊàñÂè™ÂåÖÂê´Á©∫Ê†ºÂ∞±Ë∑≥ËøáËøôÊ¨°Âæ™ÁéØ\n",
    "        if not task_string.strip():\n",
    "            continue\n",
    "        #È¶ñÂÖàÂéªÈô§È¶ñ‰ΩçÁ©∫Ê†º‰πãÂêéÂ∞ÜÂÖ∂Âº∫Âà∂ÂàÜÊàê‰∏§ÈÉ®ÂàÜÔºåÂàÜÂâ≤Á¨¶Âè∑Â∞±ÊòØ‚Äú.‚Äù,ÂæóÂà∞ÁöÑÊòØ‰∏Ä‰∏™ÂåÖÂê´‰∏§‰∏™ÂÖÉÁ¥†ÁöÑÂàóË°®task_parts\n",
    "        task_parts = task_string.strip().split(\".\", 1)\n",
    "        #Â¶ÇÊûútask_parts ÂàóË°®ÈïøÂ∫¶Á≠â‰∫é2ÔºåÂç≥ÊàêÂäüÊãÜÂàÜÂá∫task_idÂíåtask_names\n",
    "        if len(task_parts) == 2:\n",
    "            task_id = task_parts[0].strip()\n",
    "            task_name = task_parts[1].strip()\n",
    "            prioritized_task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
    "    return prioritized_task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫_get_top_tasksÁöÑÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞Êé•Âèó‰∏â‰∏™ÂèÇÊï∞Ôºövectorstore(‰∏Ä‰∏™ÂêëÈáèÂ≠òÂÇ®Â∫ì),query(Êü•ËØ¢ËØ≠Âè•)Âíåk(Ë¶ÅËøîÂõûÁöÑÁªìÊûúÊï∞Èáè)„ÄÇ\n",
    "ËØ•ÂáΩÊï∞ÁöÑÁõÆÁöÑÊòØÊ†πÊçÆÊü•ËØ¢ËØ≠Âè•ËøîÂõû‰∏éÊü•ËØ¢ÊúÄÁõ∏ÂÖ≥ÁöÑÂâçk‰∏™ÂêëÈáèÂèäÂÖ∂ÂØπÂ∫îÁöÑ‰ªªÂä°ÂêçÁß∞„ÄÇÂáΩÊï∞È¶ñÂÖàË∞ÉÁî®vectorstoreÂØπË±°ÁöÑsimilarity_search_with_scoreÊñπÊ≥ï\n",
    "ËøõË°åÁõ∏‰ººÂ∫¶ÊêúÁ¥¢ÔºåÂπ∂Â∞ÜÁªìÊûúÂ≠òÂÇ®Âú®results‰∏≠„ÄÇÂ¶ÇÊûúÊ≤°ÊúâÊâæÂà∞‰ªª‰ΩïÂåπÈÖçÈ°πÔºåÂàôÂáΩÊï∞ËøîÂõûÁ©∫ÂàóË°®„ÄÇÂê¶ÂàôÔºåÂáΩÊï∞‰ΩøÁî®PythonÂÜÖÁΩÆÁöÑsortedÂáΩÊï∞ÂØπresults‰∏≠ÁöÑÂÖÉÁ¥†\n",
    "ÊåâÁÖßÁõ∏‰ººÊÄßÂàÜÊï∞‰ªéÂ§ßÂà∞Â∞èËøõË°åÊéíÂ∫è„ÄÇËØ•ÂáΩÊï∞‰ΩøÁî®lambdaË°®ËææÂºèÊåáÂÆöÊåâÁ¨¨‰∫å‰∏™ÂÖÉÁ¥†(Âç≥ÂàÜÊï∞)ËøõË°åÊéíÂ∫èÔºåÂπ∂‰ΩøÁî®reverse=TrueÂèÇÊï∞‰ª•ÂÄíÂ∫èÊñπÂºèÊéíÂ∫è„ÄÇÁÑ∂ÂêéÔºåÂáΩÊï∞\n",
    "Â∞ÜÊéíÂ∫èÂêéÁöÑÁªìÊûúÊãÜÂàÜ‰∏∫‰∏§‰∏™ÂÖÉÁªÑÔºåÂπ∂Â∞ÜÊØè‰∏™ÂÖÉÁªÑ‰∏≠ÁöÑtask_namesËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÊúÄÂêéÂ∞ÜËøô‰∫õÂ≠óÁ¨¶‰∏≤‰Ωú‰∏∫ÂàóË°®ËøîÂõû„ÄÇ\n",
    "\"\"\"\n",
    "def _get_top_tasks(vectorstore, query: str, k: int) -> List[str]:\n",
    "    \"\"\"Get the top k tasks based on the query.\"\"\"\n",
    "    #Áî±vectorstoreÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÂáΩÊï∞ËøõË°åËÆ°ÁÆóÔºåËøîÂõûÁöÑÊòØÊúÄÁõ∏‰ººÁöÑK‰∏™ÂêëÈáè‰ª•ÂèäÂÖ∂Áõ∏‰ººÂàÜÊï∞ÔºåÂ≠òÂÇ®Âú®results‰∏≠ÔºåËøô‰∏™ÈáåÈù¢Âπ∂Ê≤°ÊúâÊéíÂ∫è‰πãÂêéÁöÑÁªìÊûú\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    if not results:\n",
    "        return []\n",
    "    #sortedÂáΩÊï∞ÊòØÂØπresults‰∏≠ÁªìÊûúÂÖÉÁ¥†ÊåâÁÖßÁõ∏‰ººÊÄßÂàÜÊï∞‰ªéÂ§ßÂà∞Â∞èËøõË°åÊéíÂ∫èÔºåÂπ∂Â∞ÜÊéíÂ∫èÂ•ΩÁöÑÂêëÈáè‰ª•ÂèäÂàÜÊï∞ÊãÜÂàÜ‰∏∫‰∏§‰∏™ÂÖÉÁªÑÔºåÂàÜÂà´Â≠òÂÇ®Âà∞sorted_resultsÂíå_‰∏§‰∏™ÂèòÈáè‰∏≠ÔºåÂÖ∂‰∏≠ÁöÑ\n",
    "    #key=lambda xÔºöx[1]Ë°®Á§∫ÊåâÁÖßÂÖÉÁ¥†‰∏≠ÁöÑÁ¨¨‰∫å‰∏™ÂÄºÔºàÂç≥ÂàÜÊï∞ÔºâËøõË°åÊéíÂ∫èÔºåreverseË°®Á§∫ÂÄíÂ∫èÊéíÂ∫è\n",
    "    sorted_results, _ = zip(*sorted(results, key=lambda x: x[1], reverse=True))\n",
    "    #Â∞Üsorted_resultsÂàóË°®‰∏≠ÁöÑÊØè‰∏Ä‰∏™ÂêëÈáèÂØπÂ∫îÁöÑtask_namesÔºàÂ≠òÂÇ®Âú®metadata[\"task\"]‰∏≠ÔºâËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÂπ∂‰ª•ÂàóË°®ÁöÑÂΩ¢ÂºèËøîÂõû\n",
    "    return [str(item.metadata[\"task\"]) for item in sorted_results]\n",
    "\n",
    "\"\"\"\n",
    "ËøôÊÆµ‰ª£Á†ÅÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫execute_taskÁöÑÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞Êé•ÂèóÂõõ‰∏™ÂèÇÊï∞Ôºövectorstore(‰∏Ä‰∏™ÂêëÈáèÂ≠òÂÇ®Â∫ì)„ÄÅexecution_chain(ÊâßË°åÈìæÂØπË±°)„ÄÅ\n",
    "objective(ÁõÆÊ†áÂ≠óÁ¨¶‰∏≤)Âíåtask(Ë¶ÅÊâßË°åÁöÑ‰ªªÂä°Â≠óÁ¨¶‰∏≤)„ÄÇËØ•ÂáΩÊï∞ÁöÑÁõÆÁöÑÊòØÊ†πÊçÆÁªôÂÆöÁöÑÁõÆÊ†áÂíå‰ªªÂä°ÊâßË°åÊåáÂÆöÁöÑÂêëÈáèËÆ°ÁÆó„ÄÇÂáΩÊï∞È¶ñÂÖàË∞ÉÁî®_get_top_tasksÂáΩÊï∞\n",
    "Ëé∑Âèñ‰∏éÁõÆÊ†áÊúÄÁõ∏ÂÖ≥ÁöÑÂâçk‰∏™ÂêëÈáèÂèäÂÖ∂ÂØπÂ∫îÁöÑ‰ªªÂä°ÂêçÁß∞ÔºåÂπ∂Â∞ÜÁªìÊûúÂ≠òÂÇ®Âú®contextÂèòÈáè‰∏≠„ÄÇÁÑ∂ÂêéÔºåÂáΩÊï∞Ë∞ÉÁî®execution_chain.run()ÊñπÊ≥ïÔºåÂ∞ÜÁõÆÊ†á„ÄÅ‰∏ä‰∏ãÊñáÂíå\n",
    "‰ªªÂä°‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄíÁªôÂÆÉ„ÄÇÊúÄÂêéÔºåÂáΩÊï∞ËøîÂõûÊâßË°åÁªìÊûú„ÄÇ\n",
    "\"\"\"\n",
    "def execute_task(\n",
    "    vectorstore, execution_chain: LLMChain, objective: str, task: str, k: int = 5\n",
    ") -> str:\n",
    "    \"\"\"Execute a task.\"\"\"\n",
    "    context = _get_top_tasks(vectorstore, query=objective, k=k)\n",
    "    return execution_chain.run(objective=objective, context=context, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫BabyAGIÁöÑÁ±ªÔºåÁªßÊâø‰∫ÜChainÂíåBaseModelÁ±ª„ÄÇ\n",
    "BabyAGIÁ±ªÁî®‰∫éÊéßÂà∂Ê®°ÂûãÁöÑÊâßË°åÊµÅÁ®ãÔºåÂÖ∂‰∏≠ÂÆö‰πâ‰∫ÜÂ¶Ç‰∏ãÂÜÖÂÆπÔºö\n",
    "task_listÊòØ‰∏Ä‰∏™dequeÁ±ªÂûãÔºåÁî®‰∫éÂ≠òÂÇ®‰ªªÂä°ÂàóË°®Ôºõ\n",
    "task_creation_chain„ÄÅtask_prioritization_chain„ÄÅexecution_chainÊòØ‰∏âÈìæÁ±ªÂûãÁöÑÂÆû‰æãÔºåÁî®‰∫éÂàõÂª∫‰ªªÂä°„ÄÅÊéíÂ∫è‰ªªÂä°‰ª•ÂèäÊâßË°å‰ªªÂä°Ôºõ\n",
    "task_id_counterÊòØ‰∏Ä‰∏™Êï¥ÂûãÂèòÈáèÔºåÁî®‰∫éËÆ∞ÂΩï‰ªªÂä°ID;\n",
    "vectorstoreÊòØ‰∏Ä‰∏™VectorStoreÁ±ªÂûãÁöÑÂÆû‰æãÔºåÁî®‰∫éÂ≠òÂÇ®ÂêëÈáèÊï∞ÊçÆÔºõ\n",
    "max_iterationsÊòØ‰∏Ä‰∏™Êï¥ÂûãÂèòÈáèÔºåË°®Á§∫ÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞Ôºõ\n",
    "add_taskÊñπÊ≥ïÁî®‰∫éÊ∑ªÂä†‰ªªÂä°Âà∞‰ªªÂä°ÂàóË°®‰∏≠Ôºõ\n",
    "print_task_listÊñπÊ≥ïÁî®‰∫éÊâìÂç∞ÂΩìÂâçÁöÑ‰ªªÂä°ÂàóË°®Ôºõ\n",
    "print_next_taskÊñπÊ≥ïÁî®‰∫éÊâìÂç∞‰∏ã‰∏Ä‰∏™‰ªªÂä°Ôºõ\n",
    "print_task_resultÊñπÊ≥ïÁî®‰∫éÊâìÂç∞‰ªªÂä°ÊâßË°åÁªìÊûúÔºõ\n",
    "get_next_taskÊñπÊ≥ïÁî®‰∫éËé∑Âèñ‰∏ã‰∏Ä‰∏™‰ªªÂä°Ôºõ\n",
    "prioritize_tasksÊñπÊ≥ïÁî®‰∫éÈáçÊñ∞ÊéíÂ∫è‰ªªÂä°ÂàóË°®„ÄÇ\n",
    "Âú®Á±ªÂÆö‰πâ‰∏≠ËøòÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ConfigÁ±ªÔºåÁî®‰∫éÈÖçÁΩÆpydanticÂØπË±°ÔºåÂÖ∂‰∏≠arbitrary_types_allowedÂ±ûÊÄßËÆæÁΩÆ‰∏∫TrueË°®Á§∫ÂÖÅËÆ∏‰ªªÊÑèÁ±ªÂûã„ÄÇ\n",
    "\"\"\"\n",
    "class BabyAGI(Chain, BaseModel):\n",
    "    \"\"\"Controller model for the BabyAGI agent.\"\"\"\n",
    "    #ÂÆö‰πâ‰∫Ütask_listÔºåÁ±ªÂûã‰∏∫dequeÔºå‰ΩøÁî®field‰Ωú‰∏∫Â≠óÊÆµÈ™åËØÅÂô®ÔºåËÆæÁΩÆ‰∫ÜÈªòËÆ§Â∑•ÂéÇÂáΩÊï∞‰∏∫dequeÔºå‰πüÂ∞±ÊòØÂàõÂª∫‰∏Ä‰∏™Á©∫ÁöÑÂèåÁ´ØÈòüÂàó‰Ωú‰∏∫ÈªòËÆ§ÂÄº\n",
    "    task_list: deque = Field(default_factory=deque)\n",
    "    #ÂÆö‰πâ‰∫Ütask_creation_chainÔºåÁ±ªÂûã‰∏∫TaskCreationChainÔºå‰ΩøÁî®field‰Ωú‰∏∫Â≠óÊÆµÈ™åËØÅÂô®ÔºåËÆæÁΩÆ‰∫ÜÂøÖÈ°ªÁöÑÂ≠óÊÆµÊ†áÂøó\"...\",ÂàùÂßãÂåñÁöÑÊó∂ÂÄôÊèê‰æõ\n",
    "    task_creation_chain: TaskCreationChain = Field(...)\n",
    "    #Âêå‰∏ä\n",
    "    task_prioritization_chain: TaskPrioritizationChain = Field(...)\n",
    "    execution_chain: ExecutionChain = Field(...)\n",
    "    #Á±ªÂûã‰∏∫intÔºåÂàùÂßãÂÄº‰∏∫1\n",
    "    task_id_counter: int = Field(1)\n",
    "    #ÂàõÂª∫Êó∂ÂÄô‰∏çÈúÄË¶ÅÂàùÂßãÂåñ\n",
    "    vectorstore: VectorStore = Field(init=False)\n",
    "    #ÈªòËÆ§ÂÄº‰∏∫NoneÔºåË°®Á§∫Ê≤°ÊúâÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞ÈôêÂà∂\n",
    "    max_iterations: Optional[int] = None\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def add_task(self, task: Dict):\n",
    "        self.task_list.append(task)\n",
    "\n",
    "    def print_task_list(self):\n",
    "        #Âà©Áî®ANSIÁ†ÅËÆæÁΩÆÁªàÁ´ØÁöÑÊñáÊú¨È¢úËâ≤ÂíåÊ†∑ÂºèÔºå‰∏ãÂêå\n",
    "        print(\"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        for t in self.task_list:\n",
    "            print(str(t[\"task_id\"]) + \": \" + t[\"task_name\"])\n",
    "\n",
    "    def print_next_task(self, task: Dict):\n",
    "        print(\"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        print(str(task[\"task_id\"]) + \": \" + task[\"task_name\"])\n",
    "\n",
    "    def print_task_result(self, result: str):\n",
    "        print(\"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        print(result)\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        return [\"objective\"]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return []\n",
    "    \"\"\"\n",
    "    Ëøô‰∏™ÊñπÊ≥ïÁî®‰∫éÊâßË°å‰ªªÂä°„ÄÇËØ•ÊñπÊ≥ïÊé•Êî∂‰∏Ä‰∏™Â≠óÂÖ∏ÂèÇÊï∞inputs‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂ËøîÂõûÊâßË°åÁªìÊûú„ÄÇÂú®ÊñπÊ≥ïÂÜÖÈÉ®Ôºå\n",
    "    È¶ñÂÖà‰ªéinputs‰∏≠Ëé∑Âèñ‰ªªÂä°IDÂíåÁ¨¨‰∏Ä‰∏™‰ªªÂä°ÔºåÁÑ∂ÂêéÊ†πÊçÆÁ¨¨‰∏Ä‰∏™‰ªªÂä°ÁöÑÂêçÁß∞ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑ‰ªªÂä°ÔºåÂ∞ÜÂÖ∂Ê∑ªÂä†Âà∞\n",
    "    ‰ªªÂä°ÂàóË°®‰∏≠ÔºåÂπ∂ÊâßË°åËØ•‰ªªÂä°„ÄÇÊé•ÁùÄÔºåÊ†πÊçÆÊâßË°åÁªìÊûúÊõ¥Êñ∞ÂêëÈáèÂ≠òÂÇ®‰∏≠ÁöÑÊñáÊú¨ÂÜÖÂÆπÂíåÂÖÉÊï∞ÊçÆÔºåÂπ∂ÁîüÊàêÊñ∞‰ªªÂä°ÁöÑID,\n",
    "    Â∞ÜÊñ∞‰ªªÂä°Ê∑ªÂä†Âà∞‰ªªÂä°ÂàóË°®‰∏≠ÔºåÊúÄÂêéÈáçÊñ∞ÊéíÂ∫è‰ªªÂä°ÂàóË°®„ÄÇÂ¶ÇÊûúËææÂà∞‰∫ÜÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞ÔºåÂàôÊâìÂç∞ÁªìÊùü‰ø°ÊÅØÂπ∂ÈÄÄÂá∫Âæ™ÁéØ„ÄÇ\n",
    "    Âú®Á±ª‰∏≠ËøòÂÆö‰πâ‰∫Ü‰∏Ä‰∫õËæÖÂä©ÊñπÊ≥ïÂíåÂ±ûÊÄßÔºåÂ¶Çinput_keys()Â±ûÊÄßÁî®‰∫éËé∑ÂèñËæìÂÖ•ÈîÆÂàóË°®Ôºõoutput_keys()Â±ûÊÄßÁî®\n",
    "    ‰∫éËé∑ÂèñËæìÂá∫ÈîÆÂàóË°®ÔºõTaskCreationChain.from_list()ÊñπÊ≥ïÁî®‰∫é‰ªé‰ªªÂä°ÂàóË°®‰∏≠ÂàõÂª∫‰ªªÂä°ÂàõÂª∫ÈìæÁ≠â„ÄÇ\n",
    "    \"\"\"\n",
    "    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Run the agent.ËøîÂõû‰∏Ä‰∏™Â≠óÂÖ∏ÂØπË±°\"\"\"\n",
    "        #‰ªéËæìÂÖ•ÂèÇÊï∞inputs‰∏≠Ëé∑ÂèñÈîÆ‰∏∫objectiveÁöÑÂÄºÔºåÂπ∂Â∞ÜÂÖ∂ËµãÁªôÂèòÈáèobjective\n",
    "        objective = inputs[\"objective\"]\n",
    "        #‰ªéËæìÂÖ•ÂèÇÊï∞inputs‰∏≠Ëé∑ÂèñÈîÆ‰∏∫first_taskÁöÑÂÄºÔºåÂπ∂Â∞ÜÂÖ∂ËµãÂÄºÁªôÂèòÈáèfirst_task,\n",
    "        #Â¶ÇÊûúinputs‰∏≠Ê≤°ÊúâÈîÆ‰∏∫first_taskÁöÑÈ°πÔºåÊ≤°ÊúâËøô‰∏™ÈîÆÂ∞±‰ΩøÁî®ÈªòËÆ§ÁöÑmake a todo list\n",
    "        #ËµãÂÄºÁªôfirst_task,getÊñπÊ≥ïÂèØ‰ª•ÈÅøÂÖçÂ≠óÂÖ∏‰∏≠‰∏çÂ≠òÂú®Êüê‰∏™ÈîÆÊó∂ÂÄôÊä•Èîô\n",
    "        first_task = inputs.get(\"first_task\", \"Make a todo list\")\n",
    "        self.add_task({\"task_id\": 1, \"task_name\": first_task})\n",
    "        num_iters = 0\n",
    "        while True:\n",
    "            if self.task_list:\n",
    "                self.print_task_list()\n",
    "\n",
    "                # Step 1: Pull the first task\n",
    "                #popleftÊòØÁßªÈô§ÈòüÈ¶ñÁöÑ‰ªªÂä°Ôºå‰ªéÈòüÈ¶ñÁßªÈô§‰∏Ä‰∏™ÂÖÉÁ¥†Âπ∂ËøîÂõûÂÖ∂ÂÄº\n",
    "                task = self.task_list.popleft()\n",
    "                self.print_next_task(task)\n",
    "\n",
    "                # Step 2: Execute the task\n",
    "                result = execute_task(\n",
    "                    self.vectorstore, self.execution_chain, objective, task[\"task_name\"]\n",
    "                )\n",
    "                this_task_id = int(task[\"task_id\"])\n",
    "                self.print_task_result(result)\n",
    "\n",
    "                # Step 3: Store the result in Pinecone\n",
    "                result_id = f\"result_{task['task_id']}\"\n",
    "                self.vectorstore.add_texts(\n",
    "                    texts=[result],\n",
    "                    metadatas=[{\"task\": task[\"task_name\"]}],\n",
    "                    ids=[result_id],\n",
    "                )\n",
    "\n",
    "                # Step 4: Create new tasks and reprioritize task list\n",
    "                new_tasks = get_next_task(\n",
    "                    self.task_creation_chain,\n",
    "                    result,\n",
    "                    task[\"task_name\"],\n",
    "                    [t[\"task_name\"] for t in self.task_list],\n",
    "                    objective,\n",
    "                )\n",
    "                for new_task in new_tasks:\n",
    "                    self.task_id_counter += 1\n",
    "                    new_task.update({\"task_id\": self.task_id_counter})\n",
    "                    self.add_task(new_task)\n",
    "                self.task_list = deque(\n",
    "                    prioritize_tasks(\n",
    "                        self.task_prioritization_chain,\n",
    "                        this_task_id,\n",
    "                        list(self.task_list),\n",
    "                        objective,\n",
    "                    )\n",
    "                )\n",
    "            num_iters += 1\n",
    "            if self.max_iterations is not None and num_iters == self.max_iterations:\n",
    "                print(\n",
    "                    \"\\033[91m\\033[1m\" + \"\\n*****TASK ENDING*****\\n\" + \"\\033[0m\\033[0m\"\n",
    "                )\n",
    "                break\n",
    "        return {}\n",
    "\n",
    "    \"\"\"\n",
    "    ËøôÊòØ‰∏Ä‰∏™Á±ªÊñπÊ≥ïÔºåÁî®‰∫é‰ªéLLM(Language Model)ÂÆû‰æã‰∏≠ÂàùÂßãÂåñBabyAGIÊéßÂà∂Âô®„ÄÇ\n",
    "    ËØ•Á±ªÊñπÊ≥ïÊé•ÂèóÂõõ‰∏™ÂèÇÊï∞Ôºöllm„ÄÅvectorstore„ÄÅverboseÂíåkwargs„ÄÇÂÖ∂‰∏≠ÔºållmË°®Á§∫LLMÂÆû‰æãÔºåvectorstoreË°®Á§∫ÂêëÈáèÂ≠òÂÇ®ÂÆû‰æãÔºå\n",
    "    verboseË°®Á§∫ÊòØÂê¶ÂêØÁî®ËØ¶ÁªÜËæìÂá∫Ê®°ÂºèÔºåkwargsË°®Á§∫ÂÖ∂‰ªñÂèØÈÄâÂèÇÊï∞„ÄÇÂú®Á±ªÊñπÊ≥ï‰∏≠ÔºåÈ¶ñÂÖàË∞ÉÁî®TaskCreationChain.from_llm()\n",
    "    ÂíåTaskPrioritizationChain.from_llm()ÊñπÊ≥ïÂàÜÂà´ÂàõÂª∫‰ªªÂä°ÂàõÂª∫ÈìæÂíå‰ªªÂä°ÊéíÂ∫èÈìæ„ÄÇÁÑ∂ÂêéË∞ÉÁî®ExecutionChain.from_llm()ÊñπÊ≥ï\n",
    "    ÂàõÂª∫ÊâßË°åÈìæ„ÄÇÊúÄÂêé‰ΩøÁî®Ëøô‰∫õÈìæÂíåvectorstore‰ª•Âèä‰º†ÂÖ•ÁöÑÂÖ∂‰ªñÂèÇÊï∞Êù•ÂàõÂª∫‰∏Ä‰∏™BabyAGIÁ±ªÂÆû‰æãÂπ∂ËøîÂõû„ÄÇ\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls, llm: BaseLLM, vectorstore: VectorStore, verbose: bool = False, **kwargs\n",
    "    ) -> \"BabyAGI\":\n",
    "        \"\"\"Initialize the BabyAGI Controller.\"\"\"\n",
    "        task_creation_chain = TaskCreationChain.from_llm(llm, verbose=verbose)\n",
    "        task_prioritization_chain = TaskPrioritizationChain.from_llm(\n",
    "            llm, verbose=verbose\n",
    "        )\n",
    "        execution_chain = ExecutionChain.from_llm(llm, verbose=verbose)\n",
    "        return cls(\n",
    "            task_creation_chain=task_creation_chain,\n",
    "            task_prioritization_chain=task_prioritization_chain,\n",
    "            execution_chain=execution_chain,\n",
    "            vectorstore=vectorstore,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËøêË°å BabyAGI \n",
    "\n",
    "Áé∞Âú®ÊòØÂàõÂª∫ BabyAGI ÊéßÂà∂Âô®Âπ∂ËßÇÂØüÂÆÉÂ∞ùËØïÂÆûÁé∞ÊÇ®ÁöÑÁõÆÊ†áÁöÑÊó∂ÂÄô‰∫Ü„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTIVE = \"Make a plan to travel around the world for a month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ÂÆö‰πâ‰∫Ü‰∏â‰∏™ÂèòÈáèÔºöverbose„ÄÅmax_iterationsÂíåbaby_agi„ÄÇ\n",
    "verbose:ËøôÊòØ‰∏Ä‰∏™Â∏ÉÂ∞îÁ±ªÂûãÁöÑÂèòÈáèÔºåÂàùÂßãÂÄº‰∏∫False„ÄÇÂÆÉË°®Á§∫ÊòØÂê¶ÂêØÁî®ËØ¶ÁªÜËæìÂá∫Ê®°Âºè„ÄÇÂ¶ÇÊûúËÆæÁΩÆ‰∏∫True,ÂàôÂú®ÊâßË°å‰ªªÂä°Êó∂‰ºöËæìÂá∫Êõ¥Â§öÁöÑ‰ø°ÊÅØ„ÄÇ\n",
    "max_iterations:ËøôÊòØ‰∏Ä‰∏™ÂèØÈÄâÊï¥Êï∞Á±ªÂûãÁöÑÂèòÈáèÔºåÂàùÂßãÂÄº‰∏∫3„ÄÇÂÆÉË°®Á§∫BabyAGIÊéßÂà∂Âô®ÁöÑÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞„ÄÇÂ¶ÇÊûúÊ≤°ÊúâÊåáÂÆöÔºåÂàôÈªòËÆ§‰∏∫3„ÄÇ\n",
    "baby_agi:ËøôÊòØ‰ªéLLMÂÆû‰æã‰∏≠ÂàùÂßãÂåñBabyAGIÊéßÂà∂Âô®ÁöÑÁªìÊûú„ÄÇÂÆÉÊòØ‰∏Ä‰∏™BabyAGIÁ±ªÁöÑÂØπË±°ÔºåÂåÖÂê´‰∫Ü‰ªéLLMÂÆû‰æã‰∏≠ÁîüÊàêÁöÑ‰ªªÂä°ÂàóË°®„ÄÅÊâßË°å‰ªªÂä°ÁöÑ\n",
    "Èìæ‰ª•ÂèäÂêëÈáèÂ≠òÂÇ®Á≠â‰ø°ÊÅØ„ÄÇ\n",
    "\"\"\"\n",
    "verbose = False\n",
    "max_iterations: Optional[int] = 3\n",
    "baby_agi = BabyAGI.from_llm(\n",
    "    llm=llm, vectorstore=vectorstore, verbose=verbose, max_iterations=max_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "1. Research potential destinations\n",
      "2. Create a budget\n",
      "3. Book flights\n",
      "4. Book accommodations\n",
      "5. Research local attractions\n",
      "6. Pack necessary items\n",
      "7. Make copies of important documents\n",
      "8. Notify bank and credit card companies of travel plans\n",
      "9. Purchase travel insurance\n",
      "10. Make a list of emergency contacts\n",
      "11. Research visa requirements\n",
      "12. Apply for necessary visas\n",
      "13. Make a list of must-see attractions\n",
      "14. Make a list of must-do activities\n",
      "15. Make a list of must-try foods\n",
      "16. Make a list of must-visit restaurants\n",
      "17. Make a list of must-visit shops\n",
      "18. Make a list of must-visit markets\n",
      "19. Make a list of must-visit museums\n",
      "20. Make a list of must-visit galleries\n",
      "21. Make a list of must-visit parks\n",
      "22. Make a list of must-visit historical sites\n",
      "23. Make a list of must-visit religious sites\n",
      "24. Make a list of must-visit natural sites\n",
      "25. Make a list of must-visit cultural sites\n",
      "26. Make a list of must-visit nightlife spots\n",
      "\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Research local currency exchange rates\n",
      "3: Research local safety and security information\n",
      "4: Research local customs and etiquette\n",
      "5: Research local language basics\n",
      "6: Research local weather conditions\n",
      "7: Research local medical facilities\n",
      "8: Research local emergency services\n",
      "9: Research local shopping options\n",
      "10: Research local entertainment options\n",
      "11: Research local cultural events\n",
      "12: Research local outdoor activities\n",
      "13: Research local festivals\n",
      "14: Research local sports teams\n",
      "15: Research local volunteer opportunities\n",
      "16: Research local job opportunities\n",
      "17: Research local educational opportunities\n",
      "18: Research local religious services\n",
      "19: Research local political activities\n",
      "20: Research local environmental initiatives\n",
      "21: Research local community organizations\n",
      "22: Research local charities\n",
      "23: Research local art galleries\n",
      "24: Research local music venues\n",
      "25: Research local theater venues\n",
      "26: Research local libraries\n",
      "1: Research local transportation options\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Research local currency exchange rates\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "I will research local currency exchange rates for the countries I plan to visit during my month-long trip around the world. I will use online resources such as currency conversion websites and travel blogs to find the most up-to-date exchange rates. I will also research the best ways to exchange money in each country, such as using ATMs or exchanging cash at banks.\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Research local transportation costs\n",
      "4: Research local accommodation options\n",
      "5: Research local food options\n",
      "6: Research local tourist attractions\n",
      "7: Research local tourist discounts\n",
      "8: Research local tourist visas\n",
      "9: Research local tourist activities\n",
      "10: Research local tourist guides\n",
      "11: Research local tourist maps\n",
      "12: Research local tourist safety tips\n",
      "13: Research local safety and security information\n",
      "14: Research local customs and etiquette\n",
      "15: Research local language basics\n",
      "16: Research local weather conditions\n",
      "17: Research local medical facilities\n",
      "18: Research local emergency services\n",
      "19: Research local shopping options\n",
      "20: Research local entertainment options\n",
      "21: Research local cultural events\n",
      "22: Research local outdoor activities\n",
      "23: Research local festivals\n",
      "24: Research local sports teams\n",
      "25: Research local volunteer opportunities\n",
      "26: Research local job opportunities\n",
      "27: Research local educational opportunities\n",
      "28: Research local religious services\n",
      "29: Research local political activities\n",
      "30: Research local environmental initiatives\n",
      "31: Research local community organizations\n",
      "32: Research local charities\n",
      "33: Research local art galleries\n",
      "34: Research local\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Research local transportation costs\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "I will research local transportation costs by looking up the cost of flights, trains, buses, and other forms of transportation in each of the countries I plan to visit. I will also look into the cost of renting a car or taking a taxi in each country. Additionally, I will research any discounts or promotions that may be available for transportation costs.\n",
      "\u001b[91m\u001b[1m\n",
      "*****TASK ENDING*****\n",
      "\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'Make a plan to travel around the world for a month'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_agi({\"objective\": OBJECTIVE})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áé∞Âú®ÔºåÊàë‰ª¨ÁÜüÊÇâ‰∫ÜBabyAGIÁöÑÂü∫Êú¨Êìç‰ΩúÔºåÁé∞Âú®Áúã‰∏Ä‰∏ãÊúâÂÖ≥ÂÆÉÁöÑ‰ª£Á†ÅÊ°à‰æãÂêß,‰∏ãÈù¢ÁöÑÊ°à‰æãÂ∞Ü‰ºöÁî®Âà∞Ë∞∑Ê≠åÁöÑÊêúÁ¥¢APIÔºåÂèØ‰ª•‰ΩøagentËøõË°åËÅîÁΩëÊêúÁ¥¢Âπ∂ÂÆåÊàê‰ªªÂä°ËßÑÂàí\n",
    "\n",
    "È¶ñÂÖàÊòØÂØºÂÖ•Áõ∏ÂÖ≥Â∫ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import deque\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.base import Chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËøûÊé•Âà∞ Vector Store \n",
    "\n",
    "Ê†πÊçÆÊÇ®‰ΩøÁî®ÁöÑÁü¢ÈáèÂ≠òÂÇ®ÔºåÊ≠§Ê≠•È™§ÂèØËÉΩÁúãËµ∑Êù•ÊúâÊâÄ‰∏çÂêå„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu > /dev/null\n",
    "%pip install google-search-results > /dev/null\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#embeddings_model:ËøôÊòØ‰∏Ä‰∏™OpenAIEmbeddingsÁ±ªÁöÑÂØπË±°ÔºåÁî®‰∫éÂ∞ÜÊü•ËØ¢ÂµåÂÖ•Âà∞Ê®°Âûã‰∏≠‰ª•ÁîüÊàêÁõ∏‰ººÂ∫¶ÂêëÈáè„ÄÇ\n",
    "#ÂÆÉÂåÖÂê´‰∫Ü‰∏Ä‰∏™embed_query()ÊñπÊ≥ïÔºåÁî®‰∫éÂ∞ÜÊü•ËØ¢ÂµåÂÖ•Âà∞ÊåáÂÆöÁöÑÁª¥Â∫¶‰∏≠„ÄÇ\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "import faiss\n",
    "#embedding_size:ËøôÊòØ‰∏Ä‰∏™Êï¥Êï∞Á±ªÂûãÁöÑÂèòÈáèÔºåÂàùÂßãÂÄº‰∏∫1536„ÄÇÂÆÉË°®Á§∫ÂµåÂÖ•ÂêëÈáèÁöÑÁª¥Â∫¶„ÄÇ\n",
    "embedding_size = 1536\n",
    "#index:ËøôÊòØ‰∏Ä‰∏™faiss.IndexFlatL2Á±ªÂûãÁöÑÂØπË±°ÔºåÁî®‰∫éÂ≠òÂÇ®ÂµåÂÖ•ÂêëÈáè„ÄÇÂÆÉÊòØ‰∏Ä‰∏™ÊâÅÂπ≥Á¥¢ÂºïÔºå\n",
    "#ÂèØ‰ª•Âø´ÈÄüÊü•ÊâæÁõ∏‰ººÂêëÈáè„ÄÇÂú®ÂàõÂª∫Á¥¢ÂºïÊó∂ÔºåÈúÄË¶Å‰º†ÂÖ•embedding_model.embed_query()ÊñπÊ≥ïÁöÑÁªìÊûú‰Ωú‰∏∫ËæìÂÖ•„ÄÇ\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "#vectorstore:ËøôÊòØ‰∏Ä‰∏™FAISSÁ±ªÂûãÁöÑÂØπË±°ÔºåÁî®‰∫éÂ≠òÂÇ®ÂµåÂÖ•ÂêëÈáè„ÄÇÂÆÉ‰∏éindex‰∏ÄËµ∑‰ΩøÁî®ÔºåÂèØ‰ª•Â∞ÜÊü•ËØ¢ÂµåÂÖ•Âà∞ÊåáÂÆöÁöÑ\n",
    "#Áª¥Â∫¶‰∏≠Âπ∂Â≠òÂÇ®Âà∞ÂÜÖÂ≠ò‰∏≠‰ª•‰æõÂø´ÈÄüÊü•Êâæ„ÄÇÂú®ÂàõÂª∫vectorstoreÊó∂ÔºåÈúÄË¶Å‰º†ÂÖ•embeddings_model.embed_query()ÊñπÊ≥ïÁöÑÁªìÊûú‰Ωú‰∏∫ËæìÂÖ•„ÄÇ\"\"\"\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏ãÈù¢ÁöÑÂÆö‰πâÈìæÁöÑËøáÁ®ãÔºåÂêå‰∏äÔºåÂ§ßÂêåÂ∞èÂºÇÔºåËøôÈáåÂ∞±‰∏çÂÜçËµòËø∞Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskCreationChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Get the response parser.\"\"\"\n",
    "        task_creation_template = (\n",
    "            \"You are an task creation AI that uses the result of an execution agent\"\n",
    "            \" to create new tasks with the following objective: {objective},\"\n",
    "            \" The last completed task has the result: {result}.\"\n",
    "            \" This result was based on this task description: {task_description}.\"\n",
    "            \" These are incomplete tasks: {incomplete_tasks}.\"\n",
    "            \" Based on the result, create new tasks to be completed\"\n",
    "            \" by the AI system that do not overlap with incomplete tasks.\"\n",
    "            \" Return the tasks as an array.\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_creation_template,\n",
    "            input_variables=[\n",
    "                \"result\",\n",
    "                \"task_description\",\n",
    "                \"incomplete_tasks\",\n",
    "                \"objective\",\n",
    "            ],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskPrioritizationChain(LLMChain):\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Get the response parser.\"\"\"\n",
    "        task_prioritization_template = (\n",
    "            \"You are an task prioritization AI tasked with cleaning the formatting of and reprioritizing\"\n",
    "            \" the following tasks: {task_names}.\"\n",
    "            \" Consider the ultimate objective of your team: {objective}.\"\n",
    "            \" Do not remove any tasks. Return the result as a numbered list, like:\"\n",
    "            \" #. First task\"\n",
    "            \" #. Second task\"\n",
    "            \" Start the task list with number {next_task_id}.\"\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_prioritization_template,\n",
    "            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ë∞∑Ê≠åÊêúÁ¥¢apiÊàë‰ª¨‰ºöÁî®Âà∞ÔºåÂõ†Ê≠§Âú®ËøôÈáåÈúÄË¶ÅÂä†ÂÖ•Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "\n",
    "#ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™todo_promptÊ®°ÊùøÔºåËØ•Ê®°ÊùøÂ∞ÜË¢´Áî®‰∫éÁîüÊàê‰ªªÂä°ÁöÑÊèêÁ§∫‰ø°ÊÅØ\n",
    "todo_prompt = PromptTemplate.from_template(\n",
    "    \"You are a planner who is an expert at coming up with a todo list for a given objective. Come up with a todo list for this objective: {objective}\"\n",
    ")\n",
    "#ÂÆö‰πâ‰∫Ü‰∏§‰∏™Â∑•ÂÖ∑ÈìæÔºö‰∏Ä‰∏™ÊòØLLMChain(‰ΩøÁî®OpenAIÂ∫ì),Âè¶‰∏Ä‰∏™ÊòØSerpAPIWrapper(Áî®‰∫éÊêúÁ¥¢)„ÄÇ\n",
    "todo_chain = LLMChain(llm=OpenAI(temperature=0), prompt=todo_prompt)\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "\"\"\"\n",
    "ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ÂåÖÂê´‰∏§‰∏™Â∑•ÂÖ∑ÁöÑÂ∑•ÂÖ∑ÂàóË°®ÔºåÂÖ∂‰∏≠Á¨¨‰∏Ä‰∏™Â∑•ÂÖ∑ÊòØ‚ÄúSearch‚ÄùÔºåÁî®‰∫éÂõûÁ≠îÂΩìÂâç‰∫ã‰ª∂Áõ∏ÂÖ≥ÁöÑÈóÆÈ¢òÔºõ\n",
    "Á¨¨‰∫å‰∏™Â∑•ÂÖ∑ÊòØ‚ÄúTODO‚ÄùÔºåÁî®‰∫é‰∏∫ÁªôÂÆöÁöÑÁõÆÊ†áÁîüÊàê‰ªªÂä°ÂàóË°®„ÄÇ\n",
    "\"\"\"\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"TODO\",\n",
    "        func=todo_chain.run,\n",
    "        description=\"useful for when you need to come up with todo lists. Input: an objective to create a todo list for. Output: a todo list for that objective. Please be very clear what the objective is!\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "#ÂÆö‰πâ‰∫ÜÂâçÁºÄ„ÄÅÂêéÁºÄÂíåÊ®°ÊùøÔºåËøô‰∫õÂèòÈáèÂ∞ÜË¢´‰º†ÈÄíÁªôZeroShotAgent‰ª•ÁîüÊàê‰ªªÂä°ÊèêÁ§∫‰ø°ÊÅØ„ÄÇ\n",
    "prefix = \"\"\"You are an AI who performs one task based on the following objective: {objective}. Take into account these previously completed tasks: {context}.\"\"\"\n",
    "suffix = \"\"\"Question: {task}\n",
    "{agent_scratchpad}\"\"\"\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"objective\", \"task\", \"context\", \"agent_scratchpad\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂÆö‰πâAGI controllerÔºå ‰∏∫‰∫ÜÊää‰∏â‰∏™ÂÆö‰πâÈìæÁªÑÊàêÊàê‰∏Ä‰∏™Âæ™ÁéØÁöÑÈìæËøõÂÖ•‰∏ãÈù¢ÁöÑÊ≠•È™§Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ëøô‰∏™ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØËé∑Âèñ‰∏ã‰∏Ä‰∏™‰ªªÂä°„ÄÇ\n",
    "ÂÆÉÈ¶ñÂÖàÂ∞Ü‰πãÂâçÊâßË°åËøáÁöÑ‰ªªÂä°ÂàóË°®ËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÂπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄíÁªô‰ªªÂä°ÂàõÂª∫ÈìæÁöÑrunÊñπÊ≥ï„ÄÇ\n",
    "ÁÑ∂ÂêéÔºåÂÆÉ‰ªé‰ªªÂä°ÂàõÂª∫ÈìæÁöÑÂìçÂ∫î‰∏≠ÊèêÂèñÂá∫Êñ∞‰ªªÂä°ÔºåÂπ∂Â∞ÜÂÆÉ‰ª¨Â≠òÂÇ®Âú®‰∏Ä‰∏™ÂàóË°®‰∏≠„ÄÇÊúÄÂêéÔºåÂÆÉËøîÂõû‰∏Ä\n",
    "‰∏™ÂåÖÂê´Êñ∞‰ªªÂä°ÂêçÁß∞ÁöÑÂ≠óÂÖ∏ÂàóË°®ÔºåÊØè‰∏™Â≠óÂÖ∏ÈÉΩÂåÖÂê´‰∏Ä‰∏™Âêç‰∏∫‚Äútask_name‚ÄùÁöÑÈîÆÂíåÂØπÂ∫îÁöÑÂÄº„ÄÇ\n",
    "\n",
    "task_creation_chain: LLMChainÁ±ªÂûãÔºåË°®Á§∫‰ªªÂä°ÂàõÂª∫Èìæ„ÄÇ\n",
    "result: DictÁ±ªÂûãÔºåË°®Á§∫‰πãÂâçÊâßË°å‰ªªÂä°ÁöÑÁªìÊûú„ÄÇ\n",
    "task_description: strÁ±ªÂûãÔºåË°®Á§∫Ë¶Å‰∏∫Êñ∞‰ªªÂä°ÁîüÊàêÁöÑ‰ªªÂä°ÊèèËø∞„ÄÇ\n",
    "task_list: List[str]Á±ªÂûãÔºåË°®Á§∫‰πãÂâçÊâßË°åËøáÁöÑ‰ªªÂä°ÂàóË°®„ÄÇ\n",
    "objective: strÁ±ªÂûãÔºåË°®Á§∫‰ªªÂä°ÁöÑÁõÆÊ†á„ÄÇ\n",
    "\"\"\"\n",
    "def get_next_task(\n",
    "    task_creation_chain: LLMChain,\n",
    "    result: Dict,\n",
    "    task_description: str,\n",
    "    task_list: List[str],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Get the next task.\"\"\"\n",
    "    incomplete_tasks = \", \".join(task_list)\n",
    "    response = task_creation_chain.run(\n",
    "        result=result,\n",
    "        task_description=task_description,\n",
    "        incomplete_tasks=incomplete_tasks,\n",
    "        objective=objective,\n",
    "    )\n",
    "    new_tasks = response.split(\"\\n\")\n",
    "    return [{\"task_name\": task_name} for task_name in new_tasks if task_name.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËØ•ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØÁ°ÆÂÆöÊØè‰∏™‰ªªÂä°ÁöÑ‰ºòÂÖàÁ∫ß„ÄÇÂÆÉÈ¶ñÂÖàÂ∞Ü‰ªªÂä°ÂàóË°®‰∏≠ÁöÑÊâÄÊúâ‰ªªÂä°ÂêçÁß∞ÊèêÂèñÂá∫Êù•ÔºåÂπ∂Â∞ÜÂÖ∂Â≠òÂÇ®Âú®‰∏Ä‰∏™ÂàóË°®‰∏≠„ÄÇ\n",
    "ÁÑ∂ÂêéÔºåÂÆÉËÆ°ÁÆó‰∏ã‰∏Ä‰∏™‰ªªÂä°ÁöÑID,Âπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄíÁªô‰ªªÂä°‰ºòÂÖàÁ∫ßÂàõÂª∫ÈìæÁöÑrunÊñπÊ≥ï„ÄÇÊé•‰∏ãÊù•ÔºåÂÆÉ‰ªé‰ªªÂä°‰ºòÂÖàÁ∫ßÂàõÂª∫ÈìæÁöÑ\n",
    "ÂìçÂ∫î‰∏≠ÊèêÂèñÂá∫Êñ∞‰ªªÂä°ÔºåÂπ∂Â∞ÜÂÆÉ‰ª¨Â≠òÂÇ®Âú®‰∏Ä‰∏™ÂàóË°®‰∏≠„ÄÇÊúÄÂêéÔºåÂÆÉÈÅçÂéÜÊñ∞‰ªªÂä°ÂàóË°®‰∏≠ÁöÑÊØè‰∏™‰ªªÂä°Â≠óÁ¨¶‰∏≤ÔºåÂπ∂‰ΩøÁî®Á©∫Ê†ºÂàÜÈöîÁ¨¶Â∞Ü\n",
    "ÂÖ∂ÊãÜÂàÜ‰∏∫‰∏§‰∏™ÈÉ®ÂàÜ„ÄÇÂ¶ÇÊûúÁ¨¨‰∫å‰∏™ÈÉ®ÂàÜ‰∏ç‰∏∫Á©∫ÔºåÂàôË°®Á§∫ËøôÊòØ‰∏Ä‰∏™ÂÖ∑ÊúâIDÂíåÂêçÁß∞ÁöÑ‰ªªÂä°„ÄÇÂÆÉÂ∞ÜËØ•‰ªªÂä°Ê∑ªÂä†Âà∞‰∏Ä‰∏™‰ºòÂÖàÁ∫ß‰ªªÂä°Âàó\n",
    "Ë°®‰∏≠ÔºåÂπ∂ËøîÂõûËØ•ÂàóË°®„ÄÇ\n",
    "task_prioritization_chain: LLMChainÁ±ªÂûãÔºåË°®Á§∫‰ªªÂä°‰ºòÂÖàÁ∫ßÂàõÂª∫Èìæ„ÄÇ\n",
    "this_task_id: intÁ±ªÂûãÔºåË°®Á§∫ÂΩìÂâç‰ªªÂä°ÁöÑID„ÄÇ\n",
    "task_list: List[Dict]Á±ªÂûãÔºåË°®Á§∫ÊâÄÊúâ‰ªªÂä°ÁöÑÂàóË°®„ÄÇ\n",
    "objective: strÁ±ªÂûãÔºåË°®Á§∫‰ªªÂä°ÁöÑÁõÆÊ†á„ÄÇ\n",
    "\"\"\"\n",
    "def prioritize_tasks(\n",
    "    task_prioritization_chain: LLMChain,\n",
    "    this_task_id: int,\n",
    "    task_list: List[Dict],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Prioritize tasks.\"\"\"\n",
    "    task_names = [t[\"task_name\"] for t in task_list]\n",
    "    next_task_id = int(this_task_id) + 1\n",
    "    response = task_prioritization_chain.run(\n",
    "        task_names=task_names, next_task_id=next_task_id, objective=objective\n",
    "    )\n",
    "    new_tasks = response.split(\"\\n\")\n",
    "    prioritized_task_list = []\n",
    "    for task_string in new_tasks:\n",
    "        if not task_string.strip():\n",
    "            continue\n",
    "        task_parts = task_string.strip().split(\".\", 1)\n",
    "        if len(task_parts) == 2:\n",
    "            task_id = task_parts[0].strip()\n",
    "            task_name = task_parts[1].strip()\n",
    "            prioritized_task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
    "    return prioritized_task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ËØ•ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØÊ†πÊçÆÊü•ËØ¢ËØ≠Âè•ËøîÂõû‰∏éÊü•ËØ¢ÊúÄÁõ∏ÂÖ≥ÁöÑk‰∏™‰ªªÂä°ÂêçÁß∞„ÄÇÂÆÉÈ¶ñÂÖàË∞ÉÁî®Áõ∏‰ººÂêëÈáèÂ≠òÂÇ®ÂØπË±°ÁöÑsimilarity_search_with_scoreÊñπÊ≥ï\n",
    "Êù•ÊâßË°åÊü•ËØ¢ÔºåÂπ∂Â∞ÜÁªìÊûúÂ≠òÂÇ®Âú®resultsÂèòÈáè‰∏≠„ÄÇÂ¶ÇÊûúÊ≤°ÊúâÁªìÊûúÔºåÂàôÂáΩÊï∞ËøîÂõûÁ©∫ÂàóË°®„ÄÇÂê¶ÂàôÔºåÂÆÉ‰ΩøÁî®zipÂíåsortedÂáΩÊï∞Êù•ÊåâÁõ∏ÂÖ≥ÊÄßÂØπÁªìÊûúËøõË°å\n",
    "ÊéíÂ∫èÔºåÂπ∂Â∞ÜÁªìÊûúÂ≠òÂÇ®Âú®sorted_resultsÂèòÈáè‰∏≠„ÄÇÊúÄÂêéÔºåÂÆÉÈÅçÂéÜsorted_results‰∏≠ÁöÑÊØè‰∏™È°πÁõÆÔºåÂπ∂‰ªéÂÖ∂ÂÖÉÊï∞ÊçÆ‰∏≠ÊèêÂèñ‰ªªÂä°ÂêçÁß∞ÔºåÂπ∂Â∞ÜÂÖ∂Â≠ò\n",
    "ÂÇ®Âú®‰∏Ä‰∏™ÂàóË°®‰∏≠ÔºåÊúÄÁªàËøîÂõûËØ•ÂàóË°®„ÄÇ\n",
    "\"\"\"\n",
    "def _get_top_tasks(vectorstore, query: str, k: int) -> List[str]:\n",
    "    \"\"\"Get the top k tasks based on the query.\"\"\"\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    if not results:\n",
    "        return []\n",
    "    sorted_results, _ = zip(*sorted(results, key=lambda x: x[1], reverse=True))\n",
    "    return [str(item.metadata[\"task\"]) for item in sorted_results]\n",
    "\n",
    "\"\"\"\n",
    "ËØ•ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØÊâßË°åÁªôÂÆöÁöÑ‰ªªÂä°„ÄÇÂÆÉÈ¶ñÂÖàË∞ÉÁî®Âêç‰∏∫‚Äú_get_top_tasks‚ÄùÁöÑËæÖÂä©ÂáΩÊï∞Êù•Ëé∑Âèñ‰∏é‰ªªÂä°ÁõÆÊ†áÁõ∏ÂÖ≥ÁöÑÂâçk‰∏™‰ªªÂä°ÂàóË°®ÔºåÂπ∂Â∞ÜÁªìÊûúÂ≠òÂÇ®\n",
    "Âú®contextÂèòÈáè‰∏≠„ÄÇÁÑ∂ÂêéÔºåÂÆÉÂ∞Ü‰∏ä‰∏ãÊñá‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄíÁªôÊâßË°åÈìæÁöÑrunÊñπÊ≥ïÔºå‰ª•ÊâßË°å‰ªªÂä°„ÄÇÊúÄÂêéÔºåËØ•ÂáΩÊï∞ËøîÂõûÊâßË°åÁªìÊûú„ÄÇ\n",
    "\"\"\"\n",
    "def execute_task(\n",
    "    vectorstore, execution_chain: LLMChain, objective: str, task: str, k: int = 5\n",
    ") -> str:\n",
    "    \"\"\"Execute a task.\"\"\"\n",
    "    context = _get_top_tasks(vectorstore, query=objective, k=k)\n",
    "    return execution_chain.run(objective=objective, context=context, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‰πâ‰∫Ü‰∏Ä‰∏™ÊéßÂà∂Ê®°ÊãüAI‰ª£ÁêÜË°å‰∏∫ÁöÑÁ±ªÔºåÂèØ‰ª•Ê∑ªÂä†‰ªªÂä°„ÄÅÊâßË°å‰ªªÂä°Âπ∂ËæìÂá∫ÁªìÊûú„ÄÇÂÆÉËøòÊèê‰æõ‰∫Ü‰∏Ä‰∫õÈÖçÁΩÆÈÄâÈ°πÔºå‰ª•‰æøÂú®ËøêË°åÊó∂Ëá™ÂÆö‰πâÁ±ªÁöÑË°å‰∏∫„ÄÇ\n",
    "task_list: ‰∏Ä‰∏™ÂèåÂêëÈòüÂàóÔºåÂ≠òÂÇ®‰∫Ü‰ªªÂä°ÂàóË°®Ôºõ\n",
    "task_creation_chain: ÂàõÂª∫‰ªªÂä°ÁöÑÈìæÊù°Ôºõ\n",
    "task_prioritization_chain: ÂØπ‰ªªÂä°ËøõË°å‰ºòÂÖàÁ∫ßÊéíÂ∫èÁöÑÈìæÊù°Ôºõ\n",
    "execution_chain: ÊâßË°å‰ªªÂä°ÁöÑ‰ª£ÁêÜÔºõ\n",
    "task_id_counter: ‰ªªÂä°IDËÆ°Êï∞Âô®Ôºõ\n",
    "vectorstore: ‰∏Ä‰∏™ÂêëÈáèÂÇ®Â≠òÂ∫ìÔºõ\n",
    "max_iterations: ÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞„ÄÇ\n",
    "Á±ªÂÆö‰πâ‰∏≠ËøòÊúâ‰∏Ä‰∫õÊñπÊ≥ïÂíåÂ±ûÊÄßÔºö\n",
    "add_task(task): Ê∑ªÂä†‰ªªÂä°Âà∞‰ªªÂä°ÂàóË°®‰∏≠Ôºõ\n",
    "print_task_list(): ÊâìÂç∞‰ªªÂä°ÂàóË°®Ôºõ\n",
    "print_next_task(task): ÊâìÂç∞‰∏ã‰∏Ä‰∏™‰ªªÂä°Ôºõ\n",
    "print_task_result(result): ÊâìÂç∞‰ªªÂä°ÁªìÊûúÔºõ\n",
    "input_keys: ËæìÂÖ•ÂÖ≥ÈîÆÂ≠óÂàóË°®Ôºõ\n",
    "output_keys: ËæìÂá∫ÂÖ≥ÈîÆÂ≠óÂàóË°®„ÄÇ\n",
    "\"\"\"\n",
    "class BabyAGI(Chain, BaseModel):\n",
    "    \"\"\"Controller model for the BabyAGI agent.\"\"\"\n",
    "\n",
    "    task_list: deque = Field(default_factory=deque)\n",
    "    task_creation_chain: TaskCreationChain = Field(...)\n",
    "    task_prioritization_chain: TaskPrioritizationChain = Field(...)\n",
    "    execution_chain: AgentExecutor = Field(...)\n",
    "    task_id_counter: int = Field(1)\n",
    "    vectorstore: VectorStore = Field(init=False)\n",
    "    max_iterations: Optional[int] = None\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def add_task(self, task: Dict):\n",
    "        self.task_list.append(task)\n",
    "\n",
    "    def print_task_list(self):\n",
    "        print(\"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        for t in self.task_list:\n",
    "            print(str(t[\"task_id\"]) + \": \" + t[\"task_name\"])\n",
    "\n",
    "    def print_next_task(self, task: Dict):\n",
    "        print(\"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        print(str(task[\"task_id\"]) + \": \" + task[\"task_name\"])\n",
    "\n",
    "    def print_task_result(self, result: str):\n",
    "        print(\"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        print(result)\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        return [\"objective\"]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return []\n",
    "\n",
    "    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Run the agent.\"\"\"\n",
    "        objective = inputs[\"objective\"]\n",
    "        #Ë¶ÅÊâßË°åÁöÑÁ¨¨‰∏Ä‰∏™‰ªªÂä°ÁöÑÂêçÁß∞\n",
    "        first_task = inputs.get(\"first_task\", \"Make a todo list\")\n",
    "        #Âä†‰∏Ä‰∏™Êñ∞‰ªªÂä°Âà∞‰ªªÂä°ÂàóË°®‰∏≠„ÄÇ\n",
    "        self.add_task({\"task_id\": 1, \"task_name\": first_task})\n",
    "        num_iters = 0\n",
    "        #‰∏Ä‰∏™Êó†ÈôêÂæ™ÁéØÔºåÁõ¥Âà∞ÈÅáÂà∞Êüê‰∏™ÈÄÄÂá∫Êù°‰ª∂‰∏∫Ê≠¢„ÄÇ\n",
    "        while True:\n",
    "            if self.task_list:\n",
    "                self.print_task_list()\n",
    "\n",
    "                # Step 1: Pull the first task\n",
    "                task = self.task_list.popleft()\n",
    "                self.print_next_task(task)\n",
    "\n",
    "                # Step 2: Execute the task\n",
    "                result = execute_task(\n",
    "                    self.vectorstore, self.execution_chain, objective, task[\"task_name\"]\n",
    "                )\n",
    "                this_task_id = int(task[\"task_id\"])\n",
    "                self.print_task_result(result)\n",
    "\n",
    "                # Step 3: Store the result in Pinecone\n",
    "                result_id = f\"result_{task['task_id']}\"\n",
    "                self.vectorstore.add_texts(\n",
    "                    texts=[result],\n",
    "                    metadatas=[{\"task\": task[\"task_name\"]}],\n",
    "                    ids=[result_id],\n",
    "                )\n",
    "\n",
    "                # Step 4: Create new tasks and reprioritize task list\n",
    "                new_tasks = get_next_task(\n",
    "                    self.task_creation_chain,\n",
    "                    result,\n",
    "                    task[\"task_name\"],\n",
    "                    [t[\"task_name\"] for t in self.task_list],\n",
    "                    objective,\n",
    "                )\n",
    "                for new_task in new_tasks:\n",
    "                    self.task_id_counter += 1\n",
    "                    new_task.update({\"task_id\": self.task_id_counter})\n",
    "                    self.add_task(new_task)\n",
    "                self.task_list = deque(\n",
    "                    prioritize_tasks(\n",
    "                        self.task_prioritization_chain,\n",
    "                        this_task_id,\n",
    "                        list(self.task_list),\n",
    "                        objective,\n",
    "                    )\n",
    "                )\n",
    "            num_iters += 1\n",
    "            if self.max_iterations is not None and num_iters == self.max_iterations:\n",
    "                print(\n",
    "                    \"\\033[91m\\033[1m\" + \"\\n*****TASK ENDING*****\\n\" + \"\\033[0m\\033[0m\"\n",
    "                )\n",
    "                break\n",
    "        return {}\n",
    "    \"\"\"È¶ñÂÖà‰ΩøÁî®TaskCreationChain.from_llm()ÂíåTaskPrioritizationChain.from_llm()ÊñπÊ≥ï\n",
    "    ÂàÜÂà´ÂàõÂª∫‰ªªÂä°ÂàõÂª∫ÈìæÂíå‰ªªÂä°‰ºòÂÖàÁ∫ßÈìæ„ÄÇÁÑ∂Âêé‰ΩøÁî®LLMChain()ÊñπÊ≥ïÂàõÂª∫‰∏Ä‰∏™LLMÈìæÔºåÂπ∂‰ΩøÁî®ZeroShotAgent()ÊñπÊ≥ï\n",
    "    ÂàõÂª∫‰∏Ä‰∏™ZeroShotAgent„ÄÇÊúÄÂêé‰ΩøÁî®AgentExecutor.from_agent_and_tools()ÊñπÊ≥ïÂàõÂª∫‰∏Ä‰∏™‰ª£ÁêÜÊâßË°åÂô®„ÄÇ\n",
    "    ÊúÄÂêéÔºåËØ•ÊñπÊ≥ïËøîÂõû‰∏Ä‰∏™Áî±Ëøô‰∫õÂØπË±°ÁªÑÊàêÁöÑBabyAGIÊéßÂà∂Âô®ÂØπË±°„ÄÇ\"\"\"\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls, llm: BaseLLM, vectorstore: VectorStore, verbose: bool = False, **kwargs\n",
    "    ) -> \"BabyAGI\":\n",
    "        \"\"\"Initialize the BabyAGI Controller.\"\"\"\n",
    "        task_creation_chain = TaskCreationChain.from_llm(llm, verbose=verbose)\n",
    "        task_prioritization_chain = TaskPrioritizationChain.from_llm(\n",
    "            llm, verbose=verbose\n",
    "        )\n",
    "        llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        tool_names = [tool.name for tool in tools]\n",
    "        agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n",
    "        agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "            agent=agent, tools=tools, verbose=True\n",
    "        )\n",
    "        return cls(\n",
    "            task_creation_chain=task_creation_chain,\n",
    "            task_prioritization_chain=task_prioritization_chain,\n",
    "            execution_chain=agent_executor,\n",
    "            vectorstore=vectorstore,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËøêË°å BabyAGI \n",
    "\n",
    "Áé∞Âú®ÊòØÂàõÂª∫ BabyAGI ÊéßÂà∂Âô®Âπ∂ËßÇÂØüÂÆÉÂ∞ùËØïÂÆûÁé∞ÊÇ®ÁöÑÁõÆÊ†áÁöÑÊó∂ÂÄô‰∫Ü„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTIVE = \"Write a weather report for Beijing today\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging of LLMChains\n",
    "verbose = False\n",
    "# If None, will keep on going forever\n",
    "max_iterations: Optional[int] = 3\n",
    "baby_agi = BabyAGI.from_llm(\n",
    "    llm=llm, vectorstore=vectorstore, verbose=verbose, max_iterations=max_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to come up with a todo list\n",
      "Action: TODO\n",
      "Action Input: Write a weather report for Beijing today\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "\n",
      "1. Research current weather conditions in Beijing\n",
      "2. Gather data on temperature, humidity, wind speed, and other relevant weather conditions\n",
      "3. Research historical weather patterns in Beijing\n",
      "4. Analyze current and historical data to determine any trends\n",
      "5. Write a brief introduction to the weather report\n",
      "6. Describe current weather conditions in Beijing\n",
      "7. Discuss any trends in the weather\n",
      "8. Make predictions about the weather in Beijing for the next 24 hours\n",
      "9. Conclude the report with a summary of the weather conditions\n",
      "10. Proofread and edit the report for accuracy and clarity\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: A todo list for writing a weather report for Beijing today: \n",
      "1. Research current weather conditions in Beijing\n",
      "2. Gather data on temperature, humidity, wind speed, and other relevant weather conditions\n",
      "3. Research historical weather patterns in Beijing\n",
      "4. Analyze current and historical data to determine any trends\n",
      "5. Write a brief introduction to the weather report\n",
      "6. Describe current weather conditions in Beijing\n",
      "7. Discuss any trends in the weather\n",
      "8. Make predictions about the weather in Beijing for the next 24 hours\n",
      "9. Conclude the report with a summary of the weather conditions\n",
      "10. Proofread and edit the report for accuracy and clarity\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "A todo list for writing a weather report for Beijing today: \n",
      "1. Research current weather conditions in Beijing\n",
      "2. Gather data on temperature, humidity, wind speed, and other relevant weather conditions\n",
      "3. Research historical weather patterns in Beijing\n",
      "4. Analyze current and historical data to determine any trends\n",
      "5. Write a brief introduction to the weather report\n",
      "6. Describe current weather conditions in Beijing\n",
      "7. Discuss any trends in the weather\n",
      "8. Make predictions about the weather in Beijing for the next 24 hours\n",
      "9. Conclude the report with a summary of the weather conditions\n",
      "10. Proofread and edit the report for accuracy and clarity\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Gather data on air quality, air pollution, and other relevant environmental conditions\n",
      "3: Research historical air quality patterns in Beijing\n",
      "4: Analyze current and historical data to determine any trends\n",
      "5: Compare current air quality to air quality standards\n",
      "6: Make predictions about the air quality in Beijing for the next 24 hours\n",
      "7: Discuss any trends in the air quality\n",
      "8: Write a brief summary of the air quality in Beijing\n",
      "9: Create a chart or graph to illustrate the air quality data\n",
      "10: Proofread and edit the report for accuracy and clarity\n",
      "1: Research current air quality in Beijing\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Gather data on air quality, air pollution, and other relevant environmental conditions\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for data on air quality, air pollution, and other relevant environmental conditions\n",
      "Action: Search\n",
      "Action Input: air quality, air pollution, and other relevant environmental conditions\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDespite the dramatic progress to date, air pollution continues to threaten Americans' health and welfare. The main obstacles are climate change, ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Despite the dramatic progress to date, air pollution continues to threaten Americans' health and welfare. The main obstacles are climate change, ...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "Despite the dramatic progress to date, air pollution continues to threaten Americans' health and welfare. The main obstacles are climate change, ...\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Compare current air quality to air quality standards\n",
      "4: Make predictions about the air quality in Beijing for the next 24 hours\n",
      "5: Research current air quality in Beijing\n",
      "6: Identify any sources of air pollution in Beijing and their potential impacts on air quality\n",
      "7: Investigate the effectiveness of current air quality regulations in Beijing\n",
      "8: Analyze the impact of climate change on air quality in Beijing\n",
      "9: Compare air quality in Beijing to other cities in China\n",
      "10: Examine the health effects of air pollution in Beijing\n",
      "11: Investigate the economic costs of air pollution in Beijing\n",
      "12: Research the potential solutions to improve air quality in Beijing\n",
      "13: Create a timeline of air quality in Beijing over the past decade\n",
      "14: Discuss any trends in the air quality\n",
      "15: Research historical air quality patterns in Beijing\n",
      "16: Analyze current and historical data to determine any trends\n",
      "17: Write a brief summary of the air quality in Beijing\n",
      "18: Create a chart or graph to illustrate the air quality data\n",
      "19: Proofread and edit the report for accuracy and clarity\n",
      "20: Summarize the findings of the report in a concise\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Compare current air quality to air quality standards\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for air quality standards\n",
      "Action: Search\n",
      "Action Input: air quality standards\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAQI values at or below 100 are generally thought of as satisfactory. When AQI values are above 100, air quality is unhealthy: at first for certain sensitive groups of people, then for everyone as AQI values get higher.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to search for current air quality\n",
      "Action: Search\n",
      "Action Input: current air quality\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mGet air quality data where you live. ; Air Quality Index Scale ; 0 - 50. Good ; 51 - 100. Moderate ; 101 - 150. Unhealthy for Sensitive Groups (USG) ; 151 - 200.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current air quality in Beijing is Unhealthy for Sensitive Groups (USG).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "The current air quality in Beijing is Unhealthy for Sensitive Groups (USG).\n",
      "\u001b[91m\u001b[1m\n",
      "*****TASK ENDING*****\n",
      "\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'Write a weather report for Beijing today'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_agi({\"objective\": OBJECTIVE})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-GPT Assistant "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./autogpt.png\"  height=\"20%\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È¶ñÂÖàÊàë‰ª¨ÂØπAutoGPTÂü∫‰∫élangchainËøõË°åÁõ∏Â∫îÂú∞ÂÆûÁé∞,‰ª•‰æø‰∫ÜËß£ÂÖ∂ÂéüÁêÜ‰∏éÊ≠•È™§"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È¶ñÂÖàÂª∫Á´ãtoolsÔºåÂÆö‰πâsearch tool, write-file tool, read-file tool\n",
    "ÂÆâË£Ö‰∏Ä‰∫õÊàë‰ª¨Ëøô‰∏™Ê†èÁõÆ‰∏≠Âç≥Â∞ÜË¶Å‰ΩøÁî®Âà∞ÁöÑÂ∫ìÂáΩÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install duckduckgo_search\n",
    "%pip install playwright\n",
    "%pip install bs4\n",
    "%pip install nest_asyncio\n",
    "%pip install tiktoken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÈÖçÁΩÆÁ®ãÂ∫èËøêË°å‰ª£ÁêÜ‰ª•ÂèäÁõ∏ÂÖ≥API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ËÆæÁΩÆHTTP‰ª£ÁêÜ\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:xxxx'\n",
    "# ËÆæÁΩÆHTTPS‰ª£ÁêÜ\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:xxxx'\n",
    "\n",
    "# openaiÁöÑkey\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxx\"\n",
    "#Ë∞∑Ê≠åÊêúÁ¥¢apiÁöÑkey,‰ªÖÂú®agent‰∏≠‰ΩøÁî®\n",
    "os.environ['SERPAPI_API_KEY']='--------------Your API KEY----------------------'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰ª•‰∏ãÁöÑ‰ª£Á†ÅÊ≥®ÈáäÁî±‰∫éÂú®Coding Examples‰∏≠Â∑≤ÁªèÂá∫Áé∞ËøáÔºåÂ∞ÜÂØπ‰∫éÈáçÂ§çÁöÑÈÉ®ÂàÜ‰∏çÂÜçÁâπÂà´Ê∑ªÂä†Ê≥®ÈáäËØ¥ÊòéÔºåÂ¶Ç‰æùÁÑ∂ÊúâÁñëÈóÆËØ∑ÂèÇÈòÖÂÆåÊï¥ÁöÑ[Coding Examples](#coding-exampls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools.file_management.write import WriteFileTool\n",
    "from langchain.tools.file_management.read import ReadFileTool\n",
    "\n",
    "\"\"\"\n",
    "ÂÆÉÂàõÂª∫‰∫Ü‰∏Ä‰∏™SerpAPIWrapperÂØπË±°ÔºåÂπ∂Â∞ÜÂÖ∂ËµãÂÄºÁªôÂèòÈáèsearch„ÄÇÁÑ∂ÂêéÔºåÂÆÉÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫‚Äútools‚ÄùÁöÑÂàóË°®ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫Ü\n",
    "‰∏â‰∏™ÂÖÉÁ¥†Ôºö‰∏Ä‰∏™ToolÂØπË±°ÔºåËØ•ÂØπË±°‰ª£Ë°®ÂêçÁß∞‰∏∫‚Äúsearch‚ÄùÁöÑÂ∑•ÂÖ∑Ôºõ‰∏Ä‰∏™WriteFileToolÂØπË±°ÔºõÂíå‰∏Ä‰∏™ReadFileToolÂØπË±°„ÄÇ\n",
    "\"\"\"\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events. You should ask targeted questions\"\n",
    "    ),\n",
    "    WriteFileTool(),\n",
    "    ReadFileTool(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings()\n",
    "import faiss\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.experimental.autonomous_agents.autogpt.agent import AutoGPT\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‰∏ãÈù¢ÊòØ‰ΩøÁî®AutoGPTÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫\"agent\"ÁöÑÊô∫ËÉΩ‰ª£ÁêÜ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËØ•Êô∫ËÉΩ‰ª£ÁêÜÂ∞ÜÊâÆÊºî‰∏Ä‰∏™Âä©ÁêÜÁöÑËßíËâ≤Ôºå\n",
    "Âπ∂‰ΩøÁî®ÊåáÂÆöÁöÑÂ∑•ÂÖ∑ÂíåËØ≠Ë®ÄÊ®°Âûã(Âú®ËøôÈáåÊòØChatOpenAI)Êù•‰∏éÁî®Êà∑ËøõË°å‰∫§‰∫í„ÄÇÂÖ∂‰∏≠ÔºåÂèÇÊï∞ai_nameÊåáÂÆö‰∫ÜÊô∫ËÉΩ\n",
    "‰ª£ÁêÜÁöÑÂêçÁß∞‰∏∫\"Tom\",ai_roleÊåáÂÆö‰∫ÜÂÖ∂ËßíËâ≤‰∏∫Âä©ÁêÜÔºõÂèÇÊï∞toolsÊåáÂÆö‰∫ÜÊô∫ËÉΩ‰ª£ÁêÜÂèØ‰ª•‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑ÂàóË°®ÔºõÂèÇÊï∞\n",
    "llmÊåáÂÆö‰∫ÜÊô∫ËÉΩ‰ª£ÁêÜÁöÑËØ≠Ë®ÄÊ®°Âûã‰∏∫ChatOpenAI,Âπ∂Â∞ÜÂÖ∂Ê∏©Â∫¶ËÆæÁΩÆ‰∏∫0,ËøôÊÑèÂë≥ÁùÄÂÆÉÂ∞ÜÂ∞ΩÂèØËÉΩÂú∞Êèê‰æõÂáÜÁ°ÆÁöÑÂõûÁ≠îÔºõ\n",
    "ÂèÇÊï∞memoryÊåáÂÆö‰∫ÜÊô∫ËÉΩ‰ª£ÁêÜ‰ΩøÁî®ÁöÑÊ£ÄÁ¥¢Âô®‰∏∫vectorstore.as_retriever()„ÄÇ\n",
    "ÈÄöËøáËøôÈÉ®ÂàÜ‰ª£Á†ÅÔºåÊàë‰ª¨ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™ÂÖ∑ÊúâËá™ÂÆö‰πâËßíËâ≤„ÄÅÂ∑•ÂÖ∑ÂíåËØ≠Ë®ÄÊ®°ÂûãÁöÑÊô∫ËÉΩ‰ª£ÁêÜÔºåÂπ∂‰ΩøÁî®ÊåáÂÆöÁöÑÊ£ÄÁ¥¢Âô®Êù•Ëé∑\n",
    "Âèñ‰ø°ÊÅØ„ÄÇ\n",
    "\"\"\"\n",
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"Tom\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    memory=vectorstore.as_retriever()\n",
    ")\n",
    "agent.chain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run([\"make a plan to travel around the China for a month, and give me five advices\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËøêË°å‰ª£Á†ÅÊúÄÁªàÂ∞Ü‰ºöÂú®ÂΩìÂâçÁõÆÂΩï‰∏ãÊñ∞Âª∫Âá∫ÂæàÂ§öÁöÑtxtÊñá‰ª∂ÔºåÂåÖÊã¨‰∏çÈôê‰∫échina_trip_plan.txt, china_info.txt, budge.txt, flight_info.txtÁ≠âÊñá‰ª∂ÔºåÊÇ®ÂèØ‰ª•ÈÄöËøáËøêË°åËØ•noteboook‰ª£Á†ÅËøõË°å‰ΩìÈ™å„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áî±‰∫éËøêË°åËøáÁ®ã‰∏≠ÈúÄË¶ÅfinishÁöÑ‰∏≠Êñ≠ÂëΩ‰ª§ÔºåÂõ†Ê≠§Êàë‰ª¨‰∏äÈù¢ËøêË°åÁöÑÁ®ãÂ∫èÂ∞ÜÈÉ®ÂàÜËøêË°åÁªìÊûúÊîæÁΩÆÂú®ËøôÈáåÔºö\n",
    "OUTÔºö\n",
    "\n",
    "\n",
    "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
    "Prompt after formatting:\n",
    "\u001b[32;1m\u001b[1;3mSystem: You are Tom, Assistant\n",
    "Your decisions must always be made independently without seeking user assistance.\n",
    "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
    "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
    "\n",
    "GOALS:\n",
    "\n",
    "1. make a plan to travel around the China for a month, and give me five advices\n",
    "\n",
    "\n",
    "Constraints:\n",
    "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
    "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
    "3. No user assistance\n",
    "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
    "\n",
    "Commands:\n",
    "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"query\": {\"title\": \"Query\", \"type\": \"string\"}}\n",
    "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}}\n",
    "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
    "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
    "\n",
    "Resources:\n",
    "1. Internet access for searches and information gathering.\n",
    "2. Long Term memory management.\n",
    "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
    "4. File output.\n",
    "\n",
    "Performance Evaluation:\n",
    "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
    "2. Constructively self-criticize your big-picture behavior constantly.\n",
    "3. Reflect on past decisions and strategies to refine your approach.\n",
    "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
    "\n",
    "You should only respond in JSON format as described below \n",
    "Response Format: \n",
    "{\n",
    "    \"thoughts\": {\n",
    "        \"text\": \"thought\",\n",
    "        \"reasoning\": \"reasoning\",\n",
    "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
    "        \"criticism\": \"constructive self-criticism\",\n",
    "        \"speak\": \"thoughts summary to say to user\"\n",
    "    },\n",
    "    \"command\": {\n",
    "        \"name\": \"command name\",\n",
    "        \"args\": {\n",
    "            \"arg name\": \"value\"\n",
    "        }\n",
    "    }\n",
    "} \n",
    "Ensure the response can be parsed by Python json.loads\n",
    "System: The current time and date is Wed Apr 26 16:17:15 2023\n",
    "System: This reminds you of these events from your past:\n",
    "['Assistant Reply: {\"thoughts\": {\"text\": \"I will use the information I retrieved from the affordable accommodations and transportation file to create a budget for my trip. I will use the write_file command to save the budget to a file. Then, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\", \"reasoning\": \"I have retrieved the information I need to create a budget for my trip. I also need to find popular tourist attractions in China and create a packing list. I will use the write_file command to save both the budget and packing list to files.\", \"plan\": \"- Use the information from the affordable accommodations and transportation file to create a budget for my trip.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use the write_file command to save the budget to a file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use the search command to find popular tourist attractions in China and save the information to a file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use the write_file command to save a packing list to a file.\", \"criticism\": \"I need to make sure I am not spending too much time on planning and that I am making progress towards actually traveling to China.\", \"speak\": \"I am going to use the information I retrieved from the affordable accommodations and transportation file to create a budget for my trip. I will use the write_file command to save the budget to a file. Then, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\"}, \"command\": {\"name\": \"write_file\", \"args\": {\"file_path\": \"budget.txt\", \"text\": \"Budget for China Trip:\\\\\\\\nAccommodation: $80 per day\\\\\\\\nTransportation: $3 per day\\\\\\\\nFood: $30 per day\\\\\\\\nTotal: $113 per day\\\\\\\\nTotal for 30 days: $3,390\"}}} \\nResult: Command write_file returned: File written successfully to budget.txt. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"Now that I have all the necessary information saved to files, I can start planning my trip. I will use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China. Then, I will use this information to create a budget for my trip. After that, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\",\\n        \"reasoning\": \"I have all the necessary information saved to files. I can use the information I saved earlier about affordable accommodations and transportation in China to create a budget for my trip. I also need to find popular tourist attractions in China and create a packing list. I will use the write_file command to save both the budget and packing list to files.\",\\n        \"plan\": \"- Use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China.\\\\\\\\\\\\\\\\n- Use this information to create a budget for my trip.\\\\\\\\\\\\\\\\n- Use the search command to find popular tourist attractions in China and save the information to a file.\\\\\\\\\\\\\\\\n- Use the write_file command to save a packing list to a file.\",\\n        \"criticism\": \"I need to make sure I am not spending too much time on planning and that I am making progress towards actually traveling to China.\",\\n        \"speak\": \"Now that I have all the necessary information saved to files, I am going to use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China. Then, I will use this information to create a budget for my trip. After that, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\"\\n    },\\n    \"command\": {\\n        \"name\": \"read_file\",\\n        \"args\": {\\n            \"file_path\": \"china_accommodations_transportation.txt\"\\n        }\\n    }\\n} \\nResult: Command read_file returned: Accommodation: $80 per day; Transportation: $3 per day; Food: $30 per day ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I am going to use the write_file command to save the information I found earlier about affordable accommodations and transportation in China to a file. This will make it easier for me to access the information later when I need it.\", \\n        \"reasoning\": \"I have found affordable accommodations and transportation options for my trip to China. I want to make sure I have easy access to this information later when I need it.\", \\n        \"plan\": \"- Use the write_file command to save the information about affordable accommodations and transportation in China to a file\", \\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually traveling to China.\", \\n        \"speak\": \"I am going to use the write_file command to save the information I found earlier about affordable accommodations and transportation in China to a file.\"\\n    }, \\n    \"command\": {\\n        \"name\": \"write_file\", \\n        \"args\": {\\n            \"file_path\": \"china_info.txt\", \\n            \"text\": \"Accommodation: $80 per day; Transportation: $3 per day; Food: $30 per ...\"\\n        }\\n    }\\n} \\nResult: Command write_file returned: File written successfully to china_info.txt. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I will use the write_file command to save the information about affordable accommodations and transportation in China to a file. Then, I will use the search command to find affordable flights to China and use the write_file command to save the flight information to a file.\",\\n        \"reasoning\": \"I have found information about affordable accommodations and transportation in China using the search command. I need to save this information to a file so that I can refer to it later. I also need to find affordable flights to China and save this information to a file.\",\\n        \"plan\": \"- Use the write_file command to save the information about affordable accommodations and transportation in China to a file.\\\\\\\\\\\\\\\\n- Use the search command to find affordable flights to China and use the write_file command to save the flight information to a file.\",\\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually traveling to China.\",\\n        \"speak\": \"I am going to use the write_file command to save the information about affordable accommodations and transportation in China to a file. Then, I will use the search command to find affordable flights to China and use the write_file command to save the flight information to a file.\"\\n    },\\n    \"command\": {\\n        \"name\": \"write_file\",\\n        \"args\": {\\n            \"file_path\": \"china_accommodations_transportation.txt\",\\n            \"text\": \"Accommodation: $80 per day; Transportation: $3 per day; Food: $30 per day\"\\n        }\\n    }\\n} \\nResult: Command write_file returned: File written successfully to china_accommodations_transportation.txt. ']\n",
    "\n",
    "\n",
    "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n",
    "\n",
    "\u001b[1m> Finished chain.\u001b[0m\n",
    "{\n",
    "    \"thoughts\": {\n",
    "        \"text\": \"Now that I have all the necessary information saved to files, I can start planning my trip. I will use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China. Then, I will use this information to create a budget for my trip. After that, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\",\n",
    "        \"reasoning\": \"I have all the necessary information saved to files. I can use the information I saved earlier about affordable accommodations and transportation in China to create a budget for my trip. I also need to find popular tourist attractions in China and create a packing list. I will use the write_file command to save both the budget and packing list to files.\",\n",
    "        \"plan\": \"- Use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China.\\\\n- Use this information to create a budget for my trip.\\\\n- Use the search command to find popular tourist attractions in China and save the information to a file.\\\\n- Use the write_file command to save a packing list to a file.\",\n",
    "        \"criticism\": \"I need to make sure I am not spending too much time on planning and that I am making progress towards actually traveling to China.\",\n",
    "        \"speak\": \"Now that I have all the necessary information saved to files, I am going to use the read_file command to access the information I saved earlier about affordable accommodations and transportation in China. Then, I will use this information to create a budget for my trip. After that, I will use the search command to find popular tourist attractions in China and save the information to a file. Finally, I will use the write_file command to save a packing list to a file.\"\n",
    "    },\n",
    "    \"command\": {\n",
    "        \"name\": \"read_file\",\n",
    "        \"args\": {\n",
    "            \"file_path\": \"china_accommodations_transportation.txt\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
    "Prompt after formatting:\n",
    "\u001b[32;1m\u001b[1;3mSystem: You are Tom, Assistant\n",
    "Your decisions must always be made independently without seeking user assistance.\n",
    "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
    "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
    "\n",
    "GOALS:\n",
    "\n",
    "1. make a plan to travel around the China for a month, and give me five advices\n",
    "\n",
    "\n",
    "Constraints:\n",
    "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
    "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
    "3. No user assistance\n",
    "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
    "\n",
    "Commands:\n",
    "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"query\": {\"title\": \"Query\", \"type\": \"string\"}}\n",
    "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}}\n",
    "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
    "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
    "\n",
    "Resources:\n",
    "1. Internet access for searches and information gathering.\n",
    "2. Long Term memory management.\n",
    "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
    "4. File output.\n",
    "\n",
    "Performance Evaluation:\n",
    "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
    "2. Constructively self-criticize your big-picture behavior constantly.\n",
    "3. Reflect on past decisions and strategies to refine your approach.\n",
    "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
    "\n",
    "You should only respond in JSON format as described below \n",
    "Response Format: \n",
    "{\n",
    "    \"thoughts\": {\n",
    "        \"text\": \"thought\",\n",
    "        \"reasoning\": \"reasoning\",\n",
    "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
    "        \"criticism\": \"constructive self-criticism\",\n",
    "        \"speak\": \"thoughts summary to say to user\"\n",
    "    },\n",
    "    \"command\": {\n",
    "        \"name\": \"command name\",\n",
    "        \"args\": {\n",
    "            \"arg name\": \"value\"\n",
    "        }\n",
    "    }\n",
    "} \n",
    "Ensure the response can be parsed by Python json.loads\n",
    "System: The current time and date is Wed Apr 26 16:18:07 2023\n",
    "System: This reminds you of these events from your past:\n",
    "['Assistant Reply: {\"thoughts\": {\"text\": \"I will use the search command to find popular tourist attractions in China and save the information to a file. I should make sure to include the location, hours of operation, and admission fees for each attraction. Then, I will use the write_file command to save the information to a file.\", \"reasoning\": \"I need to find popular tourist attractions in China and save the information to a file. I will use the search command to find this information and the write_file command to save it to a file.\", \"plan\": \"- Use the search command to find popular tourist attractions in China and save the information to a file.\\\\\\\\\\\\\\\\n- Use the write_file command to save the information to a file.\", \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually traveling to China.\", \"speak\": \"I am going to use the search command to find popular tourist attractions in China and save the information to a file. Then, I will use the write_file command to save the information to a file.\"}, \"command\": {\"name\": \"search\", \"args\": {\"query\": \"popular tourist attractions in China\"}}} \\nResult: Command search returned: China, officially the People\\'s Republic of China, is a country in East Asia. It has been the world\\'s most populous country since at least 1950, with a population exceeding 1.4 billion, but is expected to be overtaken by India in mid-2023. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I will use the search command to find information about the best places to visit in China. This will help me plan my itinerary for the month.\", \\n        \"reasoning\": \"Now that I have booked my accommodations, transportation, and flights to China, I need to plan my itinerary. I will use the search command to find information about the best places to visit in China.\", \\n        \"plan\": \"- Use the search command to find information about the best places to visit in China\", \\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually traveling to China.\", \\n        \"speak\": \"I am going to use the search command to find information about the best places to visit in China.\"\\n    }, \\n    \"command\": {\\n        \"name\": \"search\", \\n        \"args\": {\\n            \"query\": \"best places to visit in China\"\\n        }\\n    }\\n} \\nResult: Command search returned: China, officially the People\\'s Republic of China, is a country in East Asia. It has been the world\\'s most populous country since at least 1950, with a population exceeding 1.4 billion, but is expected to be overtaken by India in mid-2023. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I need to find the best places to visit in China. I should search for articles or travel guides that list the top tourist destinations in China.\",\\n        \"reasoning\": \"I want to make sure I don\\'t miss any important tourist destinations in China.\",\\n        \"plan\": \"- Search for articles or travel guides that list the top tourist destinations in China\",\\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually planning my trip.\",\\n        \"speak\": \"I am going to search for articles or travel guides that list the top tourist destinations in China.\"\\n    },\\n    \"command\": {\\n        \"name\": \"search\",\\n        \"args\": {\\n            \"query\": \"best tourist destinations in China\"\\n        }\\n    }\\n} \\nResult: Command search returned: China, officially the People\\'s Republic of China, is a country in East Asia. It has been the world\\'s most populous country since at least 1950, with a population exceeding 1.4 billion, but is expected to be overtaken by India in mid-2023. ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I need to start planning my trip to China. I should start by researching the best places to visit and the most efficient way to travel between them.\",\\n        \"reasoning\": \"I need to gather information to make informed decisions about my trip.\",\\n        \"plan\": \"- Research the best places to visit in China\\\\n- Research the most efficient way to travel between destinations\\\\n- Create a rough itinerary for my trip\",\\n        \"criticism\": \"I need to make sure I am not spending too much time on research and that I am making progress towards actually planning my trip.\",\\n        \"speak\": \"I am going to start by researching the best places to visit in China and the most efficient way to travel between them.\"\\n    },\\n    \"command\": {\\n        \"name\": \"search\",\\n        \"args\": {\\n            \"query\": \"best places to visit in China\"\\n        }\\n    }\\n} \\nResult: Command search returned: China, officially the People\\'s Republic of China, is a country in East Asia. It has been the world\\'s most populous country since at least 1950, with a population exceeding 1.4 billion, but is expected to be overtaken by India in mid-2023. ']\n",
    "\n",
    "\n",
    "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â¶Ç‰∏ãÁöÑÁ§∫‰æãÊòØÁî®AutoGPTËøõË°åWinning Marathon TimesÁöÑÊü•Êâæ„ÄÇËØ•Á§∫‰æã‰ª£Á†Å‰∏≠‰ΩøÁî®Âà∞ÁöÑmodelÊòØGPT-4ÔºåÂõ†Ê≠§ÈúÄË¶ÅÊèêÂâçÂáÜÂ§áÂ•ΩGPT-4Ë∞ÉÁî®ÈúÄË¶ÅÁöÑÁéØÂ¢ÉÊù°‰ª∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain.experimental.autonomous_agents.autogpt.agent import AutoGPT\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent\n",
    "from langchain.docstore.document import Document\n",
    "\"\"\"\n",
    "asyncioÊòØ‰∏Ä‰∏™PythonÊ†áÂáÜÂ∫ìÔºåÁî®‰∫éÁºñÂÜôÂºÇÊ≠•‰ª£Á†Å„ÄÇ\n",
    "nest_asyncioÊòØ‰∏Ä‰∏™Á¨¨‰∏âÊñπÂ∫ìÔºåÁî®‰∫éÂú®Python‰∏≠‰ΩøÁî®asyncioÁöÑÈùûÈòªÂ°ûI/OÊìç‰Ωú„ÄÇ\n",
    "Ë∞ÉÁî®nest_asyncio.apply()ÂáΩÊï∞Êù•ËøêË°åÊâÄÊúâÂºÇÊ≠•‰ª£Á†Å„ÄÇ\n",
    "\"\"\"\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import contextmanager\n",
    "from typing import Optional\n",
    "from langchain.agents import tool\n",
    "from langchain.tools.file_management.read import ReadFileTool\n",
    "from langchain.tools.file_management.write import WriteFileTool\n",
    "\n",
    "ROOT_DIR = \"./data/\"\n",
    "\"\"\"\n",
    "pushedÂáΩÊï∞ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫pushdÁöÑ‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®ÔºåÁî®‰∫éÊõ¥ÊîπÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩï„ÄÇÂÆÉÊé•Âèó‰∏Ä‰∏™ÂèÇÊï∞new_dir,Ë°®Á§∫Êñ∞ÁöÑÂ∑•‰ΩúÁõÆÂΩïË∑ØÂæÑ„ÄÇ\n",
    "Âú®ËøõÂÖ•pushd‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®Êó∂ÔºåÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩïÂ∞ÜË¢´‰øùÂ≠ò‰∏∫prev_dir,ÁÑ∂Âêé‰ΩøÁî®os.chdir()ÂáΩÊï∞Â∞ÜÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩïÊõ¥Êîπ‰∏∫new_dir„ÄÇÂú®\n",
    "Á¶ªÂºÄ‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®Êó∂Ôºåprev_dirÂ∞ÜË¢´ÊÅ¢Â§ç‰∏∫ÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩï„ÄÇËøô‰∏™‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®ÂèØ‰ª•Áî®Êù•Âú®ÈúÄË¶ÅÊöÇÊó∂Êõ¥ÊîπÂ∑•‰ΩúÁõÆÂΩïÁöÑÊÉÖÂÜµ‰∏ãÔºå‰øùÊåÅ‰ª£Á†Å\n",
    "‰∏≠Ë∑ØÂæÑÂíåÊñá‰ª∂ÂêçÁöÑÊ≠£Á°ÆÊÄß„ÄÇ‰æãÂ¶ÇÔºåÂú®‰∏Ä‰∏™PythonËÑöÊú¨‰∏≠ÔºåÂèØ‰ª•‰ΩøÁî®pushd‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®Êù•ÂàáÊç¢Âà∞Êï∞ÊçÆÈõÜÊâÄÂú®ÁöÑÁõÆÂΩïÔºåÁÑ∂ÂêéÊâßË°åÊï∞ÊçÆÈ¢Ñ\n",
    "Â§ÑÁêÜÊàñÊ®°ÂûãËÆ≠ÁªÉÁ≠â‰ªªÂä°„ÄÇÂÆåÊàê‰ªªÂä°ÂêéÔºåÂèØ‰ª•‰ΩøÁî®Áõ∏ÂêåÁöÑ‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®Â∞ÜÂ∑•‰ΩúÁõÆÂΩïÂàáÊç¢ÂõûÂéüÂßãÁõÆÂΩï„ÄÇ\n",
    "\"\"\"\n",
    "@contextmanager\n",
    "def pushd(new_dir):\n",
    "    \"\"\"Context manager for changing the current working directory.\"\"\"\n",
    "    prev_dir = os.getcwd()\n",
    "    os.chdir(new_dir)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(prev_dir)\n",
    "\n",
    "\"\"\"\n",
    "ËØ•ÂáΩÊï∞Âêç‰∏∫process_csv,Áî®‰∫éÂ§ÑÁêÜCSVÊñá‰ª∂Âπ∂ÊâßË°å‰∏Ä‰∫õÊìç‰Ωú.\n",
    "Êé•Âèó‰∏â‰∏™ÂèÇÊï∞Ôºöcsv_file_path(Â≠óÁ¨¶‰∏≤Á±ªÂûãÔºåË°®Á§∫CSVÊñá‰ª∂Ë∑ØÂæÑ)\n",
    "instructions(Â≠óÁ¨¶‰∏≤Á±ªÂûãÔºåË°®Á§∫Êåá‰ª§)\n",
    "output_path(ÂèØÈÄâÂ≠óÁ¨¶‰∏≤Á±ªÂûãÔºåË°®Á§∫ËæìÂá∫Ë∑ØÂæÑ)„ÄÇ\n",
    "Âú®ÂáΩÊï∞‰∏≠Ôºå‰ΩøÁî®‰∫ÜpandasÂ∫ìÊù•ËØªÂèñCSVÊñá‰ª∂ÔºåÁÑ∂ÂêéÂàõÂª∫‰∫Ü‰∏Ä‰∏™pandasÊï∞ÊçÆÂ∏ß‰ª£ÁêÜÂØπË±°agent„ÄÇÊé•‰∏ãÊù•ÔºåÊ†πÊçÆ‰º†ÂÖ•ÁöÑÊåá‰ª§ÂØπÊï∞ÊçÆËøõË°åÂ§ÑÁêÜÔºå\n",
    "Âπ∂Â∞ÜÁªìÊûú‰øùÂ≠òÂà∞ÊåáÂÆöÁöÑËæìÂá∫Ë∑ØÂæÑ‰∏≠„ÄÇÂ¶ÇÊûúÂ§ÑÁêÜËøáÁ®ã‰∏≠Âá∫Áé∞ÂºÇÂ∏∏ÔºåÂàôËøîÂõûÈîôËØØ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåËØ•‰ª£Á†ÅËøòÂåÖÂê´‰∫Ü‰∏Ä‰∏™Ê≥®Èáä@tool,ËØ¥ÊòéËØ•ÂáΩÊï∞ÁöÑ‰Ωú\n",
    "Áî®ÊòØÁî®‰∫éÂú®REPLÁéØÂ¢É‰∏≠‰ΩøÁî®pandasÂ§ÑÁêÜCSVÊñá‰ª∂„ÄÇ\n",
    "\"\"\"\n",
    "@tool\n",
    "def process_csv(\n",
    "    csv_file_path: str, instructions: str, output_path: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"Process a CSV by with pandas in a limited REPL.\\\n",
    " Only use this after writing data to disk as a csv file.\\\n",
    " Any figures must be saved to disk to be viewed by the human.\\\n",
    " Instructions should be written in natural language, not code. Assume the dataframe is already loaded.\"\"\"\n",
    "    with pushd(ROOT_DIR):\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "        agent = create_pandas_dataframe_agent(llm, df, max_iterations=30, verbose=True)\n",
    "        if output_path is not None:\n",
    "            instructions += f\" Save output to disk at {output_path}\"\n",
    "        try:\n",
    "            result = agent.run(instructions)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_load_playwright(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Âä†ËΩΩÊåáÂÆöÁöÑURLÂπ∂‰ΩøÁî®PlaywrightËß£Êûê‰∏∫BeautifulSoupÂØπË±°„ÄÇ\n",
    "    ÂèÇÊï∞Ôºö\n",
    "        url (str): Ë¶ÅÂä†ËΩΩÂíåËß£ÊûêÁöÑURL„ÄÇ\n",
    "    ËøîÂõûÂÄºÔºö\n",
    "        str: Ëß£ÊûêÂêéÁöÑHTMLÊñáÊú¨„ÄÇ\n",
    "    \"\"\"\n",
    "    from bs4 import BeautifulSoup\n",
    "    from playwright.async_api import async_playwright\n",
    "\n",
    "    # Â≠òÂÇ®Ëß£ÊûêÂêéÁöÑHTMLÊñáÊú¨\n",
    "    results = \"\" \n",
    "    #‰ΩøÁî®async withËØ≠Âè•ÂàõÂª∫‰∏Ä‰∏™‰∏ä‰∏ãÊñáÁéØÂ¢ÉÔºåËá™Âä®ÂÖ≥Èó≠ÊµèËßàÂô®ÂÆû‰æã\n",
    "    async with async_playwright() as p:\n",
    "        #Âú®Êó†Â§¥Ê®°Âºè‰∏ãÂêØÂä®ChromiumÊµèËßàÂô®ÂÆû‰æã\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        try:\n",
    "            #ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÈ°µÈù¢ÂÆû‰æã\n",
    "            page = await browser.new_page()\n",
    "            #Âä†ËΩΩÊåáÂÆöÁöÑURL\n",
    "            await page.goto(url)\n",
    "\n",
    "            #Ëé∑ÂèñÈ°µÈù¢Ê∫ê‰ª£Á†Å\n",
    "            page_source = await page.content()\n",
    "            #Â∞ÜÈ°µÈù¢Ê∫ê‰ª£Á†ÅËß£Êûê‰∏∫BeautifulSoupÂØπË±°\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "            #‰ªéHTML‰∏≠ÊèêÂèñÊâÄÊúâËÑöÊú¨ÂíåÊ†∑ÂºèÊ†áÁ≠æÁöÑÂÜÖÂÆπ\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.extract()\n",
    "\n",
    "            #‰ªéHTML‰∏≠ÊèêÂèñÁ∫ØÊñáÊú¨ÂÜÖÂÆπ\n",
    "            text = soup.get_text()\n",
    "            #Â∞ÜÊñáÊú¨ÊåâË°åÂàÜÂâ≤Âπ∂ÂéªÈô§Á©∫Ê†º\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            #Â∞ÜÊñáÊú¨ÊåâÂçïËØçÊàñÁ©∫Ê†ºÂàÜÂâ≤Âπ∂ÂéªÈô§Á©∫Ê†º\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            #Â∞ÜÁªìÊûúÊãºÊé•ÊàêÂ≠óÁ¨¶‰∏≤Âπ∂ÂéªÈô§Á©∫Ê†º\n",
    "            results = \"\\n\".join(chunk for chunk in chunks if chunk)\n",
    "        except Exception as e:\n",
    "            #Â¶ÇÊûúÂá∫Áé∞ÂºÇÂ∏∏ÔºåÂ∞ÜÈîôËØØ‰ø°ÊÅØÊ∑ªÂä†Âà∞ÁªìÊûúÂ≠óÁ¨¶‰∏≤‰∏≠\n",
    "            results = f\"Error: {e}\"\n",
    "        #ÂÖ≥Èó≠ÊµèËßàÂô®ÂÆû‰æã\n",
    "        await browser.close()\n",
    "    #ËøîÂõûËß£ÊûêÂêéÁöÑHTMLÊñáÊú¨\n",
    "    return results\n",
    "#ÂÆö‰πâ‰∏Ä‰∏™ÂºÇÊ≠•ÂáΩÊï∞ÔºåÁî®‰∫éËøêË°åÁ∫øÁ®ã\n",
    "def run_async(coro):\n",
    "    #Ëé∑Âèñ‰∫ã‰ª∂Âæ™ÁéØÂØπË±°\n",
    "    event_loop = asyncio.get_event_loop()\n",
    "    #ËøêË°åÂçèÁ®ãÂπ∂ËøîÂõûÁªìÊûú\n",
    "    return event_loop.run_until_complete(coro)\n",
    "\n",
    "#ÂÆö‰πâ‰∏Ä‰∏™Â∑•ÂÖ∑ÂáΩÊï∞ÔºåÁî®‰∫éÊµèËßàÁΩëÈ°µ\n",
    "#‰ª•ÂÜóÈïøÁöÑÊñπÂºèÊäìÂèñÊï¥‰∏™ÁΩëÈ°µ„ÄÇÂæàÂèØËÉΩ‰ºöÂØºËá¥Ëß£ÊûêÈóÆÈ¢ò\n",
    "@tool\n",
    "def browse_web_page(url: str) -> str:\n",
    "    \"\"\"Ë∞ÉÁî®ÂºÇÊ≠•ÂáΩÊï∞ÔºåÂä†ËΩΩÊåáÂÆöÁöÑURLÂπ∂Ëß£Êûê‰∏∫BeautifulSoupÂØπË±°\"\"\"\n",
    "    return run_async(async_load_playwright(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool, DuckDuckGoSearchTool\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from pydantic import Field\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain, BaseCombineDocumentsChain\n",
    "\n",
    "\"\"\"\n",
    "ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫_get_text_splitter()ÁöÑÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞ËøîÂõû‰∏Ä‰∏™RecursiveCharacterTextSplitterÂØπË±°„ÄÇ\n",
    "Ëøô‰∏™ÂØπË±°ÊòØ‰∏Ä‰∏™Áî®‰∫éÂ∞ÜÊñáÊú¨ÂàÜÂâ≤ÊàêÊõ¥Â∞èÈÉ®ÂàÜÁöÑÂ∑•ÂÖ∑„ÄÇÂú®ÂáΩÊï∞‰∏≠ÔºåÊàë‰ª¨ËÆæÁΩÆ‰∫Ü‰∏Ä‰∫õÂèÇÊï∞Êù•ÊéßÂà∂ÂàÜÂâ≤ÁöÑË°å‰∏∫Ôºå‰æãÂ¶ÇÂùóÁöÑÂ§ßÂ∞è„ÄÅ\n",
    "Âùó‰πãÈó¥ÁöÑÈáçÂè†Â§ßÂ∞è‰ª•ÂèäÊåáÂÆöÈïøÂ∫¶ÂáΩÊï∞„ÄÇËøô‰∫õÂèÇÊï∞ÂèØ‰ª•Ê†πÊçÆÂÖ∑‰ΩìÁöÑÈúÄÊ±ÇËøõË°åË∞ÉÊï¥„ÄÇ\n",
    "\"\"\"\n",
    "def _get_text_splitter():\n",
    "    return RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap  = 20,\n",
    "        length_function = len,\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫WebpageQAToolÁöÑÁ±ªÔºåËØ•Á±ªÁªßÊâøËá™BaseToolÁ±ª„ÄÇÂú®Á±ª‰∏≠ÔºåÊàë‰ª¨ÂÆö‰πâ‰∫Ü‰∏Ä‰∫õÂ±ûÊÄßÂíåÊñπÊ≥ïÔºåÁî®‰∫éÂÆûÁé∞ÊµèËßàÁΩëÈ°µÂπ∂ÊèêÂèñÊñáÊú¨‰ø°ÊÅØÁöÑÂäüËÉΩ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå\n",
    "Êàë‰ª¨ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫text_splitterÁöÑÂ±ûÊÄßÔºåÁî®‰∫éÂ≠òÂÇ®ÊñáÊú¨ÂàÜÂâ≤Âô®ÂØπË±°ÔºõÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫qa_chainÁöÑÂ±ûÊÄßÔºåÁî®‰∫éÂ≠òÂÇ®qaÈìæÂØπË±°ÔºõÂÆûÁé∞‰∫ÜrunÊñπÊ≥ïÂíåÂºÇÊ≠•runÊñπ\n",
    "Ê≥ïÔºåÂàÜÂà´Áî®‰∫éÊâßË°åÂÖ∑‰Ωì‰ªªÂä°ÁöÑÈÄªËæë„ÄÇÂú®runÊñπÊ≥ï‰∏≠ÔºåÊàë‰ª¨È¶ñÂÖàË∞ÉÁî®browse_web_page.runÊñπÊ≥ïÊµèËßàÁΩëÈ°µÂπ∂ÊèêÂèñÊñáÊú¨‰ø°ÊÅØ„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨Â∞ÜÊèêÂèñÂà∞ÁöÑÊñáÊú¨‰ø°ÊÅØÂ≠òÂÇ®\n",
    "Âú®‰∏Ä‰∏™DocumentÂØπË±°‰∏≠ÔºåÂπ∂‰ΩøÁî®text_splitterÂØπË±°ÂØπÂÖ∂ËøõË°åÂàÜÂâ≤„ÄÇÊúÄÂêéÔºåÊàë‰ª¨‰ΩøÁî®qa_chainÂØπË±°ÂØπÂàÜÂâ≤ÂêéÁöÑÊñáÊ°£ËøõË°åÂ§ÑÁêÜÔºåÂπ∂ËøîÂõûÁªìÊûú„ÄÇÂú®ÂºÇÊ≠•runÊñπÊ≥ï\n",
    "‰∏≠ÔºåÊàë‰ª¨ÂêåÊ†∑Ë∞ÉÁî®browse_web_page.runÊñπÊ≥ïÊµèËßàÁΩëÈ°µÂπ∂ÊèêÂèñÊñáÊú¨‰ø°ÊÅØ„ÄÇ‰ΩÜÊòØÔºåÁî±‰∫éÂºÇÊ≠•Êìç‰ΩúÈúÄË¶ÅÁ≠âÂæÖ‰ªªÂä°ÂÆåÊàêÊâçËÉΩÁªßÁª≠ÊâßË°å‰∏ã‰∏ÄÊ≠•Êìç‰ΩúÔºåÂõ†Ê≠§Êàë‰ª¨ÈúÄË¶ÅÂú®ÂáΩ\n",
    "Êï∞‰∏≠‰ΩøÁî®awaitÂÖ≥ÈîÆÂ≠óÊù•Á≠âÂæÖ‰ªªÂä°ÁöÑÂÆåÊàê„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåÁõÆÂâçÂú®ÂºÇÊ≠•runÊñπÊ≥ï‰∏≠ËøòÂ≠òÂú®‰∏Ä‰∫õÊú™ÂÆûÁé∞ÁöÑÂäüËÉΩ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Âú®ÂáΩÊï∞Êú´Â∞æ‰ΩøÁî®‰∫Ü\n",
    "raise NotImplementedErrorËØ≠Âè•ÔºåËøôË°®Á§∫Â∞öÊú™ÂÆûÁé∞ËØ•ÊñπÊ≥ï„ÄÇÂõ†Ê≠§ÔºåÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÔºåÂ¶ÇÊûúÈúÄË¶Å‰ΩøÁî®ÂºÇÊ≠•runÊñπÊ≥ïÔºåÂàôÈúÄË¶ÅÂÖàÂÆåÊàêÊú™ÂÆûÁé∞ÁöÑÈÉ®ÂàÜ„ÄÇ\n",
    "\"\"\"\n",
    "class WebpageQATool(BaseTool):\n",
    "    #ÂÆö‰πâÁ±ªÂêçÂíåÊèèËø∞‰ø°ÊÅØ\n",
    "    name = \"query_webpage\"\n",
    "    description = \"Browse a webpage and retrieve the information relevant to the question.\"\n",
    "    #ÂÆö‰πâ‰∏Ä‰∏™Âêç‰∏∫text_splitterÁöÑÂ±ûÊÄßÔºåÁî®‰∫éÂ≠òÂÇ®ÊñáÊú¨ÂàÜÂâ≤Âô®ÂØπË±°\n",
    "    text_splitter: RecursiveCharacterTextSplitter = Field(default_factory=_get_text_splitter)\n",
    "    #ÂÆö‰πâ‰∏Ä‰∏™Âêç‰∏∫qa_chainÁöÑÂ±ûÊÄßÔºåÁî®‰∫éÂ≠òÂÇ®qaÈìæÂØπË±°\n",
    "    qa_chain: BaseCombineDocumentsChain\n",
    "\n",
    "    #ÂÆûÁé∞runÊñπÊ≥ïÔºåÁî®‰∫éÊâßË°åÂÖ∑‰Ωì‰ªªÂä°ÁöÑÈÄªËæë\n",
    "    def _run(self, url: str, question: str) -> str:\n",
    "        \"\"\"ÊµèËßàÁΩëÁ´ôÂπ∂ÊèêÂèñÊñáÊú¨‰ø°ÊÅØ\"\"\"\n",
    "        result = browse_web_page.run(url)\n",
    "        docs = [Document(page_content=result, metadata={\"source\": url})]\n",
    "        web_docs = self.text_splitter.split_documents(docs)\n",
    "        results = []\n",
    "        # TODO: ÂÆûÁé∞MapReduceChainÁöÑÁõ∏ÂÖ≥ÂäüËÉΩ\n",
    "        for i in range(0, len(web_docs), 4):\n",
    "            input_docs = web_docs[i:i+4]\n",
    "            window_result = self.qa_chain({\"input_documents\": input_docs, \"question\": question}, return_only_outputs=True)\n",
    "            results.append(f\"Response from window {i} - {window_result}\")\n",
    "        results_docs = [Document(page_content=\"\\n\".join(results), metadata={\"source\": url})]\n",
    "        return self.qa_chain({\"input_documents\": results_docs, \"question\": question}, return_only_outputs=True)\n",
    "    \n",
    "    #ÂÆûÁé∞ÂºÇÊ≠•runÊñπÊ≥ïÔºåÁî®‰∫éÊâßË°åÂÖ∑‰Ωì‰ªªÂä°ÁöÑÈÄªËæë\n",
    "    async def _arun(self, url: str, question: str) -> str:\n",
    "        raise NotImplementedError\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_website_tool = WebpageQATool(qa_chain=load_qa_with_sources_chain(llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.tools.human.tool import HumanInputRun\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install duckduckgo_search\n",
    "web_search = DuckDuckGoSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    web_search,\n",
    "    WriteFileTool(root_dir=\"./data\"),\n",
    "    ReadFileTool(root_dir=\"./data\"),\n",
    "    process_csv,\n",
    "    query_website_tool,\n",
    "    # human_in_the_loop=True, # Â¶ÇÊûúË¶ÅÂú®ÊØè‰∏™Ê≠•È™§‰∏≠Ê∑ªÂä†ÂèçÈ¶àÔºåËØ∑Â∞ÜÂÖ∂ËÆæÁΩÆ‰∏∫True„ÄÇ\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"Tom\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=vectorstore.as_retriever(search_kwargs={\"k\": 8}),\n",
    "    # human_in_the_loop=True, # Â¶ÇÊûúË¶ÅÂú®ÊØè‰∏™Ê≠•È™§‰∏≠Ê∑ªÂä†ÂèçÈ¶àÔºåËØ∑Â∞ÜÂÖ∂ËÆæÁΩÆ‰∏∫True„ÄÇ\n",
    ")\n",
    "# agent.chain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run([\"What were the winning boston marathon times for the past 5 years (ending in 2022)? Generate a table of the year, name, country of origin, and times.\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåπ ‰∏äËø∞ÂÜÖÂÆπÊù•Ëá™‰∫é[LangChainÂÆòÁΩëÊïôÁ®ã](https://python.langchain.com/en/latest/index.html)Âπ∂ÊúâÈÄÇÂΩìÁöÑÊõ¥ÊîπÔºåÂ¶ÇÊúâÂïÜ‰∏öÂåñÁ≠âË°å‰∏∫Êàë‰ª¨‰ºöÁâπÂà´ËØ¥Êòé„ÄÇËØ•ÊñáÊ°£ËØ∑ÂãøÈöèÊÑèËΩ¨ËΩΩÔºåÂ¶ÇÊúâÁõ∏ÂÖ≥Âª∫ËÆÆÊàñËÄÖÊõ¥ÊîπÈúÄÊ±ÇÔºåËØ∑‰∏é[Êàë‰ª¨ÂèñÂæóËÅîÁ≥ª‚úâÔ∏è](helloegoalpha@gmail.com)ÔºåÂÜçÊ¨°ÊÑüË∞¢ÔºÅ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
