# ðŸ’¥ History News

## 2023

**[2023.4.21]**

- Paper: [Progressive-Hint Prompting Improves Reasoning in Large Language Models](https://arxiv.org/pdf/2304.09797.pdf)

**[2023.4.20]**

- [Google DeepMind: Bringing together two world-class AI teams](https://blog.google/technology/ai/april-ai-update/)

- Paper: [Visual Instruction Tuning](https://arxiv.org/pdf/2304.08485.pdf)

**[2023.4.19]** 
    
- Paper: [Towards Robust Prompts on Vision-Language Models](https://arxiv.org/pdf/2304.08479.pdf)

**[2023.4.18]**
-   [HuaTuo:Tunning LLaMA Model with chinese medical instructions](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese)
-   MiniGPT-4 [[Project Page](https://minigpt-4.github.io/)/[Paper](https://github.com/Vision-CAIR/MiniGPT-4/blob/main/MiniGPT_4.pdf)]

- Paper: 
        [Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text](https://arxiv.org/abs/2304.06939 )

**[2023.4.17]** 
- The open source democratizes large language models,**OpenAssistant**, supports 35 languages, and can use RLHF data for free[[Project Page](https://open-assistant.io/chat)/[Code](ttps://github.com/LAION-AI/Open-Assistant)/[Paper](https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view )]

- Paper: [Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition](https://arxiv.org/pdf/2304.04704.pdf)

**[2023.4.16]** 
- Paper: [AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models](https://arxiv.org/pdf/2304.06364.pdf)

**[2023.4.15]** 
- Paper: [CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society](https://arxiv.org/abs/2303.17760)

- [Visual Med-Alpaca: Bridging Modalities in Biomedical Language Models](https://cambridgeltl.github.io/visual-med-alpaca/)

**[2023.4.14]**

- [Amazon announcing new tools for building with Generative AI](https://aws.amazon.com/cn/blogs/machine-learning/announcing-new-tools-for-building-with-generative-ai-on-aws/)

- Paper: [ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning](https://arxiv.org/pdf/2304.05613.pdf)

**[2023.4.13]** Three Amazing Works:

- AutoGPT: An Autonomous GPT-4 Experiment ðŸ‘‰[Code](https://github.com/torantulino/auto-gpt)ðŸ‘ˆ

- [Databricks releases Dolly 2.0, the first open, instruction-following LLM for commercial use](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)

- [Microsoft released the DeepSpeed Chat: Own your ChatGPT](https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-chat)

**[2023.4.12]** [OpenAGI: When LLM Meets Domain Experts](https://arxiv.org/pdf/2304.04370.pdf)

**[2023.4.11]** [Why think step-by-step? Reasoning emerges from the locality of experience](https://arxiv.org/pdf/2304.03843.pdf)

**[2023.4.10]** [TagGPT: Large Language Models are Zero-shot Multimodal Taggers](https://arxiv.org/pdf/2304.03022.pdf)

**[2023.4.9]** A new AI model from Meta AI: Segment Anything Model (SAM) ([Paper](https://arxiv.org/pdf/2304.02643.pdf)/[Code](https://github.com/facebookresearch/segment-anything))

**[2023.4.8]** EleutherAI&Yale et al. proposed a large-scale language model analysis suite that spans training and extension: Pythia ([Paper](https://arxiv.org/pdf/2304.01373.pdf)/[Code](https://github.com/EleutherAI/pythia))

**[2023.4.7]** [Stanford releases the 7 billion parameter open-source model Vicuna-7B, which is compact, efficient, but powerful in functionality](https://vicuna.lmsys.org/)

**[2023.4.6]** [Effective Theory of Transformers at Initialization](https://arxiv.org/pdf/2304.02034.pdf)

**[2023.4.5]** [REFINER: Reasoning Feedback on Intermediate Representations](https://arxiv.org/pdf/2304.01904.pdf)

**[2023.4.4]** [Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence?](https://arxiv.org/pdf/2303.18240.pdf)

**[2023.4.3]** [Self-Refine: Iterative Refinement with Self-Feedback](https://arxiv.org/pdf/2303.17651.pdf)

**[2023.4.1]** [A survey of Large Language Models](https://arxiv.org/abs/2303.18223)

**[2023.3.31]** [BloombergGPT: A Large Language Model for Finance](https://arxiv.org/pdf/2303.17564.pdf)

**[2023.3.30]** [GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment](https://arxiv.org/pdf/2303.16634.pdf)

**[2023.3.29]** [LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention](https://arxiv.org/pdf/2303.16199.pdf.)

**[2023.3.28]** [ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks](https://arxiv.org/pdf/2303.15056.pdf)

**[2023.3.27]** [Scaling Expert Language Models with Unsupervised Domain Discovery](https://arxiv.org/pdf/2303.14177.pdf)
 
**[2023.3.26]** [CoLT5: Faster Long-Range Transformers with Conditional Computation](https://arxiv.org/pdf/2303.09752.pdf)

**[2023.3.23]** [OpenAI announces 'Plug-ins' for ChatGPT that enable it to perform actions beyond text.](https://platform.openai.com/docs/plugins/introduction)

**[2023.3.22]** [GitHub launches Copilot X, aiming at the future of AI-powered software development.](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/) 

**[2023.3.21]** [Google Bard is now available in the US and UK, w/ more countries to come.](https://bard.google.com) 

**[2023.3.20]** OpenAIâ€™s new paper looks at the economical impact of LLMs+Labor Market.[GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models](https://arxiv.org/pdf/2303.10130.pdf) 

**[2023.3.17]** [Microsoft 365 Copilot released. Word, Excel, PowerPoint, Outlook powered by LLMs.](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/)

**[2023.3.16]**  Baidu announcing the LLM named ["æ–‡å¿ƒä¸€è¨€"(ERNIE3.0 + PLATO)](https://yiyan.baidu.com/welcome) 

**[2023.3.15]** Two Breaking News:
    -  Announcing [GPT4](https://openai.com/product/gpt-4) by OpenAI from Microsoft. **[PaperðŸ”—](https://cdn.openai.com/papers/gpt-4.pdf)**
    -  Announcing [PaLM](https://developers.googleblog.com/2023/03/announcing-palm-api-and-makersuite.html) API by Google. 

**[2023.3.13]** [LLaMA has been fine-tuned by Stanford](https://github.com/tatsu-lab/stanford_alpaca)

**[2023.3.10]** [Announcing OpenChatKit by Together](https://huggingface.co/spaces/togethercomputer/OpenChatKit)

**[2023.3.9]**  GPT-4 is coming next week and it will be multimodal,announced by OpenAI.

**[2023.3.8]** [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models](https://arxiv.org/abs/2303.04671)

**[2023.3.7]** [Larger language models do in-context learning differently](https://arxiv.org/abs/2303.03846)

**[2023.3.6]** [Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning](https://arxiv.org/abs/2303.02861)