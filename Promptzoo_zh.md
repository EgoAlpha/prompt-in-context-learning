# üî• Ê∏∏‰πêÂú∫
ÊÇ®ÂèØ‰ª•‰ΩøÁî®ÂàóË°®‰∏≠ÁöÑÊ®°Âûã‰ΩìÈ™åÊàñÂÆåÊàêÊÇ®ÁöÑÂ∑•‰ΩúÂÜÖÂÆπ„ÄÇ

| Ê®°ÂûãÂêçÁß∞  | Ê°ÜÊû∂Á±ªÂûã | Âá∫Â§Ñ | Â§ßÊ®°Âûã‰∏ªÈ°µ| ÂèÇÊï∞Èáè(B) |ËÆ∫Êñá/‰ª£Á†Å|
| ---- | ---- | ----  | ---- | ---- |----|
| ChatGPT | Decoder| OpenAI | [here](https://chat.openai.com) | 175 |[Paper](https://arxiv.org/abs/2005.14165)/ [Code]()|
| GPT-JT | Decoder | Together | [here](https://huggingface.co/spaces/togethercomputer/GPT-JT) | 6 |-/[Code](https://huggingface.co/togethercomputer/GPT-JT-6B-v1)|
| Flan-T5 | Encoder-Decoder | Google Research | [here](https://huggingface.co/google/flan-t5-xxl?text=Please+answer+the+following+question+What+is+the+boiling+point+of+Nitrogen%3F) | 11|[Paper](https://arxiv.org/abs/2210.11416)/-|
| CodeGeeX | Decoder | Tsinghua | [here](https://huggingface.co/spaces/THUDM/CodeGeeX) | 13 | -|-/[Code](https://github.com/THUDM/CodeGeeX)|
| GLM-130B | Encoder-Decoder | Tsinghua & Zhipu | [here](https://huggingface.co/spaces/THUDM/GLM-130B) | 130 |[Paper](https://arxiv.org/abs/2210.02414)/-|
| BLOOM(tr11-176B-ml) | Decoder | BigScience | [here](https://huggingface.co/spaces/huggingface/bloom_demo) | 176|-/[Code](https://github.com/bigscience-workshop/bigscience/tree/master/train/tr11-176B-ml)|
| ERNIE3.0 | Encoder-Decoder | Baidu | [here](https://huggingface.co/swtx/ernie-3.0-base-chinese) | 10|[Paper](https://arxiv.org/abs/2112.12731)/-|
| CodeT5 | Encoder-Decoder | Salesforce Research Asia | **[here](Huggingface)** | small:0.06,base:0.22|[Paper](https://arxiv.org/abs/2109.00859)/-|
| CodeX | Decoder | OpenAI | **[here](Playground)** | 12|[Paper](https://arxiv.org/abs/2107.03374)/-|
| GPT-3 | Decoder | OpenAI | **[here](Playground,Emerson)** | 175|[Paper](https://arxiv.org/abs/2005.14165)/-|
| T5 | Encoder-Decoder | Google | **[here](huggingface)** | 11|[Paper](https://arxiv.org/abs/1910.10683)/-|
| RoBERTa | Encoder | MetaAI | **[here](huggingface)** | 0.355|[Paper](https://arxiv.org/abs/1907.11692)/-|
| GPT-2 | Decoder| OpenAI | **[here](huggingface)** | 1.5|[Paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)/-|
| GPT-1 | Decoder| OpenAI | **[here](huggingface)** | 0.117|[Paper](https://gwern.net/doc/www/s3-us-west-2.amazonaws.com/d73fdc5ffa8627bce44dcda2fc012da638ffb158.pdf)/-|
| BERT | Encoder | Google | **[here](huggingface)** | 0.3|[Paper](https://arxiv.org/abs/1810.04805)/-|

| Ê®°ÂûãÂêçÁß∞  | Ê°ÜÊû∂Á±ªÂûã | Âá∫Â§Ñ | Â§ßÊ®°Âûã‰∏ªÈ°µ| ÂèÇÊï∞Èáè(B) |ËÆ∫Êñá/‰ª£Á†Å|
| ---- | ---- | ----  | ---- | ---- |----|
| OPT-IML | Decoder| MetaAI | [here](https://github.com/facebookresearch/metaseq/tree/main/projects/OPT-IML) | 175|[Paper](https://arxiv.org/pdf/2212.12017.pdf)/-|
| ERNIE-Code | Encoder-Decoder | Baidu | [here](https://github.com/thunlp/ERNIE) | 0.56|[Paper](https://arxiv.org/abs/2212.06742#baidu)/-|
| Galactica | Decoder| MetaAI | [here](https://galactica.org/) | 120|[Paper](https://galactica.org/static/paper.pdf)/-|
| mT0 | Encoder-Decoder | BigScience | [here](https://github.com/bigscience-workshop/xmtf) | 13|[Paper](https://arxiv.org/abs/2211.01786)/-|
| BLOOMZ | Decoder | BigScience | [here](https://github.com/bigscience-workshop/xmtf)| 176|[Paper](https://arxiv.org/abs/2211.01786)/-|
| RETRO | Encoder-Decoder | DeepMind | [here](https://github.com/lucidrains/RETRO-pytorch) | 7.5|[Paper](https://arxiv.org/abs/2112.04426)/-|
| FLAN | Encoder-Decoder | Google | [here](https://github.com/google-research/FLAN) | 137|[Paper](https://arxiv.org/abs/2109.01652)/-|

| Ê®°ÂûãÂêçÁß∞  | Ê°ÜÊû∂Á±ªÂûã | Âá∫Â§Ñ | Â§ßÊ®°Âûã‰∏ªÈ°µ| ÂèÇÊï∞Èáè(B) |ËÆ∫Êñá/‰ª£Á†Å|
| ---- | ---- | ----  | ---- | ---- |----|
| GPT-4 | Unreleased | OpenAI | **Unreleased** | **TBA**|-/-|
| LLaMA-65B| Decoder | MetaAI | [here](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/) | 65|[Paper](https://scontent-hkg4-1.xx.fbcdn.net/v/t39.8562-6/333078981_693988129081760_4712707815225756708_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=4srK2r5szdYAX8tuGSV&_nc_ht=scontent-hkg4-1.xx&oh=00_AfAUdcLc_-aVJHTm60I_1mIOLIEcecJ1N9s8-G4drVrd3Q&oe=6409B2E2)/ [Code](https://github.com/facebookresearch/llama)|
| MOSS| Decoder | Fudan University | [here](https://moss.fastnlp.top/) | 20|[Paper]()/ [Code](https://github.com/txsun1997/MOSS)|
|FLAME | Encoder-Decoder | Microsoft | [here](https://www.theregister.com/2023/02/04/microsoft_excel_ai/)| 0.06|[Paper](https://arxiv.org/abs/2301.13779)/ [Code]()|
| Med-PaLM | Encoder | Google & DeepMind | [here](https://gpt3demo.com/apps/med-palm) | 540|[Paper](https://arxiv.org/abs/2212.13138)/ [Code]|
| RL-CAI | Encoder| Anthropic | [here](https://lifearchitect.ai/anthropic/) | 52|[Paper](https://arxiv.org/abs/2212.08073)/ [Code]()|
| Sparrow | Decoder | DeepMind | [here](https://www.deepmind.com/blog/building-safer-dialogue-agents) | 70|[Paper](https://storage.googleapis.com/deepmind-media/DeepMind.com/Authors-Notes/sparrow/sparrow-final.pdf)/-|
| PaLI | Encoder-Decoder | Google | [here](https://ai.googleblog.com/2022/09/pali-scaling-language-image-learning-in.html) | 17|[Paper](https://arxiv.org/abs/2209.06794)/-|
| Atlas | Encoder-Decoder | MetaAI | [here](https://github.com/facebookresearch/atlas) | 11|[Paper](https://arxiv.org/abs/2208.03299)/-|
| Gato(Cat) | Encoder-Decoder | DeepMind | [here](https://www.deepmind.com/blog/a-generalist-agent) | 1|[Paper](https://storage.googleapis.com/deepmind-media/A%20Generalist%20Agent/Generalist%20Agent.pdf)/-|
| OPT-175B | Decoder  | MetaAI | **[here](HF¬†(train/deploy))** | 175|[Paper](https://arxiv.org/abs/2205.01068)/-|
| PaLM | Decoder | Google Research | [here](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html) | 540|[Paper](https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf)/-|
| Chinchilla | Encoder | DeepMind | [here](https://deepmind.github.io/dramatron/details.html) | 70|[Paper](https://arxiv.org/abs/2203.15556)/-|
| GPT-NeoX-20B | Decoder | EleutherAI | **[here](LabML,¬†Forefront,¬†TS,¬†Goose)** | 20|[Paper](https://arxiv.org/abs/2204.06745)/-|
| Gopher | Encoder  | DeepMind | [here](https://www.deepmind.com/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval) | 280|[Paper](https://arxiv.org/abs/2112.11446)/-|
| GLaM | Encoder | Google Inc | [here](https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html) | 1200|[Paper](https://arxiv.org/abs/2112.06905)/-|
| LaMDA | Decoder | GoogleAI |[here](https://www.youtube.com/watch?v=aUSSfo5nCdM)| 137|[Paper](https://arxiv.org/abs/2201.08239)/-|
|