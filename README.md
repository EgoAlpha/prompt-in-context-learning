<div align="center">


<img src="./figures/Prompt-EgoAlpha_white.svg" width="600px">

 <div align="center">

 [![Typing SVG](https://readme-typing-svg.demolab.com?font=Fira+Code&weight=500&size=30&duration=2500&pause=500&color=8D589A&background=FCFCFF00&center=true&vCenter=true&width=500&lines=Hello!+Human%2C+Are+You+Ready%3F;Welcome+to+my+world!)]()
 
 </div>

**An Open-Source Engineering Guide for Prompt-in-context-learning from EgoAlpha Lab.**

<img width="200%" src="./figures/hr.gif" />

<!-- <h3 align="center">

    <p>Resources for prompt learning and engineering; Mastery of LLMs like ChatGPT, GPT3, FlanT5, etc.</p>

</h3> -->

<h4 align="center">
    <p>
        <a href="./README.md">English</a> |
        <a href="./chatgptprompt_zh.md">ÁÆÄ‰Ωì‰∏≠Êñá</a>
    <p>
</h4>

<p align="center">

  <a href="#üìú-papers">üìù Papers</a> |
  <a href="./Playground.md">‚ö°Ô∏è  Playground</a> |
  <a href="./PromptEngineering.md">üõ† Prompt Engineering</a> |
  <a href="./chatgptprompt.md">üåç ChatGPT Prompt</a> 

</p>

</div>

<div align="center">

<!-- ![Build](https://img.shields.io/appveyor/build/gruntjs/grunt) -->

![version](https://img.shields.io/badge/version-v1.0.0-blue)
![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)

<!-- ![license](https://img.shields.io/bower/l/bootstrap?style=plastic) -->

</div>

> **‚≠êÔ∏è Shining ‚≠êÔ∏è:** This is fresh, daily-updated resources for in-context learning and prompt engineering. As Artificial General Intelligence (AGI) is approaching, let‚Äôs take action and become a super learner so as to position ourselves at the forefront of this exciting era and strive for personal and professional greatness.

The resources include:

*üéâ[Papers](#üìú-papers)üéâ*:  The latest papers about in-context learning or prompt engineering. 

*üéâ[Playground](./Playground.md)üéâ*:  Large language models that enable prompt experimentation. 

*üéâ[Prompt Engineering](./PromptEngineering.md)üéâ*: Prompt techniques for leveraging large language models. 

*üéâ[ChatGPT Prompt](./chatgptprompt.md)üéâ*: Prompt examples that can be applied in our work and daily lives. 

In the future, there will likely be two types of people on Earth (perhaps even on Mars, but that's a question for Musk): 
- Those who enhance their abilities through the use of AI; 
- Those whose jobs are replaced by AI automation.

```

üíéEgoAlpha: Hello! humanüë§, are you ready?

```  

# üì¢ News

- **[2023.3.22]** [GitHub launches Copilot X, aiming at the future of AI-powered software development.](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/) 

- **[2023.3.21]** [Google Bard is now available in the US and UK, w/ more countries to come.](https://bard.google.com) 

- **[2023.3.20]** OpenAI‚Äôs new paper looks at the economical impact of LLMs+Labor Market.[GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models](https://arxiv.org/pdf/2303.10130.pdf) 

- **[2023.3.17]** [Microsoft 365 Copilot released. Word, Excel, PowerPoint, Outlook powered by LLMs.](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/)

- **[2023.3.16]**  Baidu announcing the LLM named ["ÊñáÂøÉ‰∏ÄË®Ä"(ERNIE3.0 + PLATO)](https://yiyan.baidu.com/welcome) 

- **[2023.3.15]** Two Breaking News:
    -  Announcing [GPT4](https://openai.com/product/gpt-4) by OpenAI from Microsoft. **[Paperüîó](https://cdn.openai.com/papers/gpt-4.pdf)**
    -  Announcing [PaLM](https://developers.googleblog.com/2023/03/announcing-palm-api-and-makersuite.html) API by Google. 

[üëâ Complete history news üëà](./historynews.md)

<img width="200%" src="./figures/hr.gif" />

# üìú Papers

> You can directly click on the title to jump to the corresponding PDF link location

- [Survey](#Survey)

- [Prompt Engineering](#prompt-engineering)

- [In-context learning](#in-context-learning)

- [Multimodal Prompt](#multimodal-prompt)

- [Prompt Application](#prompt-application)

- [Foundation Models](#foundation-models)

---

## Survey

<div style="line-height:0.2em;">



[**Augmented Language Models: a Survey**](https://doi.org/10.48550/arXiv.2302.07842) Ôºà**2023.02.15**Ôºâ

![](https://img.shields.io/badge/Citations-4-green)

[**A Survey for In-context Learning**](https://doi.org/10.48550/arXiv.2301.00234) Ôºà**2022.12.31**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Towards Reasoning in Large Language Models: A Survey**](https://doi.org/10.48550/arXiv.2212.10403) Ôºà**2022.12.20**Ôºâ

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-201-blue)](https://github.com/jeffhj/lm-reasoning)

[**Reasoning with Language Model Prompting: A Survey**](https://doi.org/10.48550/arXiv.2212.09597) Ôºà**2022.12.19**Ôºâ

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-179-blue)](https://github.com/zjunlp/Prompt4ReasoningPapers)

[**Emergent Abilities of Large Language Models**](https://doi.org/10.48550/arXiv.2206.07682) Ôºà**2022.06.15**Ôºâ

![](https://img.shields.io/badge/Citations-156-green)

[**Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**](https://doi.org/10.1145/3560815) Ôºà**2021.07.28**Ôºâ

![](https://img.shields.io/badge/Citations-462-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1.4k-red)  [![](https://img.shields.io/badge/Github%20Stars-153-blue)](https://github.com/mingkaid/rl-prompt)


</div>

üëâ[Complete paper list üîó for "Survey"](./PaperList/survey.md)üëà

## Prompt Engineering

### üìå Prompt Design

<div style="line-height:0.2em;">



[**A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT**](https://doi.org/10.48550/arXiv.2302.11382) Ôºà**2023.02.21**Ôºâ

![](https://img.shields.io/badge/Citations-3-green)

[**GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks**](https://doi.org/10.48550/arXiv.2302.08043) Ôºà**2023.02.16**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation**](https://doi.org/10.48550/arXiv.2302.01441) Ôºà**2023.02.02**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Progressive Prompts: Continual Learning for Language Models**](https://doi.org/10.48550/arXiv.2301.12314) Ôºà**2023.01.29**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)

[**Batch Prompting: Efficient Inference with Large Language Model APIs**](https://doi.org/10.48550/arXiv.2301.08721) Ôºà**2023.01.19**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-24-blue)](https://github.com/hkunlp/batch-prompting)

[**Promptagator: Few-shot Dense Retrieval From 8 Examples**](https://doi.org/10.48550/arXiv.2209.11755) Ôºà**2022.09.23**Ôºâ

![](https://img.shields.io/badge/Citations-16-green)

[**Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models**](https://doi.org/10.1109/TVCG.2022.3209479) Ôºà**2022.08.16**Ôºâ

![](https://img.shields.io/badge/Citations-10-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-23-red)

[**DocPrompting: Generating Code by Retrieving the Docs**](https://arxiv.org/abs/2207.05987) Ôºà**2022.07.13**Ôºâ

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)  [![](https://img.shields.io/badge/Github%20Stars-133-blue)](https://github.com/shuyanzhou/docprompting)

[**Design Guidelines for Prompt Engineering Text-to-Image Generative Models**](https://doi.org/10.1145/3491102.3501825) Ôºà**2021.09.14**Ôºâ

![](https://img.shields.io/badge/Citations-44-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-50-red)

[**Program Synthesis with Large Language Models**](https://arxiv.org/abs/2108.07732) Ôºà**2021.08.16**Ôºâ

![](https://img.shields.io/badge/Citations-175-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-148-red)


</div>

üëâ[Complete paper list üîó for "Prompt Design"](./PaperList/PromptDesignList.md)üëà

### üìå Automatic Prompt 

<div style="line-height:0.2em;">



[**Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data**](https://doi.org/10.48550/arXiv.2302.12822) Ôºà**2023.02.24**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Guiding Large Language Models via Directional Stimulus Prompting**](https://doi.org/10.48550/arXiv.2302.11520) Ôºà**2023.02.22**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Evaluating the Robustness of Discrete Prompts**](https://doi.org/10.48550/arXiv.2302.05619) Ôºà**2023.02.11**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/livnlp/prompt-robustness)

[**Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery**](https://doi.org/10.48550/arXiv.2302.03668) Ôºà**2023.02.07**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-365-blue)](https://github.com/YuxinWenRick/hard-prompts-made-easy)

[**Making Pre-trained Language Models Better Few-shot Learners**](https://doi.org/10.18653/v1/2021.acl-long.295) Ôºà**2021.01.01**Ôºâ

![](https://img.shields.io/badge/Citations-648-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-708-red)  [![](https://img.shields.io/badge/Github%20Stars-636-blue)](https://github.com/princeton-nlp/LM-BFF)

[**Eliciting Knowledge from Language Models Using Automatically Generated Prompts**](https://doi.org/10.18653/v1/2020.emnlp-main.346) Ôºà**2020.10.29**Ôºâ

![](https://img.shields.io/badge/Citations-136-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-477-red)

[**Automatically Identifying Words That Can Serve as Labels for Few-Shot Text Classification**](https://doi.org/10.5282/UBM/EPUB.74034) Ôºà**2020.10.26**Ôºâ

![](https://img.shields.io/badge/Citations-85-green)  [![](https://img.shields.io/badge/Github%20Stars-1.5k-blue)](https://github.com/timoschick/pet)


</div>

üëâ[Complete paper list üîó for "Automatic Prompt"](./PaperList/AutomaticPromptList.md)üëà

### üìå Chain of Thought

<div style="line-height:0.2em;">



[**Active Prompting with Chain-of-Thought for Large Language Models**](https://doi.org/10.48550/arXiv.2302.12246) Ôºà**2023.02.23**Ôºâ

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-61-blue)](https://github.com/shizhediao/active-cot)

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2302.00923) Ôºà**2023.02.02**Ôºâ

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3.1k-blue)](https://github.com/amazon-science/mm-cot)

[**Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models**](https://doi.org/10.48550/arXiv.2302.00618) Ôºà**2023.02.01**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)

[**Faithful Chain-of-Thought Reasoning**](https://doi.org/10.48550/arXiv.2301.13379) Ôºà**2023.01.31**Ôºâ

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-36-blue)](https://github.com/veronica320/faithful-cot)

[**Large Language Models Are Reasoning Teachers**](https://doi.org/10.48550/arXiv.2212.10071) Ôºà**2022.12.20**Ôºâ

![](https://img.shields.io/badge/Citations-5-green)

[**The Impact of Symbolic Representations on In-context Learning for Few-shot Reasoning**](https://doi.org/10.48550/arXiv.2212.08686) Ôºà**2022.12.16**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)

[**Complementary Explanations for Effective In-Context Learning**](https://doi.org/10.48550/arXiv.2211.13892) Ôºà**2022.11.25**Ôºâ

![](https://img.shields.io/badge/Citations-5-green)

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) Ôºà**2022.10.17**Ôºâ

![](https://img.shields.io/badge/Citations-29-green)  [![](https://img.shields.io/badge/Github%20Stars-66-blue)](https://github.com/suzgunmirac/big-bench-hard)

[**Prompting GPT-3 To Be Reliable**](https://doi.org/10.48550/arXiv.2210.09150) Ôºà**2022.10.17**Ôºâ

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-48-blue)](https://github.com/noviscl/gpt3-reliability)

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) Ôºà**2022.10.07**Ôºâ

![](https://img.shields.io/badge/Citations-24-green)  [![](https://img.shields.io/badge/Github%20Stars-311-blue)](https://github.com/amazon-research/auto-cot)


</div>

üëâ[Complete paper list üîó for "Chain of Thought"](./PaperList/ChainofThoughtList.md)üëà

### üìå Knowledge Augmented Prompts

<div style="line-height:0.2em;">



[**A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT**](https://doi.org/10.48550/arXiv.2302.11382) Ôºà**2023.02.21**Ôºâ

![](https://img.shields.io/badge/Citations-3-green)

[**GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks**](https://doi.org/10.48550/arXiv.2302.08043) Ôºà**2023.02.16**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation**](https://doi.org/10.48550/arXiv.2302.01441) Ôºà**2023.02.02**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Progressive Prompts: Continual Learning for Language Models**](https://doi.org/10.48550/arXiv.2301.12314) Ôºà**2023.01.29**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)

[**Batch Prompting: Efficient Inference with Large Language Model APIs**](https://doi.org/10.48550/arXiv.2301.08721) Ôºà**2023.01.19**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-24-blue)](https://github.com/hkunlp/batch-prompting)

[**Promptagator: Few-shot Dense Retrieval From 8 Examples**](https://doi.org/10.48550/arXiv.2209.11755) Ôºà**2022.09.23**Ôºâ

![](https://img.shields.io/badge/Citations-16-green)

[**Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models**](https://doi.org/10.1109/TVCG.2022.3209479) Ôºà**2022.08.16**Ôºâ

![](https://img.shields.io/badge/Citations-10-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-23-red)

[**DocPrompting: Generating Code by Retrieving the Docs**](https://arxiv.org/abs/2207.05987) Ôºà**2022.07.13**Ôºâ

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)  [![](https://img.shields.io/badge/Github%20Stars-133-blue)](https://github.com/shuyanzhou/docprompting)

[**Design Guidelines for Prompt Engineering Text-to-Image Generative Models**](https://doi.org/10.1145/3491102.3501825) Ôºà**2021.09.14**Ôºâ

![](https://img.shields.io/badge/Citations-44-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-50-red)

[**Program Synthesis with Large Language Models**](https://arxiv.org/abs/2108.07732) Ôºà**2021.08.16**Ôºâ

![](https://img.shields.io/badge/Citations-175-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-148-red)


</div>

üëâ[Complete paper list üîó for "Knowledge Augmented Prompts"](./PaperList/KnowledgeAugmentedPromptList.md)üëà


### üìå Evaluation & Reliability

<div style="line-height:0.2em;">



[**Language Model Crossover: Variation through Few-Shot Prompting**](https://doi.org/10.48550/arXiv.2302.12170) Ôºà**2023.02.23**Ôºâ

![](https://img.shields.io/badge/Citations-1-green)

[**Evaluating the Robustness of Discrete Prompts**](https://doi.org/10.48550/arXiv.2302.05619) Ôºà**2023.02.11**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/livnlp/prompt-robustness)

[**PLACES: Prompting Language Models for Social Conversation Synthesis**](https://doi.org/10.48550/arXiv.2302.03269) Ôºà**2023.02.07**Ôºâ

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/alexa/places)

[**Controlling for Stereotypes in Multimodal Language Model Evaluation**](https://doi.org/10.48550/arXiv.2302.01582) Ôºà**2023.02.03**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Large Language Models Can Be Easily Distracted by Irrelevant Context**](https://doi.org/10.48550/arXiv.2302.00093) Ôºà**2023.01.31**Ôºâ

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/google-research-datasets/gsm-ic)

[**Emergent Analogical Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2212.09196) Ôºà**2022.12.19**Ôºâ

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/taylorwwebb/emergent_analogies_llm)

[**Discovering Language Model Behaviors with Model-Written Evaluations**](https://doi.org/10.48550/arXiv.2212.09251) Ôºà**2022.12.19**Ôºâ

![](https://img.shields.io/badge/Citations-8-green)  [![](https://img.shields.io/badge/Github%20Stars-109-blue)](https://github.com/anthropics/evals)

[**On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning**](https://doi.org/10.48550/arXiv.2212.08061) Ôºà**2022.12.15**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)

[**Solving math word problems with process- and outcome-based feedback**](https://doi.org/10.48550/arXiv.2211.14275) Ôºà**2022.11.25**Ôºâ

![](https://img.shields.io/badge/Citations-3-green)

[**Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks**](https://doi.org/10.48550/arXiv.2211.12588) Ôºà**2022.11.22**Ôºâ

![](https://img.shields.io/badge/Citations-22-green)  [![](https://img.shields.io/badge/Github%20Stars-57-blue)](https://github.com/wenhuchen/program-of-thoughts)


</div>

üëâ[Complete paper list üîó for "Evaluation & Reliability"](./PaperList/EvaluationReliabilityList.md)üëà

## In-context Learning

<div style="line-height:0.2em;">



[**Larger language models do in-context learning differently**](https://doi.org/10.48550/arXiv.2303.03846) Ôºà**2023.03.07**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)

[**How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks**](https://doi.org/10.48550/arXiv.2303.00293) Ôºà**2023.03.01**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Language Model Crossover: Variation through Few-Shot Prompting**](https://doi.org/10.48550/arXiv.2302.12170) Ôºà**2023.02.23**Ôºâ

![](https://img.shields.io/badge/Citations-1-green)

[**How Does In-Context Learning Help Prompt Tuning?**](https://doi.org/10.48550/arXiv.2302.11521) Ôºà**2023.02.22**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints**](https://doi.org/10.48550/arXiv.2302.09185) Ôºà**2023.02.17**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/salt-nlp/bound-cap-llm)

[**Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning**](https://doi.org/10.48550/arXiv.2301.11916) Ôºà**2023.01.27**Ôºâ

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-12-blue)](https://github.com/wangxinyilinda/concept-based-demonstration-selection)

[**Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning**](https://doi.org/10.48550/arXiv.2301.11916) Ôºà**2023.01.27**Ôºâ

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-12-blue)](https://github.com/wangxinyilinda/concept-based-demonstration-selection)

[**One Embedder, Any Task: Instruction-Finetuned Text Embeddings**](https://doi.org/10.48550/arXiv.2212.09741) Ôºà**2022.12.19**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)

[**Complementary Explanations for Effective In-Context Learning**](https://doi.org/10.48550/arXiv.2211.13892) Ôºà**2022.11.25**Ôºâ

![](https://img.shields.io/badge/Citations-5-green)

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) Ôºà**2022.10.17**Ôºâ

![](https://img.shields.io/badge/Citations-29-green)  [![](https://img.shields.io/badge/Github%20Stars-66-blue)](https://github.com/suzgunmirac/big-bench-hard)


</div>

üëâ[Complete paper list üîó for "In-context Learning"](./PaperList/InContextLearningList.md)üëà

## Multimodal Prompt

<div style="line-height:0.2em;">



[**Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models**](https://arxiv.org/abs/2303.04671) Ôºà**2023.03.08**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-193-red)  [![](https://img.shields.io/badge/Github%20Stars-22.6k-blue)](https://github.com/microsoft/visual-chatgpt)

[**Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning**](https://arxiv.org/abs/2303.02861) Ôºà**2023.03.06**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2302.00923) Ôºà**2023.02.02**Ôºâ

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3.1k-blue)](https://github.com/amazon-science/mm-cot)

[**CoHOZ: Contrasive Multimodal prompt Tuning for Hierarchical Open-set Zero-shot Recognition**](https://doi.org/10.1145/3503161.3548021) Ôºà**2022.10.10**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**VIMA: General Robot Manipulation with Multimodal Prompts**](https://doi.org/10.48550/arXiv.2210.03094) Ôºà**2022.10.06**Ôºâ

![](https://img.shields.io/badge/Citations-15-green)  [![](https://img.shields.io/badge/Github%20Stars-76-blue)](https://github.com/vimalabs/VIMABench)

[**Learning to Prompt for Vision-Language Models**](https://doi.org/10.1007/s11263-022-01653-1) Ôºà**2022.09.01**Ôºâ

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-405-red)  [![](https://img.shields.io/badge/Github%20Stars-768-blue)](https://github.com/kaiyangzhou/coop)

[**Visual Prompt Tuning**](https://doi.org/10.48550/arXiv.2203.12119) Ôºà**2022.03.23**Ôºâ

![](https://img.shields.io/badge/Citations-104-green)  [![](https://img.shields.io/badge/Github%20Stars-359-blue)](https://github.com/KMnP/vpt)

[**Multimodal Few-Shot Learning with Frozen Language Models**](https://arxiv.org/abs/2106.13884) Ôºà**2021.06.25**Ôºâ

![](https://img.shields.io/badge/Citations-173-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-405-red)

[**Similarity-Aware Multimodal Prompt Learning for Fake News Detection**](https://doi.org/10.2139/ssrn.4347542) 

![](https://img.shields.io/badge/Citations-0-green)


</div>

üëâ[Complete paper list üîó for "Multimodal Prompt"](./PaperList/MultimodalPromptList.md)üëà

## Prompt Application

<div style="line-height:0.2em;">



[**SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks**](https://doi.org/10.48550/arXiv.2303.00733) Ôºà**2023.03.01**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis**](https://doi.org/10.48550/arXiv.2303.00815) Ôºà**2023.03.01**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**EvoPrompting: Language Models for Code-Level Neural Architecture Search**](https://doi.org/10.48550/arXiv.2302.14838) Ôºà**2023.02.28**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models**](https://doi.org/10.48550/arXiv.2302.12173) Ôºà**2023.02.23**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-372-blue)](https://github.com/greshake/lm-safety)

[**Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales**](https://doi.org/10.48550/arXiv.2302.08961) Ôºà**2023.02.17**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**LabelPrompt: Effective Prompt-based Learning for Relation Classification**](https://doi.org/10.48550/arXiv.2302.08068) Ôºà**2023.02.16**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition**](https://doi.org/10.48550/arXiv.2302.08102) Ôºà**2023.02.16**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Prompting for Multimodal Hateful Meme Classification**](https://doi.org/10.48550/arXiv.2302.04156) Ôºà**2023.02.08**Ôºâ

![](https://img.shields.io/badge/Citations-1-green)

[**QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition**](https://doi.org/10.48550/arXiv.2203.01543) Ôºà**2022.03.03**Ôºâ

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-56-blue)](https://github.com/dayyass/QaNER)

[**LightNER: A Lightweight Tuning Paradigm for Low-resource NER via Pluggable Prompting**](https://arxiv.org/abs/2109.00720) Ôºà**2021.08.31**Ôºâ

![](https://img.shields.io/badge/Citations-9-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-22-red)


</div>

üëâ[Complete paper list üîó for "Prompt Application"](./PaperList/promptapplication.md)üëà

## Foundation Models

<div style="line-height:0.2em;">



[**Meet in the Middle: A New Pre-training Paradigm**](https://doi.org/10.48550/arXiv.2303.07295) Ôºà**2023.03.13**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**High-throughput Generative Inference of Large Language Models with a Single GPU**](https://doi.org/10.48550/arXiv.2303.06865) Ôºà**2023.03.13**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-7.0k-blue)](https://github.com/fminference/flexgen)

[**Stabilizing Transformer Training by Preventing Attention Entropy Collapse**](https://doi.org/10.48550/arXiv.2303.06296) Ôºà**2023.03.11**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**An Overview on Language Models: Recent Developments and Outlook**](https://doi.org/10.48550/arXiv.2303.05759) Ôºà**2023.03.10**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Foundation Models for Decision Making: Problems, Methods, and Opportunities**](https://doi.org/10.48550/arXiv.2303.04129) Ôºà**2023.03.07**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding**](https://doi.org/10.48550/arXiv.2303.04245) Ôºà**2023.03.07**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**LLaMA: Open and Efficient Foundation Language Models**](https://doi.org/10.48550/arXiv.2302.13971) Ôºà**2023.02.27**Ôºâ

![](https://img.shields.io/badge/Citations-12-green)  [![](https://img.shields.io/badge/Github%20Stars-12.7k-blue)](https://github.com/facebookresearch/llama)

[**Self-Instruct: Aligning Language Model with Self Generated Instructions**](https://doi.org/10.48550/arXiv.2212.10560) Ôºà**2022.12.20**Ôºâ

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-672-blue)](https://github.com/yizhongw/self-instruct)

[**PaLM: Scaling Language Modeling with Pathways**](https://arxiv.org/abs/2204.02311) Ôºà**2022.04.05**Ôºâ

![](https://img.shields.io/badge/Citations-645-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-683-red)  [![](https://img.shields.io/badge/Github%20Stars-664-blue)](https://github.com/lucidrains/CoCa-pytorch)

[**LoRA: Low-Rank Adaptation of Large Language Models**](https://arxiv.org/abs/2106.09685) Ôºà**2021.06.17**Ôºâ

![](https://img.shields.io/badge/Citations-244-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-299-red)  [![](https://img.shields.io/badge/Github%20Stars-1.1k-blue)](https://github.com/microsoft/LoRA)


</div>

üëâ[Complete paper list üîó for "Foundation Models"](./PaperList/foundationmodels.md)üëà

<!-- ### üìå Hard Prompt/ Discrete Prompt

<div style="line-height:0.2em;">



[**Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery**](https://doi.org/10.48550/arXiv.2302.03668) Ôºà**2023.02.07**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-365-blue)](https://github.com/YuxinWenRick/hard-prompts-made-easy)

[**SPT: Semi-Parametric Prompt Tuning for Multitask Prompted Learning**](https://doi.org/10.48550/arXiv.2212.10929) Ôºà**2022.12.21**Ôºâ

![](https://img.shields.io/badge/Citations-1-green)

[**ADEPT: A DEbiasing PrompT Framework**](https://doi.org/10.48550/arXiv.2211.05414) Ôºà**2022.11.10**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/EmpathYang/ADEPT)

[**PromptAttack: Prompt-based Attack for Language Models via Gradient Search**](https://doi.org/10.48550/arXiv.2209.01882) Ôºà**2022.09.05**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning**](https://doi.org/10.48550/arXiv.2205.12548) Ôºà**2022.05.25**Ôºâ

![](https://img.shields.io/badge/Citations-25-green)  [![](https://img.shields.io/badge/Github%20Stars-153-blue)](https://github.com/mingkaid/rl-prompt)

[**Personalized Prompt Learning for Explainable Recommendation**](https://arxiv.org/abs/2202.07371) Ôºà**2022.02.15**Ôºâ

![](https://img.shields.io/badge/Citations-10-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)  [![](https://img.shields.io/badge/Github%20Stars-58-blue)](https://github.com/lileipisces/pepler)

[**Instance-aware Prompt Learning for Language Understanding and Generation**](https://arxiv.org/abs/2201.07126) Ôºà**2022.01.18**Ôºâ

![](https://img.shields.io/badge/Citations-10-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-21-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/jinfeihu-stan/ipl)


</div>

üëâ[Complete paper list üîó for "Hard Prompt"](./PaperList/HardPromptList.md)üëà

### üìå Soft Prompt/ Continuous Prompt

<div style="line-height:0.2em;">



[**Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts health answer correctness**](https://doi.org/10.48550/arXiv.2302.13793) Ôºà**2023.02.23**Ôºâ

![](https://img.shields.io/badge/Citations-1-green)

[**How Does In-Context Learning Help Prompt Tuning?**](https://doi.org/10.48550/arXiv.2302.11521) Ôºà**2023.02.22**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Towards Unifying Medical Vision-and-Language Pre-training via Soft Prompts**](https://doi.org/10.48550/arXiv.2302.08958) Ôºà**2023.02.17**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/zhjohnchan/ptunifier)

[**SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains**](https://doi.org/10.48550/arXiv.2302.06868) Ôºà**2023.02.14**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-44-blue)](https://github.com/boschresearch/switchprompt)

[**Parameter-Efficient Low-Resource Dialogue State Tracking by Prompt Tuning**](https://doi.org/10.48550/arXiv.2301.10915) Ôºà**2023.01.26**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too?**](https://doi.org/10.48550/arXiv.2212.10539) Ôºà**2022.12.20**Ôºâ

![](https://img.shields.io/badge/Citations-1-green)

[**Controlled Text Generation using T5 based Encoder-Decoder Soft Prompt Tuning and Analysis of the Utility of Generated Text in AI**](https://doi.org/10.48550/arXiv.2212.02924) Ôºà**2022.12.06**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning**](https://doi.org/10.48550/arXiv.2210.12587) Ôºà**2022.10.23**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)

[**XPrompt: Exploring the Extreme of Prompt Tuning**](https://doi.org/10.48550/arXiv.2210.04457) Ôºà**2022.10.10**Ôºâ

![](https://img.shields.io/badge/Citations-2-green)

[**Knowledge Prompts: Injecting World Knowledge into Language Models through Soft Prompts**](https://doi.org/10.48550/arXiv.2210.04726) Ôºà**2022.10.10**Ôºâ

![](https://img.shields.io/badge/Citations-0-green)


</div>

üëâ[Complete paper list üîó for "Soft Prompt"](./PaperList/SoftPromptList.md)üëà -->

<!-- ## Prompt for Knowledge Graph

// __PAPER_LIST__:{field:'Prompt Design',size:10,state:'corrected',type:'lite'}

üëâ[Complete paper list üîó for "Prompt for Knowledge Graph"](./PaperList/PromptKnowledgeGraphList.md)üëà --> 

<img width="200%" src="./figures/hr.gif" />

<!-- # üéì Citation

If you find our work helps, please star our project and cite our paper. Thanks a lot!

```

ÁªºËø∞ËÆ∫ÊñáÂèØ‰ª•ÊîæÂú®Ëøô‰∏™‰ΩçÁΩÆ

``` -->

<!-- <img width="200%" src="./figures/hr.gif" /> -->

# ‚úâÔ∏è Contact

This repo is maintained by [EgoAlpha Lab](https://github.com/EgoAlpha). Questions and discussions are welcome via `helloegoalpha@gmail.com`.

We are willing to engage in discussions with friends from the academic and industrial communities, and explore the latest developments in prompt engineering and in-context learning together.

<img width="200%" src="./figures/hr.gif" />

# üôè Acknowledgements

Thanks to the PhD students from [EgoAlpha Lab](https://github.com/EgoAlpha) and other workers who participated in this repo. We will improve the project in the follow-up period and maintain this community well. We also would like to express our sincere gratitude to the authors of the relevant resources. Your efforts have broadened our horizons and enabled us to perceive a more wonderful world.


<!-- <img width="200%" src="./figures/hr.gif" /> -->

<!-- # üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Contributors

## Main Contributors
* [Yu Liu]()
* [Yifei Cao](https://github.com/cyfedu1024)
* [Jizhe Yu]()
* [Yuan Yao]()
* [He Qi]() -->


<!-- ## Guest Contributors
* [No] -->

<!-- <img width="200%" src="./figures/hr.gif" />

# üìî License

This project is open source and available under the MIT

<div align="center">
<img src="./figures/rocket.png"/>
</div> -->
