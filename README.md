<div align="center">

<img src="./figures/egoalpha_logo_compress.jpeg" width="600px">

 <div align="center">
    <a href="https://blog.sunguoqi.com/">
      <img src="https://readme-typing-svg.demolab.com?font=Fira+Code&pause=1000&width=435&lines=%22Hello%2C%20World%22;Welcome to our project!&center=true&size=27" alt="Typing SVG" />
    </a>
  </div>

**An Open-Source Engineering Guide for prompt-in-context-learning from EgoAlpha Lab.**

<img width="200%" src="./figures/hr.gif" />

<!-- <h3 align="center">
    <p>Resources for prompt learning and engineering; Mastery of LLMs like ChatGPT, GPT3, FlanT5, etc.</p>
</h3> -->
<h4 align="center">
    <p>
        <a href="./README.md">English</a> |
        <a href="./README_zh.md">ç®€ä½“ä¸­æ–‡</a>
    <p>
</h4>
<p align="center">
  <a href="#papersğŸ“œ">ğŸ“ Papers</a> |
  <a href="./Playground.md">âš¡ï¸  Playground</a> |
  <a href="./Promptzoo.md">ğŸ›  Prompt Zoo</a> |
  <a href="./chatgptprompt.md">ğŸŒ ChatGPT Prompt</a> 
</p>
</div>

<div align="center">

<!-- ![Build](https://img.shields.io/appveyor/build/gruntjs/grunt) -->
![version](https://img.shields.io/badge/version-v1.0.0-blue)
<!-- ![license](https://img.shields.io/bower/l/bootstrap?style=plastic) -->
</div>


> **â­ï¸ Shining â­ï¸:** This is fresh, daily-updated resources for in-context learning and prompt engineering. As Artificial General Intelligence (AGI) is approaching, letâ€™s take action and become a super learner so as to position ourselves at the forefront of this exciting era and strive for personal and professional greatness.

The resources include:

*ğŸ‰[Papers](#papersğŸ“œ)ğŸ‰*:  The latest papers about in-context learning or prompt engineering. 

*ğŸ‰[Playground](./Playground.md)ğŸ‰*:  Large language models that enable prompt experimentation. 

*ğŸ‰[Prompt Zoo](./Promptzoo.md)ğŸ‰*: Prompt techniques for leveraging large language models. 

*ğŸ‰[ChatGPT Prompt](./chatgptprompt.md)ğŸ‰*: Prompt examples that can be applied in our work and daily lives. 

In the future, there will likely be two types of people on Earth (perhaps even on Mars, but that's a question for Musk): Those who enhance their abilities through the use of AI; 
Those whose jobs are replaced by AI automation.

```
ğŸ’EgoAlpha: Hello! humanğŸ‘¤, are you ready?
```  

# ğŸ“¢ News

- **[2023.3.4]** We establish this project that is organised by professor Yu Liu from EgoAlpha Lab.

<img width="200%" src="./figures/hr.gif" />

# PapersğŸ“œ

- [Prompt Engineering](#prompt-engineering)
- [In-context learning](#in-context-learning)
- [Multimodal Prompt](#multimodal-prompt)
- [Knowledge Augmented Prompts](#knowledge-augmented-prompts)
- [Prompt for Knowledge Graph](#prompt-for-knowledge-graph)

---

## Prompt Engineering

### ğŸ“Œ Prompt Design

[**UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning**](https://doi.org/10.18653/v1/2022.acl-long.433) ğŸ‘¨â€ğŸ“Yuning Mao,Lambert Mathias,Rui Hou,Amjad Almahairi,Hao Ma,Jiawei Han,Wen-tau Yih,Madian Khabsa 2021 ![](https://img.shields.io/badge/pub-2021--10--14-green)![](https://img.shields.io/badge/cite-31-red)

[**HETFORMER: Heterogeneous Transformer with Sparse Attention for Long-Text Extractive Summarization**](https://doi.org/10.18653/v1/2021.emnlp-main.13) ğŸ‘¨â€ğŸ“Ye Liu,Jianguo Zhang,Yao Wan,Congying Xia,Lifang He,Philip S. Yu 2021 ![](https://img.shields.io/badge/pub-2021--10--12-green)![](https://img.shields.io/badge/cite-11-red)

[**Can Language Models be Biomedical Knowledge Bases?**](https://doi.org/10.18653/v1/2021.emnlp-main.388) ğŸ‘¨â€ğŸ“Mujeen Sung,Jinhyuk Lee,Sean S. Yi,Minji Jeon,Sungdong Kim,Jaewoo Kang 2021 ![](https://img.shields.io/badge/pub-2021--09--15-green)![](https://img.shields.io/badge/cite-26-red)

[**The SelectGen Challenge: Finding the Best Training Samples for Few-Shot Neural Text Generation**](https://arxiv.org/abs/2302.135402108.06614) ğŸ‘¨â€ğŸ“Ernie Chang,Xiaoyu Shen,Alex Marin,V. Demberg 2021 ![](https://img.shields.io/badge/pub-2021--08--14-green)![](https://img.shields.io/badge/cite-4-red)

[**Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**](https://doi.org/10.1145/3560815) ğŸ‘¨â€ğŸ“Pengfei Liu,Weizhe Yuan,Jinlan Fu,Zhengbao Jiang,Hiroaki Hayashi,Graham Neubig 2021 ![](https://img.shields.io/badge/pub-2021--07--28-green)![](https://img.shields.io/badge/cite-429-red)

[**On Training Instance Selection for Few-Shot Neural Text Generation**](https://doi.org/10.18653/v1/2021.acl-short.2) ğŸ‘¨â€ğŸ“Ernie Chang,Xiaoyu Shen,Hui-Syuan Yeh,V. Demberg 2021 ![](https://img.shields.io/badge/pub-2021--07--07-green)![](https://img.shields.io/badge/cite-15-red)

[**Template-Based Named Entity Recognition Using BART**](https://doi.org/10.18653/v1/2021.findings-acl.161) ğŸ‘¨â€ğŸ“Leyang Cui,Yu Wu,Jian Liu,Sen Yang,Yue Zhang 2021 ![](https://img.shields.io/badge/pub-2021--06--03-green)![](https://img.shields.io/badge/cite-100-red)

[**Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.381) ğŸ‘¨â€ğŸ“Yichen Jiang,Asli Celikyilmaz,P. Smolensky,Paul Soulos,Sudha Rao,H. Palangi,Roland Fernandez,Caitlin Smith,Mohit Bansal,Jianfeng Gao 2021 ![](https://img.shields.io/badge/pub-2021--06--01-green)![](https://img.shields.io/badge/cite-6-red)

[**SciFive: a text-to-text transformer model for biomedical literature**](https://arxiv.org/abs/2302.135402106.03598) ğŸ‘¨â€ğŸ“Long Phan,J. Anibal,Hieu Tran,Shaurya Chanana,Erol Bahadroglu,Alec Peltekian,G. Altan-Bonnet 2021 ![](https://img.shields.io/badge/pub-2021--05--28-green)![](https://img.shields.io/badge/cite-45-red)

[**PTR: Prompt Tuning with Rules for Text Classification**](https://doi.org/10.1016/j.aiopen.2022.11.003) ğŸ‘¨â€ğŸ“Xu Han,Weilin Zhao,Ning Ding,Zhiyuan Liu,Maosong Sun 2021 ![](https://img.shields.io/badge/pub-2021--05--24-green)![](https://img.shields.io/badge/cite-169-red)

[**Not All Memories are Created Equal: Learning to Forget by Expiring**](https://arxiv.org/abs/2302.135402105.06548) ğŸ‘¨â€ğŸ“Sainbayar Sukhbaatar,Da Ju,Spencer Poff,Stephen Roller,Arthur D. Szlam,J. Weston,Angela Fan 2021 ![](https://img.shields.io/badge/pub-2021--05--13-green)![](https://img.shields.io/badge/cite-16-red)

[**Long-Span Summarization via Local Attention and Content Selection**](https://doi.org/10.18653/v1/2021.acl-long.470) ğŸ‘¨â€ğŸ“Potsawee Manakul,M. Gales 2021 ![](https://img.shields.io/badge/pub-2021--05--08-green)![](https://img.shields.io/badge/cite-20-red)

[**The Power of Scale for Parameter-Efficient Prompt Tuning**](https://doi.org/10.18653/v1/2021.emnlp-main.243) ğŸ‘¨â€ğŸ“Brian Lester,Rami Al-Rfou,Noah Constant 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-675-red)

[**KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction**](https://doi.org/10.1145/3485447.3511998) ğŸ‘¨â€ğŸ“Xiang Chen,Ningyu Zhang,Ningyu Zhang,Xin Xie,Shumin Deng,Yunzhi Yao,Chuanqi Tan,Fei Huang,Luo Si,Huajun Chen 2021 ![](https://img.shields.io/badge/pub-2021--04--15-green)![](https://img.shields.io/badge/cite-84-red)

[**Data Augmentation for Abstractive Query-Focused Multi-Document Summarization**](https://doi.org/10.1609/aaai.v35i15.17611) ğŸ‘¨â€ğŸ“Ramakanth Pasunuru,Asli Celikyilmaz,Michel Galley,Chenyan Xiong,Yizhe Zhang,Mohit Bansal,Jianfeng Gao 2021 ![](https://img.shields.io/badge/pub-2021--03--02-green)![](https://img.shields.io/badge/cite-26-red)

[**SparseBERT: Rethinking the Importance Analysis in Self-attention**](https://arxiv.org/abs/2302.135402102.12871) ğŸ‘¨â€ğŸ“Han Shi,Jiahui Gao,Xiaozhe Ren,Hang Xu,Xiaodan Liang,Zhenguo Li,J. Kwok 2021 ![](https://img.shields.io/badge/pub-2021--02--25-green)![](https://img.shields.io/badge/cite-27-red)

[**Calibrate Before Use: Improving Few-Shot Performance of Language Models**](https://arxiv.org/abs/2302.135402102.09690) ğŸ‘¨â€ğŸ“Tony Zhao,Eric Wallace,Shi Feng,D. Klein,Sameer Singh 2021 ![](https://img.shields.io/badge/pub-2021--02--19-green)![](https://img.shields.io/badge/cite-277-red)

[**Does the Order of Training Samples Matter? Improving Neural Data-to-Text Generation with Curriculum Learning**](https://doi.org/10.18653/v1/2021.eacl-main.61) ğŸ‘¨â€ğŸ“Ernie Chang,Hui-Syuan Yeh,V. Demberg 2021 ![](https://img.shields.io/badge/pub-2021--02--06-green)![](https://img.shields.io/badge/cite-17-red)

[**Making Pre-trained Language Models Better Few-shot Learners**](https://doi.org/10.18653/v1/2021.acl-long.295) ğŸ‘¨â€ğŸ“Tianyu Gao,Adam Fisch,Danqi Chen 2021 ![](https://img.shields.io/badge/pub-2021--01--01-green)![](https://img.shields.io/badge/cite-635-red)

[**Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals**](https://doi.org/10.1162/tacl_a_00359) ğŸ‘¨â€ğŸ“Yanai Elazar,Shauli Ravfogel,Alon Jacovi,Yoav Goldberg 2020 ![](https://img.shields.io/badge/pub-2020--12--07-green)![](https://img.shields.io/badge/cite-105-red)

[**How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering**](https://doi.org/10.1162/tacl_a_00407) ğŸ‘¨â€ğŸ“Zhengbao Jiang,J. Araki,Haibo Ding,Graham Neubig 2020 ![](https://img.shields.io/badge/pub-2020--12--02-green)![](https://img.shields.io/badge/cite-66-red)

[**Long Range Arena: A Benchmark for Efficient Transformers**](https://arxiv.org/abs/2302.135402011.04006) ğŸ‘¨â€ğŸ“Yi Tay,M. Dehghani,Samira Abnar,Yikang Shen,Dara Bahri,Philip Pham,J. Rao,Liu Yang,Sebastian Ruder,Donald Metzler 2020 ![](https://img.shields.io/badge/pub-2020--11--08-green)![](https://img.shields.io/badge/cite-263-red)

[**Automatically Identifying Words That Can Serve as Labels for Few-Shot Text Classification**](https://doi.org/10.5282/UBM/EPUB.74034) ğŸ‘¨â€ğŸ“Timo Schick,Helmut Schmid,Hinrich SchÃ¼tze 2020 ![](https://img.shields.io/badge/pub-2020--10--26-green)![](https://img.shields.io/badge/cite-83-red)

[**Self-Alignment Pretraining for Biomedical Entity Representations**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.334) ğŸ‘¨â€ğŸ“Fangyu Liu,Ehsan Shareghi,Zaiqiao Meng,Marco Basaldella,N. Collier 2020 ![](https://img.shields.io/badge/pub-2020--10--22-green)![](https://img.shields.io/badge/cite-101-red)

[**UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.139) ğŸ‘¨â€ğŸ“George Michalopoulos,Yuanxin Wang,H. Kaka,Helen H Chen,Alexander Wong 2020 ![](https://img.shields.io/badge/pub-2020--10--20-green)![](https://img.shields.io/badge/cite-50-red)

[**CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters**](https://doi.org/10.18653/V1/2020.COLING-MAIN.609) ğŸ‘¨â€ğŸ“Hicham El Boukkouri,Olivier Ferret,T. Lavergne,Hiroshi Noji,Pierre Zweigenbaum,Junichi Tsujii 2020 ![](https://img.shields.io/badge/pub-2020--10--20-green)![](https://img.shields.io/badge/cite-84-red)

[**X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models**](https://doi.org/10.18653/v1/2020.emnlp-main.479) ğŸ‘¨â€ğŸ“Zhengbao Jiang,Antonios Anastasopoulos,J. Araki,Haibo Ding,Graham Neubig 2020 ![](https://img.shields.io/badge/pub-2020--10--13-green)![](https://img.shields.io/badge/cite-58-red)

[**Pretrained Transformers for Text Ranking: BERT and Beyond**](https://doi.org/10.1145/3437963.3441667) ğŸ‘¨â€ğŸ“Jimmy J. Lin,Rodrigo Nogueira,Andrew Yates 2020 ![](https://img.shields.io/badge/pub-2020--10--13-green)![](https://img.shields.io/badge/cite-285-red)

[**Bio-Megatron: Larger Biomedical Domain Language Model**](https://doi.org/10.18653/v1/2020.emnlp-main.379) ğŸ‘¨â€ğŸ“Hoo-Chang Shin,Yang Zhang,Evelina Bakhturina,Raul Puri,M. Patwary,M. Shoeybi,Raghav Mani 2020 ![](https://img.shields.io/badge/pub-2020--10--12-green)![](https://img.shields.io/badge/cite-43-red)

[**Adapting In-Vehicle Voice Output:A User- and Situation-Adaptive Approach**](https://doi.org/10.1145/3409251.3411711) ğŸ‘¨â€ğŸ“D. Stier,U. Heid,W. Minker 2020 ![](https://img.shields.io/badge/pub-2020--09--21-green)![](https://img.shields.io/badge/cite-3-red)

[**Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing**](https://doi.org/10.1145/3458754) ğŸ‘¨â€ğŸ“Yu Gu,Robert Tinn,Hao Cheng,Michael R. Lucas,Naoto Usuyama,Xiaodong Liu,Tristan Naumann,Jianfeng Gao,Hoifung Poon 2020 ![](https://img.shields.io/badge/pub-2020--07--31-green)![](https://img.shields.io/badge/cite-468-red)

[**Big Bird: Transformers for Longer Sequences**](https://arxiv.org/abs/2302.135402007.14062) ğŸ‘¨â€ğŸ“M. Zaheer,Guru Guruganesh,Kumar Avinava Dubey,J. Ainslie,Chris Alberti,Santiago OntaÃ±Ã³n,Philip Pham,Anirudh Ravula,Qifan Wang,Li Yang,Amr Ahmed 2020 ![](https://img.shields.io/badge/pub-2020--07--28-green)![](https://img.shields.io/badge/cite-843-red)

[**DART: Open-Domain Structured Data Record to Text Generation**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.37) ğŸ‘¨â€ğŸ“Dragomir R. Radev,Rui Zhang,Amrit Rau,Abhinand Sivaprasad,Chia-Hsuan Hsieh,Nazneen Rajani,Xiangru Tang,Aadit Vyas,Neha Verma,P. Krishna,Yangxiaokang Liu,Nadia Irwanto,Jessica Pan,Faiaz Rahman,A. Zaidi,Murori Mutuma,Yasin Tarabar,Ankit Gupta,Tao Yu,Y. Tan,Xi Victoria Lin,Caiming Xiong,R. Socher 2020 ![](https://img.shields.io/badge/pub-2020--07--06-green)![](https://img.shields.io/badge/cite-91-red)

[**Understanding Attention for Text Classification**](https://doi.org/10.18653/v1/2020.acl-main.312) ğŸ‘¨â€ğŸ“Xiaobing Sun,Wei Lu 2020 ![](https://img.shields.io/badge/pub-2020--07--01-green)![](https://img.shields.io/badge/cite-32-red)

[**Linformer: Self-Attention with Linear Complexity**](https://arxiv.org/abs/2302.135402006.04768) ğŸ‘¨â€ğŸ“Sinong Wang,Belinda Z. Li,Madian Khabsa,Han Fang,Hao Ma 2020 ![](https://img.shields.io/badge/pub-2020--06--08-green)![](https://img.shields.io/badge/cite-641-red)

[**Language Models are Few-Shot Learners**](https://arxiv.org/abs/2302.135402005.14165) ğŸ‘¨â€ğŸ“Tom B. Brown,Benjamin Mann,Nick Ryder,Melanie Subbiah,J. Kaplan,Prafulla Dhariwal,Arvind Neelakantan,Pranav Shyam,Girish Sastry,Amanda Askell,Sandhini Agarwal,Ariel Herbert-Voss,Gretchen Krueger,T. Henighan,Rewon Child,A. Ramesh,Daniel M. Ziegler,Jeff Wu,Clemens Winter,Christopher Hesse,Mark Chen,Eric Sigler,Mateusz Litwin,Scott Gray,Benjamin Chess,Jack Clark,Christopher Berner,Sam McCandlish,Alec Radford,Ilya Sutskever,Dario Amodei 2020 ![](https://img.shields.io/badge/pub-2020--05--28-green)![](https://img.shields.io/badge/cite-8351-red)

[**UnifiedQA: Crossing Format Boundaries With a Single QA System**](https://doi.org/10.18653/v1/2020.findings-emnlp.171) ğŸ‘¨â€ğŸ“Daniel Khashabi,Sewon Min,Tushar Khot,Ashish Sabharwal,Oyvind Tafjord,Peter Clark,Hannaneh Hajishirzi 2020 ![](https://img.shields.io/badge/pub-2020--05--02-green)![](https://img.shields.io/badge/cite-357-red)

[**Donâ€™t Stop Pretraining: Adapt Language Models to Domains and Tasks**](https://doi.org/10.18653/v1/2020.acl-main.740) ğŸ‘¨â€ğŸ“Suchin Gururangan,Ana MarasoviÄ‡,Swabha Swayamdipta,Kyle Lo,Iz Beltagy,Doug Downey,Noah A. Smith 2020 ![](https://img.shields.io/badge/pub-2020--04--23-green)![](https://img.shields.io/badge/cite-1128-red)

[**Sparse Text Generation**](https://doi.org/10.18653/v1/2020.emnlp-main.348) ğŸ‘¨â€ğŸ“Pedro Henrique Martins,Zita Marinho,AndrÃ© F. T. Martins 2020 ![](https://img.shields.io/badge/pub-2020--04--06-green)![](https://img.shields.io/badge/cite-25-red)

[**Efficient Content-Based Sparse Attention with Routing Transformers**](https://doi.org/10.1162/tacl_a_00353) ğŸ‘¨â€ğŸ“Aurko Roy,M. Saffar,Ashish Vaswani,David Grangier 2020 ![](https://img.shields.io/badge/pub-2020--03--12-green)![](https://img.shields.io/badge/cite-281-red)

[**Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference**](https://doi.org/10.18653/v1/2021.eacl-main.20) ğŸ‘¨â€ğŸ“Timo Schick,Hinrich SchÃ¼tze 2020 ![](https://img.shields.io/badge/pub-2020--01--21-green)![](https://img.shields.io/badge/cite-579-red)

[**How Can We Know What Language Models Know?**](https://doi.org/10.1162/tacl_a_00324) ğŸ‘¨â€ğŸ“Zhengbao Jiang,Frank F. Xu,J. Araki,Graham Neubig 2019 ![](https://img.shields.io/badge/pub-2019--11--28-green)![](https://img.shields.io/badge/cite-419-red)

[**SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization**](https://doi.org/10.18653/v1/D19-5409) ğŸ‘¨â€ğŸ“Bogdan Gliwa,Iwona Mochol,M. Biesek,A. Wawer 2019 ![](https://img.shields.io/badge/pub-2019--11--27-green)![](https://img.shields.io/badge/cite-217-red)

[**Semantic Noise Matters for Neural Natural Language Generation**](https://doi.org/10.18653/v1/W19-8652) ğŸ‘¨â€ğŸ“Ondrej Dusek,David M. Howcroft,Verena Rieser 2019 ![](https://img.shields.io/badge/pub-2019--11--01-green)![](https://img.shields.io/badge/cite-74-red)

[**Fine-tune BERT with Sparse Self-Attention Mechanism**](https://doi.org/10.18653/v1/D19-1361) ğŸ‘¨â€ğŸ“Baiyun Cui,Yingming Li,Ming Chen,Zhongfei Zhang 2019 ![](https://img.shields.io/badge/pub-2019--11--01-green)![](https://img.shields.io/badge/cite-41-red)

[**BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension**](https://doi.org/10.18653/v1/2020.acl-main.703) ğŸ‘¨â€ğŸ“M. Lewis,Yinhan Liu,Naman Goyal,Marjan Ghazvininejad,Abdelrahman Mohamed,Omer Levy,Veselin Stoyanov,Luke Zettlemoyer 2019 ![](https://img.shields.io/badge/pub-2019--10--29-green)![](https://img.shields.io/badge/cite-4052-red)

[**Reading Between the Guidelines: How Commercial Voice Assistant Guidelines Hinder Accessibility for Blind Users**](https://doi.org/10.1145/3308561.3353797) ğŸ‘¨â€ğŸ“Stacy M. Branham,Antony Rishin Mukkath Roy 2019 ![](https://img.shields.io/badge/pub-2019--10--24-green)![](https://img.shields.io/badge/cite-35-red)

[**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**](https://arxiv.org/abs/2302.135401910.10683) ğŸ‘¨â€ğŸ“Colin Raffel,Noam M. Shazeer,Adam Roberts,Katherine Lee,Sharan Narang,Michael Matena,Yanqi Zhou,Wei Li,Peter J. Liu 2019 ![](https://img.shields.io/badge/pub-2019--10--23-green)![](https://img.shields.io/badge/cite-6286-red)

[**Language Models as Knowledge Bases?**](https://doi.org/10.18653/v1/D19-1250) ğŸ‘¨â€ğŸ“Fabio Petroni,Tim RocktÃ¤schel,Patrick Lewis,A. Bakhtin,Yuxiang Wu,Alexander H. Miller,S. Riedel 2019 ![](https://img.shields.io/badge/pub-2019--09--01-green)![](https://img.shields.io/badge/cite-1023-red)

[**Neural Text Summarization: A Critical Evaluation**](https://doi.org/10.18653/v1/D19-1051) ğŸ‘¨â€ğŸ“Wojciech Kryscinski,N. Keskar,Bryan McCann,Caiming Xiong,R. Socher 2019 ![](https://img.shields.io/badge/pub-2019--08--23-green)![](https://img.shields.io/badge/cite-227-red)

[**Neural Text Generation with Unlikelihood Training**](https://arxiv.org/abs/2302.135401908.04319) ğŸ‘¨â€ğŸ“S. Welleck,Ilia Kulikov,Stephen Roller,Emily Dinan,Kyunghyun Cho,J. Weston 2019 ![](https://img.shields.io/badge/pub-2019--08--12-green)![](https://img.shields.io/badge/cite-296-red)

[**What Does BERT Learn about the Structure of Language?**](https://doi.org/10.18653/v1/P19-1356) ğŸ‘¨â€ğŸ“Ganesh Jawahar,BenoÃ®t Sagot,DjamÃ© Seddah 2019 ![](https://img.shields.io/badge/pub-2019--07--28-green)![](https://img.shields.io/badge/cite-773-red)

[**Lessons from Oz: design guidelines for automotive conversational user interfaces**](https://doi.org/10.1145/3349263.3351314) ğŸ‘¨â€ğŸ“D. Large,G. Burnett,L. Clark 2019 ![](https://img.shields.io/badge/pub-2019--07--25-green)![](https://img.shields.io/badge/cite-11-red)

[**Linguistic Design of In-Vehicle Prompts in Adaptive Dialog Systems: An Analysis of Potential Factors Involved in the Perception of Naturalness**](https://doi.org/10.1145/3320435.3320469) ğŸ‘¨â€ğŸ“D. Stier,Ellen Sigloch 2019 ![](https://img.shields.io/badge/pub-2019--06--07-green)![](https://img.shields.io/badge/cite-7-red)

[**Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model**](https://doi.org/10.18653/v1/P19-1102) ğŸ‘¨â€ğŸ“Alexander R. Fabbri,Irene Li,Tianwei She,Suyi Li,Dragomir R. Radev 2019 ![](https://img.shields.io/badge/pub-2019--06--04-green)![](https://img.shields.io/badge/cite-274-red)

[**Hierarchical Transformers for Multi-Document Summarization**](https://doi.org/10.18653/v1/P19-1500) ğŸ‘¨â€ğŸ“Yang Liu,Mirella Lapata 2019 ![](https://img.shields.io/badge/pub-2019--05--30-green)![](https://img.shields.io/badge/cite-203-red)

[**At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces**](https://doi.org/10.1145/3290605.3300270) ğŸ‘¨â€ğŸ“Michael Braun,Anja Mainz,Ronee Chadowitz,Bastian Pfleging,Florian Alt 2019 ![](https://img.shields.io/badge/pub-2019--05--02-green)![](https://img.shields.io/badge/cite-101-red)

[**The Curious Case of Neural Text Degeneration**](https://arxiv.org/abs/2302.135401904.09751) ğŸ‘¨â€ğŸ“Ari Holtzman,Jan Buys,Maxwell Forbes,Yejin Choi 2019 ![](https://img.shields.io/badge/pub-2019--04--22-green)![](https://img.shields.io/badge/cite-1322-red)

[**Publicly Available Clinical BERT Embeddings**](https://doi.org/10.18653/v1/W19-1909) ğŸ‘¨â€ğŸ“Emily Alsentzer,John R. Murphy,Willie Boag,W. Weng,Di Jin,Tristan Naumann,Matthew B. A. McDermott 2019 ![](https://img.shields.io/badge/pub-2019--04--06-green)![](https://img.shields.io/badge/cite-934-red)

[**SciBERT: A Pretrained Language Model for Scientific Text**](https://doi.org/10.18653/v1/D19-1371) ğŸ‘¨â€ğŸ“Iz Beltagy,Kyle Lo,Arman Cohan 2019 ![](https://img.shields.io/badge/pub-2019--03--01-green)![](https://img.shields.io/badge/cite-1476-red)

[**Parameter-Efficient Transfer Learning for NLP**](https://arxiv.org/abs/2302.135401902.00751) ğŸ‘¨â€ğŸ“N. Houlsby,A. Giurgiu,Stanislaw Jastrzebski,Bruna Morrone,Quentin de Laroussilhe,Andrea Gesmundo,Mona Attariyan,S. Gelly 2019 ![](https://img.shields.io/badge/pub-2019--02--02-green)![](https://img.shields.io/badge/cite-989-red)

[**BioBERT: a pre-trained biomedical language representation model for biomedical text mining**](https://doi.org/10.1093/bioinformatics/btz682) ğŸ‘¨â€ğŸ“Jinhyuk Lee,Wonjin Yoon,Sungdong Kim,Donghyeon Kim,Sunkyu Kim,Chan Ho So,Jaewoo Kang 2019 ![](https://img.shields.io/badge/pub-2019--01--25-green)![](https://img.shields.io/badge/cite-2743-red)

[**On Controllable Sparse Alternatives to Softmax**](https://arxiv.org/abs/2302.135401810.11975) ğŸ‘¨â€ğŸ“Anirban Laha,Saneem A. Chemmengath,Priyanka Agrawal,Mitesh M. Khapra,Karthik Sankaranarayanan,H. G. Ramaswamy 2018 ![](https://img.shields.io/badge/pub-2018--10--29-green)![](https://img.shields.io/badge/cite-36-red)

[**WikiHow: A Large Scale Text Summarization Dataset**](https://arxiv.org/abs/2302.135401810.09305) ğŸ‘¨â€ğŸ“Mahnaz Koupaee,William Yang Wang 2018 ![](https://img.shields.io/badge/pub-2018--10--18-green)![](https://img.shields.io/badge/cite-129-red)

[**Design guidelines for hands-free speech interaction**](https://doi.org/10.1145/3236112.3236149) ğŸ‘¨â€ğŸ“Christine Murad,Cosmin Munteanu,L. Clark,Benjamin R. Cowan 2018 ![](https://img.shields.io/badge/pub-2018--09--03-green)![](https://img.shields.io/badge/cite-62-red)

[**Donâ€™t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization**](https://doi.org/10.18653/v1/D18-1206) ğŸ‘¨â€ğŸ“Shashi Narayan,Shay B. Cohen,Mirella Lapata 2018 ![](https://img.shields.io/badge/pub-2018--08--27-green)![](https://img.shields.io/badge/cite-704-red)

[**Social Boundaries of Appropriate Speech in HCI: A Politeness Perspective**](https://doi.org/10.14236/EWIC/HCI2018.76) ğŸ‘¨â€ğŸ“L. Clark 2018 ![](https://img.shields.io/badge/pub-2018--07--01-green)![](https://img.shields.io/badge/cite-8-red)

[**A Simple Method for Commonsense Reasoning**](https://arxiv.org/abs/2302.135401806.02847) ğŸ‘¨â€ğŸ“Trieu H. Trinh,Quoc V. Le 2018 ![](https://img.shields.io/badge/pub-2018--06--07-green)![](https://img.shields.io/badge/cite-300-red)

[**Hierarchical Neural Story Generation**](https://doi.org/10.18653/v1/P18-1082) ğŸ‘¨â€ğŸ“Angela Fan,M. Lewis,Y. Dauphin 2018 ![](https://img.shields.io/badge/pub-2018--05--01-green)![](https://img.shields.io/badge/cite-839-red)

[**GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding**](https://doi.org/10.18653/v1/W18-5446) ğŸ‘¨â€ğŸ“Alex Wang,Amanpreet Singh,Julian Michael,Felix Hill,Omer Levy,Samuel R. Bowman 2018 ![](https://img.shields.io/badge/pub-2018--04--20-green)![](https://img.shields.io/badge/cite-3499-red)

[**Patterns for How Users Overcome Obstacles in Voice User Interfaces**](https://doi.org/10.1145/3173574.3173580) ğŸ‘¨â€ğŸ“Chelsea M. Myers,Anushay Furqan,Jessica Nebolsky,Karina Caro,Jichen Zhu 2018 ![](https://img.shields.io/badge/pub-2018--04--19-green)![](https://img.shields.io/badge/cite-151-red)

[**A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents**](https://doi.org/10.18653/v1/N18-2097) ğŸ‘¨â€ğŸ“Arman Cohan,Franck Dernoncourt,Doo Soon Kim,Trung Bui,Seokhwan Kim,W. Chang,Nazli Goharian 2018 ![](https://img.shields.io/badge/pub-2018--04--01-green)![](https://img.shields.io/badge/cite-408-red)

[**Steering the conversation: A linguistic exploration of natural language interactions with a digital assistant during simulated driving.**](https://doi.org/10.1016/j.apergo.2017.04.003) ğŸ‘¨â€ğŸ“D. Large,L. Clark,Annie Quandt,G. Burnett,L. Skrypchuk 2017 ![](https://img.shields.io/badge/pub-2017--09--01-green)![](https://img.shields.io/badge/cite-55-red)

[**The E2E Dataset: New Challenges For End-to-End Generation**](https://doi.org/10.18653/v1/W17-5525) ğŸ‘¨â€ğŸ“Jekaterina Novikova,Ondrej Dusek,Verena Rieser 2017 ![](https://img.shields.io/badge/pub-2017--06--28-green)![](https://img.shields.io/badge/cite-290-red)

[**Attention is All you Need**](https://arxiv.org/abs/2302.135401706.03762) ğŸ‘¨â€ğŸ“Ashish Vaswani,Noam M. Shazeer,Niki Parmar,Jakob Uszkoreit,Llion Jones,Aidan N. Gomez,Lukasz Kaiser,Illia Polosukhin 2017 ![](https://img.shields.io/badge/pub-2017--06--12-green)![](https://img.shields.io/badge/cite-51971-red)

[**Get To The Point: Summarization with Pointer-Generator Networks**](https://doi.org/10.18653/v1/P17-1099) ğŸ‘¨â€ğŸ“A. See,Peter J. Liu,Christopher D. Manning 2017 ![](https://img.shields.io/badge/pub-2017--04--01-green)![](https://img.shields.io/badge/cite-2927-red)

[**Categorical Reparameterization with Gumbel-Softmax**](https://arxiv.org/abs/2302.135401611.01144) ğŸ‘¨â€ğŸ“Eric Jang,S. Gu,Ben Poole 2016 ![](https://img.shields.io/badge/pub-2016--11--03-green)![](https://img.shields.io/badge/cite-3360-red)

[**The Oxford handbook of information structure**](https://doi.org/10.1093/OXFORDHB/9780199642670.001.0001) ğŸ‘¨â€ğŸ“C. FÃ©ry,S. Ishihara 2016 ![](https://img.shields.io/badge/pub-2016--07--28-green)![](https://img.shields.io/badge/cite-94-red)

[**Zur Stellung von Modalpartikeln in der gesprochenen Sprache**](https://doi.org/10.37307/j.1868-775x.2016.02.02) ğŸ‘¨â€ğŸ“Daniel Gutzmann,Katharina Turgay 2016 ![](https://img.shields.io/badge/pub-2016--06--10-green)![](https://img.shields.io/badge/cite-2-red)

[**Assessing Cognitive Distraction in the Automobile**](https://doi.org/10.1177/0018720815575149) ğŸ‘¨â€ğŸ“D. Strayer,Jonna Turrill,J. Cooper,James R. Coleman,Nathan Medeiros-Ward,F. Biondi 2015 ![](https://img.shields.io/badge/pub-2015--12--01-green)![](https://img.shields.io/badge/cite-147-red)

[**Teaching Machines to Read and Comprehend**](https://arxiv.org/abs/2302.135401506.03340) ğŸ‘¨â€ğŸ“K. Hermann,TomÃ¡s KociskÃ½,Edward Grefenstette,Lasse Espeholt,Will Kay,Mustafa Suleyman,P. Blunsom 2015 ![](https://img.shields.io/badge/pub-2015--06--10-green)![](https://img.shields.io/badge/cite-2785-red)

[**Empirical Evidence for a Diminished Sense of Agency in Speech Interfaces**](https://doi.org/10.1145/2702123.2702379) ğŸ‘¨â€ğŸ“Hannah Limerick,James W. Moore,D. Coyle 2015 ![](https://img.shields.io/badge/pub-2015--04--18-green)![](https://img.shields.io/badge/cite-48-red)

[**A Model of Coherence Based on Distributed Sentence Representation**](https://doi.org/10.3115/v1/D14-1218) ğŸ‘¨â€ğŸ“Jiwei Li,E. Hovy 2014 ![](https://img.shields.io/badge/pub-2014--10--01-green)![](https://img.shields.io/badge/cite-140-red)

[**Measuring linguistically-induced cognitive load during driving using the ConTRe task**](https://doi.org/10.1145/2516540.2516546) ğŸ‘¨â€ğŸ“V. Demberg,A. Sayeed,Angela Castronovo,Christian A. MÃ¼ller 2013 ![](https://img.shields.io/badge/pub-2013--10--28-green)![](https://img.shields.io/badge/cite-32-red)

[**Modeling Local Coherence: An Entity-Based Approach**](https://doi.org/10.1162/coli.2008.34.1.1) ğŸ‘¨â€ğŸ“R. Barzilay,Mirella Lapata 2008 ![](https://img.shields.io/badge/pub-2008--03--01-green)![](https://img.shields.io/badge/cite-732-red)

[**Safety and Usability of Speech Interfaces for In-Vehicle Tasks while Driving: A Brief Literature Review**](https://api.semanticscholar.org/39bbe946650c6893a816d29b350ed7a3642add5f) ğŸ‘¨â€ğŸ“Adriana Baron,P. Green 2006 ![](https://img.shields.io/badge/pub-2006--02--01-green)![](https://img.shields.io/badge/cite-122-red)

[**Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization**](https://arxiv.org/abs/2302.13540cs/0405039) ğŸ‘¨â€ğŸ“R. Barzilay,Lillian Lee 2004 ![](https://img.shields.io/badge/pub-2004--05--01-green)![](https://img.shields.io/badge/cite-410-red)

[**Grammatik der deutschen Sprache**](https://doi.org/10.1515/9783110872163) ğŸ‘¨â€ğŸ“B. Strecker,Ludger Hoffmann,G. Zifonun 1997 ![](https://img.shields.io/badge/pub-1997--12--31-green)![](https://img.shields.io/badge/cite-455-red)

[**Generated Knowledge Prompting for Commonsense Reasoning**](https://api.semanticscholar.org/12a763cb52f650710900790ca0bc43e5d5b88be6) 2021 

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification**](https://api.semanticscholar.org/6f0aba8102d63938ce0b48ec23ff5ddd8110f2e8) 2021 

[**RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction**](https://api.semanticscholar.org/743dcf234cffd54c4e096a10a284dd81572b16ea) 2022 

[**GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks**](https://api.semanticscholar.org/e147cc46b7f441a68706ca53549d45e9a9843fb6) 2023 

[**Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning**](https://api.semanticscholar.org/096c2791c3dd4b123333e324ce88cd97661ffd3f) 2022 

[**A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT**](https://api.semanticscholar.org/08b85bce712168998004ee80ce4e475390413c74) 2023 

[**Learning to Transfer Prompts for Text Generation**](https://api.semanticscholar.org/42117d01d498eb9f8c21b788c3565bc6855d620b) 2022 

[**Multitask Prompted Training Enables Zero-Shot Task Generalization**](https://api.semanticscholar.org/17dd3555fd1ccf1141cf984347fa1b3fd6b009ca) 2021 

[**Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models**](https://api.semanticscholar.org/fcfc9648561a221750b8085790ad9ba1bebb1800) 2021 

[**Unified Structure Generation for Universal Information Extraction**](https://api.semanticscholar.org/5382c28b9f2dd30f15c836bea92382091b1d886f) 2022 

[**Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation**](https://api.semanticscholar.org/eb53979c96eacec543620af2b899a3772eb6d32f) 2023 

[**Successive Prompting for Decomposing Complex Questions**](https://api.semanticscholar.org/c90151f00b1ac4abf1cc353849b453aa21cc2df3) 2022 

[**SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based Sentiment Analysis**](https://api.semanticscholar.org/2145582245) ğŸ‘¨â€ğŸ“ 2021 

[**Scientific Language Models for Biomedical Knowledge Base Completion: An Empirical Study**](https://api.semanticscholar.org/5bebacad8c1ba330314c87405a86d321f1cfda4b) 2021 

[**Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries**](https://api.semanticscholar.org/51ae2c451a1a05293334a509b71c9c9e0377d35c) 2020 

[**PromptChainer: Chaining Large Language Model Prompts through Visual Programming**](https://api.semanticscholar.org/0f733817e82026f7c29909a51cb4df7d2685f0e7) 2022 

[**Toxicity Detection with Generative Prompt-based Inference**](https://api.semanticscholar.org/2afb07359e9c67499e1f373ac6f1520d3ea9c46a) 2022 

[**Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales**](https://api.semanticscholar.org/03eb8b41de5b201c0535fc3b8a91033abe645325) 2023 

[**Ignore Previous Prompt: Attack Techniques For Language Models**](https://api.semanticscholar.org/9716a2876d08fce9d8e5c5ba4d7b1a9af44806d6) 2022 

[**COPEN: Probing Conceptual Knowledge in Pre-trained Language Models**](https://api.semanticscholar.org/bcec7d17e68aceb91d020dd796ece075694f77c6) 2022 

[**Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding**](https://api.semanticscholar.org/17dcfef70619c0423e0527f0c9d90f4858125f5f) 2022 

[**Representing Text for Joint Embedding of Text and Knowledge Bases**](https://doi.org/10.18653/v1/D15-1174) ğŸ‘¨â€ğŸ“Kristina Toutanova,Danqi Chen,P. Pantel,Hoifung Poon,Pallavi Choudhury,Michael Gamon 2015 ![](https://img.shields.io/badge/cite-550-red)

[**How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks**](https://api.semanticscholar.org/1f040c3a8d49f8e54169a0e07013692c7d58de4b) 2023 

[**Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction**](https://api.semanticscholar.org/85061c524fdd5ec75f06a3329352621bb8d05f43) 2021 

[**SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks**](https://api.semanticscholar.org/b50c27607d7a858297232310bbec9819ade875a8) 2023 

[**LabelPrompt: Effective Prompt-based Learning for Relation Classification**](https://api.semanticscholar.org/b2d783c0ed3bd2c631b99b1487399016a5f00d5f) 2023 

[**Time-Aware Language Models as Temporal Knowledge Bases**](https://api.semanticscholar.org/ac8d33e4c0a45e227a47353f3f26fbb231482dc1) 2021 

[**Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften**](https://doi.org/10.1007/978-3-662-64762-2) ğŸ‘¨â€ğŸ“N. DÃ¶ring 2016 ![](https://img.shields.io/badge/cite-864-red)

[**The Influence of Syntax on the Perception of In-Vehicle Prompts and Driving Performance**](https://doi.org/10.1007/978-981-15-8395-7_26) ğŸ‘¨â€ğŸ“D. Stier,U. Heid,Patricia Kittel,Maria Schmidt,W. Minker 2020 ![](https://img.shields.io/badge/cite-4-red)

[**Menschliche Kommunikation : Formen, StÃ¶rungen, Parodoxien**](https://api.semanticscholar.org/8871dab83c31fce0b01c3574bcb8687cb5d0b0b1) ğŸ‘¨â€ğŸ“P. Watzlawick,Janet Holmick Beavin,Don D. Jackson 1996 ![](https://img.shields.io/badge/cite-387-red)

[**DialogSum: A Real-Life Scenario Dialogue Summarization Dataset**](https://doi.org/10.18653/v1/2021.findings-acl.449) ğŸ‘¨â€ğŸ“Yulong Chen,Yang Liu,Liang Chen,Yue Zhang 2021 ![](https://img.shields.io/badge/cite-58-red)

[**Soziolinguistik**](https://doi.org/10.1007/978-3-476-05861-4) ğŸ‘¨â€ğŸ“JÃ¼rgen SpitzmÃ¼ller 2022 ![](https://img.shields.io/badge/cite-1-red)

[**Prefix-Tuning: Optimizing Continuous Prompts for Generation**](https://doi.org/10.18653/v1/2021.acl-long.353) ğŸ‘¨â€ğŸ“Xiang Lisa Li,Percy Liang 2021 ![](https://img.shields.io/badge/cite-824-red)

[**Discourse-Aware Unsupervised Summarization for Long Scientific Documents**](https://doi.org/10.18653/v1/2021.eacl-main.93) ğŸ‘¨â€ğŸ“Yue Dong,Andrei Mircea,J. C. Cheung 2021 ![](https://img.shields.io/badge/cite-20-red)

[**Properties of spoken and written language.**](https://api.semanticscholar.org/f29972840d1437890af055831d654cbff4bd4058) ğŸ‘¨â€ğŸ“W. Chafe,J. Danielewicz 1987 ![](https://img.shields.io/badge/cite-428-red)

[**ChemProt-3.0: a global chemical biology diseases mapping**](https://doi.org/10.1093/database/bav123) ğŸ‘¨â€ğŸ“Jens Vindahl 2016 ![](https://img.shields.io/badge/cite-87-red)

[**One Voice Fits All? Social Implications and Research Challenges of Designing Voices for Smart Devices**](https://api.semanticscholar.org/624f21e273c74335044806e0e1669ce5f26587c4) ğŸ‘¨â€ğŸ“Julia Cambre,Chinmay Kulkarni 2019 ![](https://img.shields.io/badge/cite-35-red)

[**Promptagator: Few-shot Dense Retrieval From 8 Examples**](https://api.semanticscholar.org/e86009d9f9b1cdf083a48d087552bc4153784451) 2022 

[**EinfÃ¼hrung in die Grammatik der deutschen Gegenwartssprache**](https://doi.org/10.1515/9783110918861) ğŸ‘¨â€ğŸ“K. Sommerfeldt,G. Starke,W. Hackel 1998 ![](https://img.shields.io/badge/cite-26-red)

[**From discourse structures to text summaries**](https://api.semanticscholar.org/1daf375141571501ca8c30b62d7c14269d566762) ğŸ‘¨â€ğŸ“D. Marcu 1997 ![](https://img.shields.io/badge/cite-330-red)

[**PRIMER: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization**](https://api.semanticscholar.org/2a7023e7d1dbd6ea0d98efd09a1f18d8599fe78f) ğŸ‘¨â€ğŸ“Wen Xiao,Iz Beltagy,G. Carenini,Arman Cohan 2021 ![](https://img.shields.io/badge/cite-19-red)

[**AdaPrompt: Adaptive Prompt-based Finetuning for Relation Extraction**](https://api.semanticscholar.org/2404aecd866cfa15fee6ada095667980a63c4172) ğŸ‘¨â€ğŸ“Xiang Chen,Xin Xie,Ningyu Zhang,Jiahuan Yan,Shumin Deng,Chuanqi Tan,Fei Huang,Luo Si,Huajun Chen 2021 ![](https://img.shields.io/badge/cite-31-red)

[**Prompt Combines Paraphrase: Enhancing Biomedical â€œPre-training, Prompt and Predictingâ€ Models by Explaining Rare Biomedical Concepts**](https://api.semanticscholar.org/4e305fe2ef347caddd8936bc0a8c462e33f6e2da) ğŸ‘¨â€ğŸ“Hao Wang 2021 ![](https://img.shields.io/badge/cite-1-red)

[**Zur Abfolge nominaler Satzglieder im Deutschen**](https://api.semanticscholar.org/d93a04ab220196e6bbe3c8ff39b40ff6a8b7ca5a) ğŸ‘¨â€ğŸ“J. Lenerz 1977 ![](https://img.shields.io/badge/cite-367-red)

[**Unified Knowledge Prompt Pre-training for Customer Service Dialogues**](https://api.semanticscholar.org/d0bdabbecba66084af3e4135e656f5277097fb7c) 2022 

[**Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints**](https://api.semanticscholar.org/3f83582c08a62e5bd02398fafc93f7eaf1e4b84e) 2023 

[**Self-Instruct: Aligning Language Model with Self Generated Instructions**](https://api.semanticscholar.org/bbe93c90b7b87939cd064c805858feca61a3234d) 2022 

[**One Embedder, Any Task: Instruction-Finetuned Text Embeddings**](https://api.semanticscholar.org/9f61d366b9d00becb25f7823997c626c6b1d5c16) 2022 

[**Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis**](https://api.semanticscholar.org/cd6fba0c9c34a2c9ff1ed17d2f9f50d8a3399669) 2023 

[**Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition**](https://api.semanticscholar.org/5aa4e5b90827f1c16bed100982e2a1871925d445) 2023 

[**QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition**](https://api.semanticscholar.org/b159dffadb69940e14693e812bdaa32e3957717f) 2022 

[**Materialized Knowledge Bases from Commonsense Transformers**](https://api.semanticscholar.org/66a660bc912fd212db40ded34d34f28e4860a676) 2021 

[**Good Visual Guidance Makes A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction**](https://api.semanticscholar.org/81ad863f8bc438455cb973ae20778a949a54d2b7) 2022 

[**Investigating Prompt Engineering in Diffusion Models**](https://api.semanticscholar.org/d2cfabde7383704e876373e9da9891714b0bd62b) 2022 

[**Language Model Crossover: Variation through Few-Shot Prompting**](https://api.semanticscholar.org/49fede098a0d2a48e8100b30189224fc6f5eb25b) 2023 

[**How Much Knowledge Can You Pack into the Parameters of a Language Model?**](https://api.semanticscholar.org/80376bdec5f534be78ba82821f540590ebce5559) 2020 

[**LightNER: A Lightweight Tuning Paradigm for Low-resource NER via Pluggable Prompting**](https://api.semanticscholar.org/3c12482e523b283cb1a3433b962e9ffc2ed5c65b) 2021 

[**How Context Affects Language Models' Factual Predictions**](https://api.semanticscholar.org/c44120f765fc43994c5cfb4e12e4f62999efeae6) 2020 

[**Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data**](https://api.semanticscholar.org/08433ddb8c799c00008bc71a6252ee473585f7e3) 2022 

[**Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models**](https://api.semanticscholar.org/69619a2a47faee7a29ec596db13172e2a42ff921) 2023 

[**Language Models are Unsupervised Multitask Learners**](https://api.semanticscholar.org/9405cc0d6169988371b2755e573cc28650d14dfe) ğŸ‘¨â€ğŸ“Alec Radford,Jeff Wu,Rewon Child,D. Luan,Dario Amodei,Ilya Sutskever 2019 ![](https://img.shields.io/badge/cite-8849-red)

[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://doi.org/10.18653/v1/N19-1423) ğŸ‘¨â€ğŸ“Jacob Devlin,Ming-Wei Chang,Kenton Lee,Kristina Toutanova 2019 ![](https://img.shields.io/badge/cite-47696-red)

[**of the Association for Computational Linguistics:**](https://doi.org/10.1016/b0-08-044854-2/05234-2) ğŸ‘¨â€ğŸ“Vladimir Meza Ruiz,Rashmi Gangadharaiah,Maria Leonor Pacheco,Danqi Chen,Ryan Cotterell 2001 ![](https://img.shields.io/badge/cite-4067-red)

[**Probing Simile Knowledge from Pre-trained Language Models**](https://api.semanticscholar.org/37e664778284314b05fd26177ce14f631ac1550e) 2022 

[**Progressive Prompts: Continual Learning for Language Models**](https://api.semanticscholar.org/86478f285356b5c8d27423e6b939634d9e010fba) 2023 

[**More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models**](https://api.semanticscholar.org/8fdd34153d1035d09dd4a6efa9cb0c91d23d0045) 2023 

[**How Does In-Context Learning Help Prompt Tuning?**](https://api.semanticscholar.org/8c75f0f2393ac08f1749e6177f31a0f8842dae0f) 2023 

[**DocPrompting: Generating Code by Retrieving the Docs**](https://api.semanticscholar.org/0a39442979d6e678dd36bb443ad529c14e86a86e) 2022 

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://api.semanticscholar.org/780a7f5e8ba9b4b451e3dfee1bcfb0f68aba5050) 2023 

[**PLACES: Prompting Language Models for Social Conversation Synthesis**](https://api.semanticscholar.org/5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691) 2023 

[**EvoPrompting: Language Models for Code-Level Neural Architecture Search**](https://api.semanticscholar.org/35d083ff4dc2805c477d0aedc8158fc7a1aefeda) 2023 

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classiï¬cation Rolling Review submission**](https://api.semanticscholar.org/80366efe644f9fa5d1e89775eb7cb135ca46582f) 2021 

[**Legal Prompt Engineering for Multilingual Legal Judgement Prediction**](https://api.semanticscholar.org/ec27f85979899a4193a8ec3b932ddb677c59be62) 2022 

[**Visual Prompt Tuning**](https://api.semanticscholar.org/adb272fbdea3631059cf88ab764bb6c2ce29f965) 2022 

[**Prompting for Multimodal Hateful Meme Classification**](https://api.semanticscholar.org/ae766548699f27e669932de14e1c0f47b2828536) 2023 

[**Batch Prompting: Efficient Inference with Large Language Model APIs**](https://api.semanticscholar.org/e659fa1e79a2a151be331125c14339988542aac3) 2023 



### ğŸ“Œ Automatic Prompt 

[**Active Example Selection for In-Context Learning**](https://doi.org/10.48550/arXiv.2211.04486) ğŸ‘¨â€ğŸ“Yiming Zhang,Shi Feng,Chenhao Tan 2022 ![](https://img.shields.io/badge/pub-2022--11--08-green)![](https://img.shields.io/badge/cite-6-red)

[**Large Language Models Can Self-Improve**](https://doi.org/10.48550/arXiv.2210.11610) ğŸ‘¨â€ğŸ“Jiaxin Huang,S. Gu,Le Hou,Yuexin Wu,Xuezhi Wang,Hongkun Yu,Jiawei Han 2022 ![](https://img.shields.io/badge/pub-2022--10--20-green)![](https://img.shields.io/badge/cite-28-red)

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) ğŸ‘¨â€ğŸ“Zhuosheng Zhang,Aston Zhang,Mu Li,Alexander J. Smola 2022 ![](https://img.shields.io/badge/pub-2022--10--07-green)![](https://img.shields.io/badge/cite-21-red)

[**Complexity-Based Prompting for Multi-Step Reasoning**](https://doi.org/10.48550/arXiv.2210.00720) ğŸ‘¨â€ğŸ“Yao Fu,Hao-Chun Peng,Ashish Sabharwal,Peter Clark,Tushar Khot 2022 ![](https://img.shields.io/badge/pub-2022--10--03-green)![](https://img.shields.io/badge/cite-17-red)

[**Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning**](https://doi.org/10.48550/arXiv.2209.14610) ğŸ‘¨â€ğŸ“Pan Lu,Liang Qiu,Kai-Wei Chang,Y. Wu,Song-Chun Zhu,Tanmay Rajpurohit,Peter Clark,A. Kalyan 2022 ![](https://img.shields.io/badge/pub-2022--09--29-green)![](https://img.shields.io/badge/cite-11-red)

[**Selective Annotation Makes Language Models Better Few-Shot Learners**](https://doi.org/10.48550/arXiv.2209.01975) ğŸ‘¨â€ğŸ“Hongjin Su,Jungo Kasai,Chen Henry Wu,Weijia Shi,Tianlu Wang,Jiayi Xin,Rui Zhang,Mari Ostendorf,Luke Zettlemoyer,Noah A. Smith,Tao Yu 2022 ![](https://img.shields.io/badge/pub-2022--09--05-green)![](https://img.shields.io/badge/cite-20-red)

[**Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models**](https://doi.org/10.1109/TVCG.2022.3209479) ğŸ‘¨â€ğŸ“Hendrik Strobelt,Albert Webson,Victor Sanh,Benjamin Hoover,J. Beyer,H. Pfister,Alexander M. Rush 2022 ![](https://img.shields.io/badge/pub-2022--08--16-green)![](https://img.shields.io/badge/cite-9-red)

[**Exploring CLIP for Assessing the Look and Feel of Images**](https://doi.org/10.48550/arXiv.2207.12396) ğŸ‘¨â€ğŸ“Jianyi Wang,Kelvin C. K. Chan,Chen Change Loy 2022 ![](https://img.shields.io/badge/pub-2022--07--25-green)![](https://img.shields.io/badge/cite-1-red)

[**Rationale-Augmented Ensembles in Language Models**](https://doi.org/10.48550/arXiv.2207.00747) ğŸ‘¨â€ğŸ“Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou 2022 ![](https://img.shields.io/badge/pub-2022--07--02-green)![](https://img.shields.io/badge/cite-25-red)

[**Initial Images: Using Image Prompts to Improve Subject Representation in Multimodal AI Generated Art**](https://doi.org/10.1145/3527927.3532792) ğŸ‘¨â€ğŸ“Han Qiao,Vivian Liu,Lydia B. Chilton 2022 ![](https://img.shields.io/badge/pub-2022--06--20-green)![](https://img.shields.io/badge/cite-5-red)

[**Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models**](https://arxiv.org/abs/2302.135402206.04615) ğŸ‘¨â€ğŸ“A. Srivastava,Abhinav Rastogi,Abhishek Rao,Abu Awal Md Shoeb,Abubakar Abid,Adam Fisch,Adam R. Brown,Adam Santoro,Aditya Gupta,AdriÃ  Garriga-Alonso,Agnieszka Kluska,Aitor Lewkowycz,Akshat Agarwal,Alethea Power,Alex Ray,Alex Warstadt,Alexander W. Kocurek,Ali Safaya,Ali Tazarv,Alice Xiang,Alicia Parrish,Allen Nie,A. Hussain,Amanda Askell,Amanda Dsouza,A. Rahane,Anantharaman S. Iyer,Anders Andreassen,Andrea Santilli,Andreas Stuhlmuller,Andrew M. Dai,Andrew D. La,Andrew Kyle Lampinen,Andy Zou,Angela Jiang,Angelica Chen,Anh Vuong,Animesh Gupta,Anna Gottardi,Antonio Norelli,Anu Venkatesh,Arash Gholamidavoodi,Arfa Tabassum,Arul Menezes,Arun Kirubarajan,A. Mullokandov,Ashish Sabharwal,Austin Herrick,Avia Efrat,Aykut Erdem,Ayla Karakacs,B. R. Roberts,B. S. Loe,Barret Zoph,Bartlomiej Bojanowski,Batuhan Ozyurt,Behnam Hedayatnia,Behnam Neyshabur,Benjamin Inden,Benno Stein,Berk Ekmekci,Bill Yuchen Lin,B. Howald,Cameron Diao,Cameron Dour,Catherine Stinson,Cedrick Argueta,C'esar Ferri Ram'irez,Chandan Singh,Charles Rathkopf,Chenlin Meng,Chitta Baral,Chiyu Wu,Chris Callison-Burch,Chris Waites,Christian Voigt,Christopher D. Manning,Christopher Potts,C. Ramirez,Clara Rivera,Clemencia Siro,Colin Raffel,Courtney Ashcraft,Cristina Garbacea,Damien Sileo,Daniel H Garrette,Dan Hendrycks,D. Kilman,D. Roth,Daniel Freeman,Daniel Khashabi,Daniel Levy,Daniel Gonz'alez,Danny Hernandez,Danqi Chen,Daphne Ippolito,D. Gilboa,David Dohan,D. Drakard,David Jurgens,Debajyoti Datta,Deep Ganguli,Denis Emelin,D. Kleyko,Deniz Yuret,Derek Chen,Derek Tam,D. Hupkes,Diganta Misra,Dilyar Buzan,Dimitri Coelho Mollo,Diyi Yang,Dong-Ho Lee,Ekaterina Shutova,E. D. Cubuk,Elad Segal,Eleanor Hagerman,Elizabeth Barnes,Elizabeth P. Donoway,Ellie Pavlick,E. RodolÃ ,E. Lam,Eric Chu,Eric Tang,Erkut Erdem,Ernie Chang,Ethan A. Chi,Ethan Dyer,E. Jerzak,Ethan Kim,Eunice Engefu Manyasi,Evgenii Zheltonozhskii,Fan Xia,F. Siar,Fernando Mart'inez-Plumed,Francesca Happ'e,FranÃ§ois Chollet,Frieda Rong,Gaurav Mishra,Genta Indra Winata,Gerard de Melo,GermÃ¡n Kruszewski,Giambattista Parascandolo,G. Mariani,Gloria Wang,Gonzalo Jaimovitch-L'opez,Gregor Betz,Guy Gur-Ari,Hana Galijasevic,H. Kim,Hannah Rashkin,Hanna Hajishirzi,Harsh Mehta,H. Bogar,Henry Shevlin,Hinrich SchÃ¼tze,Hiromu Yakura,Hongming Zhang,Hubert Wong,I. Ng,Isaac Noble,Jaap Jumelet,Jack Geissinger,John Kernion,Jacob Hilton,Jaehoon Lee,J. Fisac,J. B. Simon,James Koppel,James Zheng,James Zou,Jan Koco'n,Jana Thompson,Jared Kaplan,Jarema Radom,Jascha Narain Sohl-Dickstein,Jason Phang,Jason Wei,J. Yosinski,Jekaterina Novikova,Jelle Bosscher,Jenni Marsh,Jeremy Kim,Jeroen Taal,Jesse Engel,Jesujoba Oluwadara Alabi,Jiacheng Xu,Jiaming Song,Jillian Tang,Jane W Waweru,John Burden,John Miller,John U. Balis,Jonathan Berant,Jorg Frohberg,Jos Rozen,J. HernÃ¡ndez-Orallo,Joseph Boudeman,Joseph Jones,J. Tenenbaum,Joshua S. Rule,Joyce Chua,Kamil Kanclerz,Karen Livescu,K. Krauth,Karthik Gopalakrishnan,Katerina Ignatyeva,K. Markert,Kaustubh D. Dhole,Kevin Gimpel,K. Omondi,K. Mathewson,Kristen Chiafullo,Ksenia Shkaruta,K. Shridhar,Kyle McDonell,Kyle Richardson,Laria Reynolds,Leo Gao,Li Zhang,Liam Dugan,Lianhui Qin,Lidia Contreras-Ochando,Louis-Philippe Morency,Luca Moschella,Luca Lam,Lucy Noble,Ludwig Schmidt,Luheng He,Luis Oliveros Col'on,Luke Metz,Lutfi Kerem cSenel,Maarten Bosma,Maarten Sap,Maartje ter Hoeve,Madotto Andrea,M. Farooqi,Manaal Faruqui,Mantas Mazeika,Marco Baturan,M. Marelli,Marco Maru,M. Quintana,Marie Tolkiehn,Mario Giulianelli,Martha Lewis,Martin Potthast,Matthew Leavitt,Matthias Hagen,M. Schubert,Medina Baitemirova,M. Arnaud,M. McElrath,Michael A. Yee,Michael Cohen,Mi Gu,Michael I. Ivanitskiy,Michael Starritt,M. Strube,Michal Swkedrowski,Michele Bevilacqua,Michihiro Yasunaga,Mihir Kale,Mike Cain,Mimee Xu,Mirac Suzgun,Monica Tiwari,Mohit Bansal,Moin Aminnaseri,Mor Geva,Mozhdeh Gheini,T. MukundVarma,Nanyun Peng,Nathan Chi,Nayeon Lee,Neta Gur-Ari Krakover,Nicholas Cameron,Nicholas S. Roberts,Nicholas Doiron,Nikita Nangia,Niklas Deckers,Niklas Muennighoff,N. Keskar,Niveditha Iyer,Noah Constant,Noah Fiedel,Nuan Wen,Oliver Zhang,Omar Agha,Omar Elbaghdadi,Omer Levy,Owain Evans,Pablo Antonio Moreno Casares,P. Doshi,Pascale Fung,Paul Pu Liang,Paul Vicol,Pegah Alipoormolabashi,Peiyuan Liao,Percy Liang,Peter W. Chang,P. Eckersley,Phu Mon Htut,Pi-Bei Hwang,P. Milkowski,P. Patil,Pouya Pezeshkpour,P. Oli,Q. Mei,QING LYU,Qinlang Chen,Rabin Banjade,R. Rudolph,Raefer Gabriel,Rahel Habacker,R. Delgado,RaphaÃ«l MilliÃ¨re,Rhythm Garg,Richard Barnes,R. Saurous,Riku Arakawa,Robbe Raymaekers,R. Frank,Rohan Sikand,Roman Novak,Roman Sitelew,Ronan Le Bras,Rosanne Liu,Rowan Jacobs,Rui Zhang,R. Salakhutdinov,Ryan Chi,Ryan Lee,Ryan Stovall,Ryan Teehan,Rylan Yang,Sahib J. Singh,Saif M. Mohammad,Sajant Anand,Sam Dillavou,Sam Shleifer,Sam Wiseman,Samuel Gruetter,Sam Bowman,S. Schoenholz,Sanghyun Han,Sanjeev Kwatra,Sarah A. Rous,Sarik Ghazarian,Sayan Ghosh,S. Casey,Sebastian Bischoff,Sebastian Gehrmann,Sebastian Schuster,Sepideh Sadeghi,Shadi S. Hamdan,Sharon Zhou,Shashank Srivastava,Sherry Shi,Shikhar Singh,Shima Asaadi,S. Gu,Shubh Pachchigar,Shubham Toshniwal,Shyam Upadhyay,Shyamolima Debnath,Siamak Shakeri,Simon Thormeyer,S. Melzi,Siva Reddy,S. Makini,Soo-hwan Lee,Spencer Bradley Torene,Sriharsha Hatwar,S. Dehaene,Stefan Divic,S. Ermon,Stella Rose Biderman,Stephanie C. Lin,S. Prasad,S. Piantadosi,S. Shieber,Summer Misherghi,Svetlana Kiritchenko,Swaroop Mishra,Tal Linzen,Tal Schuster,Tao Li,Tao Yu,Tariq A. Ali,Tatsuo Hashimoto,Te-Lin Wu,T. Desbordes,Theodore Rothschild,Thomas Phan,Tianle Wang,Tiberius Nkinyili,Timo Schick,T. Kornev,Timothy Telleen-Lawton,T. Tunduny,Tobias Gerstenberg,T. Chang,Trishala Neeraj,Tushar Khot,T. Shultz,Uri Shaham,Vedant Misra,V. Demberg,Victoria Nyamai,Vikas Raunak,V. Ramasesh,Vinay Uday Prabhu,Vishakh Padmakumar,Vivek Srikumar,W. Fedus,W. Saunders,William Zhang,W. Vossen,Xiang Ren,Xiaoyu Tong,Xinyi Wu,Xudong Shen,Yadollah Yaghoobzadeh,Yair Lakretz,Yang Song,Yasaman Bahri,Y. Choi,Yichi Yang,Yiding Hao,Yifu Chen,Yonatan Belinkov,Yu Hou,Yu Hou,Yuntao Bai,Zachary Seid,Zhao Xinran,Zhuoye Zhao,Z. Wang,Zijie J. Wang,Zirui Wang,Ziyi Wu,Sahib Singh,Uri Shaham 2022 ![](https://img.shields.io/badge/pub-2022--06--09-green)![](https://img.shields.io/badge/cite-159-red)

[**On the Advance of Making Language Models Better Reasoners**](https://doi.org/10.48550/arXiv.2206.02336) ğŸ‘¨â€ğŸ“Yifei Li,Zeqi Lin,Shizhuo Zhang,Qiang Fu,Bei Chen,Jian-Guang Lou,Weizhu Chen 2022 ![](https://img.shields.io/badge/pub-2022--06--06-green)![](https://img.shields.io/badge/cite-38-red)

[**Large Language Models are Zero-Shot Reasoners**](https://arxiv.org/abs/2302.135402205.11916) ğŸ‘¨â€ğŸ“Takeshi Kojima,S. Gu,Machel Reid,Yutaka Matsuo,Yusuke Iwasawa 2022 ![](https://img.shields.io/badge/pub-2022--05--24-green)![](https://img.shields.io/badge/cite-176-red)

[**Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding**](https://doi.org/10.48550/arXiv.2205.11487) ğŸ‘¨â€ğŸ“Chitwan Saharia,William Chan,Saurabh Saxena,Lala Li,Jay Whang,Emily L. Denton,Seyed Kamyar Seyed Ghasemipour,Burcu Karagol Ayan,S. S. Mahdavi,Raphael Gontijo Lopes,Tim Salimans,Jonathan Ho,David J. Fleet,Mohammad Norouzi 2022 ![](https://img.shields.io/badge/pub-2022--05--23-green)![](https://img.shields.io/badge/cite-528-red)

[**Empathetic Conversational Systems: A Review of Current Advances, Gaps, and Opportunities**](https://doi.org/10.48550/arXiv.2206.05017) ğŸ‘¨â€ğŸ“Aravind Sesagiri Raamkumar,Yinping Yang 2022 ![](https://img.shields.io/badge/pub-2022--05--09-green)![](https://img.shields.io/badge/cite-1-red)

[**Design of Digital Workplace Stress-Reduction Intervention Systems: Effects of Intervention Type and Timing**](https://doi.org/10.1145/3491102.3502027) ğŸ‘¨â€ğŸ“Esther Howe,J. Suh,M. B. Morshed,Daniel J. McDuff,Kael Rowan,Javier Hernandez,Marah Abdin,Gonzalo A. Ramos,Tracy Tran,M. Czerwinski 2022 ![](https://img.shields.io/badge/pub-2022--04--29-green)![](https://img.shields.io/badge/cite-4-red)

[**What are you thinking?: Using CBT and Storytelling to Improve Mental Health Among College Students**](https://doi.org/10.1145/3491102.3517603) ğŸ‘¨â€ğŸ“Aleesha Hamid,Rabiah Arshad,S. Shahid 2022 ![](https://img.shields.io/badge/pub-2022--04--29-green)![](https://img.shields.io/badge/cite-3-red)

[**Opal: Multimodal Image Generation for News Illustration**](https://doi.org/10.1145/3526113.3545621) ğŸ‘¨â€ğŸ“Vivian Liu,Han Qiao,Lydia B. Chilton 2022 ![](https://img.shields.io/badge/pub-2022--04--19-green)![](https://img.shields.io/badge/cite-6-red)

[**VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance**](https://doi.org/10.48550/arXiv.2204.08583) ğŸ‘¨â€ğŸ“Katherine Crowson,Stella Rose Biderman,Daniel Kornis,Dashiell Stander,Eric Hallahan,Louis Castricato,Edward Raff 2022 ![](https://img.shields.io/badge/pub-2022--04--18-green)![](https://img.shields.io/badge/cite-90-red)

[**Hierarchical Text-Conditional Image Generation with CLIP Latents**](https://doi.org/10.48550/arXiv.2204.06125) ğŸ‘¨â€ğŸ“A. Ramesh,Prafulla Dhariwal,Alex Nichol,Casey Chu,Mark Chen 2022 ![](https://img.shields.io/badge/pub-2022--04--13-green)![](https://img.shields.io/badge/cite-891-red)

[**PaLM: Scaling Language Modeling with Pathways**](https://arxiv.org/abs/2302.135402204.02311) ğŸ‘¨â€ğŸ“Aakanksha Chowdhery,Sharan Narang,Jacob Devlin,Maarten Bosma,Gaurav Mishra,Adam Roberts,P. Barham,Hyung Won Chung,Charles Sutton,Sebastian Gehrmann,Parker Schuh,Kensen Shi,Sasha Tsvyashchenko,Joshua Maynez,Abhishek Rao,Parker Barnes,Yi Tay,Noam M. Shazeer,Vinodkumar Prabhakaran,Emily Reif,Nan Du,B. Hutchinson,Reiner Pope,James Bradbury,Jacob Austin,M. Isard,Guy Gur-Ari,Pengcheng Yin,Toju Duke,Anselm Levskaya,S. Ghemawat,Sunipa Dev,H. Michalewski,Xavier GarcÃ­a,Vedant Misra,Kevin Robinson,L. Fedus,Denny Zhou,Daphne Ippolito,D. Luan,Hyeontaek Lim,Barret Zoph,A. Spiridonov,Ryan Sepassi,David Dohan,Shivani Agrawal,Mark Omernick,Andrew M. Dai,T. S. Pillai,Marie Pellat,Aitor Lewkowycz,Erica Moreira,Rewon Child,Oleksandr Polozov,Katherine Lee,Zongwei Zhou,Xuezhi Wang,Brennan Saeta,Mark DÃ­az,Orhan Firat,Michele Catasta,Jason Wei,K. Meier-Hellstern,D. Eck,J. Dean,Slav Petrov,Noah Fiedel 2022 ![](https://img.shields.io/badge/pub-2022--04--05-green)![](https://img.shields.io/badge/cite-596-red)

[**Can language models learn from explanations in context?**](https://doi.org/10.48550/arXiv.2204.02329) ğŸ‘¨â€ğŸ“Andrew Kyle Lampinen,I. Dasgupta,Stephanie C. Y. Chan,Kory Matthewson,Michael Henry Tessler,Antonia Creswell,James L. McClelland,Jane X. Wang,Felix Hill 2022 ![](https://img.shields.io/badge/pub-2022--04--05-green)![](https://img.shields.io/badge/cite-60-red)

[**Personalized Image Aesthetics Assessment with Rich Attributes**](https://doi.org/10.1109/CVPR52688.2022.01924) ğŸ‘¨â€ğŸ“Yuzhe Yang,Liwu Xu,Leida Li,Nan Qie,Yaqian Li,Peng Zhang,Yandong Guo 2022 ![](https://img.shields.io/badge/pub-2022--03--31-green)![](https://img.shields.io/badge/cite-5-red)

[**STaR: Bootstrapping Reasoning With Reasoning**](https://doi.org/10.48550/arXiv.2203.14465) ğŸ‘¨â€ğŸ“E. Zelikman,Yuhuai Wu,Noah D. Goodman 2022 ![](https://img.shields.io/badge/pub-2022--03--28-green)![](https://img.shields.io/badge/cite-55-red)

[**Self-Consistency Improves Chain of Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2203.11171) ğŸ‘¨â€ğŸ“Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou 2022 ![](https://img.shields.io/badge/pub-2022--03--21-green)![](https://img.shields.io/badge/cite-126-red)

[**GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models**](https://doi.org/10.48550/arXiv.2203.07281) ğŸ‘¨â€ğŸ“Archiki Prasad,Peter Hase,Xiang Zhou,Mohit Bansal 2022 ![](https://img.shields.io/badge/pub-2022--03--14-green)![](https://img.shields.io/badge/cite-23-red)

[**Training language models to follow instructions with human feedback**](https://doi.org/10.48550/arXiv.2203.02155) ğŸ‘¨â€ğŸ“Long Ouyang,Jeff Wu,Xu Jiang,Diogo Almeida,Carroll L. Wainwright,Pamela Mishkin,Chong Zhang,Sandhini Agarwal,Katarina Slama,Alex Ray,J. Schulman,Jacob Hilton,Fraser Kelton,Luke E. Miller,Maddie Simens,Amanda Askell,P. Welinder,P. Christiano,J. Leike,Ryan J. Lowe 2022 ![](https://img.shields.io/badge/pub-2022--03--04-green)![](https://img.shields.io/badge/cite-411-red)

[**CLIPasso: Semantically-Aware Object Sketching**](https://doi.org/10.1145/3528223.3530068) ğŸ‘¨â€ğŸ“Yael Vinker,Ehsan Pajouheshgar,Jessica Y. Bo,Roman Bachmann,Amit H. Bermano,D. Cohen-Or,A. Zamir,Ariel Shamir 2022 ![](https://img.shields.io/badge/pub-2022--02--11-green)![](https://img.shields.io/badge/cite-22-red)

[**Reasoning Like Program Executors**](https://arxiv.org/abs/2302.135402201.11473) ğŸ‘¨â€ğŸ“Xinyu Pi,Qian Liu,Bei Chen,Morteza Ziyadi,Zeqi Lin,Yan Gao,Qiang Fu,Jian-Guang Lou,Weizhu Chen 2022 ![](https://img.shields.io/badge/pub-2022--01--27-green)![](https://img.shields.io/badge/cite-21-red)

[**Black-box Prompt Learning for Pre-trained Language Models**](https://arxiv.org/abs/2302.135402201.08531) ğŸ‘¨â€ğŸ“Shizhe Diao,Xuechun Li,Yong Lin,Zhichao Huang,Xiao Zhou,Tong Zhang 2022 ![](https://img.shields.io/badge/pub-2022--01--21-green)![](https://img.shields.io/badge/cite-17-red)

[**Black-Box Tuning for Language-Model-as-a-Service**](https://arxiv.org/abs/2302.135402201.03514) ğŸ‘¨â€ğŸ“Tianxiang Sun,Yunfan Shao,Hong Qian,Xuanjing Huang,Xipeng Qiu 2022 ![](https://img.shields.io/badge/pub-2022--01--10-green)![](https://img.shields.io/badge/cite-28-red)

[**High-Resolution Image Synthesis with Latent Diffusion Models**](https://doi.org/10.1109/CVPR52688.2022.01042) ğŸ‘¨â€ğŸ“Robin Rombach,A. Blattmann,Dominik Lorenz,Patrick Esser,B. Ommer 2021 ![](https://img.shields.io/badge/pub-2021--12--20-green)![](https://img.shields.io/badge/cite-678-red)

[**GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models**](https://arxiv.org/abs/2302.135402112.10741) ğŸ‘¨â€ğŸ“Alex Nichol,Prafulla Dhariwal,A. Ramesh,Pranav Shyam,Pamela Mishkin,Bob McGrew,Ilya Sutskever,Mark Chen 2021 ![](https://img.shields.io/badge/pub-2021--12--20-green)![](https://img.shields.io/badge/cite-428-red)

[**Human Parity on CommonsenseQA: Augmenting Self-Attention with External Attention**](https://doi.org/10.24963/ijcai.2022/383) ğŸ‘¨â€ğŸ“Yichong Xu,Chenguang Zhu,Shuohang Wang,Siqi Sun,Hao Cheng,Xiaodong Liu,Jianfeng Gao,Pengcheng He,Michael Zeng,Xuedong Huang 2021 ![](https://img.shields.io/badge/pub-2021--12--06-green)![](https://img.shields.io/badge/cite-18-red)

[**Efficient Neural Network Training via Forward and Backward Propagation Sparsification**](https://arxiv.org/abs/2302.135402111.05685) ğŸ‘¨â€ğŸ“Xiao Zhou,Weizhong Zhang,Zonghao Chen,Shizhe Diao,Tong Zhang 2021 ![](https://img.shields.io/badge/pub-2021--11--10-green)![](https://img.shields.io/badge/cite-18-red)

[**Training Verifiers to Solve Math Word Problems**](https://arxiv.org/abs/2302.135402110.14168) ğŸ‘¨â€ğŸ“Karl Cobbe,V. Kosaraju,Mohammad Bavarian,Jacob Hilton,Reiichiro Nakano,Christopher Hesse,J. Schulman 2021 ![](https://img.shields.io/badge/pub-2021--10--27-green)![](https://img.shields.io/badge/cite-171-red)

[**AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts**](https://doi.org/10.1145/3491102.3517582) ğŸ‘¨â€ğŸ“Tongshuang Sherry Wu,Michael Terry,Carrie J. Cai 2021 ![](https://img.shields.io/badge/pub-2021--10--04-green)![](https://img.shields.io/badge/cite-42-red)

[**AffectGAN: Affect-Based Generative Art Driven by Semantics**](https://doi.org/10.1109/aciiw52867.2021.9666317) ğŸ‘¨â€ğŸ“Theodoros Galanos,Antonios Liapis,Georgios N. Yannakakis 2021 ![](https://img.shields.io/badge/pub-2021--09--28-green)![](https://img.shields.io/badge/cite-5-red)

[**Interpretable Directed Diversity: Leveraging Model Explanations for Iterative Crowd Ideation**](https://doi.org/10.1145/3491102.3517551) ğŸ‘¨â€ğŸ“Yunlong Wang,Priyadarshini Venkatesh,Brian Y. Lim 2021 ![](https://img.shields.io/badge/pub-2021--09--21-green)![](https://img.shields.io/badge/cite-6-red)

[**Design Guidelines for Prompt Engineering Text-to-Image Generative Models**](https://doi.org/10.1145/3491102.3501825) ğŸ‘¨â€ğŸ“Vivian Liu,Lydia B. Chilton 2021 ![](https://img.shields.io/badge/pub-2021--09--14-green)![](https://img.shields.io/badge/cite-41-red)

[**MWPToolkit: An Open-Source Framework for Deep Learning-Based Math Word Problem Solvers**](https://doi.org/10.1609/aaai.v36i11.21723) ğŸ‘¨â€ğŸ“Yihuai Lan,Lei Wang,Qiyuan Zhang,Yunshi Lan,B. Dai,Yan Wang,Dongxiang Zhang,Ee-Peng Lim 2021 ![](https://img.shields.io/badge/pub-2021--09--02-green)![](https://img.shields.io/badge/cite-26-red)

[**Learning to Prompt for Vision-Language Models**](https://doi.org/10.1007/s11263-022-01653-1) ğŸ‘¨â€ğŸ“Kaiyang Zhou,Jingkang Yang,Chen Change Loy,Ziwei Liu 2021 ![](https://img.shields.io/badge/pub-2021--09--02-green)![](https://img.shields.io/badge/cite-222-red)

[**Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**](https://doi.org/10.1145/3560815) ğŸ‘¨â€ğŸ“Pengfei Liu,Weizhe Yuan,Jinlan Fu,Zhengbao Jiang,Hiroaki Hayashi,Graham Neubig 2021 ![](https://img.shields.io/badge/pub-2021--07--28-green)![](https://img.shields.io/badge/cite-429-red)

[**Evaluating Large Language Models Trained on Code**](https://arxiv.org/abs/2302.135402107.03374) ğŸ‘¨â€ğŸ“Mark Chen,Jerry Tworek,Heewoo Jun,Qiming Yuan,Henrique Ponde,Jared Kaplan,Harrison Edwards,Yura Burda,Nicholas Joseph,Greg Brockman,Alex Ray,Raul Puri,Gretchen Krueger,Michael Petrov,Heidy Khlaaf,Girish Sastry,Pamela Mishkin,Brooke Chan,Scott Gray,Nick Ryder,Mikhail Pavlov,Alethea Power,Lukasz Kaiser,Mohammad Bavarian,Clemens Winter,Philippe Tillet,F. Such,D. Cummings,Matthias Plappert,Fotios Chantzis,Elizabeth Barnes,Ariel Herbert-Voss,William H. Guss,Alex Nichol,I. Babuschkin,S. Balaji,Shantanu Jain,A. Carr,J. Leike,Joshua Achiam,Vedant Misra,Evan Morikawa,Alec Radford,M. Knight,Miles Brundage,Mira Murati,Katie Mayer,P. Welinder,Bob McGrew,Dario Amodei,Sam McCandlish,Ilya Sutskever,Wojciech Zaremba 2021 ![](https://img.shields.io/badge/pub-2021--07--07-green)![](https://img.shields.io/badge/cite-594-red)

[**BARTScore: Evaluating Generated Text as Text Generation**](https://arxiv.org/abs/2302.135402106.11520) ğŸ‘¨â€ğŸ“Weizhe Yuan,Graham Neubig,Pengfei Liu 2021 ![](https://img.shields.io/badge/pub-2021--06--22-green)![](https://img.shields.io/badge/cite-167-red)

[**What Context Features Can Transformer Language Models Use?**](https://doi.org/10.18653/v1/2021.acl-long.70) ğŸ‘¨â€ğŸ“J. O'Connor,Jacob Andreas 2021 ![](https://img.shields.io/badge/pub-2021--06--15-green)![](https://img.shields.io/badge/cite-36-red)

[**PTR: Prompt Tuning with Rules for Text Classification**](https://doi.org/10.1016/j.aiopen.2022.11.003) ğŸ‘¨â€ğŸ“Xu Han,Weilin Zhao,Ning Ding,Zhiyuan Liu,Maosong Sun 2021 ![](https://img.shields.io/badge/pub-2021--05--24-green)![](https://img.shields.io/badge/cite-169-red)

[**The Power of Scale for Parameter-Efficient Prompt Tuning**](https://doi.org/10.18653/v1/2021.emnlp-main.243) ğŸ‘¨â€ğŸ“Brian Lester,Rami Al-Rfou,Noah Constant 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-675-red)

[**Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity**](https://doi.org/10.18653/v1/2022.acl-long.556) ğŸ‘¨â€ğŸ“Yao Lu,Max Bartolo,Alastair Moore,S. Riedel,Pontus Stenetorp 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-165-red)

[**CLIPScore: A Reference-free Evaluation Metric for Image Captioning**](https://doi.org/10.18653/v1/2021.emnlp-main.595) ğŸ‘¨â€ğŸ“Jack Hessel,Ari Holtzman,Maxwell Forbes,R. L. Bras,Yejin Choi 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-108-red)

[**Are Explanations Helpful? A Comparative Study of the Effects of Explanations in AI-Assisted Decision-Making**](https://doi.org/10.1145/3397481.3450650) ğŸ‘¨â€ğŸ“Xinru Wang,M. Yin 2021 ![](https://img.shields.io/badge/pub-2021--04--14-green)![](https://img.shields.io/badge/cite-68-red)

[**Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little**](https://doi.org/10.18653/v1/2021.emnlp-main.230) ğŸ‘¨â€ğŸ“Koustuv Sinha,Robin Jia,D. Hupkes,J. Pineau,Adina Williams,Douwe Kiela 2021 ![](https://img.shields.io/badge/pub-2021--04--14-green)![](https://img.shields.io/badge/cite-119-red)

[**Learning How to Ask: Querying LMs with Mixtures of Soft Prompts**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.410) ğŸ‘¨â€ğŸ“Guanghui Qin,J. Eisner 2021 ![](https://img.shields.io/badge/pub-2021--04--14-green)![](https://img.shields.io/badge/cite-179-red)

[**Factual Probing Is [MASK]: Learning vs. Learning to Recall**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.398) ğŸ‘¨â€ğŸ“Zexuan Zhong,Dan Friedman,Danqi Chen 2021 ![](https://img.shields.io/badge/pub-2021--04--12-green)![](https://img.shields.io/badge/cite-141-red)

[**Therapist art making as a means of helping service users with anxiety problems**](https://doi.org/10.1080/17454832.2021.1918193) ğŸ‘¨â€ğŸ“Andrew Marshall-Tierney 2021 ![](https://img.shields.io/badge/pub-2021--04--03-green)![](https://img.shields.io/badge/cite-2-red)

[**GPT Understands, Too**](https://arxiv.org/abs/2302.135402103.10385) ğŸ‘¨â€ğŸ“Xiao Liu,Yanan Zheng,Zhengxiao Du,Ming Ding,Yujie Qian,Zhilin Yang,Jie Tang 2021 ![](https://img.shields.io/badge/pub-2021--03--18-green)![](https://img.shields.io/badge/cite-254-red)

[**Are NLP Models really able to Solve Simple Math Word Problems?**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.168) ğŸ‘¨â€ğŸ“Arkil Patel,S. Bhattamishra,Navin Goyal 2021 ![](https://img.shields.io/badge/pub-2021--03--11-green)![](https://img.shields.io/badge/cite-82-red)

[**BERTese: Learning to Speak to BERT**](https://doi.org/10.18653/v1/2021.eacl-main.316) ğŸ‘¨â€ğŸ“Adi Haviv,Jonathan Berant,A. Globerson 2021 ![](https://img.shields.io/badge/pub-2021--03--09-green)![](https://img.shields.io/badge/cite-43-red)

[**Learning Transferable Visual Models From Natural Language Supervision**](https://arxiv.org/abs/2302.135402103.00020) ğŸ‘¨â€ğŸ“Alec Radford,Jong Wook Kim,Chris Hallacy,A. Ramesh,Gabriel Goh,Sandhini Agarwal,Girish Sastry,Amanda Askell,Pamela Mishkin,Jack Clark,Gretchen Krueger,Ilya Sutskever 2021 ![](https://img.shields.io/badge/pub-2021--02--26-green)![](https://img.shields.io/badge/cite-3615-red)

[**PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains**](https://doi.org/10.1162/tacl_a_00468) ğŸ‘¨â€ğŸ“Eyal Ben-David,Nadav Oved,Roi Reichart 2021 ![](https://img.shields.io/badge/pub-2021--02--24-green)![](https://img.shields.io/badge/cite-26-red)

[**Calibrate Before Use: Improving Few-Shot Performance of Language Models**](https://arxiv.org/abs/2302.135402102.09690) ğŸ‘¨â€ğŸ“Tony Zhao,Eric Wallace,Shi Feng,D. Klein,Sameer Singh 2021 ![](https://img.shields.io/badge/pub-2021--02--19-green)![](https://img.shields.io/badge/cite-277-red)

[**Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm**](https://doi.org/10.1145/3411763.3451760) ğŸ‘¨â€ğŸ“Laria Reynolds,Kyle McDonell 2021 ![](https://img.shields.io/badge/pub-2021--02--15-green)![](https://img.shields.io/badge/cite-144-red)

[**Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision**](https://arxiv.org/abs/2302.135402102.05918) ğŸ‘¨â€ğŸ“Chao Jia,Yinfei Yang,Ye Xia,Yi-Ting Chen,Zarana Parekh,Hieu Pham,Quoc V. Le,Yun-Hsuan Sung,Zhen Li,Tom Duerig 2021 ![](https://img.shields.io/badge/pub-2021--02--11-green)![](https://img.shields.io/badge/cite-780-red)

[**What Makes Good In-Context Examples for GPT-3?**](https://doi.org/10.18653/v1/2022.deelio-1.10) ğŸ‘¨â€ğŸ“Jiachang Liu,Dinghan Shen,Yizhe Zhang,Bill Dolan,L. Carin,Weizhu Chen 2021 ![](https://img.shields.io/badge/pub-2021--01--17-green)![](https://img.shields.io/badge/cite-163-red)

[**Directed Diversity: Leveraging Language Embedding Distances for Collective Creativity in Crowd Ideation**](https://doi.org/10.1145/3411764.3445782) ğŸ‘¨â€ğŸ“Samuel Rhys Cox,Yunlong Wang,Ashraf Abdul,C. Weth,Brian Y. Lim 2021 ![](https://img.shields.io/badge/pub-2021--01--15-green)![](https://img.shields.io/badge/cite-7-red)

[**Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies**](https://doi.org/10.1162/tacl_a_00370) ğŸ‘¨â€ğŸ“Mor Geva,Daniel Khashabi,Elad Segal,Tushar Khot,D. Roth,Jonathan Berant 2021 ![](https://img.shields.io/badge/pub-2021--01--06-green)![](https://img.shields.io/badge/cite-99-red)

[**Making Pre-trained Language Models Better Few-shot Learners**](https://doi.org/10.18653/v1/2021.acl-long.295) ğŸ‘¨â€ğŸ“Tianyu Gao,Adam Fisch,Danqi Chen 2021 ![](https://img.shields.io/badge/pub-2021--01--01-green)![](https://img.shields.io/badge/cite-635-red)

[**WARP: Word-level Adversarial ReProgramming**](https://doi.org/10.18653/v1/2021.acl-long.381) ğŸ‘¨â€ğŸ“Karen Hambardzumyan,H. Khachatrian,Jonathan May 2021 ![](https://img.shields.io/badge/pub-2021--01--01-green)![](https://img.shields.io/badge/cite-113-red)

[**Taming Transformers for High-Resolution Image Synthesis**](https://doi.org/10.1109/CVPR46437.2021.01268) ğŸ‘¨â€ğŸ“Patrick Esser,Robin Rombach,B. Ommer 2020 ![](https://img.shields.io/badge/pub-2020--12--17-green)![](https://img.shields.io/badge/cite-567-red)

[**A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers**](https://doi.org/10.18653/v1/2020.acl-main.92) ğŸ‘¨â€ğŸ“Shen-Yun Miao,Chao-Chun Liang,Keh-Yih Su 2020 ![](https://img.shields.io/badge/pub-2020--07--01-green)![](https://img.shields.io/badge/cite-57-red)

[**Does the Whole Exceed its Parts? The Effect of AI Explanations on Complementary Team Performance**](https://doi.org/10.1145/3411764.3445717) ğŸ‘¨â€ğŸ“Gagan Bansal,Tongshuang Sherry Wu,Joyce Zhou,Raymond Fok,Besmira Nushi,Ece Kamar,Marco Tulio Ribeiro,Daniel S. Weld 2020 ![](https://img.shields.io/badge/pub-2020--06--26-green)![](https://img.shields.io/badge/cite-173-red)

[**DisARM: An Antithetic Gradient Estimator for Binary Latent Variables**](https://arxiv.org/abs/2302.135402006.10680) ğŸ‘¨â€ğŸ“Zhe Dong,A. Mnih,G. Tucker 2020 ![](https://img.shields.io/badge/pub-2020--06--18-green)![](https://img.shields.io/badge/cite-22-red)

[**DeBERTa: Decoding-enhanced BERT with Disentangled Attention**](https://arxiv.org/abs/2302.135402006.03654) ğŸ‘¨â€ğŸ“Pengcheng He,Xiaodong Liu,Jianfeng Gao,Weizhu Chen 2020 ![](https://img.shields.io/badge/pub-2020--06--05-green)![](https://img.shields.io/badge/cite-734-red)

[**Language Models are Few-Shot Learners**](https://arxiv.org/abs/2302.135402005.14165) ğŸ‘¨â€ğŸ“Tom B. Brown,Benjamin Mann,Nick Ryder,Melanie Subbiah,J. Kaplan,Prafulla Dhariwal,Arvind Neelakantan,Pranav Shyam,Girish Sastry,Amanda Askell,Sandhini Agarwal,Ariel Herbert-Voss,Gretchen Krueger,T. Henighan,Rewon Child,A. Ramesh,Daniel M. Ziegler,Jeff Wu,Clemens Winter,Christopher Hesse,Mark Chen,Eric Sigler,Mateusz Litwin,Scott Gray,Benjamin Chess,Jack Clark,Christopher Berner,Sam McCandlish,Alec Radford,Ilya Sutskever,Dario Amodei 2020 ![](https://img.shields.io/badge/pub-2020--05--28-green)![](https://img.shields.io/badge/cite-8351-red)

[**Textâ€based emotion detection: Advances, challenges, and opportunities**](https://doi.org/10.1002/eng2.12189) ğŸ‘¨â€ğŸ“F. A. Acheampong,Chen Wenyu,Henry Nunoo-Mensah 2020 ![](https://img.shields.io/badge/pub-2020--05--28-green)![](https://img.shields.io/badge/cite-100-red)

[**Towards Persona-Based Empathetic Conversational Models**](https://doi.org/10.18653/v1/2020.emnlp-main.531) ğŸ‘¨â€ğŸ“Peixiang Zhong,Yan Zhu,Yong Liu,Chen Zhang,Hao Wang,Zaiqing Nie,C. Miao 2020 ![](https://img.shields.io/badge/pub-2020--04--26-green)![](https://img.shields.io/badge/cite-44-red)

[**Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models**](https://doi.org/10.1145/3313831.3376739) ğŸ‘¨â€ğŸ“Ryan Louie,Andy Coenen,Cheng-Zhi Anna Huang,Michael Terry,Carrie J. Cai 2020 ![](https://img.shields.io/badge/pub-2020--04--21-green)![](https://img.shields.io/badge/cite-68-red)

[**ThermoPixels: Toolkit for Personalizing Arousal-based Interfaces through Hybrid Crafting**](https://doi.org/10.1145/3357236.3395512) ğŸ‘¨â€ğŸ“M. Umair,C. Sas,M. Alfaras 2020 ![](https://img.shields.io/badge/pub-2020--04--09-green)![](https://img.shields.io/badge/cite-20-red)

[**A Theory of Usable Information Under Computational Constraints**](https://arxiv.org/abs/2302.135402002.10689) ğŸ‘¨â€ğŸ“Yilun Xu,Shengjia Zhao,Jiaming Song,Russell Stewart,S. Ermon 2020 ![](https://img.shields.io/badge/pub-2020--02--25-green)![](https://img.shields.io/badge/cite-73-red)

[**Analyzing and Improving the Image Quality of StyleGAN**](https://doi.org/10.1109/cvpr42600.2020.00813) ğŸ‘¨â€ğŸ“Tero Karras,S. Laine,M. Aittala,Janne Hellsten,J. Lehtinen,Timo Aila 2019 ![](https://img.shields.io/badge/pub-2019--12--03-green)![](https://img.shields.io/badge/cite-2682-red)

[**Square Attack: a query-efficient black-box adversarial attack via random search**](https://doi.org/10.1007/978-3-030-58592-1_29) ğŸ‘¨â€ğŸ“Maksym Andriushchenko,Francesco Croce,Nicolas Flammarion,Matthias Hein 2019 ![](https://img.shields.io/badge/pub-2019--11--29-green)![](https://img.shields.io/badge/cite-412-red)

[**How Can We Know What Language Models Know?**](https://doi.org/10.1162/tacl_a_00324) ğŸ‘¨â€ğŸ“Zhengbao Jiang,Frank F. Xu,J. Araki,Graham Neubig 2019 ![](https://img.shields.io/badge/pub-2019--11--28-green)![](https://img.shields.io/badge/cite-419-red)

[**Black-Box Adversarial Attack with Transferable Model-based Embedding**](https://arxiv.org/abs/2302.135401911.07140) ğŸ‘¨â€ğŸ“Zhichao Huang,Tong Zhang 2019 ![](https://img.shields.io/badge/pub-2019--11--17-green)![](https://img.shields.io/badge/cite-71-red)

[**ZEN: Pre-training Chinese Text Encoder Enhanced by N-gram Representations**](https://doi.org/10.18653/v1/2020.findings-emnlp.425) ğŸ‘¨â€ğŸ“Shizhe Diao,Jiaxin Bai,Yan Song,Tong Zhang,Yonggang Wang 2019 ![](https://img.shields.io/badge/pub-2019--11--02-green)![](https://img.shields.io/badge/cite-77-red)

[**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**](https://arxiv.org/abs/2302.135401910.10683) ğŸ‘¨â€ğŸ“Colin Raffel,Noam M. Shazeer,Adam Roberts,Katherine Lee,Sharan Narang,Michael Matena,Yanqi Zhou,Wei Li,Peter J. Liu 2019 ![](https://img.shields.io/badge/pub-2019--10--23-green)![](https://img.shields.io/badge/cite-6286-red)

[**Online panels in social science research: Expanding sampling methods beyond Mechanical Turk**](https://doi.org/10.3758/s13428-019-01273-7) ğŸ‘¨â€ğŸ“Jesse J. Chandler,Cheskie Rosenzweig,Aaron J. Moss,Jonathan Robinson,L. Litman 2019 ![](https://img.shields.io/badge/pub-2019--09--11-green)![](https://img.shields.io/badge/cite-233-red)

[**Commonsense Knowledge Mining from Pretrained Models**](https://doi.org/10.18653/v1/D19-1109) ğŸ‘¨â€ğŸ“Joshua Feldman,Joe Davison,Alexander M. Rush 2019 ![](https://img.shields.io/badge/pub-2019--09--01-green)![](https://img.shields.io/badge/cite-210-red)

[**Universal Adversarial Triggers for Attacking and Analyzing NLP**](https://doi.org/10.18653/v1/D19-1221) ğŸ‘¨â€ğŸ“Eric Wallace,Shi Feng,Nikhil Kandpal,Matt Gardner,Sameer Singh 2019 ![](https://img.shields.io/badge/pub-2019--08--20-green)![](https://img.shields.io/badge/cite-411-red)

[**RoBERTa: A Robustly Optimized BERT Pretraining Approach**](https://arxiv.org/abs/2302.135401907.11692) ğŸ‘¨â€ğŸ“Yinhan Liu,Myle Ott,Naman Goyal,Jingfei Du,Mandar Joshi,Danqi Chen,Omer Levy,M. Lewis,Luke Zettlemoyer,Veselin Stoyanov 2019 ![](https://img.shields.io/badge/pub-2019--07--26-green)![](https://img.shields.io/badge/cite-10930-red)

[**Improving Black-box Adversarial Attacks with a Transfer-based Prior**](https://arxiv.org/abs/2302.135401906.06919) ğŸ‘¨â€ğŸ“Shuyu Cheng,Yinpeng Dong,Tianyu Pang,Hang Su,Jun Zhu 2019 ![](https://img.shields.io/badge/pub-2019--06--17-green)![](https://img.shields.io/badge/cite-172-red)

[**MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms**](https://doi.org/10.18653/v1/N19-1245) ğŸ‘¨â€ğŸ“Aida Amini,Saadia Gabriel,Shanchuan Lin,Rik Koncel-Kedziorski,Yejin Choi,Hannaneh Hajishirzi 2019 ![](https://img.shields.io/badge/pub-2019--05--30-green)![](https://img.shields.io/badge/cite-146-red)

[**e-SNLI: Natural Language Inference with Natural Language Explanations**](https://arxiv.org/abs/2302.135401812.01193) ğŸ‘¨â€ğŸ“Oana-Maria Camburu,Tim RocktÃ¤schel,Thomas Lukasiewicz,P. Blunsom 2018 ![](https://img.shields.io/badge/pub-2018--12--04-green)![](https://img.shields.io/badge/cite-314-red)

[**Large Scale GAN Training for High Fidelity Natural Image Synthesis**](https://arxiv.org/abs/2302.135401809.11096) ğŸ‘¨â€ğŸ“Andrew Brock,Jeff Donahue,K. Simonyan 2018 ![](https://img.shields.io/badge/pub-2018--09--27-green)![](https://img.shields.io/badge/cite-3453-red)

[**Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering**](https://doi.org/10.18653/v1/D18-1260) ğŸ‘¨â€ğŸ“Todor Mihaylov,Peter Clark,Tushar Khot,Ashish Sabharwal 2018 ![](https://img.shields.io/badge/pub-2018--08--13-green)![](https://img.shields.io/badge/cite-343-red)

[**Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors**](https://arxiv.org/abs/2302.135401807.07978) ğŸ‘¨â€ğŸ“Andrew Ilyas,Logan Engstrom,A. Madry 2018 ![](https://img.shields.io/badge/pub-2018--07--20-green)![](https://img.shields.io/badge/cite-264-red)

[**WikiArt Emotions: An Annotated Dataset of Emotions Evoked by Art**](https://api.semanticscholar.org/f9e3a51a38a37b896c895254e619106e9e6a0c96) ğŸ‘¨â€ğŸ“Saif M. Mohammad,Svetlana Kiritchenko 2018 ![](https://img.shields.io/badge/pub-2018--05--01-green)![](https://img.shields.io/badge/cite-34-red)

[**Anchors: High-Precision Model-Agnostic Explanations**](https://doi.org/10.1609/aaai.v32i1.11491) ğŸ‘¨â€ğŸ“Marco Tulio Ribeiro,Sameer Singh,Carlos Guestrin 2018 ![](https://img.shields.io/badge/pub-2018--04--25-green)![](https://img.shields.io/badge/cite-1213-red)

[**Black-box Adversarial Attacks with Limited Queries and Information**](https://arxiv.org/abs/2302.135401804.08598) ğŸ‘¨â€ğŸ“Andrew Ilyas,Logan Engstrom,Anish Athalye,Jessy Lin 2018 ![](https://img.shields.io/badge/pub-2018--04--23-green)![](https://img.shields.io/badge/cite-771-red)

[**Intellingo: An Intelligible Translation Environment**](https://doi.org/10.1145/3173574.3174098) ğŸ‘¨â€ğŸ“Sven Coppers,J. D. V. Bergh,K. Luyten,K. Coninx,Iulianna Van der Lek-Ciudin,Tom Vanallemeersch,Vincent Vandeghinste 2018 ![](https://img.shields.io/badge/pub-2018--04--21-green)![](https://img.shields.io/badge/cite-32-red)

[**LightGBM: A Highly Efficient Gradient Boosting Decision Tree**](https://api.semanticscholar.org/497e4b08279d69513e4d2313a7fd9a55dfb73273) ğŸ‘¨â€ğŸ“Guolin Ke,Qi Meng,Thomas Finley,Taifeng Wang,Wei Chen,Weidong Ma,Qiwei Ye,Tie-Yan Liu 2017 ![](https://img.shields.io/badge/pub-2017--12--04-green)![](https://img.shields.io/badge/cite-4855-red)

[**Decoupled Weight Decay Regularization**](https://api.semanticscholar.org/d07284a6811f1b2745d91bdb06b040b57f226882) ğŸ‘¨â€ğŸ“I. Loshchilov,F. Hutter 2017 ![](https://img.shields.io/badge/pub-2017--11--14-green)![](https://img.shields.io/badge/cite-6264-red)

[**How to Do Things with Emotional Expressions: The Theory of Affective Pragmatics**](https://doi.org/10.1080/1047840X.2017.1328951) ğŸ‘¨â€ğŸ“Andrea Scarantino 2017 ![](https://img.shields.io/badge/pub-2017--07--03-green)![](https://img.shields.io/badge/cite-68-red)

[**Measuring aesthetic emotions: A review of the literature and a new assessment tool**](https://doi.org/10.1371/journal.pone.0178899) ğŸ‘¨â€ğŸ“Ines Schindler,G. Hosoya,Winfried Menninghaus,Ursula Beermann,Valentin Wagner,M. Eid,K. Scherer 2017 ![](https://img.shields.io/badge/pub-2017--06--05-green)![](https://img.shields.io/badge/cite-138-red)

[**A Unified Approach to Interpreting Model Predictions**](https://arxiv.org/abs/2302.135401705.07874) ğŸ‘¨â€ğŸ“Scott M. Lundberg,Su-In Lee 2017 ![](https://img.shields.io/badge/pub-2017--05--22-green)![](https://img.shields.io/badge/cite-8296-red)

[**Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems**](https://doi.org/10.18653/v1/P17-1015) ğŸ‘¨â€ğŸ“Wang Ling,Dani Yogatama,Chris Dyer,P. Blunsom 2017 ![](https://img.shields.io/badge/pub-2017--05--11-green)![](https://img.shields.io/badge/cite-209-red)

[**Empathy, EinfÃ¼hlung, and aesthetic experience: the effect of emotion contagion on appreciation of representational and abstract art using fEMG and SCR**](https://doi.org/10.1007/s10339-017-0800-2) ğŸ‘¨â€ğŸ“G. Gernot,Matthew Pelowski,H. Leder 2017 ![](https://img.shields.io/badge/pub-2017--04--12-green)![](https://img.shields.io/badge/cite-45-red)

[**Introducing the Open Affective Standardized Image Set (OASIS)**](https://doi.org/10.3758/s13428-016-0715-3) ğŸ‘¨â€ğŸ“Benedek Kurdi,Shayn Lozano,M. Banaji 2017 ![](https://img.shields.io/badge/pub-2017--04--01-green)![](https://img.shields.io/badge/cite-285-red)

[**ConceptNet 5.5: An Open Multilingual Graph of General Knowledge**](https://doi.org/10.1609/aaai.v31i1.11164) ğŸ‘¨â€ğŸ“R. Speer,Joshua Chin,Catherine Havasi 2016 ![](https://img.shields.io/badge/pub-2016--12--12-green)![](https://img.shields.io/badge/cite-1624-red)

[**Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization**](https://doi.org/10.1007/s11263-019-01228-7) ğŸ‘¨â€ğŸ“Ramprasaath R. Selvaraju,Abhishek Das,Ramakrishna Vedantam,Michael Cogswell,Devi Parikh,Dhruv Batra 2016 ![](https://img.shields.io/badge/pub-2016--10--07-green)![](https://img.shields.io/badge/cite-9782-red)

[**MAWPS: A Math Word Problem Repository**](https://doi.org/10.18653/v1/N16-1136) ğŸ‘¨â€ğŸ“Rik Koncel-Kedziorski,Subhro Roy,Aida Amini,Nate Kushman,Hannaneh Hajishirzi 2016 ![](https://img.shields.io/badge/pub-2016--06--12-green)![](https://img.shields.io/badge/cite-122-red)

[**Photo Aesthetics Ranking Network with Attributes and Content Adaptation**](https://doi.org/10.1007/978-3-319-46448-0_40) ğŸ‘¨â€ğŸ“Shu Kong,Xiaohui Shen,Zhe L. Lin,R. Mech,Charless C. Fowlkes 2016 ![](https://img.shields.io/badge/pub-2016--06--06-green)![](https://img.shields.io/badge/cite-318-red)

[**XGBoost: A Scalable Tree Boosting System**](https://doi.org/10.1145/2939672.2939785) ğŸ‘¨â€ğŸ“Tianqi Chen,Carlos Guestrin 2016 ![](https://img.shields.io/badge/pub-2016--03--09-green)![](https://img.shields.io/badge/cite-18554-red)

[**Scalable Bayesian Rule Lists**](https://arxiv.org/abs/2302.135401602.08610) ğŸ‘¨â€ğŸ“Hongyu Yang,C. Rudin,M. Seltzer 2016 ![](https://img.shields.io/badge/pub-2016--02--27-green)![](https://img.shields.io/badge/cite-162-red)

[**â€œWhy Should I Trust You?â€: Explaining the Predictions of Any Classifier**](https://doi.org/10.1145/2939672.2939778) ğŸ‘¨â€ğŸ“Marco Tulio Ribeiro,Sameer Singh,Carlos Guestrin 2016 ![](https://img.shields.io/badge/pub-2016--02--16-green)![](https://img.shields.io/badge/cite-9632-red)

[**Building a Large Scale Dataset for Image Emotion Recognition: The Fine Print and The Benchmark**](https://doi.org/10.1609/aaai.v30i1.9987) ğŸ‘¨â€ğŸ“Quanzeng You,Jiebo Luo,Hailin Jin,Jianchao Yang 2016 ![](https://img.shields.io/badge/pub-2016--02--12-green)![](https://img.shields.io/badge/cite-210-red)

[**Effects of Aesthetic Chills on a Cardiac Signature of Emotionality**](https://doi.org/10.1371/journal.pone.0130117) ğŸ‘¨â€ğŸ“Maria Sumpf,Sebastian Jentschke,S. Koelsch 2015 ![](https://img.shields.io/badge/pub-2015--06--17-green)![](https://img.shields.io/badge/cite-45-red)

[**A mixed bag of emotions: Model, predict, and transfer emotion distributions**](https://doi.org/10.1109/CVPR.2015.7298687) ğŸ‘¨â€ğŸ“Kuan-Chuan Peng,Tsuhan Chen,Amir Sadovnik,Andrew C. Gallagher 2015 ![](https://img.shields.io/badge/pub-2015--06--07-green)![](https://img.shields.io/badge/cite-148-red)

[**Concreteness ratings for 40 thousand generally known English word lemmas**](https://doi.org/10.3758/s13428-013-0403-5) ğŸ‘¨â€ğŸ“M. Brysbaert,Amy Beth Warriner,V. Kuperman 2014 ![](https://img.shields.io/badge/pub-2014--09--01-green)![](https://img.shields.io/badge/cite-1149-red)

[**How Art Changes Your Brain: Differential Effects of Visual Art Production and Cognitive Art Evaluation on Functional Brain Connectivity**](https://doi.org/10.1371/journal.pone.0101035) ğŸ‘¨â€ğŸ“A. Bolwerk,Jessica Mack-Andrick,F. Lang,A. DÃ¶rfler,C. MaihÃ¶fner 2014 ![](https://img.shields.io/badge/pub-2014--07--01-green)![](https://img.shields.io/badge/cite-104-red)

[**What does the brain tell us about abstract art?**](https://doi.org/10.3389/fnhum.2014.00085) ğŸ‘¨â€ğŸ“Vered Aviv 2014 ![](https://img.shields.io/badge/pub-2014--02--28-green)![](https://img.shields.io/badge/cite-33-red)

[**Art and Emotions**](https://doi.org/10.1002/APS.1352) ğŸ‘¨â€ğŸ“P. Noy,Dorit Noy-Sharav 2013 ![](https://img.shields.io/badge/pub-2013--06--01-green)![](https://img.shields.io/badge/cite-24-red)

[**Counseling Through Images: Using Photography to Guide the Counseling Process and Achieve Treatment Goals**](https://doi.org/10.1080/15401383.2012.739955) ğŸ‘¨â€ğŸ“Misty M. Ginicola,Cherise Smith,Jessica Trzaska 2012 ![](https://img.shields.io/badge/pub-2012--10--01-green)![](https://img.shields.io/badge/cite-36-red)

[**The 'IKEA Effect': When Labor Leads to Love**](https://doi.org/10.1016/J.JCPS.2011.08.002) ğŸ‘¨â€ğŸ“M. Norton,D. Mochon,D. Ariely 2012 ![](https://img.shields.io/badge/pub-2012--07--01-green)![](https://img.shields.io/badge/cite-722-red)

[**AVA: A large-scale database for aesthetic visual analysis**](https://doi.org/10.1109/CVPR.2012.6247954) ğŸ‘¨â€ğŸ“Naila Murray,L. Marchesotti,F. Perronnin 2012 ![](https://img.shields.io/badge/pub-2012--06--16-green)![](https://img.shields.io/badge/cite-663-red)

[**Physiological Correlates of Aesthetic Perception of Artworks in a Museum**](https://doi.org/10.1037/A0023845) ğŸ‘¨â€ğŸ“W. Tschacher,Steven Greenwood,V. Kirchberg,StÃ©phanie Wintzerith,K. V. D. Berg,Martin TrÃ¶ndle 2012 ![](https://img.shields.io/badge/pub-2012--02--01-green)![](https://img.shields.io/badge/cite-109-red)

[**The effect of prompting to students with different learning styles**](https://doi.org/10.1108/17504971011075192) ğŸ‘¨â€ğŸ“P. Papadopoulos,S. Demetriadis,I. Stamelos,Ioannis A. Tsoukalas 2010 ![](https://img.shields.io/badge/pub-2010--08--24-green)![](https://img.shields.io/badge/cite-3-red)

[**New paradigms for assessing emotional intelligence: theory and data.**](https://doi.org/10.1037/a0012746) ğŸ‘¨â€ğŸ“C. MacCann,R. Roberts 2008 ![](https://img.shields.io/badge/pub-2008--08--01-green)![](https://img.shields.io/badge/cite-377-red)

[**The Perception and Evaluation of Visual Art**](https://doi.org/10.2190/EM.26.2.d) ğŸ‘¨â€ğŸ“H. Hagtvedt,V. Patrick,Reidar Hagtvedt 2008 ![](https://img.shields.io/badge/pub-2008--06--01-green)![](https://img.shields.io/badge/cite-102-red)

[**Are we sensitive to valence differences in emotionally negative stimuli? Electrophysiological evidence from an ERP study**](https://doi.org/10.1016/j.neuropsychologia.2007.04.018) ğŸ‘¨â€ğŸ“Jiajin Yuan,Qinglin Zhang,Antao Chen,Hong Li,Quanhong Wang,Zhongchunxiao Zhuang,S. Jia 2007 ![](https://img.shields.io/badge/pub-2007--12--31-green)![](https://img.shields.io/badge/cite-213-red)

[**Emotional and physical health benefits of expressive writing**](https://doi.org/10.1192/APT.11.5.338) ğŸ‘¨â€ğŸ“K. Baikie,K. Wilhelm 2005 ![](https://img.shields.io/badge/pub-2005--09--01-green)![](https://img.shields.io/badge/cite-398-red)

[**Random Forests**](https://doi.org/10.1023/A:1010933404324) ğŸ‘¨â€ğŸ“L. Breiman 2001 ![](https://img.shields.io/badge/pub-2001--10--01-green)![](https://img.shields.io/badge/cite-73819-red)

[**Simple statistical gradient-following algorithms for connectionist reinforcement learning**](https://doi.org/10.1007/BF00992696) ğŸ‘¨â€ğŸ“Ronald J. Williams 1992 ![](https://img.shields.io/badge/pub-1992--05--01-green)![](https://img.shields.io/badge/cite-6447-red)

[**The Discovery of Grounded Theory: Strategies for Qualitative Research**](https://doi.org/10.1016/S0033-3182(68)71872-7) ğŸ‘¨â€ğŸ“C. Brodsky 1968 ![](https://img.shields.io/badge/pub-1968--05--01-green)![](https://img.shields.io/badge/cite-15196-red)

[**Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language**](https://api.semanticscholar.org/0566c1c3eeeef5c968fced6d80b77fe22d02bbd9) 2022 

[**Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data**](https://api.semanticscholar.org/1358f90705b05cdb20ebe6799b02196205e7e9f0) 2023 

[**Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery**](https://api.semanticscholar.org/31eb3316e4c79f3b2eee3c672c83feceb0893b6b) 2023 

[**Contrastive Demonstration Tuning for Pre-trained Language Models**](https://api.semanticscholar.org/1bed3c1b7a079e7f86a355e4c64c995eab89d49d) 2022 

[**Evaluating the Robustness of Discrete Prompts**](https://api.semanticscholar.org/ce6b0a9877e135c38eb3a6c6705c95422181af78) 2023 

[**Prefix-Tuning: Optimizing Continuous Prompts for Generation**](https://doi.org/10.18653/v1/2021.acl-long.353) ğŸ‘¨â€ğŸ“Xiang Lisa Li,Percy Liang 2021 ![](https://img.shields.io/badge/cite-824-red)

[**Eliciting Knowledge from Language Models Using Automatically Generated Prompts**](https://api.semanticscholar.org/b68b2e81ae2de647394ec05ee62ecf108bf2b50a) 2020 

[**CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge**](https://doi.org/10.18653/v1/N19-1421) ğŸ‘¨â€ğŸ“Alon Talmor,Jonathan Herzig,Nicholas Lourie,Jonathan Berant 2019 ![](https://img.shields.io/badge/cite-523-red)

[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://doi.org/10.18653/v1/N19-1423) ğŸ‘¨â€ğŸ“Jacob Devlin,Ming-Wei Chang,Kenton Lee,Kristina Toutanova 2019 ![](https://img.shields.io/badge/cite-47696-red)

[**Guiding Large Language Models via Directional Stimulus Prompting**](https://api.semanticscholar.org/d8b34e3e1d7171f261fdcf2756e0d7600d43fcfe) 2023 

[**Leveraging CLIP for Image Emotion Recognition**](https://api.semanticscholar.org/4135af40083b7d3513e73bda130dd1106c7508a8) ğŸ‘¨â€ğŸ“Alessandro Bondielli,Lucia C. Passaro 2021 ![](https://img.shields.io/badge/cite-3-red)

[**Negative brain: an integrative review on the neural processes activated by unpleasant stimuli.**](https://doi.org/10.1016/j.ijpsycho.2008.07.006) ğŸ‘¨â€ğŸ“L. CarretiÃ©,J. Albert,S. LÃ³pez-MartÃ­n,M. Tapia 2009 ![](https://img.shields.io/badge/cite-117-red)

[**CARER: Contextualized Affect Representations for Emotion Recognition**](https://doi.org/10.18653/v1/D18-1404) ğŸ‘¨â€ğŸ“Elvis Saravia,Hsien-Chi Toby Liu,Yen-Hao Huang,Junlin Wu,Yi-Shin Chen 2018 ![](https://img.shields.io/badge/cite-105-red)

[**Do the best design ideas (really) come from conceptually distant sources of inspiration**](https://doi.org/10.1016/J.DESTUD.2014.08.001) ğŸ‘¨â€ğŸ“Joel Chan,Steven W Dow,C. Schunn 2015 ![](https://img.shields.io/badge/cite-134-red)

[**Cococo: AI-Steering Tools for Music Novices Co-Creating with Generative Models**](https://api.semanticscholar.org/5998dc629e57ad944c3f910a6b43da7780ec6997) ğŸ‘¨â€ğŸ“Ryan Louie,Any Cohen,Cheng-Zhi Anna Huang,Michael Terry,Carrie J. Cai 2020 ![](https://img.shields.io/badge/cite-7-red)

[**DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generative Transformers**](https://api.semanticscholar.org/804b27dc02becf7bbbd89ba949e1e07e8677c459) ğŸ‘¨â€ğŸ“Jaemin Cho,Abhaysinh Zala,Mohit Bansal 2022 ![](https://img.shields.io/badge/cite-34-red)

[**Prompt Engineering for Text-Based Generative Art**](https://doi.org/10.48550/arXiv.2204.13988) ğŸ‘¨â€ğŸ“J. Oppenlaender 2022 ![](https://img.shields.io/badge/cite-4-red)

[**Taming Pre-trained Language Models with N-gram Representations for Low-Resource Domain Adaptation**](https://doi.org/10.18653/v1/2021.acl-long.259) ğŸ‘¨â€ğŸ“Shizhe Diao,Ruijia Xu,Hongjin Su,Yilei Jiang,Yan Song,Tong Zhang 2021 ![](https://img.shields.io/badge/cite-20-red)

[**International affective picture system (IAPS) : affective ratings of pictures and instruction manual**](https://api.semanticscholar.org/788e2f5a24784ce952eec8a57902a6f03cd9318c) ğŸ‘¨â€ğŸ“P. Lang 2005 ![](https://img.shields.io/badge/cite-5555-red)



### ğŸ“Œ Chain of Thought

[**Large Language Models Are Reasoning Teachers**](https://doi.org/10.48550/arXiv.2212.10071) ğŸ‘¨â€ğŸ“Namgyu Ho,Laura Schmid,Se-Young Yun 2022 ![](https://img.shields.io/badge/pub-2022--12--20-green)![](https://img.shields.io/badge/cite-4-red)

[**Teaching Small Language Models to Reason**](https://doi.org/10.48550/arXiv.2212.08410) ğŸ‘¨â€ğŸ“Lucie Charlotte Magister,Jonathan Mallinson,Jakub Adamek,Eric Malmi,Aliaksei Severyn 2022 ![](https://img.shields.io/badge/pub-2022--12--16-green)![](https://img.shields.io/badge/cite-7-red)

[**The Impact of Symbolic Representations on In-context Learning for Few-shot Reasoning**](https://doi.org/10.48550/arXiv.2212.08686) ğŸ‘¨â€ğŸ“Hanlin Zhang,Yi-Fan Zhang,Li Erran Li,Eric Xing 2022 ![](https://img.shields.io/badge/pub-2022--12--16-green)![](https://img.shields.io/badge/cite-2-red)

[**Complementary Explanations for Effective In-Context Learning**](https://doi.org/10.48550/arXiv.2211.13892) ğŸ‘¨â€ğŸ“Xi Ye,Srini Iyer,Asli Celikyilmaz,V. Stoyanov,Greg Durrett,Ramakanth Pasunuru 2022 ![](https://img.shields.io/badge/pub-2022--11--25-green)![](https://img.shields.io/badge/cite-5-red)

[**PAL: Program-aided Language Models**](https://doi.org/10.48550/arXiv.2211.10435) ğŸ‘¨â€ğŸ“Luyu Gao,Aman Madaan,Shuyan Zhou,Uri Alon,Pengfei Liu,Yiming Yang,Jamie Callan,Graham Neubig 2022 ![](https://img.shields.io/badge/pub-2022--11--18-green)![](https://img.shields.io/badge/cite-18-red)

[**Active Example Selection for In-Context Learning**](https://doi.org/10.48550/arXiv.2211.04486) ğŸ‘¨â€ğŸ“Yiming Zhang,Shi Feng,Chenhao Tan 2022 ![](https://img.shields.io/badge/pub-2022--11--08-green)![](https://img.shields.io/badge/cite-6-red)

[**Large Language Models Can Self-Improve**](https://doi.org/10.48550/arXiv.2210.11610) ğŸ‘¨â€ğŸ“Jiaxin Huang,S. Gu,Le Hou,Yuexin Wu,Xuezhi Wang,Hongkun Yu,Jiawei Han 2022 ![](https://img.shields.io/badge/pub-2022--10--20-green)![](https://img.shields.io/badge/cite-28-red)

[**Scaling Instruction-Finetuned Language Models**](https://doi.org/10.48550/arXiv.2210.11416) ğŸ‘¨â€ğŸ“Hyung Won Chung,Le Hou,S. Longpre,Barret Zoph,Yi Tay,W. Fedus,Eric Li,Xuezhi Wang,M. Dehghani,Siddhartha Brahma,Albert Webson,S. Gu,Zhuyun Dai,Mirac Suzgun,Xinyun Chen,Aakanksha Chowdhery,Dasha Valter,Sharan Narang,Gaurav Mishra,A. Yu,Vincent Zhao,Yanping Huang,Andrew M. Dai,Hongkun Yu,Slav Petrov,E. Chi,J. Dean,Jacob Devlin,Adam Roberts,Denny Zhou,Quoc V. Le,Jason Wei 2022 ![](https://img.shields.io/badge/pub-2022--10--20-green)![](https://img.shields.io/badge/cite-53-red)

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) ğŸ‘¨â€ğŸ“Mirac Suzgun,Nathan Scales,Nathanael Scharli,Sebastian Gehrmann,Yi Tay,Hyung Won Chung,Aakanksha Chowdhery,Quoc V. Le,E. Chi,Denny Zhou,Jason Wei 2022 ![](https://img.shields.io/badge/pub-2022--10--17-green)![](https://img.shields.io/badge/cite-27-red)

[**Prompting GPT-3 To Be Reliable**](https://doi.org/10.48550/arXiv.2210.09150) ğŸ‘¨â€ğŸ“Chenglei Si,Zhe Gan,Zhengyuan Yang,Shuohang Wang,Jianfeng Wang,Jordan L. Boyd-Graber,Lijuan Wang 2022 ![](https://img.shields.io/badge/pub-2022--10--17-green)![](https://img.shields.io/badge/cite-9-red)

[**Large Language Models are few(1)-shot Table Reasoners**](https://doi.org/10.48550/arXiv.2210.06710) ğŸ‘¨â€ğŸ“Wenhu Chen 2022 ![](https://img.shields.io/badge/pub-2022--10--13-green)![](https://img.shields.io/badge/cite-8-red)

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) ğŸ‘¨â€ğŸ“Zhuosheng Zhang,Aston Zhang,Mu Li,Alexander J. Smola 2022 ![](https://img.shields.io/badge/pub-2022--10--07-green)![](https://img.shields.io/badge/cite-21-red)

[**Measuring and Narrowing the Compositionality Gap in Language Models**](https://doi.org/10.48550/arXiv.2210.03350) ğŸ‘¨â€ğŸ“Ofir Press,Muru Zhang,Sewon Min,Ludwig Schmidt,Noah A. Smith,M. Lewis 2022 ![](https://img.shields.io/badge/pub-2022--10--07-green)![](https://img.shields.io/badge/cite-23-red)

[**Language Models are Multilingual Chain-of-Thought Reasoners**](https://doi.org/10.48550/arXiv.2210.03057) ğŸ‘¨â€ğŸ“Freda Shi,Mirac Suzgun,Markus Freitag,Xuezhi Wang,Suraj Srivats,Soroush Vosoughi,Hyung Won Chung,Yi Tay,Sebastian Ruder,Denny Zhou,Dipanjan Das,Jason Wei 2022 ![](https://img.shields.io/badge/pub-2022--10--06-green)![](https://img.shields.io/badge/cite-19-red)

[**ReAct: Synergizing Reasoning and Acting in Language Models**](https://doi.org/10.48550/arXiv.2210.03629) ğŸ‘¨â€ğŸ“Shunyu Yao,Jeffrey Zhao,Dian Yu,Nan Du,I. Shafran,Karthik Narasimhan,Yuan Cao 2022 ![](https://img.shields.io/badge/pub-2022--10--06-green)![](https://img.shields.io/badge/cite-15-red)

[**Decomposed Prompting: A Modular Approach for Solving Complex Tasks**](https://doi.org/10.48550/arXiv.2210.02406) ğŸ‘¨â€ğŸ“Tushar Khot,H. Trivedi,Matthew Finlayson,Yao Fu,Kyle Richardson,Peter Clark,Ashish Sabharwal 2022 ![](https://img.shields.io/badge/pub-2022--10--05-green)![](https://img.shields.io/badge/cite-25-red)

[**GLM-130B: An Open Bilingual Pre-trained Model**](https://doi.org/10.48550/arXiv.2210.02414) ğŸ‘¨â€ğŸ“Aohan Zeng,Xiao Liu,Zhengxiao Du,Zihan Wang,Hanyu Lai,Ming Ding,Zhuoyi Yang,Yifan Xu,Wendi Zheng,Xiao Xia,W. Tam,Zixuan Ma,Yufei Xue,Jidong Zhai,Wenguang Chen,P. Zhang,Yuxiao Dong,Jie Tang 2022 ![](https://img.shields.io/badge/pub-2022--10--05-green)![](https://img.shields.io/badge/cite-17-red)

[**Complexity-Based Prompting for Multi-Step Reasoning**](https://doi.org/10.48550/arXiv.2210.00720) ğŸ‘¨â€ğŸ“Yao Fu,Hao-Chun Peng,Ashish Sabharwal,Peter Clark,Tushar Khot 2022 ![](https://img.shields.io/badge/pub-2022--10--03-green)![](https://img.shields.io/badge/cite-17-red)

[**Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought**](https://doi.org/10.48550/arXiv.2210.01240) ğŸ‘¨â€ğŸ“Abulhair Saparov,He He 2022 ![](https://img.shields.io/badge/pub-2022--10--03-green)![](https://img.shields.io/badge/cite-7-red)

[**Compositional Semantic Parsing with Large Language Models**](https://doi.org/10.48550/arXiv.2209.15003) ğŸ‘¨â€ğŸ“Andrew Drozdov,Nathanael Scharli,Ekin Akyuurek,Nathan Scales,Xinying Song,Xinyun Chen,O. Bousquet,Denny Zhou 2022 ![](https://img.shields.io/badge/pub-2022--09--29-green)![](https://img.shields.io/badge/cite-16-red)

[**Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering**](https://doi.org/10.48550/arXiv.2209.09513) ğŸ‘¨â€ğŸ“Pan Lu,Swaroop Mishra,Tony Xia,Liang Qiu,Kai-Wei Chang,Song-Chun Zhu,Oyvind Tafjord,Peter Clark,A. Kalyan 2022 ![](https://img.shields.io/badge/pub-2022--09--20-green)![](https://img.shields.io/badge/cite-15-red)

[**FOLIO: Natural Language Reasoning with First-Order Logic**](https://doi.org/10.48550/arXiv.2209.00840) ğŸ‘¨â€ğŸ“Simeng Han,Hailey Schoelkopf,Yilun Zhao,Zhenting Qi,Martin Riddell,Luke Benson,Lucy Sun,E. Zubova,Yujie Qiao,Matthew Burtell,David Peng,Jonathan Fan,Yixin Liu,Brian Wong,Malcolm Sailor,Ansong Ni,Linyong Nan,Jungo Kasai,Tao Yu,Rui Zhang,Shafiq R. Joty,Alexander R. Fabbri,Wojciech Kryscinski,Xi Victoria Lin,Caiming Xiong,Dragomir R. Radev 2022 ![](https://img.shields.io/badge/pub-2022--09--02-green)![](https://img.shields.io/badge/cite-5-red)

[**Faithful Reasoning Using Large Language Models**](https://doi.org/10.48550/arXiv.2208.14271) ğŸ‘¨â€ğŸ“Antonia Creswell,M. Shanahan 2022 ![](https://img.shields.io/badge/pub-2022--08--30-green)![](https://img.shields.io/badge/cite-24-red)

[**Language models show human-like content effects on reasoning**](https://doi.org/10.48550/arXiv.2207.07051) ğŸ‘¨â€ğŸ“I. Dasgupta,Andrew Kyle Lampinen,Stephanie C. Y. Chan,Antonia Creswell,D. Kumaran,James L. McClelland,Felix Hill 2022 ![](https://img.shields.io/badge/pub-2022--07--14-green)![](https://img.shields.io/badge/cite-19-red)

[**Language Models (Mostly) Know What They Know**](https://doi.org/10.48550/arXiv.2207.05221) ğŸ‘¨â€ğŸ“Saurav Kadavath,Tom Conerly,Amanda Askell,T. Henighan,Dawn Drain,Ethan Perez,Nicholas Schiefer,Z. Dodds,Nova DasSarma,Eli Tran-Johnson,Scott Johnston,S. El-Showk,Andy Jones,Nelson Elhage,Tristan Hume,Anna Chen,Yuntao Bai,Sam Bowman,Stanislav Fort,Deep Ganguli,Danny Hernandez,Josh Jacobson,John Kernion,S. Kravec,Liane Lovitt,Kamal Ndousse,Catherine Olsson,Sam Ringer,Dario Amodei,Tom B. Brown,Jack Clark,Nicholas Joseph,Benjamin Mann,Sam McCandlish,C. Olah,Jared Kaplan 2022 ![](https://img.shields.io/badge/pub-2022--07--11-green)![](https://img.shields.io/badge/cite-30-red)

[**Rationale-Augmented Ensembles in Language Models**](https://doi.org/10.48550/arXiv.2207.00747) ğŸ‘¨â€ğŸ“Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou 2022 ![](https://img.shields.io/badge/pub-2022--07--02-green)![](https://img.shields.io/badge/cite-25-red)

[**Solving Quantitative Reasoning Problems with Language Models**](https://doi.org/10.48550/arXiv.2206.14858) ğŸ‘¨â€ğŸ“Aitor Lewkowycz,Anders Andreassen,David Dohan,Ethan Dyer,H. Michalewski,V. Ramasesh,Ambrose Slone,Cem Anil,Imanol Schlag,Theo Gutman-Solo,Yuhuai Wu,Behnam Neyshabur,Guy Gur-Ari,Vedant Misra 2022 ![](https://img.shields.io/badge/pub-2022--06--29-green)![](https://img.shields.io/badge/cite-88-red)

[**Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)**](https://doi.org/10.48550/arXiv.2206.10498) ğŸ‘¨â€ğŸ“Karthik Valmeekam,Alberto Olmo,S. Sreedharan,Subbarao Kambhampati 2022 ![](https://img.shields.io/badge/pub-2022--06--21-green)![](https://img.shields.io/badge/cite-15-red)

[**Emergent Abilities of Large Language Models**](https://doi.org/10.48550/arXiv.2206.07682) ğŸ‘¨â€ğŸ“Jason Wei,Yi Tay,Rishi Bommasani,Colin Raffel,Barret Zoph,Sebastian Borgeaud,Dani Yogatama,Maarten Bosma,Denny Zhou,Donald Metzler,E. Chi,Tatsunori Hashimoto,Oriol Vinyals,P. Liang,J. Dean,W. Fedus 2022 ![](https://img.shields.io/badge/pub-2022--06--15-green)![](https://img.shields.io/badge/cite-142-red)

[**On the Advance of Making Language Models Better Reasoners**](https://doi.org/10.48550/arXiv.2206.02336) ğŸ‘¨â€ğŸ“Yifei Li,Zeqi Lin,Shizhuo Zhang,Qiang Fu,Bei Chen,Jian-Guang Lou,Weizhu Chen 2022 ![](https://img.shields.io/badge/pub-2022--06--06-green)![](https://img.shields.io/badge/cite-38-red)

[**Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations**](https://doi.org/10.48550/arXiv.2205.12685) ğŸ‘¨â€ğŸ“Junyeob Kim,Hyuhng Joon Kim,Hyunsoo Cho,Hwiyeol Jo,Sang-Woo Lee,Sang-goo Lee,Kang Min Yoo,Taeuk Kim 2022 ![](https://img.shields.io/badge/pub-2022--05--25-green)![](https://img.shields.io/badge/cite-11-red)

[**Large Language Models are Zero-Shot Reasoners**](https://arxiv.org/abs/2302.135402205.11916) ğŸ‘¨â€ğŸ“Takeshi Kojima,S. Gu,Machel Reid,Yutaka Matsuo,Yusuke Iwasawa 2022 ![](https://img.shields.io/badge/pub-2022--05--24-green)![](https://img.shields.io/badge/cite-176-red)

[**Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2205.10625) ğŸ‘¨â€ğŸ“Denny Zhou,Nathanael Scharli,Le Hou,Jason Wei,Nathan Scales,Xuezhi Wang,D. Schuurmans,O. Bousquet,Quoc Le,E. Chi 2022 ![](https://img.shields.io/badge/pub-2022--05--21-green)![](https://img.shields.io/badge/cite-83-red)

[**Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning**](https://doi.org/10.48550/arXiv.2205.09712) ğŸ‘¨â€ğŸ“Antonia Creswell,M. Shanahan,I. Higgins 2022 ![](https://img.shields.io/badge/pub-2022--05--19-green)![](https://img.shields.io/badge/cite-37-red)

[**OPT: Open Pre-trained Transformer Language Models**](https://arxiv.org/abs/2302.135402205.01068) ğŸ‘¨â€ğŸ“Susan Zhang,Stephen Roller,Naman Goyal,Mikel Artetxe,Moya Chen,Shuohui Chen,Christopher Dewan,Mona Diab,Xian Li,Xi Victoria Lin,Todor Mihaylov,Myle Ott,Sam Shleifer,Kurt Shuster,Daniel Simig,Punit Singh Koura,Anjali Sridhar,Tianlu Wang,Luke Zettlemoyer 2022 ![](https://img.shields.io/badge/pub-2022--05--02-green)![](https://img.shields.io/badge/cite-296-red)

[**PaLM: Scaling Language Modeling with Pathways**](https://arxiv.org/abs/2302.135402204.02311) ğŸ‘¨â€ğŸ“Aakanksha Chowdhery,Sharan Narang,Jacob Devlin,Maarten Bosma,Gaurav Mishra,Adam Roberts,P. Barham,Hyung Won Chung,Charles Sutton,Sebastian Gehrmann,Parker Schuh,Kensen Shi,Sasha Tsvyashchenko,Joshua Maynez,Abhishek Rao,Parker Barnes,Yi Tay,Noam M. Shazeer,Vinodkumar Prabhakaran,Emily Reif,Nan Du,B. Hutchinson,Reiner Pope,James Bradbury,Jacob Austin,M. Isard,Guy Gur-Ari,Pengcheng Yin,Toju Duke,Anselm Levskaya,S. Ghemawat,Sunipa Dev,H. Michalewski,Xavier GarcÃ­a,Vedant Misra,Kevin Robinson,L. Fedus,Denny Zhou,Daphne Ippolito,D. Luan,Hyeontaek Lim,Barret Zoph,A. Spiridonov,Ryan Sepassi,David Dohan,Shivani Agrawal,Mark Omernick,Andrew M. Dai,T. S. Pillai,Marie Pellat,Aitor Lewkowycz,Erica Moreira,Rewon Child,Oleksandr Polozov,Katherine Lee,Zongwei Zhou,Xuezhi Wang,Brennan Saeta,Mark DÃ­az,Orhan Firat,Michele Catasta,Jason Wei,K. Meier-Hellstern,D. Eck,J. Dean,Slav Petrov,Noah Fiedel 2022 ![](https://img.shields.io/badge/pub-2022--04--05-green)![](https://img.shields.io/badge/cite-596-red)

[**Can language models learn from explanations in context?**](https://doi.org/10.48550/arXiv.2204.02329) ğŸ‘¨â€ğŸ“Andrew Kyle Lampinen,I. Dasgupta,Stephanie C. Y. Chan,Kory Matthewson,Michael Henry Tessler,Antonia Creswell,James L. McClelland,Jane X. Wang,Felix Hill 2022 ![](https://img.shields.io/badge/pub-2022--04--05-green)![](https://img.shields.io/badge/cite-60-red)

[**STaR: Bootstrapping Reasoning With Reasoning**](https://doi.org/10.48550/arXiv.2203.14465) ğŸ‘¨â€ğŸ“E. Zelikman,Yuhuai Wu,Noah D. Goodman 2022 ![](https://img.shields.io/badge/pub-2022--03--28-green)![](https://img.shields.io/badge/cite-55-red)

[**Self-Consistency Improves Chain of Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2203.11171) ğŸ‘¨â€ğŸ“Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou 2022 ![](https://img.shields.io/badge/pub-2022--03--21-green)![](https://img.shields.io/badge/cite-126-red)

[**Training language models to follow instructions with human feedback**](https://doi.org/10.48550/arXiv.2203.02155) ğŸ‘¨â€ğŸ“Long Ouyang,Jeff Wu,Xu Jiang,Diogo Almeida,Carroll L. Wainwright,Pamela Mishkin,Chong Zhang,Sandhini Agarwal,Katarina Slama,Alex Ray,J. Schulman,Jacob Hilton,Fraser Kelton,Luke E. Miller,Maddie Simens,Amanda Askell,P. Welinder,P. Christiano,J. Leike,Ryan J. Lowe 2022 ![](https://img.shields.io/badge/pub-2022--03--04-green)![](https://img.shields.io/badge/cite-411-red)

[**Chain of Thought Prompting Elicits Reasoning in Large Language Models**](https://arxiv.org/abs/2302.135402201.11903) ğŸ‘¨â€ğŸ“Jason Wei,Xuezhi Wang,Dale Schuurmans,Maarten Bosma,E. Chi,Quoc Le,Denny Zhou 2022 ![](https://img.shields.io/badge/pub-2022--01--28-green)![](https://img.shields.io/badge/cite-368-red)

[**Reasoning Like Program Executors**](https://arxiv.org/abs/2302.135402201.11473) ğŸ‘¨â€ğŸ“Xinyu Pi,Qian Liu,Bei Chen,Morteza Ziyadi,Zeqi Lin,Yan Gao,Qiang Fu,Jian-Guang Lou,Weizhu Chen 2022 ![](https://img.shields.io/badge/pub-2022--01--27-green)![](https://img.shields.io/badge/cite-21-red)

[**Scaling Language Models: Methods, Analysis & Insights from Training Gopher**](https://arxiv.org/abs/2302.135402112.11446) ğŸ‘¨â€ğŸ“Jack W. Rae,Sebastian Borgeaud,Trevor Cai,Katie Millican,Jordan Hoffmann,Francis Song,J. Aslanides,Sarah Henderson,Roman Ring,Susannah Young,Eliza Rutherford,Tom Hennigan,Jacob Menick,Albin Cassirer,Richard Powell,George van den Driessche,Lisa Anne Hendricks,M. Rauh,Po-Sen Huang,A. Glaese,Johannes Welbl,Sumanth Dathathri,Saffron Huang,J. Uesato,John F. J. Mellor,I. Higgins,Antonia Creswell,Nathan McAleese,Amy Wu,Erich Elsen,Siddhant M. Jayakumar,Elena Buchatskaya,D. Budden,Esme Sutherland,K. Simonyan,Michela Paganini,L. Sifre,Lena Martens,Xiang Lorraine Li,A. Kuncoro,Aida Nematzadeh,E. Gribovskaya,Domenic Donato,Angeliki Lazaridou,A. Mensch,J. Lespiau,Maria Tsimpoukelli,N. Grigorev,Doug Fritz,Thibault Sottiaux,Mantas Pajarskas,Tobias Pohlen,Z. Gong,Daniel Toyama,Cyprien de Masson d'Autume,Yujia Li,Tayfun Terzi,Vladimir Mikulik,I. Babuschkin,Aidan Clark,Diego de Las Casas,Aurelia Guy,Chris Jones,James Bradbury,Matthew G. Johnson,Blake A. Hechtman,Laura Weidinger,Iason Gabriel,William S. Isaac,Edward Lockhart,Simon Osindero,Laura Rimell,Chris Dyer,Oriol Vinyals,Kareem W. Ayoub,Jeff Stanway,L. Bennett,D. Hassabis,K. Kavukcuoglu,Geoffrey Irving 2021 ![](https://img.shields.io/badge/pub-2021--12--08-green)![](https://img.shields.io/badge/cite-300-red)

[**Show Your Work: Scratchpads for Intermediate Computation with Language Models**](https://arxiv.org/abs/2302.135402112.00114) ğŸ‘¨â€ğŸ“Maxwell Nye,Anders Andreassen,Guy Gur-Ari,H. Michalewski,Jacob Austin,David Bieber,David Dohan,Aitor Lewkowycz,Maarten Bosma,D. Luan,Charles Sutton,Augustus Odena 2021 ![](https://img.shields.io/badge/pub-2021--11--30-green)![](https://img.shields.io/badge/cite-119-red)

[**Few-Shot Self-Rationalization with Natural Language Prompts**](https://doi.org/10.18653/v1/2022.findings-naacl.31) ğŸ‘¨â€ğŸ“Ana MarasoviÄ‡,Iz Beltagy,Doug Downey,Matthew E. Peters 2021 ![](https://img.shields.io/badge/pub-2021--11--16-green)![](https://img.shields.io/badge/cite-29-red)

[**Training Verifiers to Solve Math Word Problems**](https://arxiv.org/abs/2302.135402110.14168) ğŸ‘¨â€ğŸ“Karl Cobbe,V. Kosaraju,Mohammad Bavarian,Jacob Hilton,Reiichiro Nakano,Christopher Hesse,J. Schulman 2021 ![](https://img.shields.io/badge/pub-2021--10--27-green)![](https://img.shields.io/badge/cite-171-red)

[**Evaluating Large Language Models Trained on Code**](https://arxiv.org/abs/2302.135402107.03374) ğŸ‘¨â€ğŸ“Mark Chen,Jerry Tworek,Heewoo Jun,Qiming Yuan,Henrique Ponde,Jared Kaplan,Harrison Edwards,Yura Burda,Nicholas Joseph,Greg Brockman,Alex Ray,Raul Puri,Gretchen Krueger,Michael Petrov,Heidy Khlaaf,Girish Sastry,Pamela Mishkin,Brooke Chan,Scott Gray,Nick Ryder,Mikhail Pavlov,Alethea Power,Lukasz Kaiser,Mohammad Bavarian,Clemens Winter,Philippe Tillet,F. Such,D. Cummings,Matthias Plappert,Fotios Chantzis,Elizabeth Barnes,Ariel Herbert-Voss,William H. Guss,Alex Nichol,I. Babuschkin,S. Balaji,Shantanu Jain,A. Carr,J. Leike,Joshua Achiam,Vedant Misra,Evan Morikawa,Alec Radford,M. Knight,Miles Brundage,Mira Murati,Katie Mayer,P. Welinder,Bob McGrew,Dario Amodei,Sam McCandlish,Ilya Sutskever,Wojciech Zaremba 2021 ![](https://img.shields.io/badge/pub-2021--07--07-green)![](https://img.shields.io/badge/cite-594-red)

[**Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity**](https://doi.org/10.18653/v1/2022.acl-long.556) ğŸ‘¨â€ğŸ“Yao Lu,Max Bartolo,Alastair Moore,S. Riedel,Pontus Stenetorp 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-165-red)

[**Are NLP Models really able to Solve Simple Math Word Problems?**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.168) ğŸ‘¨â€ğŸ“Arkil Patel,S. Bhattamishra,Navin Goyal 2021 ![](https://img.shields.io/badge/pub-2021--03--11-green)![](https://img.shields.io/badge/cite-82-red)

[**Learning Transferable Visual Models From Natural Language Supervision**](https://arxiv.org/abs/2302.135402103.00020) ğŸ‘¨â€ğŸ“Alec Radford,Jong Wook Kim,Chris Hallacy,A. Ramesh,Gabriel Goh,Sandhini Agarwal,Girish Sastry,Amanda Askell,Pamela Mishkin,Jack Clark,Gretchen Krueger,Ilya Sutskever 2021 ![](https://img.shields.io/badge/pub-2021--02--26-green)![](https://img.shields.io/badge/cite-3615-red)

[**Calibrate Before Use: Improving Few-Shot Performance of Language Models**](https://arxiv.org/abs/2302.135402102.09690) ğŸ‘¨â€ğŸ“Tony Zhao,Eric Wallace,Shi Feng,D. Klein,Sameer Singh 2021 ![](https://img.shields.io/badge/pub-2021--02--19-green)![](https://img.shields.io/badge/cite-277-red)

[**Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies**](https://doi.org/10.1162/tacl_a_00370) ğŸ‘¨â€ğŸ“Mor Geva,Daniel Khashabi,Elad Segal,Tushar Khot,D. Roth,Jonathan Berant 2021 ![](https://img.shields.io/badge/pub-2021--01--06-green)![](https://img.shields.io/badge/cite-99-red)

[**Making Pre-trained Language Models Better Few-shot Learners**](https://doi.org/10.18653/v1/2021.acl-long.295) ğŸ‘¨â€ğŸ“Tianyu Gao,Adam Fisch,Danqi Chen 2021 ![](https://img.shields.io/badge/pub-2021--01--01-green)![](https://img.shields.io/badge/cite-635-red)

[**An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale**](https://arxiv.org/abs/2302.135402010.11929) ğŸ‘¨â€ğŸ“A. Dosovitskiy,L. Beyer,Alexander Kolesnikov,Dirk Weissenborn,Xiaohua Zhai,Thomas Unterthiner,M. Dehghani,Matthias Minderer,G. Heigold,S. Gelly,Jakob Uszkoreit,N. Houlsby 2020 ![](https://img.shields.io/badge/pub-2020--10--22-green)![](https://img.shields.io/badge/cite-10067-red)

[**A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers**](https://doi.org/10.18653/v1/2020.acl-main.92) ğŸ‘¨â€ğŸ“Shen-Yun Miao,Chao-Chun Liang,Keh-Yih Su 2020 ![](https://img.shields.io/badge/pub-2020--07--01-green)![](https://img.shields.io/badge/cite-57-red)

[**Language Models are Few-Shot Learners**](https://arxiv.org/abs/2302.135402005.14165) ğŸ‘¨â€ğŸ“Tom B. Brown,Benjamin Mann,Nick Ryder,Melanie Subbiah,J. Kaplan,Prafulla Dhariwal,Arvind Neelakantan,Pranav Shyam,Girish Sastry,Amanda Askell,Sandhini Agarwal,Ariel Herbert-Voss,Gretchen Krueger,T. Henighan,Rewon Child,A. Ramesh,Daniel M. Ziegler,Jeff Wu,Clemens Winter,Christopher Hesse,Mark Chen,Eric Sigler,Mateusz Litwin,Scott Gray,Benjamin Chess,Jack Clark,Christopher Berner,Sam McCandlish,Alec Radford,Ilya Sutskever,Dario Amodei 2020 ![](https://img.shields.io/badge/pub-2020--05--28-green)![](https://img.shields.io/badge/cite-8351-red)

[**End-to-End Object Detection with Transformers**](https://doi.org/10.1007/978-3-030-58452-8_13) ğŸ‘¨â€ğŸ“Nicolas Carion,Francisco Massa,Gabriel Synnaeve,Nicolas Usunier,Alexander Kirillov,Sergey Zagoruyko 2020 ![](https://img.shields.io/badge/pub-2020--05--26-green)![](https://img.shields.io/badge/cite-4239-red)

[**Unsupervised Cross-lingual Representation Learning at Scale**](https://doi.org/10.18653/v1/2020.acl-main.747) ğŸ‘¨â€ğŸ“Alexis Conneau,Kartikay Khandelwal,Naman Goyal,Vishrav Chaudhary,Guillaume Wenzek,Francisco GuzmÃ¡n,Edouard Grave,Myle Ott,Luke Zettlemoyer,Veselin Stoyanov 2019 ![](https://img.shields.io/badge/pub-2019--11--05-green)![](https://img.shields.io/badge/cite-2728-red)

[**BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension**](https://doi.org/10.18653/v1/2020.acl-main.703) ğŸ‘¨â€ğŸ“M. Lewis,Yinhan Liu,Naman Goyal,Marjan Ghazvininejad,Abdelrahman Mohamed,Omer Levy,Veselin Stoyanov,Luke Zettlemoyer 2019 ![](https://img.shields.io/badge/pub-2019--10--29-green)![](https://img.shields.io/badge/cite-4052-red)

[**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**](https://arxiv.org/abs/2302.135401910.10683) ğŸ‘¨â€ğŸ“Colin Raffel,Noam M. Shazeer,Adam Roberts,Katherine Lee,Sharan Narang,Michael Matena,Yanqi Zhou,Wei Li,Peter J. Liu 2019 ![](https://img.shields.io/badge/pub-2019--10--23-green)![](https://img.shields.io/badge/cite-6286-red)

[**Transformers: State-of-the-Art Natural Language Processing**](https://doi.org/10.18653/v1/2020.emnlp-demos.6) ğŸ‘¨â€ğŸ“Thomas Wolf,Lysandre Debut,Victor Sanh,Julien Chaumond,Clement Delangue,Anthony Moi,Pierric Cistac,T. Rault,RÃ©mi Louf,Morgan Funtowicz,Jamie Brew 2019 ![](https://img.shields.io/badge/pub-2019--10--09-green)![](https://img.shields.io/badge/cite-3941-red)

[**Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks**](https://doi.org/10.18653/v1/D19-1410) ğŸ‘¨â€ğŸ“Nils Reimers,Iryna Gurevych 2019 ![](https://img.shields.io/badge/pub-2019--08--14-green)![](https://img.shields.io/badge/cite-2944-red)

[**RoBERTa: A Robustly Optimized BERT Pretraining Approach**](https://arxiv.org/abs/2302.135401907.11692) ğŸ‘¨â€ğŸ“Yinhan Liu,Myle Ott,Naman Goyal,Jingfei Du,Mandar Joshi,Danqi Chen,Omer Levy,M. Lewis,Luke Zettlemoyer,Veselin Stoyanov 2019 ![](https://img.shields.io/badge/pub-2019--07--26-green)![](https://img.shields.io/badge/cite-10930-red)

[**SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing**](https://doi.org/10.18653/v1/D18-2012) ğŸ‘¨â€ğŸ“Taku Kudo,John Richardson 2018 ![](https://img.shields.io/badge/pub-2018--08--19-green)![](https://img.shields.io/badge/cite-1995-red)

[**Universal Language Model Fine-tuning for Text Classification**](https://doi.org/10.18653/v1/P18-1031) ğŸ‘¨â€ğŸ“Jeremy Howard,Sebastian Ruder 2018 ![](https://img.shields.io/badge/pub-2018--01--18-green)![](https://img.shields.io/badge/cite-2717-red)

[**Decoupled Weight Decay Regularization**](https://api.semanticscholar.org/d07284a6811f1b2745d91bdb06b040b57f226882) ğŸ‘¨â€ğŸ“I. Loshchilov,F. Hutter 2017 ![](https://img.shields.io/badge/pub-2017--11--14-green)![](https://img.shields.io/badge/cite-6264-red)

[**brms: An R Package for Bayesian Multilevel Models Using Stan**](https://doi.org/10.18637/JSS.V080.I01) ğŸ‘¨â€ğŸ“P. BÃ¼rkner 2017 ![](https://img.shields.io/badge/pub-2017--08--29-green)![](https://img.shields.io/badge/cite-3735-red)

[**Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering**](https://doi.org/10.1109/CVPR.2018.00636) ğŸ‘¨â€ğŸ“Peter Anderson,Xiaodong He,Chris Buehler,Damien Teney,Mark Johnson,Stephen Gould,Lei Zhang 2017 ![](https://img.shields.io/badge/pub-2017--07--25-green)![](https://img.shields.io/badge/cite-2873-red)

[**Attention is All you Need**](https://arxiv.org/abs/2302.135401706.03762) ğŸ‘¨â€ğŸ“Ashish Vaswani,Noam M. Shazeer,Niki Parmar,Jakob Uszkoreit,Llion Jones,Aidan N. Gomez,Lukasz Kaiser,Illia Polosukhin 2017 ![](https://img.shields.io/badge/pub-2017--06--12-green)![](https://img.shields.io/badge/cite-51971-red)

[**Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems**](https://doi.org/10.18653/v1/P17-1015) ğŸ‘¨â€ğŸ“Wang Ling,Dani Yogatama,Chris Dyer,P. Blunsom 2017 ![](https://img.shields.io/badge/pub-2017--05--11-green)![](https://img.shields.io/badge/cite-209-red)

[**Domain randomization for transferring deep neural networks from simulation to the real world**](https://doi.org/10.1109/IROS.2017.8202133) ğŸ‘¨â€ğŸ“Joshua Tobin,Rachel Fong,Alex Ray,Jonas Schneider,Wojciech Zaremba,P. Abbeel 2017 ![](https://img.shields.io/badge/pub-2017--03--20-green)![](https://img.shields.io/badge/cite-1944-red)

[**Overcoming catastrophic forgetting in neural networks**](https://doi.org/10.1073/pnas.1611835114) ğŸ‘¨â€ğŸ“J. Kirkpatrick,Razvan Pascanu,Neil C. Rabinowitz,J. Veness,Guillaume Desjardins,Andrei A. Rusu,K. Milan,John Quan,Tiago Ramalho,A. Grabska-Barwinska,D. Hassabis,C. Clopath,D. Kumaran,R. Hadsell 2016 ![](https://img.shields.io/badge/pub-2016--12--02-green)![](https://img.shields.io/badge/cite-3557-red)

[**MAWPS: A Math Word Problem Repository**](https://doi.org/10.18653/v1/N16-1136) ğŸ‘¨â€ğŸ“Rik Koncel-Kedziorski,Subhro Roy,Aida Amini,Nate Kushman,Hannaneh Hajishirzi 2016 ![](https://img.shields.io/badge/pub-2016--06--12-green)![](https://img.shields.io/badge/cite-122-red)

[**Mastering the game of Go with deep neural networks and tree search**](https://doi.org/10.1038/nature16961) ğŸ‘¨â€ğŸ“David Silver,Aja Huang,Chris J. Maddison,A. Guez,L. Sifre,George van den Driessche,Julian Schrittwieser,Ioannis Antonoglou,Vedavyas Panneershelvam,Marc Lanctot,S. Dieleman,Dominik Grewe,John Nham,Nal Kalchbrenner,Ilya Sutskever,T. Lillicrap,M. Leach,K. Kavukcuoglu,T. Graepel,D. Hassabis 2016 ![](https://img.shields.io/badge/pub-2016--01--27-green)![](https://img.shields.io/badge/cite-13105-red)

[**Deep Residual Learning for Image Recognition**](https://doi.org/10.1109/cvpr.2016.90) ğŸ‘¨â€ğŸ“Kaiming He,X. Zhang,Shaoqing Ren,Jian Sun 2015 ![](https://img.shields.io/badge/pub-2015--12--10-green)![](https://img.shields.io/badge/cite-122183-red)

[**Human-level control through deep reinforcement learning**](https://doi.org/10.1038/nature14236) ğŸ‘¨â€ğŸ“Volodymyr Mnih,K. Kavukcuoglu,David Silver,Andrei A. Rusu,J. Veness,Marc G. Bellemare,A. Graves,Martin A. Riedmiller,A. Fidjeland,Georg Ostrovski,Stig Petersen,Charlie Beattie,Amir Sadik,Ioannis Antonoglou,Helen King,D. Kumaran,Daan Wierstra,S. Legg,D. Hassabis 2015 ![](https://img.shields.io/badge/pub-2015--02--25-green)![](https://img.shields.io/badge/cite-19374-red)

[**The Arcade Learning Environment: An Evaluation Platform for General Agents (Extended Abstract)**](https://doi.org/10.1613/jair.3912) ğŸ‘¨â€ğŸ“Marc G. Bellemare,Yavar Naddaf,J. Veness,Michael Bowling 2012 ![](https://img.shields.io/badge/pub-2012--07--19-green)![](https://img.shields.io/badge/cite-2349-red)

[**Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems**](https://doi.org/10.1561/2200000024) ğŸ‘¨â€ğŸ“SÃ©bastien Bubeck,N. Cesa-Bianchi 2012 ![](https://img.shields.io/badge/pub-2012--04--25-green)![](https://img.shields.io/badge/cite-2359-red)

[**A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning**](https://arxiv.org/abs/2302.135401011.0686) ğŸ‘¨â€ğŸ“StÃ©phane Ross,Geoffrey J. Gordon,J. Bagnell 2010 ![](https://img.shields.io/badge/pub-2010--11--02-green)![](https://img.shields.io/badge/cite-2179-red)

[**The Probabilistic Relevance Framework: BM25 and Beyond**](https://doi.org/10.1561/1500000019) ğŸ‘¨â€ğŸ“S. Robertson,H. Zaragoza 2009 ![](https://img.shields.io/badge/pub-2009--04--01-green)![](https://img.shields.io/badge/cite-1854-red)

[**The PASCAL Recognising Textual Entailment Challenge**](https://doi.org/10.1007/11736790_9) ğŸ‘¨â€ğŸ“Ido Dagan,Oren Glickman,B. Magnini 2007 ![](https://img.shields.io/badge/pub-2007--06--28-green)![](https://img.shields.io/badge/cite-1948-red)

[**Bandit Based Monte-Carlo Planning**](https://doi.org/10.1007/11871842_29) ğŸ‘¨â€ğŸ“Levente Kocsis,Csaba Szepesvari 2006 ![](https://img.shields.io/badge/pub-2006--09--18-green)![](https://img.shields.io/badge/cite-2834-red)

[**Finite-time Analysis of the Multiarmed Bandit Problem**](https://doi.org/10.1023/A:1013689704352) ğŸ‘¨â€ğŸ“P. Auer,N. Cesa-Bianchi,P. Fischer 2002 ![](https://img.shields.io/badge/pub-2002--05--01-green)![](https://img.shields.io/badge/cite-5679-red)

[**Individual differences in reasoning: Implications for the rationality debate?**](https://doi.org/10.1017/S0140525X00003435) ğŸ‘¨â€ğŸ“K. Stanovich,R. F. West 2000 ![](https://img.shields.io/badge/pub-2000--10--01-green)![](https://img.shields.io/badge/cite-3595-red)

[**Is imitation learning the route to humanoid robots?**](https://doi.org/10.1016/S1364-6613(99)01327-3) ğŸ‘¨â€ğŸ“S. Schaal 1999 ![](https://img.shields.io/badge/pub-1999--06--01-green)![](https://img.shields.io/badge/cite-1433-red)

[**Active Learning with Statistical Models**](https://doi.org/10.1613/jair.295) ğŸ‘¨â€ğŸ“D. Cohn,Zoubin Ghahramani,Michael I. Jordan 1996 ![](https://img.shields.io/badge/pub-1996--02--29-green)![](https://img.shields.io/badge/cite-2187-red)

[**Markov Decision Processes: Discrete Stochastic Dynamic Programming**](https://doi.org/10.1002/9780470316887) ğŸ‘¨â€ğŸ“M. Puterman 1994 ![](https://img.shields.io/badge/pub-1994--04--15-green)![](https://img.shields.io/badge/cite-12348-red)

[**A Mathematical Introduction to Robotic Manipulation**](https://doi.org/10.1201/9781315136370) ğŸ‘¨â€ğŸ“R. Murray,S. Sastry,Li Ze-xiang 1994 ![](https://img.shields.io/badge/pub-1994--03--22-green)![](https://img.shields.io/badge/cite-6864-red)

[**Simple statistical gradient-following algorithms for connectionist reinforcement learning**](https://doi.org/10.1007/BF00992696) ğŸ‘¨â€ğŸ“Ronald J. Williams 1992 ![](https://img.shields.io/badge/pub-1992--05--01-green)![](https://img.shields.io/badge/cite-6447-red)

[**Probable Inference, the Law of Succession, and Statistical Inference**](https://doi.org/10.1080/01621459.1927.10502953) ğŸ‘¨â€ğŸ“E. B. Wilson 1927 ![](https://img.shields.io/badge/pub-1927--06--01-green)![](https://img.shields.io/badge/cite-3136-red)

[**CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge**](https://doi.org/10.18653/v1/N19-1421) ğŸ‘¨â€ğŸ“Alon Talmor,Jonathan Herzig,Nicholas Lourie,Jonathan Berant 2019 ![](https://img.shields.io/badge/cite-523-red)

[**Language Models are Unsupervised Multitask Learners**](https://api.semanticscholar.org/9405cc0d6169988371b2755e573cc28650d14dfe) ğŸ‘¨â€ğŸ“Alec Radford,Jeff Wu,Rewon Child,D. Luan,Dario Amodei,Ilya Sutskever 2019 ![](https://img.shields.io/badge/cite-8849-red)

[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://doi.org/10.18653/v1/N19-1423) ğŸ‘¨â€ğŸ“Jacob Devlin,Ming-Wei Chang,Kenton Lee,Kristina Toutanova 2019 ![](https://img.shields.io/badge/cite-47696-red)

[**A Learning Algorithm for Boltzmann Machines**](https://doi.org/10.1016/B978-0-08-051581-6.50053-2) ğŸ‘¨â€ğŸ“D. Ackley,Geoffrey E. Hinton,T. Sejnowski 1985 ![](https://img.shields.io/badge/cite-3668-red)

[**The Unreliability of Explanations in Few-Shot In-Context Learning**](https://doi.org/10.48550/arXiv.2205.03401) ğŸ‘¨â€ğŸ“Xi Ye,Greg Durrett 2022 ![](https://img.shields.io/badge/cite-18-red)

[**Active Learning Literature Survey**](https://api.semanticscholar.org/818826f356444f3daa3447755bf63f171f39ec47) ğŸ‘¨â€ğŸ“Burr Settles 2009 ![](https://img.shields.io/badge/cite-5213-red)

[**of the Association for Computational Linguistics:**](https://doi.org/10.1016/b0-08-044854-2/05234-2) ğŸ‘¨â€ğŸ“Vladimir Meza Ruiz,Rashmi Gangadharaiah,Maria Leonor Pacheco,Danqi Chen,Ryan Cotterell 2001 ![](https://img.shields.io/badge/cite-4067-red)

[**Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem**](https://doi.org/10.1016/S0079-7421(08)60536-8) ğŸ‘¨â€ğŸ“M. McCloskey,N. J. Cohen 1989 ![](https://img.shields.io/badge/cite-2581-red)

[**ALVINN: An Autonomous Land Vehicle in a Neural Network**](https://doi.org/10.1184/R1/6603146.V1) ğŸ‘¨â€ğŸ“D. Pomerleau 1988 ![](https://img.shields.io/badge/cite-1676-red)



### ğŸ“Œ Evaluation & Reliability

[**Relay Node Placement in Wireless Sensor Networks With Respect to Delay and Reliability Requirements**](https://doi.org/10.1109/JSYST.2018.2838072) ğŸ‘¨â€ğŸ“Chaofan Ma,W. Liang,M. Zheng,Bofu Yang 2019 ![](https://img.shields.io/badge/pub-2019--09--01-green)![](https://img.shields.io/badge/cite-24-red)

[**Comparative Analysis of Transmission Power Level and Packet Size Optimization Strategies for WSNs**](https://doi.org/10.1109/JSYST.2018.2864941) ğŸ‘¨â€ğŸ“Huseyin Ugur Yildiz,Sinan Kurt,B. Tavli 2019 ![](https://img.shields.io/badge/pub-2019--09--01-green)![](https://img.shields.io/badge/cite-9-red)

[**RBD Model-Based Approach for Reliability Assessment in Complex Systems**](https://doi.org/10.1109/JSYST.2018.2840220) ğŸ‘¨â€ğŸ“M. Catelani,L. Ciani,M. Venzi 2019 ![](https://img.shields.io/badge/pub-2019--09--01-green)![](https://img.shields.io/badge/cite-13-red)

[**Joint Transmission Power Optimization and Connectivity Control in Asymmetric Networks**](https://doi.org/10.23919/ACC.2018.8431490) ğŸ‘¨â€ğŸ“Milad Esmacilpour,A. Aghdam,S. Blouin 2018 ![](https://img.shields.io/badge/pub-2018--06--01-green)![](https://img.shields.io/badge/cite-6-red)

[**Reliability Allocation Procedures in Complex Redundant Systems**](https://doi.org/10.1109/JSYST.2017.2651161) ğŸ‘¨â€ğŸ“M. Catelani,L. Ciani,G. Patrizi,M. Venzi 2018 ![](https://img.shields.io/badge/pub-2018--06--01-green)![](https://img.shields.io/badge/cite-26-red)

[**Device-to-Device Communications: A Performance Analysis in the Context of Social Comparison-Based Relaying**](https://doi.org/10.1109/TWC.2017.2751470) ğŸ‘¨â€ğŸ“Young Jin Chun,Gualtiero Colombo,S. Cotton,W. Scanlon,R. Whitaker,S. Allen 2017 ![](https://img.shields.io/badge/pub-2017--09--15-green)![](https://img.shields.io/badge/cite-17-red)

[**MIMO Wireless Communications over Generalized Fading Channels**](https://doi.org/10.1201/9781315116778) ğŸ‘¨â€ğŸ“B. Kumbhani,R. Kshetrimayum 2017 ![](https://img.shields.io/badge/pub-2017--06--01-green)![](https://img.shields.io/badge/cite-42-red)

[**Energy Saving With Network Coding Design Over Rayleigh Fading Channel**](https://doi.org/10.1109/TWC.2017.2699188) ğŸ‘¨â€ğŸ“Shijun Lin,Liqun Fu,Yong Li 2017 ![](https://img.shields.io/badge/pub-2017--05--03-green)![](https://img.shields.io/badge/cite-6-red)

[**Optimal WSN Deployment Models for Air Pollution Monitoring**](https://doi.org/10.1109/TWC.2017.2658601) ğŸ‘¨â€ğŸ“Ahmed Boubrima,Walid Bechkit,H. Rivano 2017 ![](https://img.shields.io/badge/pub-2017--05--01-green)![](https://img.shields.io/badge/cite-132-red)

[**Distance distribution between nodes in a 3D wireless network**](https://doi.org/10.1016/j.jpdc.2016.09.006) ğŸ‘¨â€ğŸ“J. Nichols,J. Michalowicz 2017 ![](https://img.shields.io/badge/pub-2017--04--01-green)![](https://img.shields.io/badge/cite-8-red)

[**Packet Size Optimization in Wireless Sensor Networks for Smart Grid Applications**](https://doi.org/10.1109/TIE.2016.2619319) ğŸ‘¨â€ğŸ“Sinan Kurt,Huseyin Ugur Yildiz,Melike Yigit,B. Tavli,V. Gungor 2017 ![](https://img.shields.io/badge/pub-2017--03--01-green)![](https://img.shields.io/badge/cite-152-red)

[**Connectivity of Communication Networks**](https://doi.org/10.1007/978-3-319-52989-9) ğŸ‘¨â€ğŸ“Guoqiang Mao 2017 ![](https://img.shields.io/badge/pub-2017--02--28-green)![](https://img.shields.io/badge/cite-21-red)

[**Sleep Scheduling in Industrial Wireless Sensor Networks for Toxic Gas Monitoring**](https://doi.org/10.1109/MWC.2017.1600072WC) ğŸ‘¨â€ğŸ“M. Mukherjee,Lei Shu,Likun Hu,G. Hancke,Chunsheng Zhu 2017 ![](https://img.shields.io/badge/pub-2017--01--05-green)![](https://img.shields.io/badge/cite-49-red)

[**Analysis of Connectivity and Capacity in 1-D Vehicle-to-Vehicle Networks**](https://doi.org/10.1109/TWC.2016.2613078) ğŸ‘¨â€ğŸ“Sungoh Kwon,Yoora Kim,N. Shroff 2016 ![](https://img.shields.io/badge/pub-2016--12--01-green)![](https://img.shields.io/badge/cite-34-red)

[**Joint Optimization of Transmission Power Level and Packet Size for WSN Lifetime Maximization**](https://doi.org/10.1109/JSEN.2016.2548661) ğŸ‘¨â€ğŸ“Ayhan Akbas,Huseyin Ugur Yildiz,B. Tavli,S. Uludag 2016 ![](https://img.shields.io/badge/pub-2016--06--15-green)![](https://img.shields.io/badge/cite-34-red)

[**Network Reliability: Measures and Evaluation**](https://doi.org/10.1002/9781119224006) ğŸ‘¨â€ğŸ“S. Chaturvedi 2016 ![](https://img.shields.io/badge/pub-2016--05--31-green)![](https://img.shields.io/badge/cite-36-red)

[**A Stochastic Geometric Analysis of Device-to-Device Communications Operating Over Generalized Fading Channels**](https://doi.org/10.1109/TWC.2017.2689759) ğŸ‘¨â€ğŸ“Young Jin Chun,S. Cotton,Harpreet S. Dhillon,A. Ghrayeb,M. Hasna 2016 ![](https://img.shields.io/badge/pub-2016--05--10-green)![](https://img.shields.io/badge/cite-89-red)

[**All-Terminal Reliability Analysis of Wireless Networks of Redundant Radio Modules**](https://doi.org/10.1109/JIOT.2015.2496259) ğŸ‘¨â€ğŸ“Jae-Hyun Park 2016 ![](https://img.shields.io/badge/pub-2016--04--01-green)![](https://img.shields.io/badge/cite-22-red)

[**Reliability Analysis of Mobile Ad Hoc Networks Using Universal Generating Function**](https://doi.org/10.1002/qre.1731) ğŸ‘¨â€ğŸ“K. Meena,T. Vasanthi 2016 ![](https://img.shields.io/badge/pub-2016--02--01-green)![](https://img.shields.io/badge/cite-29-red)

[**Reliability Analysis of Mobile Ad Hoc Network**](https://doi.org/10.1109/CICN.2015.39) ğŸ‘¨â€ğŸ“Moirangthem Marjit Singh,J. K. Mandal 2015 ![](https://img.shields.io/badge/pub-2015--12--01-green)![](https://img.shields.io/badge/cite-7-red)

[**K-Hop Coverage and Connectivity Aware Clustering in Different Sensor Deployment Models for Wireless Sensor and Actuator Networks**](https://doi.org/10.1007/s11277-015-2920-2) ğŸ‘¨â€ğŸ“Yi-Chao Wu,Chiu-Ching Tuan 2015 ![](https://img.shields.io/badge/pub-2015--12--01-green)![](https://img.shields.io/badge/cite-9-red)

[**Mission reliability of semi-Markov systems under generalized operational time requirements**](https://doi.org/10.1016/j.ress.2015.04.002) ğŸ‘¨â€ğŸ“Xiaoyue Wu,J. Hillston 2015 ![](https://img.shields.io/badge/pub-2015--08--01-green)![](https://img.shields.io/badge/cite-39-red)

[**Interference Functionals in Poisson Networks**](https://doi.org/10.1109/TIT.2015.2501799) ğŸ‘¨â€ğŸ“Udo Schilcher,S. Toumpis,M. Haenggi,A. Crismani,GÃ¼nther Brandner,C. Bettstetter 2014 ![](https://img.shields.io/badge/pub-2014--09--30-green)![](https://img.shields.io/badge/cite-50-red)

[**Dual-Branch MRC Receivers Under Spatial Interference Correlation and Nakagami Fading**](https://doi.org/10.1109/TCOMM.2014.2321553) ğŸ‘¨â€ğŸ“Ralph Tanbourgi,Harpreet S. Dhillon,J. Andrews,F. Jondral 2013 ![](https://img.shields.io/badge/pub-2013--12--20-green)![](https://img.shields.io/badge/cite-51-red)

[**Wireless Sensor Networks: Principles, Design and Applications**](https://api.semanticscholar.org/0f5a2a9f96eca9988fbec01d4bf2a2f64c0c728b) ğŸ‘¨â€ğŸ“Shuanghua Yang 2013 ![](https://img.shields.io/badge/pub-2013--10--23-green)![](https://img.shields.io/badge/cite-99-red)

[**Evaluation of mobile ad hoc network reliability using propagation-based link reliability model**](https://doi.org/10.1016/j.ress.2013.01.008) ğŸ‘¨â€ğŸ“N. Padmavathy,S. Chaturvedi 2013 ![](https://img.shields.io/badge/pub-2013--07--01-green)![](https://img.shields.io/badge/cite-60-red)

[**Critical Density for Connectivity in 2D and 3D Wireless Multi-Hop Networks**](https://doi.org/10.1109/TWC.2013.021213.112130) ğŸ‘¨â€ğŸ“S. C. Ng,Guoqiang Mao,B. Anderson 2013 ![](https://img.shields.io/badge/pub-2013--02--15-green)![](https://img.shields.io/badge/cite-17-red)

[**Two-terminal reliability of a mobile ad hoc network under the asymptotic spatial distribution of the random waypoint model**](https://doi.org/10.1016/j.ress.2012.05.005) ğŸ‘¨â€ğŸ“Binchao Chen,A. Phillips,T. Matis 2012 ![](https://img.shields.io/badge/pub-2012--10--01-green)![](https://img.shields.io/badge/cite-18-red)

[**Reliability and survivability of vehicular ad hoc networks**](https://doi.org/10.1016/j.ress.2016.04.004) ğŸ‘¨â€ğŸ“S. Dharmaraja,Resham Vinayak,K. Trivedi 2012 ![](https://img.shields.io/badge/pub-2012--07--08-green)![](https://img.shields.io/badge/cite-43-red)

[**Reliability and Availability Evaluation of Wireless Sensor Networks for Industrial Applications**](https://doi.org/10.3390/s120100806) ğŸ‘¨â€ğŸ“I. Silva,L. A. Guedes,P. Portugal,F. Vasques 2012 ![](https://img.shields.io/badge/pub-2012--01--12-green)![](https://img.shields.io/badge/cite-180-red)

[**A primer on spatial modeling and analysis in wireless networks**](https://doi.org/10.1109/MCOM.2010.5621983) ğŸ‘¨â€ğŸ“J. Andrews,R. Ganti,M. Haenggi,N. Jindal,S. Weber 2010 ![](https://img.shields.io/badge/pub-2010--11--01-green)![](https://img.shields.io/badge/cite-409-red)

[**Handbook of Mobile Ad Hoc Networks for Mobility Models**](https://doi.org/10.1007/978-1-4419-6050-4) ğŸ‘¨â€ğŸ“R. Roy 2010 ![](https://img.shields.io/badge/pub-2010--10--20-green)![](https://img.shields.io/badge/cite-308-red)

[**Stochastic geometry and random graphs for the analysis and design of wireless networks**](https://doi.org/10.1109/JSAC.2009.090902) ğŸ‘¨â€ğŸ“M. Haenggi,J. Andrews,F. Baccelli,Olivier Dousse,M. Franceschetti 2009 ![](https://img.shields.io/badge/pub-2009--09--01-green)![](https://img.shields.io/badge/cite-1666-red)

[**Coverage and connectivity issues in wireless sensor networks: A survey**](https://doi.org/10.1016/j.pmcj.2008.02.001) ğŸ‘¨â€ğŸ“Amitava Ghosh,Sajal K. Das 2008 ![](https://img.shields.io/badge/pub-2008--06--01-green)![](https://img.shields.io/badge/cite-528-red)

[**Life Cycle Reliability Engineering**](https://doi.org/10.1198/tech.2008.s538) ğŸ‘¨â€ğŸ“H. Ng 2008 ![](https://img.shields.io/badge/pub-2008--02--01-green)![](https://img.shields.io/badge/cite-121-red)

[**Two-terminal reliability analyses for a mobile ad hoc wireless network**](https://doi.org/10.1016/j.ress.2006.04.021) ğŸ‘¨â€ğŸ“J. L. Cook,J. RamÃ­rez-MÃ¡rquez 2007 ![](https://img.shields.io/badge/pub-2007--06--01-green)![](https://img.shields.io/badge/cite-94-red)

[**The Universal Generating Function in Reliability Analysis and Optimization**](https://doi.org/10.1007/1-84628-245-4) ğŸ‘¨â€ğŸ“G. Levitin 2005 ![](https://img.shields.io/badge/pub-2005--08--19-green)![](https://img.shields.io/badge/cite-552-red)

[**Impact of interferences on connectivity in ad hoc networks**](https://doi.org/10.1109/TNET.2005.845546) ğŸ‘¨â€ğŸ“Olivier Dousse,F. Baccelli,Patrick Thiran 2005 ![](https://img.shields.io/badge/pub-2005--04--01-green)![](https://img.shields.io/badge/cite-420-red)

[**Achieving proportional fairness using local information in Aloha networks**](https://doi.org/10.1109/TAC.2004.835596) ğŸ‘¨â€ğŸ“K. Kar,S. Sarkar,L. Tassiulas 2004 ![](https://img.shields.io/badge/pub-2004--10--08-green)![](https://img.shields.io/badge/cite-127-red)

[**On selection of optimal transmission power for ad hoc networks**](https://doi.org/10.1109/HICSS.2003.1174848) ğŸ‘¨â€ğŸ“Yurong Chen,E. Sirer,S. Wicker 2003 ![](https://img.shields.io/badge/pub-2003--01--06-green)![](https://img.shields.io/badge/cite-56-red)

[**Wireless sensor networks for habitat monitoring**](https://doi.org/10.1145/570738.570751) ğŸ‘¨â€ğŸ“A. Mainwaring,D. Culler,J. Polastre,R. Szewczyk,John Anderson 2002 ![](https://img.shields.io/badge/pub-2002--09--28-green)![](https://img.shields.io/badge/cite-4911-red)

[**A survey on sensor networks**](https://doi.org/10.1109/MCOM.2002.1024422) ğŸ‘¨â€ğŸ“I. Akyildiz,Weilian Su,Y. Sankarasubramaniam,E. Cayirci 2002 ![](https://img.shields.io/badge/pub-2002--08--01-green)![](https://img.shields.io/badge/cite-15225-red)

[**A new routing protocol for the reconfigurable wireless networks**](https://doi.org/10.1109/ICUPC.1997.627227) ğŸ‘¨â€ğŸ“Z. Haas 1997 ![](https://img.shields.io/badge/pub-1997--10--12-green)![](https://img.shields.io/badge/cite-885-red)

[**Methods of numerical Integration (2nd edition), by Philip J. Davis and Philip Rabinowitz. Pp 612. Â£36Â·50. 1984. ISBN 0-12-206360-0 (Academic Press)**](https://doi.org/10.2307/3615859) ğŸ‘¨â€ğŸ“D. W. Arthur 1986 ![](https://img.shields.io/badge/pub-1986--03--01-green)![](https://img.shields.io/badge/cite-116-red)

[**Self-Consistency Improves Chain of Thought Reasoning in Language Models**](https://api.semanticscholar.org/a8983e70d42ec04f2c578fffa7156891afe32f61) ğŸ‘¨â€ğŸ“ 1 ![](https://img.shields.io/badge/pub-1-green)

[**Constitutional AI: Harmlessness from AI Feedback**](https://api.semanticscholar.org/3936fd3c6187f606c6e4e2e20b196dbc41cc4654) 2022 

[**Transformers as Soft Reasoners over Language**](https://api.semanticscholar.org/15ad2b27c5248e7d1db5456794ca1ca8a8198f5d) 2020 

[**Holistic Evaluation of Language Models**](https://api.semanticscholar.org/5032c0946ee96ff11a292762f23e6377a6cf2731) 

[**Evaluating the Robustness of Neural Language Models to Input Perturbations**](https://api.semanticscholar.org/3b451fa663704f927e1ec602d7c0845a9826922d) 

[**Controlling for Stereotypes in Multimodal Language Model Evaluation**](https://api.semanticscholar.org/2b764b71ba02f69b2f4dc3f87c2cc6e41dc0ce3e) 

[**Connectivity, Transmission Power, and Lifetime Optimization in Asymmetric Networks: A Distributed Approach**](https://doi.org/10.1109/ACCESS.2018.2880677) ğŸ‘¨â€ğŸ“Milad Esmaeilpour,A. Aghdam,S. Blouin 2018 ![](https://img.shields.io/badge/cite-4-red)

[**BBQ: A hand-built bias benchmark for question answering**](https://api.semanticscholar.org/7d5c661fa9a4255ee087e861f820564ea2e2bd6b) 

[**Reliability and performance of general two-dimensional broadcast wireless network**](https://doi.org/10.1016/j.peva.2015.09.005) ğŸ‘¨â€ğŸ“Xiaomin Ma,Kishor S. Trivedi 2016 ![](https://img.shields.io/badge/cite-16-red)

[**The Disturbing Effect of Irrelevant Information on Arithmetic Problem Solving in Inattentive Children**](https://api.semanticscholar.org/4993c55aae34325868a611251258bc5678c33e5c) 2002 

[**Recent Development in Wireless Sensor and Ad-hoc Networks**](https://doi.org/10.1007/978-81-322-2129-6) ğŸ‘¨â€ğŸ“S. Patnaik,Xiaolong Li,Yeon-Mo Yang 2015 ![](https://img.shields.io/badge/cite-16-red)

[**Transmission Power Control for Link-Level Handshaking in Wireless Sensor Networks**](https://doi.org/10.1109/JSEN.2015.2486960) ğŸ‘¨â€ğŸ“Huseyin Ugur Yildiz,B. Tavli,H. Yanikomeroglu 2016 ![](https://img.shields.io/badge/cite-56-red)

[**Handbooks in operations research and management science**](https://api.semanticscholar.org/469ceee82670d4cd4fa4c6d2c497b49825fa7064) ğŸ‘¨â€ğŸ“G. Nemhauser,A. Kan 1989 ![](https://img.shields.io/badge/cite-2292-red)

[**Refining Semantic Similarity of Paraphasias Using a Contextual Language Model.**](https://api.semanticscholar.org/1915ef7695805b8dbe712de173d77947d4720a4a) 

[**Effects of varying irrelevant information on adult age differences in problem solving.**](https://api.semanticscholar.org/97b66f89606e35ae5a35b78dbd97cf66629e9f9e) 1979 

[**Ask Me Anything: A simple strategy for prompting language models**](https://api.semanticscholar.org/fb49e88c6bd676516898e911e42b4f8479e6f1bf) 2022 

[**Working memory and intrusions of irrelevant information in a group of specific poor problem solvers**](https://api.semanticscholar.org/e726e5e67f05067826cb1c9bda50465acebcce7b) 1999 

[**Adversarial Examples for Evaluating Reading Comprehension Systems**](https://api.semanticscholar.org/ffb949d3493c3b2f3c9acf9c75cb03938933ddf0) 2017 

[**Evaluation of Typing Efficiency Using Language Model for the Chinese Typewriter**](https://api.semanticscholar.org/ade2549aa102da5a3b2d5720154908c0afa6b485) 

[**Can language models handle recursively nested grammatical structures? A case study on comparing models and humans**](https://api.semanticscholar.org/43d3dbabea106b59e1ec248457c88b19636e4f47) 

[**Adversarial Examples for Evaluating Math Word Problem Solvers**](https://api.semanticscholar.org/68900bf4b9cc820f4b47608871eafcac65a33917) 2021 

[**Program Synthesis with Large Language Models**](https://api.semanticscholar.org/a38e0f993e4805ba8a9beae4c275c91ffcec01df) 2021 

[**An Interpretability Evaluation Benchmark for Pre-trained Language Models**](https://api.semanticscholar.org/0a9df881784009cbb8efcd037d82ae222440aade) 

[**Emergent Analogical Reasoning in Large Language Models**](https://api.semanticscholar.org/cfb6c1916c0de171cd882ccf9ad42499e15a3f07) 2022 

[**Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback**](https://api.semanticscholar.org/0286b2736a114198b25fb5553c671c33aed5d477) 

[**Solving math word problems with process- and outcome-based feedback**](https://api.semanticscholar.org/6d7b8a478801bd9d21df82d5f33ae6eced90da5e) 

[**Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks**](https://api.semanticscholar.org/598d9b235f5ab148fc757240d9bc39a47b8eaf72) 2022 

[**On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning**](https://api.semanticscholar.org/5c70d4f334b7da45b156d223afcb256dbabd9b2f) 

[**Discovering Language Model Behaviors with Model-Written Evaluations**](https://api.semanticscholar.org/cef330bacf014d60daabbd489647b2006af130ca) 2022 

[**Solving Math Word Problem via Cooperative Reasoning induced Language Models**](https://api.semanticscholar.org/68e401c6f90ce421d46b0899458f3c103b4aa29a) 

[**Rethinking Our Assumptions About Language Model Evaluation**](https://api.semanticscholar.org/9967c2cc342e5c84195d93a0fb9557878068cc49) 

[**RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models**](https://api.semanticscholar.org/399e7d8129c60818ee208f236c8dda17e876d21f) 

[**Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning**](https://api.semanticscholar.org/c6fd846b9b8f9eb0a492d6d6242fffce987c4580) 

[**Large Language Models with Controllable Working Memory**](https://api.semanticscholar.org/ee8de585183763ff64cb3c81ecda2fc75fa81507) 2022 

[**Re-Examining Calibration: The Case of Question Answering**](https://arxiv.org/abs/2302.135402205.12507) ğŸ‘¨â€ğŸ“Andrew Kyle Lampinen 2022 

[**Large Language Models Can Be Easily Distracted by Irrelevant Context**](https://api.semanticscholar.org/8bfc22de7fe66286ad9ae705d677246757fbf8a8) 



## In-context Learning

[**Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning**](https://doi.org/10.48550/arXiv.2301.11916) ğŸ‘¨â€ğŸ“Xinyi Wang,Wanrong Zhu,William Yang Wang 2023 ![](https://img.shields.io/badge/pub-2023--01--27-green)![](https://img.shields.io/badge/cite-1-red)

[**OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization**](https://doi.org/10.48550/arXiv.2212.12017) ğŸ‘¨â€ğŸ“S. Iyer,Xiaojuan Lin,Ramakanth Pasunuru,Todor Mihaylov,Daniel Simig,Ping Yu,Kurt Shuster,Tianlu Wang,Qing Liu,Punit Singh Koura,Xian Li,Brian O'Horo,Gabriel Pereyra,Jeff Wang,Christopher Dewan,Asli Celikyilmaz,Luke Zettlemoyer,Veselin Stoyanov 2022 ![](https://img.shields.io/badge/pub-2022--12--22-green)![](https://img.shields.io/badge/cite-9-red)

[**Prompt-Augmented Linear Probing: Scaling Beyond The Limit of Few-shot In-Context Learners**](https://doi.org/10.48550/arXiv.2212.10873) ğŸ‘¨â€ğŸ“Hyunsoo Cho,Hyuhng Joon Kim,Junyeob Kim,Sang-Woo Lee,Sang-goo Lee,Kang Min Yoo,Taeuk Kim 2022 ![](https://img.shields.io/badge/pub-2022--12--21-green)![](https://img.shields.io/badge/cite-2-red)

[**Self-adaptive In-context Learning**](https://doi.org/10.48550/arXiv.2212.10375) ğŸ‘¨â€ğŸ“Zhiyong Wu,Yaoxiang Wang,Jiacheng Ye,Lingpeng Kong 2022 ![](https://img.shields.io/badge/pub-2022--12--20-green)![](https://img.shields.io/badge/cite-2-red)

[**Is GPT-3 a Good Data Annotator?**](https://doi.org/10.48550/arXiv.2212.10450) ğŸ‘¨â€ğŸ“Bosheng Ding,Chengwei Qin,Linlin Liu,Lidong Bing,Shafiq R. Joty,Boyang Li 2022 ![](https://img.shields.io/badge/pub-2022--12--20-green)![](https://img.shields.io/badge/cite-2-red)

[**Reasoning with Language Model Prompting: A Survey**](https://doi.org/10.48550/arXiv.2212.09597) ğŸ‘¨â€ğŸ“Shuofei Qiao,Yixin Ou,Ningyu Zhang,Xiang Chen,Yunzhi Yao,Shumin Deng,Chuanqi Tan,Fei Huang,Huajun Chen 2022 ![](https://img.shields.io/badge/pub-2022--12--19-green)![](https://img.shields.io/badge/cite-7-red)

[**Structured Prompting: Scaling In-Context Learning to 1, 000 Examples**](https://doi.org/10.48550/arXiv.2212.06713) ğŸ‘¨â€ğŸ“Y. Hao,Yutao Sun,Li Dong,Zhixiong Han,Yuxian Gu,Furu Wei 2022 ![](https://img.shields.io/badge/pub-2022--12--13-green)![](https://img.shields.io/badge/cite-2-red)

[**Complementary Explanations for Effective In-Context Learning**](https://doi.org/10.48550/arXiv.2211.13892) ğŸ‘¨â€ğŸ“Xi Ye,Srini Iyer,Asli Celikyilmaz,V. Stoyanov,Greg Durrett,Ramakanth Pasunuru 2022 ![](https://img.shields.io/badge/pub-2022--11--25-green)![](https://img.shields.io/badge/cite-5-red)

[**Active Example Selection for In-Context Learning**](https://doi.org/10.48550/arXiv.2211.04486) ğŸ‘¨â€ğŸ“Yiming Zhang,Shi Feng,Chenhao Tan 2022 ![](https://img.shields.io/badge/pub-2022--11--08-green)![](https://img.shields.io/badge/cite-6-red)

[**Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning**](https://doi.org/10.48550/arXiv.2211.03044) ğŸ‘¨â€ğŸ“Yu Meng,Martin Michalski,Jiaxin Huang,Yu Zhang,T. Abdelzaher,Jiawei Han 2022 ![](https://img.shields.io/badge/pub-2022--11--06-green)![](https://img.shields.io/badge/cite-2-red)

[**Large Language Models Are Human-Level Prompt Engineers**](https://doi.org/10.48550/arXiv.2211.01910) ğŸ‘¨â€ğŸ“Yongchao Zhou,Andrei Ioan Muresanu,Ziwen Han,Keiran Paster,Silviu Pitis,Harris Chan,Jimmy Ba 2022 ![](https://img.shields.io/badge/pub-2022--11--03-green)![](https://img.shields.io/badge/cite-19-red)

[**ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback**](https://doi.org/10.48550/arXiv.2210.12329) ğŸ‘¨â€ğŸ“Jiacheng Ye,Jiahui Gao,Jiangtao Feng,Zhiyong Wu,Tao Yu,Lingpeng Kong 2022 ![](https://img.shields.io/badge/pub-2022--10--22-green)![](https://img.shields.io/badge/cite-3-red)

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) ğŸ‘¨â€ğŸ“Mirac Suzgun,Nathan Scales,Nathanael Scharli,Sebastian Gehrmann,Yi Tay,Hyung Won Chung,Aakanksha Chowdhery,Quoc V. Le,E. Chi,Denny Zhou,Jason Wei 2022 ![](https://img.shields.io/badge/pub-2022--10--17-green)![](https://img.shields.io/badge/cite-27-red)

[**Prompting GPT-3 To Be Reliable**](https://doi.org/10.48550/arXiv.2210.09150) ğŸ‘¨â€ğŸ“Chenglei Si,Zhe Gan,Zhengyuan Yang,Shuohang Wang,Jianfeng Wang,Jordan L. Boyd-Graber,Lijuan Wang 2022 ![](https://img.shields.io/badge/pub-2022--10--17-green)![](https://img.shields.io/badge/cite-9-red)

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) ğŸ‘¨â€ğŸ“Zhuosheng Zhang,Aston Zhang,Mu Li,Alexander J. Smola 2022 ![](https://img.shields.io/badge/pub-2022--10--07-green)![](https://img.shields.io/badge/cite-21-red)

[**Language Models are Multilingual Chain-of-Thought Reasoners**](https://doi.org/10.48550/arXiv.2210.03057) ğŸ‘¨â€ğŸ“Freda Shi,Mirac Suzgun,Markus Freitag,Xuezhi Wang,Suraj Srivats,Soroush Vosoughi,Hyung Won Chung,Yi Tay,Sebastian Ruder,Denny Zhou,Dipanjan Das,Jason Wei 2022 ![](https://img.shields.io/badge/pub-2022--10--06-green)![](https://img.shields.io/badge/cite-19-red)

[**Complexity-Based Prompting for Multi-Step Reasoning**](https://doi.org/10.48550/arXiv.2210.00720) ğŸ‘¨â€ğŸ“Yao Fu,Hao-Chun Peng,Ashish Sabharwal,Peter Clark,Tushar Khot 2022 ![](https://img.shields.io/badge/pub-2022--10--03-green)![](https://img.shields.io/badge/cite-17-red)

[**In-context Learning and Induction Heads**](https://doi.org/10.48550/arXiv.2209.11895) ğŸ‘¨â€ğŸ“Catherine Olsson,Nelson Elhage,Neel Nanda,Nicholas Joseph,Nova DasSarma,T. Henighan,Benjamin Mann,Amanda Askell,Yuntao Bai,Anna Chen,Tom Conerly,Dawn Drain,Deep Ganguli,Zac Hatfield-Dodds,Danny Hernandez,Scott Johnston,Andy Jones,John Kernion,Liane Lovitt,Kamal Ndousse,Dario Amodei,Tom B. Brown,Jack Clark,Jared Kaplan,Sam McCandlish,C. Olah 2022 ![](https://img.shields.io/badge/pub-2022--09--24-green)![](https://img.shields.io/badge/cite-32-red)

[**On the Relation between Sensitivity and Accuracy in In-context Learning**](https://doi.org/10.48550/arXiv.2209.07661) ğŸ‘¨â€ğŸ“Yanda Chen,Chen Zhao,Zhou Yu,K. McKeown,He He 2022 ![](https://img.shields.io/badge/pub-2022--09--16-green)![](https://img.shields.io/badge/cite-8-red)

[**Selective Annotation Makes Language Models Better Few-Shot Learners**](https://doi.org/10.48550/arXiv.2209.01975) ğŸ‘¨â€ğŸ“Hongjin Su,Jungo Kasai,Chen Henry Wu,Weijia Shi,Tianlu Wang,Jiayi Xin,Rui Zhang,Mari Ostendorf,Luke Zettlemoyer,Noah A. Smith,Tao Yu 2022 ![](https://img.shields.io/badge/pub-2022--09--05-green)![](https://img.shields.io/badge/cite-20-red)

[**What Can Transformers Learn In-Context? A Case Study of Simple Function Classes**](https://doi.org/10.48550/arXiv.2208.01066) ğŸ‘¨â€ğŸ“Shivam Garg,Dimitris Tsipras,Percy Liang,G. Valiant 2022 ![](https://img.shields.io/badge/pub-2022--08--01-green)![](https://img.shields.io/badge/cite-24-red)

[**Rationale-Augmented Ensembles in Language Models**](https://doi.org/10.48550/arXiv.2207.00747) ğŸ‘¨â€ğŸ“Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou 2022 ![](https://img.shields.io/badge/pub-2022--07--02-green)![](https://img.shields.io/badge/cite-25-red)

[**Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator**](https://doi.org/10.48550/arXiv.2206.08082) ğŸ‘¨â€ğŸ“Hyuhng Joon Kim,Hyunsoo Cho,Junyeob Kim,Taeuk Kim,Kang Min Yoo,Sang-goo Lee 2022 ![](https://img.shields.io/badge/pub-2022--06--16-green)![](https://img.shields.io/badge/cite-1-red)

[**Emergent Abilities of Large Language Models**](https://doi.org/10.48550/arXiv.2206.07682) ğŸ‘¨â€ğŸ“Jason Wei,Yi Tay,Rishi Bommasani,Colin Raffel,Barret Zoph,Sebastian Borgeaud,Dani Yogatama,Maarten Bosma,Denny Zhou,Donald Metzler,E. Chi,Tatsunori Hashimoto,Oriol Vinyals,P. Liang,J. Dean,W. Fedus 2022 ![](https://img.shields.io/badge/pub-2022--06--15-green)![](https://img.shields.io/badge/cite-142-red)

[**RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning**](https://doi.org/10.48550/arXiv.2205.12548) ğŸ‘¨â€ğŸ“Mingkai Deng,Jianyu Wang,Cheng-Ping Hsieh,Yihan Wang,Han Guo,Tianmin Shu,Meng Song,E. Xing,Zhiting Hu 2022 ![](https://img.shields.io/badge/pub-2022--05--25-green)![](https://img.shields.io/badge/cite-25-red)

[**Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations**](https://doi.org/10.48550/arXiv.2205.12685) ğŸ‘¨â€ğŸ“Junyeob Kim,Hyuhng Joon Kim,Hyunsoo Cho,Hwiyeol Jo,Sang-Woo Lee,Sang-goo Lee,Kang Min Yoo,Taeuk Kim 2022 ![](https://img.shields.io/badge/pub-2022--05--25-green)![](https://img.shields.io/badge/cite-11-red)

[**Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations**](https://doi.org/10.48550/arXiv.2205.11822) ğŸ‘¨â€ğŸ“Jaehun Jung,Lianhui Qin,S. Welleck,Faeze Brahman,Chandra Bhagavatula,Ronan Le Bras,Yejin Choi 2022 ![](https://img.shields.io/badge/pub-2022--05--24-green)![](https://img.shields.io/badge/cite-25-red)

[**Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing**](https://doi.org/10.48550/arXiv.2205.12253) ğŸ‘¨â€ğŸ“Linlu Qiu,Peter Shaw,Panupong Pasupat,Tianze Shi,Jonathan Herzig,Emily Pitler,Fei Sha,Kristina Toutanova 2022 ![](https://img.shields.io/badge/pub-2022--05--24-green)![](https://img.shields.io/badge/cite-10-red)

[**Large Language Models are Zero-Shot Reasoners**](https://arxiv.org/abs/2302.135402205.11916) ğŸ‘¨â€ğŸ“Takeshi Kojima,S. Gu,Machel Reid,Yutaka Matsuo,Yusuke Iwasawa 2022 ![](https://img.shields.io/badge/pub-2022--05--24-green)![](https://img.shields.io/badge/cite-176-red)

[**Instruction Induction: From Few Examples to Natural Language Task Descriptions**](https://doi.org/10.48550/arXiv.2205.10782) ğŸ‘¨â€ğŸ“Or Honovich,Uri Shaham,Samuel R. Bowman,Omer Levy 2022 ![](https://img.shields.io/badge/pub-2022--05--22-green)![](https://img.shields.io/badge/cite-8-red)

[**Prototypical Calibration for Few-shot Learning of Language Models**](https://doi.org/10.48550/arXiv.2205.10183) ğŸ‘¨â€ğŸ“Zhixiong Han,Y. Hao,Li Dong,Yutao Sun,Furu Wei 2022 ![](https://img.shields.io/badge/pub-2022--05--20-green)![](https://img.shields.io/badge/cite-4-red)

[**Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning**](https://doi.org/10.48550/arXiv.2205.05638) ğŸ‘¨â€ğŸ“Haokun Liu,Derek Tam,Mohammed Muqeeth,Jay Mohta,Tenghao Huang,Mohit Bansal,Colin Raffel 2022 ![](https://img.shields.io/badge/pub-2022--05--11-green)![](https://img.shields.io/badge/cite-55-red)

[**The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning**](https://arxiv.org/abs/2302.135402205.03401) ğŸ‘¨â€ğŸ“Xi Ye,Greg Durrett 2022 ![](https://img.shields.io/badge/pub-2022--05--06-green)![](https://img.shields.io/badge/cite-9-red)

[**Improving In-Context Few-Shot Learning via Self-Supervised Training**](https://doi.org/10.48550/arXiv.2205.01703) ğŸ‘¨â€ğŸ“Mingda Chen,Jingfei Du,Ramakanth Pasunuru,Todor Mihaylov,Srini Iyer,V. Stoyanov,Zornitsa Kozareva 2022 ![](https://img.shields.io/badge/pub-2022--05--03-green)![](https://img.shields.io/badge/cite-5-red)

[**OPT: Open Pre-trained Transformer Language Models**](https://arxiv.org/abs/2302.135402205.01068) ğŸ‘¨â€ğŸ“Susan Zhang,Stephen Roller,Naman Goyal,Mikel Artetxe,Moya Chen,Shuohui Chen,Christopher Dewan,Mona Diab,Xian Li,Xi Victoria Lin,Todor Mihaylov,Myle Ott,Sam Shleifer,Kurt Shuster,Daniel Simig,Punit Singh Koura,Anjali Sridhar,Tianlu Wang,Luke Zettlemoyer 2022 ![](https://img.shields.io/badge/pub-2022--05--02-green)![](https://img.shields.io/badge/cite-296-red)

[**On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model**](https://doi.org/10.48550/arXiv.2204.13509) ğŸ‘¨â€ğŸ“Seongjin Shin,Sang-Woo Lee,Hwijeen Ahn,Sungdong Kim,Hyoungseok Kim,Boseop Kim,Kyunghyun Cho,Gichang Lee,W. Park,Jung-Woo Ha,Nako Sung 2022 ![](https://img.shields.io/badge/pub-2022--04--28-green)![](https://img.shields.io/badge/cite-13-red)

[**PaLM: Scaling Language Modeling with Pathways**](https://arxiv.org/abs/2302.135402204.02311) ğŸ‘¨â€ğŸ“Aakanksha Chowdhery,Sharan Narang,Jacob Devlin,Maarten Bosma,Gaurav Mishra,Adam Roberts,P. Barham,Hyung Won Chung,Charles Sutton,Sebastian Gehrmann,Parker Schuh,Kensen Shi,Sasha Tsvyashchenko,Joshua Maynez,Abhishek Rao,Parker Barnes,Yi Tay,Noam M. Shazeer,Vinodkumar Prabhakaran,Emily Reif,Nan Du,B. Hutchinson,Reiner Pope,James Bradbury,Jacob Austin,M. Isard,Guy Gur-Ari,Pengcheng Yin,Toju Duke,Anselm Levskaya,S. Ghemawat,Sunipa Dev,H. Michalewski,Xavier GarcÃ­a,Vedant Misra,Kevin Robinson,L. Fedus,Denny Zhou,Daphne Ippolito,D. Luan,Hyeontaek Lim,Barret Zoph,A. Spiridonov,Ryan Sepassi,David Dohan,Shivani Agrawal,Mark Omernick,Andrew M. Dai,T. S. Pillai,Marie Pellat,Aitor Lewkowycz,Erica Moreira,Rewon Child,Oleksandr Polozov,Katherine Lee,Zongwei Zhou,Xuezhi Wang,Brennan Saeta,Mark DÃ­az,Orhan Firat,Michele Catasta,Jason Wei,K. Meier-Hellstern,D. Eck,J. Dean,Slav Petrov,Noah Fiedel 2022 ![](https://img.shields.io/badge/pub-2022--04--05-green)![](https://img.shields.io/badge/cite-596-red)

[**Can language models learn from explanations in context?**](https://doi.org/10.48550/arXiv.2204.02329) ğŸ‘¨â€ğŸ“Andrew Kyle Lampinen,I. Dasgupta,Stephanie C. Y. Chan,Kory Matthewson,Michael Henry Tessler,Antonia Creswell,James L. McClelland,Jane X. Wang,Felix Hill 2022 ![](https://img.shields.io/badge/pub-2022--04--05-green)![](https://img.shields.io/badge/cite-60-red)

[**Prompt-free and Efficient Few-shot Learning with Language Models**](https://doi.org/10.48550/arXiv.2204.01172) ğŸ‘¨â€ğŸ“Rabeeh Karimi Mahabadi,Luke Zettlemoyer,J. Henderson,Marzieh Saeidi,Lambert Mathias,V. Stoyanov,Majid Yazdani 2022 ![](https://img.shields.io/badge/pub-2022--04--03-green)![](https://img.shields.io/badge/cite-20-red)

[**Self-Consistency Improves Chain of Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2203.11171) ğŸ‘¨â€ğŸ“Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou 2022 ![](https://img.shields.io/badge/pub-2022--03--21-green)![](https://img.shields.io/badge/cite-126-red)

[**Iteratively Prompt Pre-trained Language Models for Chain of Thought**](https://arxiv.org/abs/2302.135402203.08383) ğŸ‘¨â€ğŸ“Boshi Wang,Xiang Deng,Huan Sun 2022 ![](https://img.shields.io/badge/pub-2022--03--16-green)![](https://img.shields.io/badge/cite-5-red)

[**GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models**](https://doi.org/10.48550/arXiv.2203.07281) ğŸ‘¨â€ğŸ“Archiki Prasad,Peter Hase,Xiang Zhou,Mohit Bansal 2022 ![](https://img.shields.io/badge/pub-2022--03--14-green)![](https://img.shields.io/badge/cite-23-red)

[**Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?**](https://arxiv.org/abs/2302.135402202.12837) ğŸ‘¨â€ğŸ“Sewon Min,Xinxi Lyu,Ari Holtzman,Mikel Artetxe,M. Lewis,Hannaneh Hajishirzi,Luke Zettlemoyer 2022 ![](https://img.shields.io/badge/pub-2022--02--25-green)![](https://img.shields.io/badge/cite-121-red)

[**AdaPrompt: Adaptive Model Training for Prompt-based NLP**](https://arxiv.org/abs/2302.135402202.04824) ğŸ‘¨â€ğŸ“Yulong Chen,Yang Liu,Li Dong,Shuohang Wang,Chenguang Zhu,Michael Zeng,Yue Zhang 2022 ![](https://img.shields.io/badge/pub-2022--02--10-green)![](https://img.shields.io/badge/cite-11-red)

[**PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts**](https://doi.org/10.18653/v1/2022.acl-demo.9) ğŸ‘¨â€ğŸ“Stephen H. Bach,Victor Sanh,Zheng Xin Yong,Albert Webson,Colin Raffel,Nihal V. Nayak,Abheesht Sharma,Taewoon Kim,M Saiful Bari,Thibault FÃ©vry,Zaid Alyafeai,Manan Dey,Andrea Santilli,Zhiqing Sun,Srulik Ben-David,Canwen Xu,Gunjan Chhablani,Han Wang,Jason Alan Fries,Maged S. Al-shaibani,Shanya Sharma,Urmish Thakker,Khalid Almubarak,Xiangru Tang,Mike Tian-Jian Jiang,Alexander M. Rush 2022 ![](https://img.shields.io/badge/pub-2022--02--02-green)![](https://img.shields.io/badge/cite-53-red)

[**Co-training Improves Prompt-based Learning for Large Language Models**](https://arxiv.org/abs/2302.135402202.00828) ğŸ‘¨â€ğŸ“Hunter Lang,Monica Agrawal,Yoon Kim,D. Sontag 2022 ![](https://img.shields.io/badge/pub-2022--02--02-green)![](https://img.shields.io/badge/cite-8-red)

[**Chain of Thought Prompting Elicits Reasoning in Large Language Models**](https://arxiv.org/abs/2302.135402201.11903) ğŸ‘¨â€ğŸ“Jason Wei,Xuezhi Wang,Dale Schuurmans,Maarten Bosma,E. Chi,Quoc Le,Denny Zhou 2022 ![](https://img.shields.io/badge/pub-2022--01--28-green)![](https://img.shields.io/badge/cite-368-red)

[**Black-box Prompt Learning for Pre-trained Language Models**](https://arxiv.org/abs/2302.135402201.08531) ğŸ‘¨â€ğŸ“Shizhe Diao,Xuechun Li,Yong Lin,Zhichao Huang,Xiao Zhou,Tong Zhang 2022 ![](https://img.shields.io/badge/pub-2022--01--21-green)![](https://img.shields.io/badge/cite-17-red)

[**UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models**](https://arxiv.org/abs/2302.135402201.05966) ğŸ‘¨â€ğŸ“Tianbao Xie,Chen Henry Wu,Peng Shi,Ruiqi Zhong,Torsten Scholak,Michihiro Yasunaga,Chien-Sheng Wu,Ming Zhong,Pengcheng Yin,Sida I. Wang,Victor Zhong,Bailin Wang,Chengzu Li,Connor Boyle,Ansong Ni,Ziyu Yao,Dragomir R. Radev,Caiming Xiong,Lingpeng Kong,Rui Zhang,Noah A. Smith,Luke Zettlemoyer,Tao Yu 2022 ![](https://img.shields.io/badge/pub-2022--01--16-green)![](https://img.shields.io/badge/cite-96-red)

[**Learning To Retrieve Prompts for In-Context Learning**](https://doi.org/10.18653/v1/2022.naacl-main.191) ğŸ‘¨â€ğŸ“Ohad Rubin,Jonathan Herzig,Jonathan Berant 2021 ![](https://img.shields.io/badge/pub-2021--12--16-green)![](https://img.shields.io/badge/cite-80-red)

[**Few-Shot Semantic Parsing with Language Models Trained on Code**](https://doi.org/10.18653/v1/2022.naacl-main.396) ğŸ‘¨â€ğŸ“Richard Shin,Benjamin Van Durme 2021 ![](https://img.shields.io/badge/pub-2021--12--16-green)![](https://img.shields.io/badge/cite-19-red)

[**Scaling Language Models: Methods, Analysis & Insights from Training Gopher**](https://arxiv.org/abs/2302.135402112.11446) ğŸ‘¨â€ğŸ“Jack W. Rae,Sebastian Borgeaud,Trevor Cai,Katie Millican,Jordan Hoffmann,Francis Song,J. Aslanides,Sarah Henderson,Roman Ring,Susannah Young,Eliza Rutherford,Tom Hennigan,Jacob Menick,Albin Cassirer,Richard Powell,George van den Driessche,Lisa Anne Hendricks,M. Rauh,Po-Sen Huang,A. Glaese,Johannes Welbl,Sumanth Dathathri,Saffron Huang,J. Uesato,John F. J. Mellor,I. Higgins,Antonia Creswell,Nathan McAleese,Amy Wu,Erich Elsen,Siddhant M. Jayakumar,Elena Buchatskaya,D. Budden,Esme Sutherland,K. Simonyan,Michela Paganini,L. Sifre,Lena Martens,Xiang Lorraine Li,A. Kuncoro,Aida Nematzadeh,E. Gribovskaya,Domenic Donato,Angeliki Lazaridou,A. Mensch,J. Lespiau,Maria Tsimpoukelli,N. Grigorev,Doug Fritz,Thibault Sottiaux,Mantas Pajarskas,Tobias Pohlen,Z. Gong,Daniel Toyama,Cyprien de Masson d'Autume,Yujia Li,Tayfun Terzi,Vladimir Mikulik,I. Babuschkin,Aidan Clark,Diego de Las Casas,Aurelia Guy,Chris Jones,James Bradbury,Matthew G. Johnson,Blake A. Hechtman,Laura Weidinger,Iason Gabriel,William S. Isaac,Edward Lockhart,Simon Osindero,Laura Rimell,Chris Dyer,Oriol Vinyals,Kareem W. Ayoub,Jeff Stanway,L. Bennett,D. Hassabis,K. Kavukcuoglu,Geoffrey Irving 2021 ![](https://img.shields.io/badge/pub-2021--12--08-green)![](https://img.shields.io/badge/cite-300-red)

[**True Few-Shot Learning with Promptsâ€”A Real-World Perspective**](https://doi.org/10.1162/tacl_a_00485) ğŸ‘¨â€ğŸ“Timo Schick,Hinrich SchÃ¼tze 2021 ![](https://img.shields.io/badge/pub-2021--11--26-green)![](https://img.shields.io/badge/cite-14-red)

[**An Explanation of In-context Learning as Implicit Bayesian Inference**](https://arxiv.org/abs/2302.135402111.02080) ğŸ‘¨â€ğŸ“Sang Michael Xie,Aditi Raghunathan,Percy Liang,Tengyu Ma 2021 ![](https://img.shields.io/badge/pub-2021--11--03-green)![](https://img.shields.io/badge/cite-52-red)

[**MetaICL: Learning to Learn In Context**](https://doi.org/10.18653/v1/2022.naacl-main.201) ğŸ‘¨â€ğŸ“Sewon Min,M. Lewis,Luke Zettlemoyer,Hannaneh Hajishirzi 2021 ![](https://img.shields.io/badge/pub-2021--10--29-green)![](https://img.shields.io/badge/cite-80-red)

[**Meta-learning via Language Model In-context Tuning**](https://doi.org/10.18653/v1/2022.acl-long.53) ğŸ‘¨â€ğŸ“Yanda Chen,Ruiqi Zhong,Sheng Zha,G. Karypis,He He 2021 ![](https://img.shields.io/badge/pub-2021--10--15-green)![](https://img.shields.io/badge/cite-31-red)

[**Few-Shot Bot: Prompt-Based Learning for Dialogue Systems**](https://arxiv.org/abs/2302.135402110.08118) ğŸ‘¨â€ğŸ“Andrea Madotto,Zhaojiang Lin,Genta Indra Winata,Pascale Fung 2021 ![](https://img.shields.io/badge/pub-2021--10--15-green)![](https://img.shields.io/badge/cite-24-red)

[**Coherence boosting: When your pretrained language model is not paying enough attention**](https://doi.org/10.18653/v1/2022.acl-long.565) ğŸ‘¨â€ğŸ“Nikolay Malkin,Zhen Wang,N. Jojic 2021 ![](https://img.shields.io/badge/pub-2021--10--15-green)![](https://img.shields.io/badge/cite-4-red)

[**Reframing Instructional Prompts to GPTkâ€™s Language**](https://doi.org/10.18653/v1/2022.findings-acl.50) ğŸ‘¨â€ğŸ“Swaroop Mishra,Daniel Khashabi,Chitta Baral,Yejin Choi,Hannaneh Hajishirzi 2021 ![](https://img.shields.io/badge/pub-2021--09--16-green)![](https://img.shields.io/badge/cite-55-red)

[**Finetuned Language Models Are Zero-Shot Learners**](https://arxiv.org/abs/2302.135402109.01652) ğŸ‘¨â€ğŸ“Jason Wei,Maarten Bosma,Vincent Zhao,Kelvin Guu,A. Yu,Brian Lester,Nan Du,Andrew M. Dai,Quoc V. Le 2021 ![](https://img.shields.io/badge/pub-2021--09--03-green)![](https://img.shields.io/badge/cite-369-red)

[**Do Prompt-Based Models Really Understand the Meaning of Their Prompts?**](https://doi.org/10.18653/v1/2022.naacl-main.167) ğŸ‘¨â€ğŸ“Albert Webson,Ellie Pavlick 2021 ![](https://img.shields.io/badge/pub-2021--09--02-green)![](https://img.shields.io/badge/cite-66-red)

[**Noisy Channel Language Model Prompting for Few-Shot Text Classification**](https://doi.org/10.18653/v1/2022.acl-long.365) ğŸ‘¨â€ğŸ“Sewon Min,Michael Lewis,Hannaneh Hajishirzi,Luke Zettlemoyer 2021 ![](https://img.shields.io/badge/pub-2021--08--09-green)![](https://img.shields.io/badge/cite-69-red)

[**Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**](https://doi.org/10.1145/3560815) ğŸ‘¨â€ğŸ“Pengfei Liu,Weizhe Yuan,Jinlan Fu,Zhengbao Jiang,Hiroaki Hayashi,Graham Neubig 2021 ![](https://img.shields.io/badge/pub-2021--07--28-green)![](https://img.shields.io/badge/cite-429-red)

[**Evaluating Large Language Models Trained on Code**](https://arxiv.org/abs/2302.135402107.03374) ğŸ‘¨â€ğŸ“Mark Chen,Jerry Tworek,Heewoo Jun,Qiming Yuan,Henrique Ponde,Jared Kaplan,Harrison Edwards,Yura Burda,Nicholas Joseph,Greg Brockman,Alex Ray,Raul Puri,Gretchen Krueger,Michael Petrov,Heidy Khlaaf,Girish Sastry,Pamela Mishkin,Brooke Chan,Scott Gray,Nick Ryder,Mikhail Pavlov,Alethea Power,Lukasz Kaiser,Mohammad Bavarian,Clemens Winter,Philippe Tillet,F. Such,D. Cummings,Matthias Plappert,Fotios Chantzis,Elizabeth Barnes,Ariel Herbert-Voss,William H. Guss,Alex Nichol,I. Babuschkin,S. Balaji,Shantanu Jain,A. Carr,J. Leike,Joshua Achiam,Vedant Misra,Evan Morikawa,Alec Radford,M. Knight,Miles Brundage,Mira Murati,Katie Mayer,P. Welinder,Bob McGrew,Dario Amodei,Sam McCandlish,Ilya Sutskever,Wojciech Zaremba 2021 ![](https://img.shields.io/badge/pub-2021--07--07-green)![](https://img.shields.io/badge/cite-594-red)

[**Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models**](https://doi.org/10.18653/v1/2022.findings-acl.222) ğŸ‘¨â€ğŸ“Robert L Logan IV,Ivana Balavzevi'c,Eric Wallace,Fabio Petroni,Sameer Singh,Sebastian Riedel 2021 ![](https://img.shields.io/badge/pub-2021--06--24-green)![](https://img.shields.io/badge/cite-70-red)

[**True Few-Shot Learning with Language Models**](https://arxiv.org/abs/2302.135402105.11447) ğŸ‘¨â€ğŸ“Ethan Perez,Douwe Kiela,Kyunghyun Cho 2021 ![](https://img.shields.io/badge/pub-2021--05--24-green)![](https://img.shields.io/badge/cite-148-red)

[**The Power of Scale for Parameter-Efficient Prompt Tuning**](https://doi.org/10.18653/v1/2021.emnlp-main.243) ğŸ‘¨â€ğŸ“Brian Lester,Rami Al-Rfou,Noah Constant 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-675-red)

[**Constrained Language Models Yield Few-Shot Semantic Parsers**](https://doi.org/10.18653/v1/2021.emnlp-main.608) ğŸ‘¨â€ğŸ“Richard Shin,C. H. Lin,Sam Thomson,Charles C. Chen,Subhro Roy,Emmanouil Antonios Platanios,Adam Pauls,D. Klein,J. Eisner,Benjamin Van Durme 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-79-red)

[**Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity**](https://doi.org/10.18653/v1/2022.acl-long.556) ğŸ‘¨â€ğŸ“Yao Lu,Max Bartolo,Alastair Moore,S. Riedel,Pontus Stenetorp 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-165-red)

[**Surface Form Competition: Why the Highest Probability Answer Isnâ€™t Always Right**](https://doi.org/10.18653/v1/2021.emnlp-main.564) ğŸ‘¨â€ğŸ“Ari Holtzman,Peter West,Vered Schwartz,Yejin Choi,Luke Zettlemoyer 2021 ![](https://img.shields.io/badge/pub-2021--04--16-green)![](https://img.shields.io/badge/cite-73-red)

[**GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow**](https://doi.org/10.5281/ZENODO.5297715) ğŸ‘¨â€ğŸ“Sid Black,Leo Gao,Phil Wang,Connor Leahy,Stella Rose Biderman 2021 ![](https://img.shields.io/badge/pub-2021--03--21-green)![](https://img.shields.io/badge/cite-198-red)

[**Calibrate Before Use: Improving Few-Shot Performance of Language Models**](https://arxiv.org/abs/2302.135402102.09690) ğŸ‘¨â€ğŸ“Tony Zhao,Eric Wallace,Shi Feng,D. Klein,Sameer Singh 2021 ![](https://img.shields.io/badge/pub-2021--02--19-green)![](https://img.shields.io/badge/cite-277-red)

[**What Makes Good In-Context Examples for GPT-3?**](https://doi.org/10.18653/v1/2022.deelio-1.10) ğŸ‘¨â€ğŸ“Jiachang Liu,Dinghan Shen,Yizhe Zhang,Bill Dolan,L. Carin,Weizhu Chen 2021 ![](https://img.shields.io/badge/pub-2021--01--17-green)![](https://img.shields.io/badge/cite-163-red)

[**Making Pre-trained Language Models Better Few-shot Learners**](https://doi.org/10.18653/v1/2021.acl-long.295) ğŸ‘¨â€ğŸ“Tianyu Gao,Adam Fisch,Danqi Chen 2021 ![](https://img.shields.io/badge/pub-2021--01--01-green)![](https://img.shields.io/badge/cite-635-red)

[**The Pile: An 800GB Dataset of Diverse Text for Language Modeling**](https://arxiv.org/abs/2302.135402101.00027) ğŸ‘¨â€ğŸ“Leo Gao,Stella Rose Biderman,Sid Black,Laurence Golding,Travis Hoppe,Charles Foster,Jason Phang,Horace He,Anish Thite,Noa Nabeshima,Shawn Presser,Connor Leahy 2020 ![](https://img.shields.io/badge/pub-2020--12--31-green)![](https://img.shields.io/badge/cite-328-red)

[**Language Models are Few-Shot Learners**](https://arxiv.org/abs/2302.135402005.14165) ğŸ‘¨â€ğŸ“Tom B. Brown,Benjamin Mann,Nick Ryder,Melanie Subbiah,J. Kaplan,Prafulla Dhariwal,Arvind Neelakantan,Pranav Shyam,Girish Sastry,Amanda Askell,Sandhini Agarwal,Ariel Herbert-Voss,Gretchen Krueger,T. Henighan,Rewon Child,A. Ramesh,Daniel M. Ziegler,Jeff Wu,Clemens Winter,Christopher Hesse,Mark Chen,Eric Sigler,Mateusz Litwin,Scott Gray,Benjamin Chess,Jack Clark,Christopher Berner,Sam McCandlish,Alec Radford,Ilya Sutskever,Dario Amodei 2020 ![](https://img.shields.io/badge/pub-2020--05--28-green)![](https://img.shields.io/badge/cite-8351-red)

[**ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators**](https://arxiv.org/abs/2302.135402003.10555) ğŸ‘¨â€ğŸ“Kevin Clark,Minh-Thang Luong,Quoc V. Le,Christopher D. Manning 2020 ![](https://img.shields.io/badge/pub-2020--03--23-green)![](https://img.shields.io/badge/cite-1846-red)

[**Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference**](https://doi.org/10.18653/v1/2021.eacl-main.20) ğŸ‘¨â€ğŸ“Timo Schick,Hinrich SchÃ¼tze 2020 ![](https://img.shields.io/badge/pub-2020--01--21-green)![](https://img.shields.io/badge/cite-579-red)

[**Momentum Contrast for Unsupervised Visual Representation Learning**](https://doi.org/10.1109/cvpr42600.2020.00975) ğŸ‘¨â€ğŸ“Kaiming He,Haoqi Fan,Yuxin Wu,Saining Xie,Ross B. Girshick 2019 ![](https://img.shields.io/badge/pub-2019--11--13-green)![](https://img.shields.io/badge/cite-5429-red)

[**BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension**](https://doi.org/10.18653/v1/2020.acl-main.703) ğŸ‘¨â€ğŸ“M. Lewis,Yinhan Liu,Naman Goyal,Marjan Ghazvininejad,Abdelrahman Mohamed,Omer Levy,Veselin Stoyanov,Luke Zettlemoyer 2019 ![](https://img.shields.io/badge/pub-2019--10--29-green)![](https://img.shields.io/badge/cite-4052-red)

[**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**](https://arxiv.org/abs/2302.135401910.10683) ğŸ‘¨â€ğŸ“Colin Raffel,Noam M. Shazeer,Adam Roberts,Katherine Lee,Sharan Narang,Michael Matena,Yanqi Zhou,Wei Li,Peter J. Liu 2019 ![](https://img.shields.io/badge/pub-2019--10--23-green)![](https://img.shields.io/badge/cite-6286-red)

[**HuggingFace's Transformers: State-of-the-art Natural Language Processing**](https://arxiv.org/abs/2302.135401910.03771) ğŸ‘¨â€ğŸ“Thomas Wolf,Lysandre Debut,Victor Sanh,Julien Chaumond,Clement Delangue,Anthony Moi,Pierric Cistac,T. Rault,RÃ©mi Louf,Morgan Funtowicz,Jamie Brew 2019 ![](https://img.shields.io/badge/pub-2019--10--09-green)![](https://img.shields.io/badge/cite-3513-red)

[**Transformers: State-of-the-Art Natural Language Processing**](https://doi.org/10.18653/v1/2020.emnlp-demos.6) ğŸ‘¨â€ğŸ“Thomas Wolf,Lysandre Debut,Victor Sanh,Julien Chaumond,Clement Delangue,Anthony Moi,Pierric Cistac,T. Rault,RÃ©mi Louf,Morgan Funtowicz,Jamie Brew 2019 ![](https://img.shields.io/badge/pub-2019--10--09-green)![](https://img.shields.io/badge/cite-3941-red)

[**ALBERT: A Lite BERT for Self-supervised Learning of Language Representations**](https://arxiv.org/abs/2302.135401909.11942) ğŸ‘¨â€ğŸ“Zhenzhong Lan,Mingda Chen,Sebastian Goodman,Kevin Gimpel,Piyush Sharma,Radu Soricut 2019 ![](https://img.shields.io/badge/pub-2019--09--26-green)![](https://img.shields.io/badge/cite-3711-red)

[**RoBERTa: A Robustly Optimized BERT Pretraining Approach**](https://arxiv.org/abs/2302.135401907.11692) ğŸ‘¨â€ğŸ“Yinhan Liu,Myle Ott,Naman Goyal,Jingfei Du,Mandar Joshi,Danqi Chen,Omer Levy,M. Lewis,Luke Zettlemoyer,Veselin Stoyanov 2019 ![](https://img.shields.io/badge/pub-2019--07--26-green)![](https://img.shields.io/badge/cite-10930-red)

[**BERTScore: Evaluating Text Generation with BERT**](https://arxiv.org/abs/2302.135401904.09675) ğŸ‘¨â€ğŸ“Tianyi Zhang,Varsha Kishore,Felix Wu,Kilian Q. Weinberger,Yoav Artzi 2019 ![](https://img.shields.io/badge/pub-2019--04--21-green)![](https://img.shields.io/badge/cite-1634-red)

[**BioBERT: a pre-trained biomedical language representation model for biomedical text mining**](https://doi.org/10.1093/bioinformatics/btz682) ğŸ‘¨â€ğŸ“Jinhyuk Lee,Wonjin Yoon,Sungdong Kim,Donghyeon Kim,Sunkyu Kim,Chan Ho So,Jaewoo Kang 2019 ![](https://img.shields.io/badge/pub-2019--01--25-green)![](https://img.shields.io/badge/cite-2743-red)

[**Representation Learning with Contrastive Predictive Coding**](https://arxiv.org/abs/2302.135401807.03748) ğŸ‘¨â€ğŸ“AÃ¤ron van den Oord,Yazhe Li,Oriol Vinyals 2018 ![](https://img.shields.io/badge/pub-2018--07--10-green)![](https://img.shields.io/badge/cite-4597-red)

[**Know What You Donâ€™t Know: Unanswerable Questions for SQuAD**](https://doi.org/10.18653/v1/P18-2124) ğŸ‘¨â€ğŸ“Pranav Rajpurkar,Robin Jia,Percy Liang 2018 ![](https://img.shields.io/badge/pub-2018--06--11-green)![](https://img.shields.io/badge/cite-1718-red)

[**GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding**](https://doi.org/10.18653/v1/W18-5446) ğŸ‘¨â€ğŸ“Alex Wang,Amanpreet Singh,Julian Michael,Felix Hill,Omer Levy,Samuel R. Bowman 2018 ![](https://img.shields.io/badge/pub-2018--04--20-green)![](https://img.shields.io/badge/cite-3499-red)

[**UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction**](https://arxiv.org/abs/2302.135401802.03426) ğŸ‘¨â€ğŸ“Leland McInnes,John Healy 2018 ![](https://img.shields.io/badge/pub-2018--02--09-green)![](https://img.shields.io/badge/cite-5118-red)

[**Decoupled Weight Decay Regularization**](https://api.semanticscholar.org/d07284a6811f1b2745d91bdb06b040b57f226882) ğŸ‘¨â€ğŸ“I. Loshchilov,F. Hutter 2017 ![](https://img.shields.io/badge/pub-2017--11--14-green)![](https://img.shields.io/badge/cite-6264-red)

[**On Calibration of Modern Neural Networks**](https://arxiv.org/abs/2302.135401706.04599) ğŸ‘¨â€ğŸ“Chuan Guo,Geoff Pleiss,Yu Sun,Kilian Q. Weinberger 2017 ![](https://img.shields.io/badge/pub-2017--06--14-green)![](https://img.shields.io/badge/cite-3066-red)

[**Attention is All you Need**](https://arxiv.org/abs/2302.135401706.03762) ğŸ‘¨â€ğŸ“Ashish Vaswani,Noam M. Shazeer,Niki Parmar,Jakob Uszkoreit,Llion Jones,Aidan N. Gomez,Lukasz Kaiser,Illia Polosukhin 2017 ![](https://img.shields.io/badge/pub-2017--06--12-green)![](https://img.shields.io/badge/cite-51971-red)

[**Curiosity-Driven Exploration by Self-Supervised Prediction**](https://doi.org/10.1109/CVPRW.2017.70) ğŸ‘¨â€ğŸ“Deepak Pathak,Pulkit Agrawal,Alexei A. Efros,Trevor Darrell 2017 ![](https://img.shields.io/badge/pub-2017--05--15-green)![](https://img.shields.io/badge/cite-1672-red)

[**A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference**](https://doi.org/10.18653/v1/N18-1101) ğŸ‘¨â€ğŸ“Adina Williams,Nikita Nangia,Samuel R. Bowman 2017 ![](https://img.shields.io/badge/pub-2017--04--18-green)![](https://img.shields.io/badge/cite-2610-red)

[**Understanding Black-box Predictions via Influence Functions**](https://arxiv.org/abs/2302.135401703.04730) ğŸ‘¨â€ğŸ“Pang Wei Koh,Percy Liang 2017 ![](https://img.shields.io/badge/pub-2017--03--14-green)![](https://img.shields.io/badge/cite-1811-red)

[**Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks**](https://arxiv.org/abs/2302.135401703.03400) ğŸ‘¨â€ğŸ“Chelsea Finn,P. Abbeel,S. Levine 2017 ![](https://img.shields.io/badge/pub-2017--03--09-green)![](https://img.shields.io/badge/cite-7087-red)

[**Axiomatic Attribution for Deep Networks**](https://arxiv.org/abs/2302.135401703.01365) ğŸ‘¨â€ğŸ“Mukund Sundararajan,Ankur Taly,Qiqi Yan 2017 ![](https://img.shields.io/badge/pub-2017--03--04-green)![](https://img.shields.io/badge/cite-3082-red)

[**Billion-Scale Similarity Search with GPUs**](https://doi.org/10.1109/tbdata.2019.2921572) ğŸ‘¨â€ğŸ“Jeff Johnson,Matthijs Douze,H. JÃ©gou 2017 ![](https://img.shields.io/badge/pub-2017--02--28-green)![](https://img.shields.io/badge/cite-1725-red)

[**Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles**](https://arxiv.org/abs/2302.135401612.01474) ğŸ‘¨â€ğŸ“Balaji Lakshminarayanan,A. Pritzel,C. Blundell 2016 ![](https://img.shields.io/badge/pub-2016--12--05-green)![](https://img.shields.io/badge/cite-3175-red)

[**Understanding deep learning requires rethinking generalization**](https://arxiv.org/abs/2302.135401611.03530) ğŸ‘¨â€ğŸ“Chiyuan Zhang,Samy Bengio,Moritz Hardt,B. Recht,Oriol Vinyals 2016 ![](https://img.shields.io/badge/pub-2016--11--04-green)![](https://img.shields.io/badge/cite-3936-red)

[**Optimization as a Model for Few-Shot Learning**](https://api.semanticscholar.org/29c887794eed2ca9462638ff853e6fe1ab91d5d8) ğŸ‘¨â€ğŸ“S. Ravi,H. Larochelle 2016 ![](https://img.shields.io/badge/pub-2016--11--04-green)![](https://img.shields.io/badge/cite-2567-red)

[**A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks**](https://arxiv.org/abs/2302.135401610.02136) ğŸ‘¨â€ğŸ“Dan Hendrycks,Kevin Gimpel 2016 ![](https://img.shields.io/badge/pub-2016--10--07-green)![](https://img.shields.io/badge/cite-1788-red)

[**SQuAD: 100,000+ Questions for Machine Comprehension of Text**](https://doi.org/10.18653/v1/D16-1264) ğŸ‘¨â€ğŸ“Pranav Rajpurkar,Jian Zhang,Konstantin Lopyrev,Percy Liang 2016 ![](https://img.shields.io/badge/pub-2016--06--16-green)![](https://img.shields.io/badge/cite-5197-red)

[**Matching Networks for One Shot Learning**](https://arxiv.org/abs/2302.135401606.04080) ğŸ‘¨â€ğŸ“Oriol Vinyals,C. Blundell,T. Lillicrap,K. Kavukcuoglu,Daan Wierstra 2016 ![](https://img.shields.io/badge/pub-2016--06--13-green)![](https://img.shields.io/badge/cite-4816-red)

[**â€œWhy Should I Trust You?â€: Explaining the Predictions of Any Classifier**](https://doi.org/10.1145/2939672.2939778) ğŸ‘¨â€ğŸ“Marco Tulio Ribeiro,Sameer Singh,Carlos Guestrin 2016 ![](https://img.shields.io/badge/pub-2016--02--16-green)![](https://img.shields.io/badge/cite-9632-red)

[**Deep Residual Learning for Image Recognition**](https://doi.org/10.1109/cvpr.2016.90) ğŸ‘¨â€ğŸ“Kaiming He,X. Zhang,Shaoqing Ren,Jian Sun 2015 ![](https://img.shields.io/badge/pub-2015--12--10-green)![](https://img.shields.io/badge/cite-122183-red)

[**Character-level Convolutional Networks for Text Classification**](https://arxiv.org/abs/2302.135401509.01626) ğŸ‘¨â€ğŸ“Xiang Zhang,J. Zhao,Yann LeCun 2015 ![](https://img.shields.io/badge/pub-2015--09--04-green)![](https://img.shields.io/badge/cite-4160-red)

[**A large annotated corpus for learning natural language inference**](https://doi.org/10.18653/v1/D15-1075) ğŸ‘¨â€ğŸ“Samuel R. Bowman,Gabor Angeli,Christopher Potts,Christopher D. Manning 2015 ![](https://img.shields.io/badge/pub-2015--08--21-green)![](https://img.shields.io/badge/cite-2999-red)

[**ActivityNet: A large-scale video benchmark for human activity understanding**](https://doi.org/10.1109/CVPR.2015.7298698) ğŸ‘¨â€ğŸ“Fabian Caba Heilbron,Victor Escorcia,Bernard Ghanem,Juan Carlos Niebles 2015 ![](https://img.shields.io/badge/pub-2015--06--07-green)![](https://img.shields.io/badge/cite-1612-red)

[**Adam: A Method for Stochastic Optimization**](https://arxiv.org/abs/2302.135401412.6980) ğŸ‘¨â€ğŸ“Diederik P. Kingma,Jimmy Ba 2014 ![](https://img.shields.io/badge/pub-2014--12--22-green)![](https://img.shields.io/badge/cite-110816-red)

[**Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps**](https://arxiv.org/abs/2302.135401312.6034) ğŸ‘¨â€ğŸ“K. Simonyan,A. Vedaldi,Andrew Zisserman 2013 ![](https://img.shields.io/badge/pub-2013--12--20-green)![](https://img.shields.io/badge/cite-5229-red)

[**Playing Atari with Deep Reinforcement Learning**](https://arxiv.org/abs/2302.135401312.5602) ğŸ‘¨â€ğŸ“Volodymyr Mnih,K. Kavukcuoglu,David Silver,A. Graves,Ioannis Antonoglou,Daan Wierstra,Martin A. Riedmiller 2013 ![](https://img.shields.io/badge/pub-2013--12--19-green)![](https://img.shields.io/badge/cite-8414-red)

[**Hidden factors and hidden topics: understanding rating dimensions with review text**](https://doi.org/10.1145/2507157.2507163) ğŸ‘¨â€ğŸ“Julian McAuley,J. Leskovec 2013 ![](https://img.shields.io/badge/pub-2013--10--12-green)![](https://img.shields.io/badge/cite-1517-red)

[**Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank**](https://api.semanticscholar.org/687bac2d3320083eb4530bf18bb8f8f721477600) ğŸ‘¨â€ğŸ“R. Socher,Alex Perelygin,Jean Wu,Jason Chuang,Christopher D. Manning,A. Ng,Christopher Potts 2013 ![](https://img.shields.io/badge/pub-2013--10--01-green)![](https://img.shields.io/badge/cite-6124-red)

[**Efficient Estimation of Word Representations in Vector Space**](https://arxiv.org/abs/2302.135401301.3781) ğŸ‘¨â€ğŸ“Tomas Mikolov,Kai Chen,G. Corrado,J. Dean 2013 ![](https://img.shields.io/badge/pub-2013--01--16-green)![](https://img.shields.io/badge/cite-25157-red)

[**The NumPy Array: A Structure for Efficient Numerical Computation**](https://doi.org/10.1109/MCSE.2011.37) ğŸ‘¨â€ğŸ“S. Walt,S. Colbert,G. Varoquaux 2011 ![](https://img.shields.io/badge/pub-2011--02--07-green)![](https://img.shields.io/badge/cite-6594-red)

[**Steven Bird, Ewan Klein and Edward Loper: Natural Language Processing with Python, Analyzing Text with the Natural Language Toolkit**](https://doi.org/10.1007/s10579-010-9124-x) ğŸ‘¨â€ğŸ“Wiebke Wagner 2010 ![](https://img.shields.io/badge/pub-2010--12--01-green)![](https://img.shields.io/badge/cite-1724-red)

[**Why Does Unsupervised Pre-training Help Deep Learning?**](https://doi.org/10.5555/1756006.1756025) ğŸ‘¨â€ğŸ“D. Erhan,Aaron C. Courville,Yoshua Bengio,Pascal Vincent 2010 ![](https://img.shields.io/badge/pub-2010--03--01-green)![](https://img.shields.io/badge/cite-2072-red)

[**The Probabilistic Relevance Framework: BM25 and Beyond**](https://doi.org/10.1561/1500000019) ğŸ‘¨â€ğŸ“S. Robertson,H. Zaragoza 2009 ![](https://img.shields.io/badge/pub-2009--04--01-green)![](https://img.shields.io/badge/cite-1854-red)

[**Learning to rank for information retrieval**](https://doi.org/10.1007/978-3-642-14267-3) ğŸ‘¨â€ğŸ“Tie-Yan Liu 2009 ![](https://img.shields.io/badge/pub-2009--03--01-green)![](https://img.shields.io/badge/cite-2730-red)

[**The PASCAL Recognising Textual Entailment Challenge**](https://doi.org/10.1007/11736790_9) ğŸ‘¨â€ğŸ“Ido Dagan,Oren Glickman,B. Magnini 2007 ![](https://img.shields.io/badge/pub-2007--06--28-green)![](https://img.shields.io/badge/cite-1948-red)

[**Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales**](https://doi.org/10.3115/1219840.1219855) ğŸ‘¨â€ğŸ“B. Pang,Lillian Lee 2005 ![](https://img.shields.io/badge/pub-2005--06--17-green)![](https://img.shields.io/badge/cite-2509-red)

[**A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts**](https://doi.org/10.3115/1218955.1218990) ğŸ‘¨â€ğŸ“B. Pang,Lillian Lee 2004 ![](https://img.shields.io/badge/pub-2004--07--21-green)![](https://img.shields.io/badge/cite-3765-red)

[**Latent Dirichlet Allocation**](https://doi.org/10.1016/B978-0-12-411519-4.00006-9) ğŸ‘¨â€ğŸ“D. Blei,A. Ng,Michael I. Jordan 2001 ![](https://img.shields.io/badge/pub-2001--01--03-green)![](https://img.shields.io/badge/cite-33642-red)

[**Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping**](https://api.semanticscholar.org/94066dc12fe31e96af7557838159bde598cb4f10) ğŸ‘¨â€ğŸ“A. Ng,D. Harada,Stuart J. Russell 1999 ![](https://img.shields.io/badge/pub-1999--06--27-green)![](https://img.shields.io/badge/cite-1797-red)

[**OPTICS: ordering points to identify the clustering structure**](https://doi.org/10.1145/304182.304187) ğŸ‘¨â€ğŸ“M. Ankerst,M. Breunig,H. Kriegel,J. Sander 1999 ![](https://img.shields.io/badge/pub-1999--06--01-green)![](https://img.shields.io/badge/cite-3993-red)

[**An Introduction to Variational Methods for Graphical Models**](https://doi.org/10.1023/A:1007665907178) ğŸ‘¨â€ğŸ“Michael I. Jordan,Zoubin Ghahramani,T. Jaakkola,L. Saul 1999 ![](https://img.shields.io/badge/pub-1999--02--01-green)![](https://img.shields.io/badge/cite-4039-red)

[**Long Short-Term Memory**](https://doi.org/10.1162/neco.1997.9.8.1735) ğŸ‘¨â€ğŸ“S. Hochreiter,J. Schmidhuber 1997 ![](https://img.shields.io/badge/pub-1997--11--01-green)![](https://img.shields.io/badge/cite-61441-red)

[**Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory.**](https://doi.org/10.1037/0033-295X.102.3.419) ğŸ‘¨â€ğŸ“James L. McClelland,B. McNaughton,R. Oâ€™Reilly 1995 ![](https://img.shields.io/badge/pub-1995--07--01-green)![](https://img.shields.io/badge/cite-4614-red)

[**Memory and the hippocampus: a synthesis from findings with rats, monkeys, and humans.**](https://doi.org/10.1037/0033-295X.99.2.195) ğŸ‘¨â€ğŸ“L. Squire 1992 ![](https://img.shields.io/badge/pub-1992--03--30-green)![](https://img.shields.io/badge/cite-5284-red)

[**Learning internal representations by error propagation**](https://doi.org/10.1016/B978-1-4832-1446-7.50035-2) ğŸ‘¨â€ğŸ“D. Rumelhart,Geoffrey E. Hinton,Ronald J. Williams 1986 ![](https://img.shields.io/badge/pub-1986--01--03-green)![](https://img.shields.io/badge/cite-20072-red)

[**Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper**](https://doi.org/10.1111/J.2517-6161.1977.TB01600.X) ğŸ‘¨â€ğŸ“A. Dempster,N. Laird,D. Rubin 1977 ![](https://img.shields.io/badge/pub-1977--09--01-green)![](https://img.shields.io/badge/cite-50347-red)

[**Monte Carlo Sampling Methods Using Markov Chains and Their Applications**](https://doi.org/10.1093/BIOMET/57.1.97) ğŸ‘¨â€ğŸ“W. K. Hastings 1970 ![](https://img.shields.io/badge/pub-1970--04--01-green)![](https://img.shields.io/badge/cite-14415-red)

[**Statistical Inference for Probabilistic Functions of Finite State Markov Chains**](https://doi.org/10.1214/AOMS/1177699147) ğŸ‘¨â€ğŸ“L. Baum,T. Petrie 1966 ![](https://img.shields.io/badge/pub-1966--12--01-green)![](https://img.shields.io/badge/cite-2906-red)

[**A Markovian Decision Process**](https://doi.org/10.1512/IUMJ.1957.6.56038) ğŸ‘¨â€ğŸ“R. Bellman 1957 ![](https://img.shields.io/badge/pub-1957--04--18-green)![](https://img.shields.io/badge/cite-2103-red)

[**Equation of state calculations by fast computing machines**](https://doi.org/10.1063/1.1699114) ğŸ‘¨â€ğŸ“N. Metropolis,A. W. Rosenbluth,M. Rosenbluth,A. H. Teller,E. Teller 1953 ![](https://img.shields.io/badge/pub-1953--06--01-green)![](https://img.shields.io/badge/cite-33689-red)

[**DBpedia - A large-scale, multilingual knowledge base extracted from Wikipedia**](https://doi.org/10.3233/SW-140134) ğŸ‘¨â€ğŸ“Jens Lehmann,Robert Isele,Max Jakob,Anja Jentzsch,D. Kontokostas,Pablo N. Mendes,Sebastian Hellmann,M. Morsey,Patrick van Kleef,S. Auer,C. Bizer 2015 ![](https://img.shields.io/badge/cite-2645-red)

[**Probabilistic Outputs for Support vector Machines and Comparisons to Regularized Likelihood Methods**](https://api.semanticscholar.org/384bb3944abe9441dcd2cede5e7cd7353e9ee5f7) ğŸ‘¨â€ğŸ“J. Platt 1999 ![](https://img.shields.io/badge/cite-5501-red)

[**Speech and language processing - an introduction to natural language processing, computational linguistics, and speech recognition**](https://api.semanticscholar.org/b54bcfca3fddc26b8889739a247a25e445818149) ğŸ‘¨â€ğŸ“Dan Jurafsky,James H. Martin 2000 ![](https://img.shields.io/badge/cite-3977-red)

[**Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond**](https://doi.org/10.1109/tnn.2005.848998) ğŸ‘¨â€ğŸ“A. Atiya 2005 ![](https://img.shields.io/badge/cite-8566-red)

[**Stochastic Neighbor Embedding**](https://api.semanticscholar.org/14d46c6396837986bb4b9a14024cb64797b8c6c0) ğŸ‘¨â€ğŸ“Geoffrey E. Hinton,S. Roweis 2002 ![](https://img.shields.io/badge/cite-1601-red)

[**SMOTE: Synthetic Minority Over-sampling Technique**](https://doi.org/10.1613/jair.953) ğŸ‘¨â€ğŸ“N. Chawla,K. Bowyer,L. Hall,W. Kegelmeyer 2002 ![](https://img.shields.io/badge/cite-17180-red)

[**Improving Language Understanding by Generative Pre-Training**](https://api.semanticscholar.org/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035) ğŸ‘¨â€ğŸ“Alec Radford,Karthik Narasimhan 2018 ![](https://img.shields.io/badge/cite-4775-red)

[**The use of MMR, diversity-based reranking for reordering documents and producing summaries**](https://doi.org/10.1145/290941.291025) ğŸ‘¨â€ğŸ“J. Carbonell,Jade Goldstein-Stewart 1998 ![](https://img.shields.io/badge/cite-2508-red)

[**Human behavior and the principle of least effort**](https://doi.org/10.1037/h0052803) ğŸ‘¨â€ğŸ“G. Zipf 1949 ![](https://img.shields.io/badge/cite-7346-red)

[**Language Models are Unsupervised Multitask Learners**](https://api.semanticscholar.org/9405cc0d6169988371b2755e573cc28650d14dfe) ğŸ‘¨â€ğŸ“Alec Radford,Jeff Wu,Rewon Child,D. Luan,Dario Amodei,Ilya Sutskever 2019 ![](https://img.shields.io/badge/cite-8849-red)

[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://doi.org/10.18653/v1/N19-1423) ğŸ‘¨â€ğŸ“Jacob Devlin,Ming-Wei Chang,Kenton Lee,Kristina Toutanova 2019 ![](https://img.shields.io/badge/cite-47696-red)

[**Active Learning Literature Survey**](https://api.semanticscholar.org/818826f356444f3daa3447755bf63f171f39ec47) ğŸ‘¨â€ğŸ“Burr Settles 2009 ![](https://img.shields.io/badge/cite-5213-red)

[**of the Association for Computational Linguistics:**](https://doi.org/10.1016/b0-08-044854-2/05234-2) ğŸ‘¨â€ğŸ“Vladimir Meza Ruiz,Rashmi Gangadharaiah,Maria Leonor Pacheco,Danqi Chen,Ryan Cotterell 2001 ![](https://img.shields.io/badge/cite-4067-red)



## Multimodal Prompt

### ğŸ“Œ Hard Prompt/ Discrete Prompt

[**RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning**](https://api.semanticscholar.org/2146867236) ğŸ‘¨â€ğŸ“Mingkai Deng,Jianyu Wang,Cheng-Ping Hsieh,Yihan Wang,Han Guo,Tianmin Shu,Meng Song,E. Xing,Zhiting Hu 2022 

[**Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery**](https://api.semanticscholar.org/123191916) ğŸ‘¨â€ğŸ“Yuxin Wen,Neel Jain,John Kirchenbauer,Micah Goldblum,Jonas Geiping,T. Goldstein 2023 



### ğŸ“Œ Soft Prompt/ Continuous Prompt

[**Prompting through Prototype: A Prototype-based Prompt Learning on Pretrained Vision-Language Models**](https://arxiv.org/abs/2302.135402210.10841) ğŸ‘¨â€ğŸ“ 

[**P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks**](https://api.semanticscholar.org/ec936b808e0fab9281c050ad4010cddec92c8cbe) 2022 

[**FedPrompt: Communication-Efficient and Privacy Preserving Prompt Tuning in Federated Learning**](https://arxiv.org/abs/2302.135402208.12268) ğŸ‘¨â€ğŸ“ 

[**Instance-aware prompt learning for language understanding and generation**](https://arxiv.org/abs/2302.135402201.07126) ğŸ‘¨â€ğŸ“ 

[**Learning to Compose Soft Prompts for Compositional Zero-Shot Learning**](https://arxiv.org/abs/2302.135402204.03574) ğŸ‘¨â€ğŸ“ 

[**FPT: Improving Prompt Tuning Efficiency via Progressive Training**](https://arxiv.org/abs/2302.135402211.06840) ğŸ‘¨â€ğŸ“ 

[**Decomposed Soft Prompt Guided Fusion Enhancing for Compositional Zero-Shot Learning**](https://arxiv.org/abs/2302.135402211.10681) ğŸ‘¨â€ğŸ“ 

[**Prompt Distribution Learning**](https://arxiv.org/abs/2302.135402205.03340) ğŸ‘¨â€ğŸ“ 

[**Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts**](https://arxiv.org/abs/2302.135402210.11292) ğŸ‘¨â€ğŸ“ 

[**Scalable Prompt Generation for Semi-supervised Learning with Language Models**](https://arxiv.org/abs/2302.135402302.09236) ğŸ‘¨â€ğŸ“ 

[**HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification**](https://arxiv.org/abs/2302.135402204.13413) ğŸ‘¨â€ğŸ“ 

[**Structured Prompt Tuning**](https://arxiv.org/abs/2302.135402205.12309) ğŸ‘¨â€ğŸ“ 

[**Parameter-Efficient Low-Resource Dialogue State Tracking by Prompt Tuning**](https://arxiv.org/abs/2302.135402301.10915) ğŸ‘¨â€ğŸ“ 

[**Prompt-based Conservation Learning for Multi-hop Question Answering**](https://arxiv.org/abs/2302.135402209.06923) ğŸ‘¨â€ğŸ“ 

[**Making pre-trained language models end-to-end few-shot learners with contrastive prompt tuning**](https://doi.org/https://doi.org/10.1145/3539597.3570398) ğŸ‘¨â€ğŸ“Menglin Jia,Luming Tang,Bor-Chun Chen,Claire Cardie,S. Belongie,Bharath Hariharan,S. Lim 2022 

[**Continuous Detection, Rapidly React: Unseen Rumors Detection based on Continual Prompt-Tuning**](https://arxiv.org/abs/2302.135402203.11720) ğŸ‘¨â€ğŸ“ 

[**PSP: Pre-trained Soft Prompts for Few-Shot Abstractive Summarization**](https://arxiv.org/abs/2302.135402204.04413) ğŸ‘¨â€ğŸ“ 

[**Eliciting Knowledge from Pretrained Language Models for Prototypical Prompt Verbalizer**](https://doi.org/10.1007/978-3-031-15931-2_19) ğŸ‘¨â€ğŸ“ 

[**On Transferability of Prompt Tuning for Natural Language Processing**](https://doi.org/10.18653/v1/2022.naacl-main.290) ğŸ‘¨â€ğŸ“ 

[**Towards Unifying Medical Vision-and-Language Pre-training via Soft Prompts**](https://api.semanticscholar.org/da9579539385daedd33a0de0f814e2977ad0d1f5) 2023 

[**XPrompt: Exploring the Extreme of Prompt Tuning**](https://arxiv.org/abs/2302.135402210.04457) ğŸ‘¨â€ğŸ“ 

[**PromDA: Prompt-based Data Augmentation for Low-Resource NLU Tasks**](https://arxiv.org/abs/2302.135402202.12499) ğŸ‘¨â€ğŸ“ 

[**How Does In-Context Learning Help Prompt Tuning?**](https://doi.org/10.48550) ğŸ‘¨â€ğŸ“ 

[**Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding**](https://arxiv.org/abs/2302.135402205.11024) ğŸ‘¨â€ğŸ“ 

[**SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains**](https://api.semanticscholar.org/120873790) ğŸ‘¨â€ğŸ“ 

[**Continuous prompt tuning for russian: how to learn prompts efficiently with rugpt3?**](https://doi.org/10.1007/978-3-031-15168-2_3) ğŸ‘¨â€ğŸ“ 

[**No more fine-tuning? an experimental evaluation of prompt tuning in code intelligence**](https://arxiv.org/abs/2302.135402207.11680) ğŸ‘¨â€ğŸ“ 

[**Toward Human Readable Prompt Tuning: Kubrickâ€™s The Shining is a good movie, and a good prompt too?**](https://arxiv.org/abs/2302.135402212.10539) ğŸ‘¨â€ğŸ“ 

[**Tailor: A prompt-based approach to attribute-based controlled text generation**](https://arxiv.org/abs/2302.135402204.13362) ğŸ‘¨â€ğŸ“ 

[**Knowledge Prompts: Injecting World Knowledge into Language Models through Soft Prompts**](https://arxiv.org/abs/2302.135402210.04726) ğŸ‘¨â€ğŸ“ 

[**Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization**](https://arxiv.org/abs/2302.135402210.03029) ğŸ‘¨â€ğŸ“ 

[**PTAU: Prompt Tuning for Attributing Unanswerable Questions**](https://api.semanticscholar.org/97d214a10afb84f3b94881a3ad8e90372ba5809c) 2022 

[**PPT: Pre-trained Prompt Tuning for Few-shot Learning**](https://arxiv.org/abs/2302.135402109.04332) ğŸ‘¨â€ğŸ“ 

[**Unsupervised Prompt Learning for Vision-Language Models**](https://api.semanticscholar.org/732627c703a9dbc78d9384f1be4c791c3a554391) 2022 

[**Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts health answer correctness**](https://api.semanticscholar.org/5a91a012dc51db03d6eb3698d2e1c5b00115835f) 2023 

[**Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning(**](https://arxiv.org/abs/2302.135402106.09226) ğŸ‘¨â€ğŸ“ 

[**ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts**](https://arxiv.org/abs/2302.135402205.11961) ğŸ‘¨â€ğŸ“ 

[**Prompt Tuning with Soft Context Sharing for Vision-Language Models**](https://arxiv.org/abs/2302.135402208.13474) ğŸ‘¨â€ğŸ“ 

[**P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks**](https://api.semanticscholar.org/f3a332ff1b73acda482e5d83696b2c701f487819) 2021 

[**Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning**](https://arxiv.org/abs/2302.135402210.12587) ğŸ‘¨â€ğŸ“ 

[**Personalized Prompt Learning for Explainable Recommendation**](https://api.semanticscholar.org/8498daeeb893870524ffaa63086f8528795003d4) 2022 

[**SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer**](https://arxiv.org/abs/2302.135402110.07904) ğŸ‘¨â€ğŸ“ 

[**PANDA: Prompt Transfer Meets Knowledge Distillation for Efficient Model Adaptation**](https://arxiv.org/abs/2302.135402208.10160) ğŸ‘¨â€ğŸ“ 

[**Improved Universal Sentence Embeddings with Prompt-based Contrastive Learning and Energy-based Learning**](https://arxiv.org/abs/2302.135402203.06875) ğŸ‘¨â€ğŸ“ 

[**ProQA: Structural Prompt-based Pre-training for Unified Question Answering**](https://arxiv.org/abs/2302.135402205.04040) ğŸ‘¨â€ğŸ“ 

[**SPT: Semi-Parametric Prompt Tuning for Multitask Prompted Learning**](https://arxiv.org/abs/2302.135402212.10929) ğŸ‘¨â€ğŸ“ 

[**Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation**](https://arxiv.org/abs/2302.135402210.02952) ğŸ‘¨â€ğŸ“ 

[**Adversarial Soft Prompt Tuning for Cross-Domain Sentiment Analysis**](https://doi.org/10.18653/v1/2022.acl-long.174) ğŸ‘¨â€ğŸ“ 

[**Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning**](https://arxiv.org/abs/2302.135402202.09363) ğŸ‘¨â€ğŸ“ 

[**PromptFL: Let Federated Participants Cooperatively Learn Prompts Instead of Models -- Federated Learning in Age of Foundation ModePromptFL: Let Federated Participants Cooperatively Learn Prompts Instead of Models -- Federated Learning in Age of Foundation Mode**](https://arxiv.org/abs/2302.135402208.11625) ğŸ‘¨â€ğŸ“ 

[**Context-Tuning: Learning Contextualized Prompts for Natural Language Generation**](https://api.semanticscholar.org/c10d0353d8a169d23351f1dbec8cdfdd8c62a60e) 2022 

[**OpenPrompt: An Open-source Framework for Prompt-learning**](https://arxiv.org/abs/2302.135402111.01998) ğŸ‘¨â€ğŸ“ 

[**Learning a Better Initialization for Soft Prompts via Meta-Learning**](https://arxiv.org/abs/2302.135402205.12471) ğŸ‘¨â€ğŸ“ 

[**Learning to prompt for open-vocabulary object detection with vision-language model**](https://arxiv.org/abs/2302.135402203.14940) ğŸ‘¨â€ğŸ“ 

[**Enhance Performance of Ad-hoc Search via Prompt Learning**](https://doi.org/10.1007/978-3-031-24755-2_3) ğŸ‘¨â€ğŸ“ 

[**Zero-shot Cross-lingual Transfer of Prompt-based Tuning with a Unified Multilingual Prompt(**](https://arxiv.org/abs/2302.135402202.11451) ğŸ‘¨â€ğŸ“ 

[**MetaPrompting: Learning to Learn Better Prompts**](https://arxiv.org/abs/2302.135402209.11486) ğŸ‘¨â€ğŸ“ 

[**Controlled Text Generation using T5 based Encoder-Decoder Soft Prompt Tuning and Analysis of the Utility of Generated Text in AI**](https://arxiv.org/abs/2302.135402212.02924) ğŸ‘¨â€ğŸ“ 



## Knowledge Augmented Prompts

[**UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning**](https://doi.org/10.18653/v1/2022.acl-long.433) ğŸ‘¨â€ğŸ“Yuning Mao,Lambert Mathias,Rui Hou,Amjad Almahairi,Hao Ma,Jiawei Han,Wen-tau Yih,Madian Khabsa 2021 ![](https://img.shields.io/badge/pub-2021--10--14-green)![](https://img.shields.io/badge/cite-31-red)

[**HETFORMER: Heterogeneous Transformer with Sparse Attention for Long-Text Extractive Summarization**](https://doi.org/10.18653/v1/2021.emnlp-main.13) ğŸ‘¨â€ğŸ“Ye Liu,Jianguo Zhang,Yao Wan,Congying Xia,Lifang He,Philip S. Yu 2021 ![](https://img.shields.io/badge/pub-2021--10--12-green)![](https://img.shields.io/badge/cite-11-red)

[**Can Language Models be Biomedical Knowledge Bases?**](https://doi.org/10.18653/v1/2021.emnlp-main.388) ğŸ‘¨â€ğŸ“Mujeen Sung,Jinhyuk Lee,Sean S. Yi,Minji Jeon,Sungdong Kim,Jaewoo Kang 2021 ![](https://img.shields.io/badge/pub-2021--09--15-green)![](https://img.shields.io/badge/cite-26-red)

[**The SelectGen Challenge: Finding the Best Training Samples for Few-Shot Neural Text Generation**](https://arxiv.org/abs/2302.135402108.06614) ğŸ‘¨â€ğŸ“Ernie Chang,Xiaoyu Shen,Alex Marin,V. Demberg 2021 ![](https://img.shields.io/badge/pub-2021--08--14-green)![](https://img.shields.io/badge/cite-4-red)

[**Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**](https://doi.org/10.1145/3560815) ğŸ‘¨â€ğŸ“Pengfei Liu,Weizhe Yuan,Jinlan Fu,Zhengbao Jiang,Hiroaki Hayashi,Graham Neubig 2021 ![](https://img.shields.io/badge/pub-2021--07--28-green)![](https://img.shields.io/badge/cite-429-red)

[**On Training Instance Selection for Few-Shot Neural Text Generation**](https://doi.org/10.18653/v1/2021.acl-short.2) ğŸ‘¨â€ğŸ“Ernie Chang,Xiaoyu Shen,Hui-Syuan Yeh,V. Demberg 2021 ![](https://img.shields.io/badge/pub-2021--07--07-green)![](https://img.shields.io/badge/cite-15-red)

[**Template-Based Named Entity Recognition Using BART**](https://doi.org/10.18653/v1/2021.findings-acl.161) ğŸ‘¨â€ğŸ“Leyang Cui,Yu Wu,Jian Liu,Sen Yang,Yue Zhang 2021 ![](https://img.shields.io/badge/pub-2021--06--03-green)![](https://img.shields.io/badge/cite-100-red)

[**Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.381) ğŸ‘¨â€ğŸ“Yichen Jiang,Asli Celikyilmaz,P. Smolensky,Paul Soulos,Sudha Rao,H. Palangi,Roland Fernandez,Caitlin Smith,Mohit Bansal,Jianfeng Gao 2021 ![](https://img.shields.io/badge/pub-2021--06--01-green)![](https://img.shields.io/badge/cite-6-red)

[**SciFive: a text-to-text transformer model for biomedical literature**](https://arxiv.org/abs/2302.135402106.03598) ğŸ‘¨â€ğŸ“Long Phan,J. Anibal,Hieu Tran,Shaurya Chanana,Erol Bahadroglu,Alec Peltekian,G. Altan-Bonnet 2021 ![](https://img.shields.io/badge/pub-2021--05--28-green)![](https://img.shields.io/badge/cite-45-red)

[**PTR: Prompt Tuning with Rules for Text Classification**](https://doi.org/10.1016/j.aiopen.2022.11.003) ğŸ‘¨â€ğŸ“Xu Han,Weilin Zhao,Ning Ding,Zhiyuan Liu,Maosong Sun 2021 ![](https://img.shields.io/badge/pub-2021--05--24-green)![](https://img.shields.io/badge/cite-169-red)

[**Not All Memories are Created Equal: Learning to Forget by Expiring**](https://arxiv.org/abs/2302.135402105.06548) ğŸ‘¨â€ğŸ“Sainbayar Sukhbaatar,Da Ju,Spencer Poff,Stephen Roller,Arthur D. Szlam,J. Weston,Angela Fan 2021 ![](https://img.shields.io/badge/pub-2021--05--13-green)![](https://img.shields.io/badge/cite-16-red)

[**Long-Span Summarization via Local Attention and Content Selection**](https://doi.org/10.18653/v1/2021.acl-long.470) ğŸ‘¨â€ğŸ“Potsawee Manakul,M. Gales 2021 ![](https://img.shields.io/badge/pub-2021--05--08-green)![](https://img.shields.io/badge/cite-20-red)

[**The Power of Scale for Parameter-Efficient Prompt Tuning**](https://doi.org/10.18653/v1/2021.emnlp-main.243) ğŸ‘¨â€ğŸ“Brian Lester,Rami Al-Rfou,Noah Constant 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-675-red)

[**KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction**](https://doi.org/10.1145/3485447.3511998) ğŸ‘¨â€ğŸ“Xiang Chen,Ningyu Zhang,Ningyu Zhang,Xin Xie,Shumin Deng,Yunzhi Yao,Chuanqi Tan,Fei Huang,Luo Si,Huajun Chen 2021 ![](https://img.shields.io/badge/pub-2021--04--15-green)![](https://img.shields.io/badge/cite-84-red)

[**Data Augmentation for Abstractive Query-Focused Multi-Document Summarization**](https://doi.org/10.1609/aaai.v35i15.17611) ğŸ‘¨â€ğŸ“Ramakanth Pasunuru,Asli Celikyilmaz,Michel Galley,Chenyan Xiong,Yizhe Zhang,Mohit Bansal,Jianfeng Gao 2021 ![](https://img.shields.io/badge/pub-2021--03--02-green)![](https://img.shields.io/badge/cite-26-red)

[**SparseBERT: Rethinking the Importance Analysis in Self-attention**](https://arxiv.org/abs/2302.135402102.12871) ğŸ‘¨â€ğŸ“Han Shi,Jiahui Gao,Xiaozhe Ren,Hang Xu,Xiaodan Liang,Zhenguo Li,J. Kwok 2021 ![](https://img.shields.io/badge/pub-2021--02--25-green)![](https://img.shields.io/badge/cite-27-red)

[**Calibrate Before Use: Improving Few-Shot Performance of Language Models**](https://arxiv.org/abs/2302.135402102.09690) ğŸ‘¨â€ğŸ“Tony Zhao,Eric Wallace,Shi Feng,D. Klein,Sameer Singh 2021 ![](https://img.shields.io/badge/pub-2021--02--19-green)![](https://img.shields.io/badge/cite-277-red)

[**Does the Order of Training Samples Matter? Improving Neural Data-to-Text Generation with Curriculum Learning**](https://doi.org/10.18653/v1/2021.eacl-main.61) ğŸ‘¨â€ğŸ“Ernie Chang,Hui-Syuan Yeh,V. Demberg 2021 ![](https://img.shields.io/badge/pub-2021--02--06-green)![](https://img.shields.io/badge/cite-17-red)

[**Making Pre-trained Language Models Better Few-shot Learners**](https://doi.org/10.18653/v1/2021.acl-long.295) ğŸ‘¨â€ğŸ“Tianyu Gao,Adam Fisch,Danqi Chen 2021 ![](https://img.shields.io/badge/pub-2021--01--01-green)![](https://img.shields.io/badge/cite-635-red)

[**Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals**](https://doi.org/10.1162/tacl_a_00359) ğŸ‘¨â€ğŸ“Yanai Elazar,Shauli Ravfogel,Alon Jacovi,Yoav Goldberg 2020 ![](https://img.shields.io/badge/pub-2020--12--07-green)![](https://img.shields.io/badge/cite-105-red)

[**How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering**](https://doi.org/10.1162/tacl_a_00407) ğŸ‘¨â€ğŸ“Zhengbao Jiang,J. Araki,Haibo Ding,Graham Neubig 2020 ![](https://img.shields.io/badge/pub-2020--12--02-green)![](https://img.shields.io/badge/cite-66-red)

[**Long Range Arena: A Benchmark for Efficient Transformers**](https://arxiv.org/abs/2302.135402011.04006) ğŸ‘¨â€ğŸ“Yi Tay,M. Dehghani,Samira Abnar,Yikang Shen,Dara Bahri,Philip Pham,J. Rao,Liu Yang,Sebastian Ruder,Donald Metzler 2020 ![](https://img.shields.io/badge/pub-2020--11--08-green)![](https://img.shields.io/badge/cite-263-red)

[**Automatically Identifying Words That Can Serve as Labels for Few-Shot Text Classification**](https://doi.org/10.5282/UBM/EPUB.74034) ğŸ‘¨â€ğŸ“Timo Schick,Helmut Schmid,Hinrich SchÃ¼tze 2020 ![](https://img.shields.io/badge/pub-2020--10--26-green)![](https://img.shields.io/badge/cite-83-red)

[**Self-Alignment Pretraining for Biomedical Entity Representations**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.334) ğŸ‘¨â€ğŸ“Fangyu Liu,Ehsan Shareghi,Zaiqiao Meng,Marco Basaldella,N. Collier 2020 ![](https://img.shields.io/badge/pub-2020--10--22-green)![](https://img.shields.io/badge/cite-101-red)

[**UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.139) ğŸ‘¨â€ğŸ“George Michalopoulos,Yuanxin Wang,H. Kaka,Helen H Chen,Alexander Wong 2020 ![](https://img.shields.io/badge/pub-2020--10--20-green)![](https://img.shields.io/badge/cite-50-red)

[**CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters**](https://doi.org/10.18653/V1/2020.COLING-MAIN.609) ğŸ‘¨â€ğŸ“Hicham El Boukkouri,Olivier Ferret,T. Lavergne,Hiroshi Noji,Pierre Zweigenbaum,Junichi Tsujii 2020 ![](https://img.shields.io/badge/pub-2020--10--20-green)![](https://img.shields.io/badge/cite-84-red)

[**X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models**](https://doi.org/10.18653/v1/2020.emnlp-main.479) ğŸ‘¨â€ğŸ“Zhengbao Jiang,Antonios Anastasopoulos,J. Araki,Haibo Ding,Graham Neubig 2020 ![](https://img.shields.io/badge/pub-2020--10--13-green)![](https://img.shields.io/badge/cite-58-red)

[**Pretrained Transformers for Text Ranking: BERT and Beyond**](https://doi.org/10.1145/3437963.3441667) ğŸ‘¨â€ğŸ“Jimmy J. Lin,Rodrigo Nogueira,Andrew Yates 2020 ![](https://img.shields.io/badge/pub-2020--10--13-green)![](https://img.shields.io/badge/cite-285-red)

[**Bio-Megatron: Larger Biomedical Domain Language Model**](https://doi.org/10.18653/v1/2020.emnlp-main.379) ğŸ‘¨â€ğŸ“Hoo-Chang Shin,Yang Zhang,Evelina Bakhturina,Raul Puri,M. Patwary,M. Shoeybi,Raghav Mani 2020 ![](https://img.shields.io/badge/pub-2020--10--12-green)![](https://img.shields.io/badge/cite-43-red)

[**Adapting In-Vehicle Voice Output:A User- and Situation-Adaptive Approach**](https://doi.org/10.1145/3409251.3411711) ğŸ‘¨â€ğŸ“D. Stier,U. Heid,W. Minker 2020 ![](https://img.shields.io/badge/pub-2020--09--21-green)![](https://img.shields.io/badge/cite-3-red)

[**Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing**](https://doi.org/10.1145/3458754) ğŸ‘¨â€ğŸ“Yu Gu,Robert Tinn,Hao Cheng,Michael R. Lucas,Naoto Usuyama,Xiaodong Liu,Tristan Naumann,Jianfeng Gao,Hoifung Poon 2020 ![](https://img.shields.io/badge/pub-2020--07--31-green)![](https://img.shields.io/badge/cite-468-red)

[**Big Bird: Transformers for Longer Sequences**](https://arxiv.org/abs/2302.135402007.14062) ğŸ‘¨â€ğŸ“M. Zaheer,Guru Guruganesh,Kumar Avinava Dubey,J. Ainslie,Chris Alberti,Santiago OntaÃ±Ã³n,Philip Pham,Anirudh Ravula,Qifan Wang,Li Yang,Amr Ahmed 2020 ![](https://img.shields.io/badge/pub-2020--07--28-green)![](https://img.shields.io/badge/cite-843-red)

[**DART: Open-Domain Structured Data Record to Text Generation**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.37) ğŸ‘¨â€ğŸ“Dragomir R. Radev,Rui Zhang,Amrit Rau,Abhinand Sivaprasad,Chia-Hsuan Hsieh,Nazneen Rajani,Xiangru Tang,Aadit Vyas,Neha Verma,P. Krishna,Yangxiaokang Liu,Nadia Irwanto,Jessica Pan,Faiaz Rahman,A. Zaidi,Murori Mutuma,Yasin Tarabar,Ankit Gupta,Tao Yu,Y. Tan,Xi Victoria Lin,Caiming Xiong,R. Socher 2020 ![](https://img.shields.io/badge/pub-2020--07--06-green)![](https://img.shields.io/badge/cite-91-red)

[**Understanding Attention for Text Classification**](https://doi.org/10.18653/v1/2020.acl-main.312) ğŸ‘¨â€ğŸ“Xiaobing Sun,Wei Lu 2020 ![](https://img.shields.io/badge/pub-2020--07--01-green)![](https://img.shields.io/badge/cite-32-red)

[**Linformer: Self-Attention with Linear Complexity**](https://arxiv.org/abs/2302.135402006.04768) ğŸ‘¨â€ğŸ“Sinong Wang,Belinda Z. Li,Madian Khabsa,Han Fang,Hao Ma 2020 ![](https://img.shields.io/badge/pub-2020--06--08-green)![](https://img.shields.io/badge/cite-641-red)

[**Language Models are Few-Shot Learners**](https://arxiv.org/abs/2302.135402005.14165) ğŸ‘¨â€ğŸ“Tom B. Brown,Benjamin Mann,Nick Ryder,Melanie Subbiah,J. Kaplan,Prafulla Dhariwal,Arvind Neelakantan,Pranav Shyam,Girish Sastry,Amanda Askell,Sandhini Agarwal,Ariel Herbert-Voss,Gretchen Krueger,T. Henighan,Rewon Child,A. Ramesh,Daniel M. Ziegler,Jeff Wu,Clemens Winter,Christopher Hesse,Mark Chen,Eric Sigler,Mateusz Litwin,Scott Gray,Benjamin Chess,Jack Clark,Christopher Berner,Sam McCandlish,Alec Radford,Ilya Sutskever,Dario Amodei 2020 ![](https://img.shields.io/badge/pub-2020--05--28-green)![](https://img.shields.io/badge/cite-8351-red)

[**UnifiedQA: Crossing Format Boundaries With a Single QA System**](https://doi.org/10.18653/v1/2020.findings-emnlp.171) ğŸ‘¨â€ğŸ“Daniel Khashabi,Sewon Min,Tushar Khot,Ashish Sabharwal,Oyvind Tafjord,Peter Clark,Hannaneh Hajishirzi 2020 ![](https://img.shields.io/badge/pub-2020--05--02-green)![](https://img.shields.io/badge/cite-357-red)

[**Donâ€™t Stop Pretraining: Adapt Language Models to Domains and Tasks**](https://doi.org/10.18653/v1/2020.acl-main.740) ğŸ‘¨â€ğŸ“Suchin Gururangan,Ana MarasoviÄ‡,Swabha Swayamdipta,Kyle Lo,Iz Beltagy,Doug Downey,Noah A. Smith 2020 ![](https://img.shields.io/badge/pub-2020--04--23-green)![](https://img.shields.io/badge/cite-1128-red)

[**Sparse Text Generation**](https://doi.org/10.18653/v1/2020.emnlp-main.348) ğŸ‘¨â€ğŸ“Pedro Henrique Martins,Zita Marinho,AndrÃ© F. T. Martins 2020 ![](https://img.shields.io/badge/pub-2020--04--06-green)![](https://img.shields.io/badge/cite-25-red)

[**Efficient Content-Based Sparse Attention with Routing Transformers**](https://doi.org/10.1162/tacl_a_00353) ğŸ‘¨â€ğŸ“Aurko Roy,M. Saffar,Ashish Vaswani,David Grangier 2020 ![](https://img.shields.io/badge/pub-2020--03--12-green)![](https://img.shields.io/badge/cite-281-red)

[**Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference**](https://doi.org/10.18653/v1/2021.eacl-main.20) ğŸ‘¨â€ğŸ“Timo Schick,Hinrich SchÃ¼tze 2020 ![](https://img.shields.io/badge/pub-2020--01--21-green)![](https://img.shields.io/badge/cite-579-red)

[**How Can We Know What Language Models Know?**](https://doi.org/10.1162/tacl_a_00324) ğŸ‘¨â€ğŸ“Zhengbao Jiang,Frank F. Xu,J. Araki,Graham Neubig 2019 ![](https://img.shields.io/badge/pub-2019--11--28-green)![](https://img.shields.io/badge/cite-419-red)

[**SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization**](https://doi.org/10.18653/v1/D19-5409) ğŸ‘¨â€ğŸ“Bogdan Gliwa,Iwona Mochol,M. Biesek,A. Wawer 2019 ![](https://img.shields.io/badge/pub-2019--11--27-green)![](https://img.shields.io/badge/cite-217-red)

[**Semantic Noise Matters for Neural Natural Language Generation**](https://doi.org/10.18653/v1/W19-8652) ğŸ‘¨â€ğŸ“Ondrej Dusek,David M. Howcroft,Verena Rieser 2019 ![](https://img.shields.io/badge/pub-2019--11--01-green)![](https://img.shields.io/badge/cite-74-red)

[**Fine-tune BERT with Sparse Self-Attention Mechanism**](https://doi.org/10.18653/v1/D19-1361) ğŸ‘¨â€ğŸ“Baiyun Cui,Yingming Li,Ming Chen,Zhongfei Zhang 2019 ![](https://img.shields.io/badge/pub-2019--11--01-green)![](https://img.shields.io/badge/cite-41-red)

[**BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension**](https://doi.org/10.18653/v1/2020.acl-main.703) ğŸ‘¨â€ğŸ“M. Lewis,Yinhan Liu,Naman Goyal,Marjan Ghazvininejad,Abdelrahman Mohamed,Omer Levy,Veselin Stoyanov,Luke Zettlemoyer 2019 ![](https://img.shields.io/badge/pub-2019--10--29-green)![](https://img.shields.io/badge/cite-4052-red)

[**Reading Between the Guidelines: How Commercial Voice Assistant Guidelines Hinder Accessibility for Blind Users**](https://doi.org/10.1145/3308561.3353797) ğŸ‘¨â€ğŸ“Stacy M. Branham,Antony Rishin Mukkath Roy 2019 ![](https://img.shields.io/badge/pub-2019--10--24-green)![](https://img.shields.io/badge/cite-35-red)

[**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**](https://arxiv.org/abs/2302.135401910.10683) ğŸ‘¨â€ğŸ“Colin Raffel,Noam M. Shazeer,Adam Roberts,Katherine Lee,Sharan Narang,Michael Matena,Yanqi Zhou,Wei Li,Peter J. Liu 2019 ![](https://img.shields.io/badge/pub-2019--10--23-green)![](https://img.shields.io/badge/cite-6286-red)

[**Language Models as Knowledge Bases?**](https://doi.org/10.18653/v1/D19-1250) ğŸ‘¨â€ğŸ“Fabio Petroni,Tim RocktÃ¤schel,Patrick Lewis,A. Bakhtin,Yuxiang Wu,Alexander H. Miller,S. Riedel 2019 ![](https://img.shields.io/badge/pub-2019--09--01-green)![](https://img.shields.io/badge/cite-1023-red)

[**Neural Text Summarization: A Critical Evaluation**](https://doi.org/10.18653/v1/D19-1051) ğŸ‘¨â€ğŸ“Wojciech Kryscinski,N. Keskar,Bryan McCann,Caiming Xiong,R. Socher 2019 ![](https://img.shields.io/badge/pub-2019--08--23-green)![](https://img.shields.io/badge/cite-227-red)

[**Neural Text Generation with Unlikelihood Training**](https://arxiv.org/abs/2302.135401908.04319) ğŸ‘¨â€ğŸ“S. Welleck,Ilia Kulikov,Stephen Roller,Emily Dinan,Kyunghyun Cho,J. Weston 2019 ![](https://img.shields.io/badge/pub-2019--08--12-green)![](https://img.shields.io/badge/cite-296-red)

[**What Does BERT Learn about the Structure of Language?**](https://doi.org/10.18653/v1/P19-1356) ğŸ‘¨â€ğŸ“Ganesh Jawahar,BenoÃ®t Sagot,DjamÃ© Seddah 2019 ![](https://img.shields.io/badge/pub-2019--07--28-green)![](https://img.shields.io/badge/cite-773-red)

[**Lessons from Oz: design guidelines for automotive conversational user interfaces**](https://doi.org/10.1145/3349263.3351314) ğŸ‘¨â€ğŸ“D. Large,G. Burnett,L. Clark 2019 ![](https://img.shields.io/badge/pub-2019--07--25-green)![](https://img.shields.io/badge/cite-11-red)

[**Linguistic Design of In-Vehicle Prompts in Adaptive Dialog Systems: An Analysis of Potential Factors Involved in the Perception of Naturalness**](https://doi.org/10.1145/3320435.3320469) ğŸ‘¨â€ğŸ“D. Stier,Ellen Sigloch 2019 ![](https://img.shields.io/badge/pub-2019--06--07-green)![](https://img.shields.io/badge/cite-7-red)

[**Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model**](https://doi.org/10.18653/v1/P19-1102) ğŸ‘¨â€ğŸ“Alexander R. Fabbri,Irene Li,Tianwei She,Suyi Li,Dragomir R. Radev 2019 ![](https://img.shields.io/badge/pub-2019--06--04-green)![](https://img.shields.io/badge/cite-274-red)

[**Hierarchical Transformers for Multi-Document Summarization**](https://doi.org/10.18653/v1/P19-1500) ğŸ‘¨â€ğŸ“Yang Liu,Mirella Lapata 2019 ![](https://img.shields.io/badge/pub-2019--05--30-green)![](https://img.shields.io/badge/cite-203-red)

[**At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces**](https://doi.org/10.1145/3290605.3300270) ğŸ‘¨â€ğŸ“Michael Braun,Anja Mainz,Ronee Chadowitz,Bastian Pfleging,Florian Alt 2019 ![](https://img.shields.io/badge/pub-2019--05--02-green)![](https://img.shields.io/badge/cite-101-red)

[**The Curious Case of Neural Text Degeneration**](https://arxiv.org/abs/2302.135401904.09751) ğŸ‘¨â€ğŸ“Ari Holtzman,Jan Buys,Maxwell Forbes,Yejin Choi 2019 ![](https://img.shields.io/badge/pub-2019--04--22-green)![](https://img.shields.io/badge/cite-1322-red)

[**Publicly Available Clinical BERT Embeddings**](https://doi.org/10.18653/v1/W19-1909) ğŸ‘¨â€ğŸ“Emily Alsentzer,John R. Murphy,Willie Boag,W. Weng,Di Jin,Tristan Naumann,Matthew B. A. McDermott 2019 ![](https://img.shields.io/badge/pub-2019--04--06-green)![](https://img.shields.io/badge/cite-934-red)

[**SciBERT: A Pretrained Language Model for Scientific Text**](https://doi.org/10.18653/v1/D19-1371) ğŸ‘¨â€ğŸ“Iz Beltagy,Kyle Lo,Arman Cohan 2019 ![](https://img.shields.io/badge/pub-2019--03--01-green)![](https://img.shields.io/badge/cite-1476-red)

[**Parameter-Efficient Transfer Learning for NLP**](https://arxiv.org/abs/2302.135401902.00751) ğŸ‘¨â€ğŸ“N. Houlsby,A. Giurgiu,Stanislaw Jastrzebski,Bruna Morrone,Quentin de Laroussilhe,Andrea Gesmundo,Mona Attariyan,S. Gelly 2019 ![](https://img.shields.io/badge/pub-2019--02--02-green)![](https://img.shields.io/badge/cite-989-red)

[**BioBERT: a pre-trained biomedical language representation model for biomedical text mining**](https://doi.org/10.1093/bioinformatics/btz682) ğŸ‘¨â€ğŸ“Jinhyuk Lee,Wonjin Yoon,Sungdong Kim,Donghyeon Kim,Sunkyu Kim,Chan Ho So,Jaewoo Kang 2019 ![](https://img.shields.io/badge/pub-2019--01--25-green)![](https://img.shields.io/badge/cite-2743-red)

[**On Controllable Sparse Alternatives to Softmax**](https://arxiv.org/abs/2302.135401810.11975) ğŸ‘¨â€ğŸ“Anirban Laha,Saneem A. Chemmengath,Priyanka Agrawal,Mitesh M. Khapra,Karthik Sankaranarayanan,H. G. Ramaswamy 2018 ![](https://img.shields.io/badge/pub-2018--10--29-green)![](https://img.shields.io/badge/cite-36-red)

[**WikiHow: A Large Scale Text Summarization Dataset**](https://arxiv.org/abs/2302.135401810.09305) ğŸ‘¨â€ğŸ“Mahnaz Koupaee,William Yang Wang 2018 ![](https://img.shields.io/badge/pub-2018--10--18-green)![](https://img.shields.io/badge/cite-129-red)

[**Design guidelines for hands-free speech interaction**](https://doi.org/10.1145/3236112.3236149) ğŸ‘¨â€ğŸ“Christine Murad,Cosmin Munteanu,L. Clark,Benjamin R. Cowan 2018 ![](https://img.shields.io/badge/pub-2018--09--03-green)![](https://img.shields.io/badge/cite-62-red)

[**Donâ€™t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization**](https://doi.org/10.18653/v1/D18-1206) ğŸ‘¨â€ğŸ“Shashi Narayan,Shay B. Cohen,Mirella Lapata 2018 ![](https://img.shields.io/badge/pub-2018--08--27-green)![](https://img.shields.io/badge/cite-704-red)

[**Social Boundaries of Appropriate Speech in HCI: A Politeness Perspective**](https://doi.org/10.14236/EWIC/HCI2018.76) ğŸ‘¨â€ğŸ“L. Clark 2018 ![](https://img.shields.io/badge/pub-2018--07--01-green)![](https://img.shields.io/badge/cite-8-red)

[**A Simple Method for Commonsense Reasoning**](https://arxiv.org/abs/2302.135401806.02847) ğŸ‘¨â€ğŸ“Trieu H. Trinh,Quoc V. Le 2018 ![](https://img.shields.io/badge/pub-2018--06--07-green)![](https://img.shields.io/badge/cite-300-red)

[**Hierarchical Neural Story Generation**](https://doi.org/10.18653/v1/P18-1082) ğŸ‘¨â€ğŸ“Angela Fan,M. Lewis,Y. Dauphin 2018 ![](https://img.shields.io/badge/pub-2018--05--01-green)![](https://img.shields.io/badge/cite-839-red)

[**GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding**](https://doi.org/10.18653/v1/W18-5446) ğŸ‘¨â€ğŸ“Alex Wang,Amanpreet Singh,Julian Michael,Felix Hill,Omer Levy,Samuel R. Bowman 2018 ![](https://img.shields.io/badge/pub-2018--04--20-green)![](https://img.shields.io/badge/cite-3499-red)

[**Patterns for How Users Overcome Obstacles in Voice User Interfaces**](https://doi.org/10.1145/3173574.3173580) ğŸ‘¨â€ğŸ“Chelsea M. Myers,Anushay Furqan,Jessica Nebolsky,Karina Caro,Jichen Zhu 2018 ![](https://img.shields.io/badge/pub-2018--04--19-green)![](https://img.shields.io/badge/cite-151-red)

[**A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents**](https://doi.org/10.18653/v1/N18-2097) ğŸ‘¨â€ğŸ“Arman Cohan,Franck Dernoncourt,Doo Soon Kim,Trung Bui,Seokhwan Kim,W. Chang,Nazli Goharian 2018 ![](https://img.shields.io/badge/pub-2018--04--01-green)![](https://img.shields.io/badge/cite-408-red)

[**Steering the conversation: A linguistic exploration of natural language interactions with a digital assistant during simulated driving.**](https://doi.org/10.1016/j.apergo.2017.04.003) ğŸ‘¨â€ğŸ“D. Large,L. Clark,Annie Quandt,G. Burnett,L. Skrypchuk 2017 ![](https://img.shields.io/badge/pub-2017--09--01-green)![](https://img.shields.io/badge/cite-55-red)

[**The E2E Dataset: New Challenges For End-to-End Generation**](https://doi.org/10.18653/v1/W17-5525) ğŸ‘¨â€ğŸ“Jekaterina Novikova,Ondrej Dusek,Verena Rieser 2017 ![](https://img.shields.io/badge/pub-2017--06--28-green)![](https://img.shields.io/badge/cite-290-red)

[**Attention is All you Need**](https://arxiv.org/abs/2302.135401706.03762) ğŸ‘¨â€ğŸ“Ashish Vaswani,Noam M. Shazeer,Niki Parmar,Jakob Uszkoreit,Llion Jones,Aidan N. Gomez,Lukasz Kaiser,Illia Polosukhin 2017 ![](https://img.shields.io/badge/pub-2017--06--12-green)![](https://img.shields.io/badge/cite-51971-red)

[**Get To The Point: Summarization with Pointer-Generator Networks**](https://doi.org/10.18653/v1/P17-1099) ğŸ‘¨â€ğŸ“A. See,Peter J. Liu,Christopher D. Manning 2017 ![](https://img.shields.io/badge/pub-2017--04--01-green)![](https://img.shields.io/badge/cite-2927-red)

[**Categorical Reparameterization with Gumbel-Softmax**](https://arxiv.org/abs/2302.135401611.01144) ğŸ‘¨â€ğŸ“Eric Jang,S. Gu,Ben Poole 2016 ![](https://img.shields.io/badge/pub-2016--11--03-green)![](https://img.shields.io/badge/cite-3360-red)

[**The Oxford handbook of information structure**](https://doi.org/10.1093/OXFORDHB/9780199642670.001.0001) ğŸ‘¨â€ğŸ“C. FÃ©ry,S. Ishihara 2016 ![](https://img.shields.io/badge/pub-2016--07--28-green)![](https://img.shields.io/badge/cite-94-red)

[**Zur Stellung von Modalpartikeln in der gesprochenen Sprache**](https://doi.org/10.37307/j.1868-775x.2016.02.02) ğŸ‘¨â€ğŸ“Daniel Gutzmann,Katharina Turgay 2016 ![](https://img.shields.io/badge/pub-2016--06--10-green)![](https://img.shields.io/badge/cite-2-red)

[**Assessing Cognitive Distraction in the Automobile**](https://doi.org/10.1177/0018720815575149) ğŸ‘¨â€ğŸ“D. Strayer,Jonna Turrill,J. Cooper,James R. Coleman,Nathan Medeiros-Ward,F. Biondi 2015 ![](https://img.shields.io/badge/pub-2015--12--01-green)![](https://img.shields.io/badge/cite-147-red)

[**Teaching Machines to Read and Comprehend**](https://arxiv.org/abs/2302.135401506.03340) ğŸ‘¨â€ğŸ“K. Hermann,TomÃ¡s KociskÃ½,Edward Grefenstette,Lasse Espeholt,Will Kay,Mustafa Suleyman,P. Blunsom 2015 ![](https://img.shields.io/badge/pub-2015--06--10-green)![](https://img.shields.io/badge/cite-2785-red)

[**Empirical Evidence for a Diminished Sense of Agency in Speech Interfaces**](https://doi.org/10.1145/2702123.2702379) ğŸ‘¨â€ğŸ“Hannah Limerick,James W. Moore,D. Coyle 2015 ![](https://img.shields.io/badge/pub-2015--04--18-green)![](https://img.shields.io/badge/cite-48-red)

[**A Model of Coherence Based on Distributed Sentence Representation**](https://doi.org/10.3115/v1/D14-1218) ğŸ‘¨â€ğŸ“Jiwei Li,E. Hovy 2014 ![](https://img.shields.io/badge/pub-2014--10--01-green)![](https://img.shields.io/badge/cite-140-red)

[**Measuring linguistically-induced cognitive load during driving using the ConTRe task**](https://doi.org/10.1145/2516540.2516546) ğŸ‘¨â€ğŸ“V. Demberg,A. Sayeed,Angela Castronovo,Christian A. MÃ¼ller 2013 ![](https://img.shields.io/badge/pub-2013--10--28-green)![](https://img.shields.io/badge/cite-32-red)

[**Modeling Local Coherence: An Entity-Based Approach**](https://doi.org/10.1162/coli.2008.34.1.1) ğŸ‘¨â€ğŸ“R. Barzilay,Mirella Lapata 2008 ![](https://img.shields.io/badge/pub-2008--03--01-green)![](https://img.shields.io/badge/cite-732-red)

[**Safety and Usability of Speech Interfaces for In-Vehicle Tasks while Driving: A Brief Literature Review**](https://api.semanticscholar.org/39bbe946650c6893a816d29b350ed7a3642add5f) ğŸ‘¨â€ğŸ“Adriana Baron,P. Green 2006 ![](https://img.shields.io/badge/pub-2006--02--01-green)![](https://img.shields.io/badge/cite-122-red)

[**Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization**](https://arxiv.org/abs/2302.13540cs/0405039) ğŸ‘¨â€ğŸ“R. Barzilay,Lillian Lee 2004 ![](https://img.shields.io/badge/pub-2004--05--01-green)![](https://img.shields.io/badge/cite-410-red)

[**Grammatik der deutschen Sprache**](https://doi.org/10.1515/9783110872163) ğŸ‘¨â€ğŸ“B. Strecker,Ludger Hoffmann,G. Zifonun 1997 ![](https://img.shields.io/badge/pub-1997--12--31-green)![](https://img.shields.io/badge/cite-455-red)

[**Generated Knowledge Prompting for Commonsense Reasoning**](https://api.semanticscholar.org/12a763cb52f650710900790ca0bc43e5d5b88be6) 2021 

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification**](https://api.semanticscholar.org/6f0aba8102d63938ce0b48ec23ff5ddd8110f2e8) 2021 

[**RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction**](https://api.semanticscholar.org/743dcf234cffd54c4e096a10a284dd81572b16ea) 2022 

[**GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks**](https://api.semanticscholar.org/e147cc46b7f441a68706ca53549d45e9a9843fb6) 2023 

[**Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning**](https://api.semanticscholar.org/096c2791c3dd4b123333e324ce88cd97661ffd3f) 2022 

[**A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT**](https://api.semanticscholar.org/08b85bce712168998004ee80ce4e475390413c74) 2023 

[**Learning to Transfer Prompts for Text Generation**](https://api.semanticscholar.org/42117d01d498eb9f8c21b788c3565bc6855d620b) 2022 

[**Multitask Prompted Training Enables Zero-Shot Task Generalization**](https://api.semanticscholar.org/17dd3555fd1ccf1141cf984347fa1b3fd6b009ca) 2021 

[**Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models**](https://api.semanticscholar.org/fcfc9648561a221750b8085790ad9ba1bebb1800) 2021 

[**Unified Structure Generation for Universal Information Extraction**](https://api.semanticscholar.org/5382c28b9f2dd30f15c836bea92382091b1d886f) 2022 

[**Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation**](https://api.semanticscholar.org/eb53979c96eacec543620af2b899a3772eb6d32f) 2023 

[**Successive Prompting for Decomposing Complex Questions**](https://api.semanticscholar.org/c90151f00b1ac4abf1cc353849b453aa21cc2df3) 2022 

[**SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based Sentiment Analysis**](https://api.semanticscholar.org/2145582245) ğŸ‘¨â€ğŸ“ 2021 

[**Scientific Language Models for Biomedical Knowledge Base Completion: An Empirical Study**](https://api.semanticscholar.org/5bebacad8c1ba330314c87405a86d321f1cfda4b) 2021 

[**Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries**](https://api.semanticscholar.org/51ae2c451a1a05293334a509b71c9c9e0377d35c) 2020 

[**PromptChainer: Chaining Large Language Model Prompts through Visual Programming**](https://api.semanticscholar.org/0f733817e82026f7c29909a51cb4df7d2685f0e7) 2022 

[**Toxicity Detection with Generative Prompt-based Inference**](https://api.semanticscholar.org/2afb07359e9c67499e1f373ac6f1520d3ea9c46a) 2022 

[**Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales**](https://api.semanticscholar.org/03eb8b41de5b201c0535fc3b8a91033abe645325) 2023 

[**Ignore Previous Prompt: Attack Techniques For Language Models**](https://api.semanticscholar.org/9716a2876d08fce9d8e5c5ba4d7b1a9af44806d6) 2022 

[**COPEN: Probing Conceptual Knowledge in Pre-trained Language Models**](https://api.semanticscholar.org/bcec7d17e68aceb91d020dd796ece075694f77c6) 2022 

[**Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding**](https://api.semanticscholar.org/17dcfef70619c0423e0527f0c9d90f4858125f5f) 2022 

[**Representing Text for Joint Embedding of Text and Knowledge Bases**](https://doi.org/10.18653/v1/D15-1174) ğŸ‘¨â€ğŸ“Kristina Toutanova,Danqi Chen,P. Pantel,Hoifung Poon,Pallavi Choudhury,Michael Gamon 2015 ![](https://img.shields.io/badge/cite-550-red)

[**How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks**](https://api.semanticscholar.org/1f040c3a8d49f8e54169a0e07013692c7d58de4b) 2023 

[**Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction**](https://api.semanticscholar.org/85061c524fdd5ec75f06a3329352621bb8d05f43) 2021 

[**SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks**](https://api.semanticscholar.org/b50c27607d7a858297232310bbec9819ade875a8) 2023 

[**LabelPrompt: Effective Prompt-based Learning for Relation Classification**](https://api.semanticscholar.org/b2d783c0ed3bd2c631b99b1487399016a5f00d5f) 2023 

[**Time-Aware Language Models as Temporal Knowledge Bases**](https://api.semanticscholar.org/ac8d33e4c0a45e227a47353f3f26fbb231482dc1) 2021 

[**Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften**](https://doi.org/10.1007/978-3-662-64762-2) ğŸ‘¨â€ğŸ“N. DÃ¶ring 2016 ![](https://img.shields.io/badge/cite-864-red)

[**The Influence of Syntax on the Perception of In-Vehicle Prompts and Driving Performance**](https://doi.org/10.1007/978-981-15-8395-7_26) ğŸ‘¨â€ğŸ“D. Stier,U. Heid,Patricia Kittel,Maria Schmidt,W. Minker 2020 ![](https://img.shields.io/badge/cite-4-red)

[**Menschliche Kommunikation : Formen, StÃ¶rungen, Parodoxien**](https://api.semanticscholar.org/8871dab83c31fce0b01c3574bcb8687cb5d0b0b1) ğŸ‘¨â€ğŸ“P. Watzlawick,Janet Holmick Beavin,Don D. Jackson 1996 ![](https://img.shields.io/badge/cite-387-red)

[**DialogSum: A Real-Life Scenario Dialogue Summarization Dataset**](https://doi.org/10.18653/v1/2021.findings-acl.449) ğŸ‘¨â€ğŸ“Yulong Chen,Yang Liu,Liang Chen,Yue Zhang 2021 ![](https://img.shields.io/badge/cite-58-red)

[**Soziolinguistik**](https://doi.org/10.1007/978-3-476-05861-4) ğŸ‘¨â€ğŸ“JÃ¼rgen SpitzmÃ¼ller 2022 ![](https://img.shields.io/badge/cite-1-red)

[**Prefix-Tuning: Optimizing Continuous Prompts for Generation**](https://doi.org/10.18653/v1/2021.acl-long.353) ğŸ‘¨â€ğŸ“Xiang Lisa Li,Percy Liang 2021 ![](https://img.shields.io/badge/cite-824-red)

[**Discourse-Aware Unsupervised Summarization for Long Scientific Documents**](https://doi.org/10.18653/v1/2021.eacl-main.93) ğŸ‘¨â€ğŸ“Yue Dong,Andrei Mircea,J. C. Cheung 2021 ![](https://img.shields.io/badge/cite-20-red)

[**Properties of spoken and written language.**](https://api.semanticscholar.org/f29972840d1437890af055831d654cbff4bd4058) ğŸ‘¨â€ğŸ“W. Chafe,J. Danielewicz 1987 ![](https://img.shields.io/badge/cite-428-red)

[**ChemProt-3.0: a global chemical biology diseases mapping**](https://doi.org/10.1093/database/bav123) ğŸ‘¨â€ğŸ“Jens Vindahl 2016 ![](https://img.shields.io/badge/cite-87-red)

[**One Voice Fits All? Social Implications and Research Challenges of Designing Voices for Smart Devices**](https://api.semanticscholar.org/624f21e273c74335044806e0e1669ce5f26587c4) ğŸ‘¨â€ğŸ“Julia Cambre,Chinmay Kulkarni 2019 ![](https://img.shields.io/badge/cite-35-red)

[**Promptagator: Few-shot Dense Retrieval From 8 Examples**](https://api.semanticscholar.org/e86009d9f9b1cdf083a48d087552bc4153784451) 2022 

[**EinfÃ¼hrung in die Grammatik der deutschen Gegenwartssprache**](https://doi.org/10.1515/9783110918861) ğŸ‘¨â€ğŸ“K. Sommerfeldt,G. Starke,W. Hackel 1998 ![](https://img.shields.io/badge/cite-26-red)

[**From discourse structures to text summaries**](https://api.semanticscholar.org/1daf375141571501ca8c30b62d7c14269d566762) ğŸ‘¨â€ğŸ“D. Marcu 1997 ![](https://img.shields.io/badge/cite-330-red)

[**PRIMER: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization**](https://api.semanticscholar.org/2a7023e7d1dbd6ea0d98efd09a1f18d8599fe78f) ğŸ‘¨â€ğŸ“Wen Xiao,Iz Beltagy,G. Carenini,Arman Cohan 2021 ![](https://img.shields.io/badge/cite-19-red)

[**AdaPrompt: Adaptive Prompt-based Finetuning for Relation Extraction**](https://api.semanticscholar.org/2404aecd866cfa15fee6ada095667980a63c4172) ğŸ‘¨â€ğŸ“Xiang Chen,Xin Xie,Ningyu Zhang,Jiahuan Yan,Shumin Deng,Chuanqi Tan,Fei Huang,Luo Si,Huajun Chen 2021 ![](https://img.shields.io/badge/cite-31-red)

[**Prompt Combines Paraphrase: Enhancing Biomedical â€œPre-training, Prompt and Predictingâ€ Models by Explaining Rare Biomedical Concepts**](https://api.semanticscholar.org/4e305fe2ef347caddd8936bc0a8c462e33f6e2da) ğŸ‘¨â€ğŸ“Hao Wang 2021 ![](https://img.shields.io/badge/cite-1-red)

[**Zur Abfolge nominaler Satzglieder im Deutschen**](https://api.semanticscholar.org/d93a04ab220196e6bbe3c8ff39b40ff6a8b7ca5a) ğŸ‘¨â€ğŸ“J. Lenerz 1977 ![](https://img.shields.io/badge/cite-367-red)

[**Unified Knowledge Prompt Pre-training for Customer Service Dialogues**](https://api.semanticscholar.org/d0bdabbecba66084af3e4135e656f5277097fb7c) 2022 

[**Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints**](https://api.semanticscholar.org/3f83582c08a62e5bd02398fafc93f7eaf1e4b84e) 2023 

[**Self-Instruct: Aligning Language Model with Self Generated Instructions**](https://api.semanticscholar.org/bbe93c90b7b87939cd064c805858feca61a3234d) 2022 

[**One Embedder, Any Task: Instruction-Finetuned Text Embeddings**](https://api.semanticscholar.org/9f61d366b9d00becb25f7823997c626c6b1d5c16) 2022 

[**Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis**](https://api.semanticscholar.org/cd6fba0c9c34a2c9ff1ed17d2f9f50d8a3399669) 2023 

[**Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition**](https://api.semanticscholar.org/5aa4e5b90827f1c16bed100982e2a1871925d445) 2023 

[**QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition**](https://api.semanticscholar.org/b159dffadb69940e14693e812bdaa32e3957717f) 2022 

[**Materialized Knowledge Bases from Commonsense Transformers**](https://api.semanticscholar.org/66a660bc912fd212db40ded34d34f28e4860a676) 2021 

[**Good Visual Guidance Makes A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction**](https://api.semanticscholar.org/81ad863f8bc438455cb973ae20778a949a54d2b7) 2022 

[**Investigating Prompt Engineering in Diffusion Models**](https://api.semanticscholar.org/d2cfabde7383704e876373e9da9891714b0bd62b) 2022 

[**Language Model Crossover: Variation through Few-Shot Prompting**](https://api.semanticscholar.org/49fede098a0d2a48e8100b30189224fc6f5eb25b) 2023 

[**How Much Knowledge Can You Pack into the Parameters of a Language Model?**](https://api.semanticscholar.org/80376bdec5f534be78ba82821f540590ebce5559) 2020 

[**LightNER: A Lightweight Tuning Paradigm for Low-resource NER via Pluggable Prompting**](https://api.semanticscholar.org/3c12482e523b283cb1a3433b962e9ffc2ed5c65b) 2021 

[**How Context Affects Language Models' Factual Predictions**](https://api.semanticscholar.org/c44120f765fc43994c5cfb4e12e4f62999efeae6) 2020 

[**Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data**](https://api.semanticscholar.org/08433ddb8c799c00008bc71a6252ee473585f7e3) 2022 

[**Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models**](https://api.semanticscholar.org/69619a2a47faee7a29ec596db13172e2a42ff921) 2023 

[**Language Models are Unsupervised Multitask Learners**](https://api.semanticscholar.org/9405cc0d6169988371b2755e573cc28650d14dfe) ğŸ‘¨â€ğŸ“Alec Radford,Jeff Wu,Rewon Child,D. Luan,Dario Amodei,Ilya Sutskever 2019 ![](https://img.shields.io/badge/cite-8849-red)

[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://doi.org/10.18653/v1/N19-1423) ğŸ‘¨â€ğŸ“Jacob Devlin,Ming-Wei Chang,Kenton Lee,Kristina Toutanova 2019 ![](https://img.shields.io/badge/cite-47696-red)

[**of the Association for Computational Linguistics:**](https://doi.org/10.1016/b0-08-044854-2/05234-2) ğŸ‘¨â€ğŸ“Vladimir Meza Ruiz,Rashmi Gangadharaiah,Maria Leonor Pacheco,Danqi Chen,Ryan Cotterell 2001 ![](https://img.shields.io/badge/cite-4067-red)

[**Probing Simile Knowledge from Pre-trained Language Models**](https://api.semanticscholar.org/37e664778284314b05fd26177ce14f631ac1550e) 2022 

[**Progressive Prompts: Continual Learning for Language Models**](https://api.semanticscholar.org/86478f285356b5c8d27423e6b939634d9e010fba) 2023 

[**More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models**](https://api.semanticscholar.org/8fdd34153d1035d09dd4a6efa9cb0c91d23d0045) 2023 

[**How Does In-Context Learning Help Prompt Tuning?**](https://api.semanticscholar.org/8c75f0f2393ac08f1749e6177f31a0f8842dae0f) 2023 

[**DocPrompting: Generating Code by Retrieving the Docs**](https://api.semanticscholar.org/0a39442979d6e678dd36bb443ad529c14e86a86e) 2022 

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://api.semanticscholar.org/780a7f5e8ba9b4b451e3dfee1bcfb0f68aba5050) 2023 

[**PLACES: Prompting Language Models for Social Conversation Synthesis**](https://api.semanticscholar.org/5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691) 2023 

[**EvoPrompting: Language Models for Code-Level Neural Architecture Search**](https://api.semanticscholar.org/35d083ff4dc2805c477d0aedc8158fc7a1aefeda) 2023 

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classiï¬cation Rolling Review submission**](https://api.semanticscholar.org/80366efe644f9fa5d1e89775eb7cb135ca46582f) 2021 

[**Legal Prompt Engineering for Multilingual Legal Judgement Prediction**](https://api.semanticscholar.org/ec27f85979899a4193a8ec3b932ddb677c59be62) 2022 

[**Visual Prompt Tuning**](https://api.semanticscholar.org/adb272fbdea3631059cf88ab764bb6c2ce29f965) 2022 

[**Prompting for Multimodal Hateful Meme Classification**](https://api.semanticscholar.org/ae766548699f27e669932de14e1c0f47b2828536) 2023 

[**Batch Prompting: Efficient Inference with Large Language Model APIs**](https://api.semanticscholar.org/e659fa1e79a2a151be331125c14339988542aac3) 2023 



## Prompt for Knowledge Graph

[**UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning**](https://doi.org/10.18653/v1/2022.acl-long.433) ğŸ‘¨â€ğŸ“Yuning Mao,Lambert Mathias,Rui Hou,Amjad Almahairi,Hao Ma,Jiawei Han,Wen-tau Yih,Madian Khabsa 2021 ![](https://img.shields.io/badge/pub-2021--10--14-green)![](https://img.shields.io/badge/cite-31-red)

[**HETFORMER: Heterogeneous Transformer with Sparse Attention for Long-Text Extractive Summarization**](https://doi.org/10.18653/v1/2021.emnlp-main.13) ğŸ‘¨â€ğŸ“Ye Liu,Jianguo Zhang,Yao Wan,Congying Xia,Lifang He,Philip S. Yu 2021 ![](https://img.shields.io/badge/pub-2021--10--12-green)![](https://img.shields.io/badge/cite-11-red)

[**Can Language Models be Biomedical Knowledge Bases?**](https://doi.org/10.18653/v1/2021.emnlp-main.388) ğŸ‘¨â€ğŸ“Mujeen Sung,Jinhyuk Lee,Sean S. Yi,Minji Jeon,Sungdong Kim,Jaewoo Kang 2021 ![](https://img.shields.io/badge/pub-2021--09--15-green)![](https://img.shields.io/badge/cite-26-red)

[**The SelectGen Challenge: Finding the Best Training Samples for Few-Shot Neural Text Generation**](https://arxiv.org/abs/2302.135402108.06614) ğŸ‘¨â€ğŸ“Ernie Chang,Xiaoyu Shen,Alex Marin,V. Demberg 2021 ![](https://img.shields.io/badge/pub-2021--08--14-green)![](https://img.shields.io/badge/cite-4-red)

[**Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**](https://doi.org/10.1145/3560815) ğŸ‘¨â€ğŸ“Pengfei Liu,Weizhe Yuan,Jinlan Fu,Zhengbao Jiang,Hiroaki Hayashi,Graham Neubig 2021 ![](https://img.shields.io/badge/pub-2021--07--28-green)![](https://img.shields.io/badge/cite-429-red)

[**On Training Instance Selection for Few-Shot Neural Text Generation**](https://doi.org/10.18653/v1/2021.acl-short.2) ğŸ‘¨â€ğŸ“Ernie Chang,Xiaoyu Shen,Hui-Syuan Yeh,V. Demberg 2021 ![](https://img.shields.io/badge/pub-2021--07--07-green)![](https://img.shields.io/badge/cite-15-red)

[**Template-Based Named Entity Recognition Using BART**](https://doi.org/10.18653/v1/2021.findings-acl.161) ğŸ‘¨â€ğŸ“Leyang Cui,Yu Wu,Jian Liu,Sen Yang,Yue Zhang 2021 ![](https://img.shields.io/badge/pub-2021--06--03-green)![](https://img.shields.io/badge/cite-100-red)

[**Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.381) ğŸ‘¨â€ğŸ“Yichen Jiang,Asli Celikyilmaz,P. Smolensky,Paul Soulos,Sudha Rao,H. Palangi,Roland Fernandez,Caitlin Smith,Mohit Bansal,Jianfeng Gao 2021 ![](https://img.shields.io/badge/pub-2021--06--01-green)![](https://img.shields.io/badge/cite-6-red)

[**SciFive: a text-to-text transformer model for biomedical literature**](https://arxiv.org/abs/2302.135402106.03598) ğŸ‘¨â€ğŸ“Long Phan,J. Anibal,Hieu Tran,Shaurya Chanana,Erol Bahadroglu,Alec Peltekian,G. Altan-Bonnet 2021 ![](https://img.shields.io/badge/pub-2021--05--28-green)![](https://img.shields.io/badge/cite-45-red)

[**PTR: Prompt Tuning with Rules for Text Classification**](https://doi.org/10.1016/j.aiopen.2022.11.003) ğŸ‘¨â€ğŸ“Xu Han,Weilin Zhao,Ning Ding,Zhiyuan Liu,Maosong Sun 2021 ![](https://img.shields.io/badge/pub-2021--05--24-green)![](https://img.shields.io/badge/cite-169-red)

[**Not All Memories are Created Equal: Learning to Forget by Expiring**](https://arxiv.org/abs/2302.135402105.06548) ğŸ‘¨â€ğŸ“Sainbayar Sukhbaatar,Da Ju,Spencer Poff,Stephen Roller,Arthur D. Szlam,J. Weston,Angela Fan 2021 ![](https://img.shields.io/badge/pub-2021--05--13-green)![](https://img.shields.io/badge/cite-16-red)

[**Long-Span Summarization via Local Attention and Content Selection**](https://doi.org/10.18653/v1/2021.acl-long.470) ğŸ‘¨â€ğŸ“Potsawee Manakul,M. Gales 2021 ![](https://img.shields.io/badge/pub-2021--05--08-green)![](https://img.shields.io/badge/cite-20-red)

[**The Power of Scale for Parameter-Efficient Prompt Tuning**](https://doi.org/10.18653/v1/2021.emnlp-main.243) ğŸ‘¨â€ğŸ“Brian Lester,Rami Al-Rfou,Noah Constant 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-675-red)

[**KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction**](https://doi.org/10.1145/3485447.3511998) ğŸ‘¨â€ğŸ“Xiang Chen,Ningyu Zhang,Ningyu Zhang,Xin Xie,Shumin Deng,Yunzhi Yao,Chuanqi Tan,Fei Huang,Luo Si,Huajun Chen 2021 ![](https://img.shields.io/badge/pub-2021--04--15-green)![](https://img.shields.io/badge/cite-84-red)

[**Data Augmentation for Abstractive Query-Focused Multi-Document Summarization**](https://doi.org/10.1609/aaai.v35i15.17611) ğŸ‘¨â€ğŸ“Ramakanth Pasunuru,Asli Celikyilmaz,Michel Galley,Chenyan Xiong,Yizhe Zhang,Mohit Bansal,Jianfeng Gao 2021 ![](https://img.shields.io/badge/pub-2021--03--02-green)![](https://img.shields.io/badge/cite-26-red)

[**SparseBERT: Rethinking the Importance Analysis in Self-attention**](https://arxiv.org/abs/2302.135402102.12871) ğŸ‘¨â€ğŸ“Han Shi,Jiahui Gao,Xiaozhe Ren,Hang Xu,Xiaodan Liang,Zhenguo Li,J. Kwok 2021 ![](https://img.shields.io/badge/pub-2021--02--25-green)![](https://img.shields.io/badge/cite-27-red)

[**Calibrate Before Use: Improving Few-Shot Performance of Language Models**](https://arxiv.org/abs/2302.135402102.09690) ğŸ‘¨â€ğŸ“Tony Zhao,Eric Wallace,Shi Feng,D. Klein,Sameer Singh 2021 ![](https://img.shields.io/badge/pub-2021--02--19-green)![](https://img.shields.io/badge/cite-277-red)

[**Does the Order of Training Samples Matter? Improving Neural Data-to-Text Generation with Curriculum Learning**](https://doi.org/10.18653/v1/2021.eacl-main.61) ğŸ‘¨â€ğŸ“Ernie Chang,Hui-Syuan Yeh,V. Demberg 2021 ![](https://img.shields.io/badge/pub-2021--02--06-green)![](https://img.shields.io/badge/cite-17-red)

[**Making Pre-trained Language Models Better Few-shot Learners**](https://doi.org/10.18653/v1/2021.acl-long.295) ğŸ‘¨â€ğŸ“Tianyu Gao,Adam Fisch,Danqi Chen 2021 ![](https://img.shields.io/badge/pub-2021--01--01-green)![](https://img.shields.io/badge/cite-635-red)

[**Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals**](https://doi.org/10.1162/tacl_a_00359) ğŸ‘¨â€ğŸ“Yanai Elazar,Shauli Ravfogel,Alon Jacovi,Yoav Goldberg 2020 ![](https://img.shields.io/badge/pub-2020--12--07-green)![](https://img.shields.io/badge/cite-105-red)

[**How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering**](https://doi.org/10.1162/tacl_a_00407) ğŸ‘¨â€ğŸ“Zhengbao Jiang,J. Araki,Haibo Ding,Graham Neubig 2020 ![](https://img.shields.io/badge/pub-2020--12--02-green)![](https://img.shields.io/badge/cite-66-red)

[**Long Range Arena: A Benchmark for Efficient Transformers**](https://arxiv.org/abs/2302.135402011.04006) ğŸ‘¨â€ğŸ“Yi Tay,M. Dehghani,Samira Abnar,Yikang Shen,Dara Bahri,Philip Pham,J. Rao,Liu Yang,Sebastian Ruder,Donald Metzler 2020 ![](https://img.shields.io/badge/pub-2020--11--08-green)![](https://img.shields.io/badge/cite-263-red)

[**Automatically Identifying Words That Can Serve as Labels for Few-Shot Text Classification**](https://doi.org/10.5282/UBM/EPUB.74034) ğŸ‘¨â€ğŸ“Timo Schick,Helmut Schmid,Hinrich SchÃ¼tze 2020 ![](https://img.shields.io/badge/pub-2020--10--26-green)![](https://img.shields.io/badge/cite-83-red)

[**Self-Alignment Pretraining for Biomedical Entity Representations**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.334) ğŸ‘¨â€ğŸ“Fangyu Liu,Ehsan Shareghi,Zaiqiao Meng,Marco Basaldella,N. Collier 2020 ![](https://img.shields.io/badge/pub-2020--10--22-green)![](https://img.shields.io/badge/cite-101-red)

[**UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.139) ğŸ‘¨â€ğŸ“George Michalopoulos,Yuanxin Wang,H. Kaka,Helen H Chen,Alexander Wong 2020 ![](https://img.shields.io/badge/pub-2020--10--20-green)![](https://img.shields.io/badge/cite-50-red)

[**CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters**](https://doi.org/10.18653/V1/2020.COLING-MAIN.609) ğŸ‘¨â€ğŸ“Hicham El Boukkouri,Olivier Ferret,T. Lavergne,Hiroshi Noji,Pierre Zweigenbaum,Junichi Tsujii 2020 ![](https://img.shields.io/badge/pub-2020--10--20-green)![](https://img.shields.io/badge/cite-84-red)

[**X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models**](https://doi.org/10.18653/v1/2020.emnlp-main.479) ğŸ‘¨â€ğŸ“Zhengbao Jiang,Antonios Anastasopoulos,J. Araki,Haibo Ding,Graham Neubig 2020 ![](https://img.shields.io/badge/pub-2020--10--13-green)![](https://img.shields.io/badge/cite-58-red)

[**Pretrained Transformers for Text Ranking: BERT and Beyond**](https://doi.org/10.1145/3437963.3441667) ğŸ‘¨â€ğŸ“Jimmy J. Lin,Rodrigo Nogueira,Andrew Yates 2020 ![](https://img.shields.io/badge/pub-2020--10--13-green)![](https://img.shields.io/badge/cite-285-red)

[**Bio-Megatron: Larger Biomedical Domain Language Model**](https://doi.org/10.18653/v1/2020.emnlp-main.379) ğŸ‘¨â€ğŸ“Hoo-Chang Shin,Yang Zhang,Evelina Bakhturina,Raul Puri,M. Patwary,M. Shoeybi,Raghav Mani 2020 ![](https://img.shields.io/badge/pub-2020--10--12-green)![](https://img.shields.io/badge/cite-43-red)

[**Adapting In-Vehicle Voice Output:A User- and Situation-Adaptive Approach**](https://doi.org/10.1145/3409251.3411711) ğŸ‘¨â€ğŸ“D. Stier,U. Heid,W. Minker 2020 ![](https://img.shields.io/badge/pub-2020--09--21-green)![](https://img.shields.io/badge/cite-3-red)

[**Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing**](https://doi.org/10.1145/3458754) ğŸ‘¨â€ğŸ“Yu Gu,Robert Tinn,Hao Cheng,Michael R. Lucas,Naoto Usuyama,Xiaodong Liu,Tristan Naumann,Jianfeng Gao,Hoifung Poon 2020 ![](https://img.shields.io/badge/pub-2020--07--31-green)![](https://img.shields.io/badge/cite-468-red)

[**Big Bird: Transformers for Longer Sequences**](https://arxiv.org/abs/2302.135402007.14062) ğŸ‘¨â€ğŸ“M. Zaheer,Guru Guruganesh,Kumar Avinava Dubey,J. Ainslie,Chris Alberti,Santiago OntaÃ±Ã³n,Philip Pham,Anirudh Ravula,Qifan Wang,Li Yang,Amr Ahmed 2020 ![](https://img.shields.io/badge/pub-2020--07--28-green)![](https://img.shields.io/badge/cite-843-red)

[**DART: Open-Domain Structured Data Record to Text Generation**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.37) ğŸ‘¨â€ğŸ“Dragomir R. Radev,Rui Zhang,Amrit Rau,Abhinand Sivaprasad,Chia-Hsuan Hsieh,Nazneen Rajani,Xiangru Tang,Aadit Vyas,Neha Verma,P. Krishna,Yangxiaokang Liu,Nadia Irwanto,Jessica Pan,Faiaz Rahman,A. Zaidi,Murori Mutuma,Yasin Tarabar,Ankit Gupta,Tao Yu,Y. Tan,Xi Victoria Lin,Caiming Xiong,R. Socher 2020 ![](https://img.shields.io/badge/pub-2020--07--06-green)![](https://img.shields.io/badge/cite-91-red)

[**Understanding Attention for Text Classification**](https://doi.org/10.18653/v1/2020.acl-main.312) ğŸ‘¨â€ğŸ“Xiaobing Sun,Wei Lu 2020 ![](https://img.shields.io/badge/pub-2020--07--01-green)![](https://img.shields.io/badge/cite-32-red)

[**Linformer: Self-Attention with Linear Complexity**](https://arxiv.org/abs/2302.135402006.04768) ğŸ‘¨â€ğŸ“Sinong Wang,Belinda Z. Li,Madian Khabsa,Han Fang,Hao Ma 2020 ![](https://img.shields.io/badge/pub-2020--06--08-green)![](https://img.shields.io/badge/cite-641-red)

[**Language Models are Few-Shot Learners**](https://arxiv.org/abs/2302.135402005.14165) ğŸ‘¨â€ğŸ“Tom B. Brown,Benjamin Mann,Nick Ryder,Melanie Subbiah,J. Kaplan,Prafulla Dhariwal,Arvind Neelakantan,Pranav Shyam,Girish Sastry,Amanda Askell,Sandhini Agarwal,Ariel Herbert-Voss,Gretchen Krueger,T. Henighan,Rewon Child,A. Ramesh,Daniel M. Ziegler,Jeff Wu,Clemens Winter,Christopher Hesse,Mark Chen,Eric Sigler,Mateusz Litwin,Scott Gray,Benjamin Chess,Jack Clark,Christopher Berner,Sam McCandlish,Alec Radford,Ilya Sutskever,Dario Amodei 2020 ![](https://img.shields.io/badge/pub-2020--05--28-green)![](https://img.shields.io/badge/cite-8351-red)

[**UnifiedQA: Crossing Format Boundaries With a Single QA System**](https://doi.org/10.18653/v1/2020.findings-emnlp.171) ğŸ‘¨â€ğŸ“Daniel Khashabi,Sewon Min,Tushar Khot,Ashish Sabharwal,Oyvind Tafjord,Peter Clark,Hannaneh Hajishirzi 2020 ![](https://img.shields.io/badge/pub-2020--05--02-green)![](https://img.shields.io/badge/cite-357-red)

[**Donâ€™t Stop Pretraining: Adapt Language Models to Domains and Tasks**](https://doi.org/10.18653/v1/2020.acl-main.740) ğŸ‘¨â€ğŸ“Suchin Gururangan,Ana MarasoviÄ‡,Swabha Swayamdipta,Kyle Lo,Iz Beltagy,Doug Downey,Noah A. Smith 2020 ![](https://img.shields.io/badge/pub-2020--04--23-green)![](https://img.shields.io/badge/cite-1128-red)

[**Sparse Text Generation**](https://doi.org/10.18653/v1/2020.emnlp-main.348) ğŸ‘¨â€ğŸ“Pedro Henrique Martins,Zita Marinho,AndrÃ© F. T. Martins 2020 ![](https://img.shields.io/badge/pub-2020--04--06-green)![](https://img.shields.io/badge/cite-25-red)

[**Efficient Content-Based Sparse Attention with Routing Transformers**](https://doi.org/10.1162/tacl_a_00353) ğŸ‘¨â€ğŸ“Aurko Roy,M. Saffar,Ashish Vaswani,David Grangier 2020 ![](https://img.shields.io/badge/pub-2020--03--12-green)![](https://img.shields.io/badge/cite-281-red)

[**Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference**](https://doi.org/10.18653/v1/2021.eacl-main.20) ğŸ‘¨â€ğŸ“Timo Schick,Hinrich SchÃ¼tze 2020 ![](https://img.shields.io/badge/pub-2020--01--21-green)![](https://img.shields.io/badge/cite-579-red)

[**How Can We Know What Language Models Know?**](https://doi.org/10.1162/tacl_a_00324) ğŸ‘¨â€ğŸ“Zhengbao Jiang,Frank F. Xu,J. Araki,Graham Neubig 2019 ![](https://img.shields.io/badge/pub-2019--11--28-green)![](https://img.shields.io/badge/cite-419-red)

[**SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization**](https://doi.org/10.18653/v1/D19-5409) ğŸ‘¨â€ğŸ“Bogdan Gliwa,Iwona Mochol,M. Biesek,A. Wawer 2019 ![](https://img.shields.io/badge/pub-2019--11--27-green)![](https://img.shields.io/badge/cite-217-red)

[**Semantic Noise Matters for Neural Natural Language Generation**](https://doi.org/10.18653/v1/W19-8652) ğŸ‘¨â€ğŸ“Ondrej Dusek,David M. Howcroft,Verena Rieser 2019 ![](https://img.shields.io/badge/pub-2019--11--01-green)![](https://img.shields.io/badge/cite-74-red)

[**Fine-tune BERT with Sparse Self-Attention Mechanism**](https://doi.org/10.18653/v1/D19-1361) ğŸ‘¨â€ğŸ“Baiyun Cui,Yingming Li,Ming Chen,Zhongfei Zhang 2019 ![](https://img.shields.io/badge/pub-2019--11--01-green)![](https://img.shields.io/badge/cite-41-red)

[**BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension**](https://doi.org/10.18653/v1/2020.acl-main.703) ğŸ‘¨â€ğŸ“M. Lewis,Yinhan Liu,Naman Goyal,Marjan Ghazvininejad,Abdelrahman Mohamed,Omer Levy,Veselin Stoyanov,Luke Zettlemoyer 2019 ![](https://img.shields.io/badge/pub-2019--10--29-green)![](https://img.shields.io/badge/cite-4052-red)

[**Reading Between the Guidelines: How Commercial Voice Assistant Guidelines Hinder Accessibility for Blind Users**](https://doi.org/10.1145/3308561.3353797) ğŸ‘¨â€ğŸ“Stacy M. Branham,Antony Rishin Mukkath Roy 2019 ![](https://img.shields.io/badge/pub-2019--10--24-green)![](https://img.shields.io/badge/cite-35-red)

[**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**](https://arxiv.org/abs/2302.135401910.10683) ğŸ‘¨â€ğŸ“Colin Raffel,Noam M. Shazeer,Adam Roberts,Katherine Lee,Sharan Narang,Michael Matena,Yanqi Zhou,Wei Li,Peter J. Liu 2019 ![](https://img.shields.io/badge/pub-2019--10--23-green)![](https://img.shields.io/badge/cite-6286-red)

[**Language Models as Knowledge Bases?**](https://doi.org/10.18653/v1/D19-1250) ğŸ‘¨â€ğŸ“Fabio Petroni,Tim RocktÃ¤schel,Patrick Lewis,A. Bakhtin,Yuxiang Wu,Alexander H. Miller,S. Riedel 2019 ![](https://img.shields.io/badge/pub-2019--09--01-green)![](https://img.shields.io/badge/cite-1023-red)

[**Neural Text Summarization: A Critical Evaluation**](https://doi.org/10.18653/v1/D19-1051) ğŸ‘¨â€ğŸ“Wojciech Kryscinski,N. Keskar,Bryan McCann,Caiming Xiong,R. Socher 2019 ![](https://img.shields.io/badge/pub-2019--08--23-green)![](https://img.shields.io/badge/cite-227-red)

[**Neural Text Generation with Unlikelihood Training**](https://arxiv.org/abs/2302.135401908.04319) ğŸ‘¨â€ğŸ“S. Welleck,Ilia Kulikov,Stephen Roller,Emily Dinan,Kyunghyun Cho,J. Weston 2019 ![](https://img.shields.io/badge/pub-2019--08--12-green)![](https://img.shields.io/badge/cite-296-red)

[**What Does BERT Learn about the Structure of Language?**](https://doi.org/10.18653/v1/P19-1356) ğŸ‘¨â€ğŸ“Ganesh Jawahar,BenoÃ®t Sagot,DjamÃ© Seddah 2019 ![](https://img.shields.io/badge/pub-2019--07--28-green)![](https://img.shields.io/badge/cite-773-red)

[**Lessons from Oz: design guidelines for automotive conversational user interfaces**](https://doi.org/10.1145/3349263.3351314) ğŸ‘¨â€ğŸ“D. Large,G. Burnett,L. Clark 2019 ![](https://img.shields.io/badge/pub-2019--07--25-green)![](https://img.shields.io/badge/cite-11-red)

[**Linguistic Design of In-Vehicle Prompts in Adaptive Dialog Systems: An Analysis of Potential Factors Involved in the Perception of Naturalness**](https://doi.org/10.1145/3320435.3320469) ğŸ‘¨â€ğŸ“D. Stier,Ellen Sigloch 2019 ![](https://img.shields.io/badge/pub-2019--06--07-green)![](https://img.shields.io/badge/cite-7-red)

[**Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model**](https://doi.org/10.18653/v1/P19-1102) ğŸ‘¨â€ğŸ“Alexander R. Fabbri,Irene Li,Tianwei She,Suyi Li,Dragomir R. Radev 2019 ![](https://img.shields.io/badge/pub-2019--06--04-green)![](https://img.shields.io/badge/cite-274-red)

[**Hierarchical Transformers for Multi-Document Summarization**](https://doi.org/10.18653/v1/P19-1500) ğŸ‘¨â€ğŸ“Yang Liu,Mirella Lapata 2019 ![](https://img.shields.io/badge/pub-2019--05--30-green)![](https://img.shields.io/badge/cite-203-red)

[**At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces**](https://doi.org/10.1145/3290605.3300270) ğŸ‘¨â€ğŸ“Michael Braun,Anja Mainz,Ronee Chadowitz,Bastian Pfleging,Florian Alt 2019 ![](https://img.shields.io/badge/pub-2019--05--02-green)![](https://img.shields.io/badge/cite-101-red)

[**The Curious Case of Neural Text Degeneration**](https://arxiv.org/abs/2302.135401904.09751) ğŸ‘¨â€ğŸ“Ari Holtzman,Jan Buys,Maxwell Forbes,Yejin Choi 2019 ![](https://img.shields.io/badge/pub-2019--04--22-green)![](https://img.shields.io/badge/cite-1322-red)

[**Publicly Available Clinical BERT Embeddings**](https://doi.org/10.18653/v1/W19-1909) ğŸ‘¨â€ğŸ“Emily Alsentzer,John R. Murphy,Willie Boag,W. Weng,Di Jin,Tristan Naumann,Matthew B. A. McDermott 2019 ![](https://img.shields.io/badge/pub-2019--04--06-green)![](https://img.shields.io/badge/cite-934-red)

[**SciBERT: A Pretrained Language Model for Scientific Text**](https://doi.org/10.18653/v1/D19-1371) ğŸ‘¨â€ğŸ“Iz Beltagy,Kyle Lo,Arman Cohan 2019 ![](https://img.shields.io/badge/pub-2019--03--01-green)![](https://img.shields.io/badge/cite-1476-red)

[**Parameter-Efficient Transfer Learning for NLP**](https://arxiv.org/abs/2302.135401902.00751) ğŸ‘¨â€ğŸ“N. Houlsby,A. Giurgiu,Stanislaw Jastrzebski,Bruna Morrone,Quentin de Laroussilhe,Andrea Gesmundo,Mona Attariyan,S. Gelly 2019 ![](https://img.shields.io/badge/pub-2019--02--02-green)![](https://img.shields.io/badge/cite-989-red)

[**BioBERT: a pre-trained biomedical language representation model for biomedical text mining**](https://doi.org/10.1093/bioinformatics/btz682) ğŸ‘¨â€ğŸ“Jinhyuk Lee,Wonjin Yoon,Sungdong Kim,Donghyeon Kim,Sunkyu Kim,Chan Ho So,Jaewoo Kang 2019 ![](https://img.shields.io/badge/pub-2019--01--25-green)![](https://img.shields.io/badge/cite-2743-red)

[**On Controllable Sparse Alternatives to Softmax**](https://arxiv.org/abs/2302.135401810.11975) ğŸ‘¨â€ğŸ“Anirban Laha,Saneem A. Chemmengath,Priyanka Agrawal,Mitesh M. Khapra,Karthik Sankaranarayanan,H. G. Ramaswamy 2018 ![](https://img.shields.io/badge/pub-2018--10--29-green)![](https://img.shields.io/badge/cite-36-red)

[**WikiHow: A Large Scale Text Summarization Dataset**](https://arxiv.org/abs/2302.135401810.09305) ğŸ‘¨â€ğŸ“Mahnaz Koupaee,William Yang Wang 2018 ![](https://img.shields.io/badge/pub-2018--10--18-green)![](https://img.shields.io/badge/cite-129-red)

[**Design guidelines for hands-free speech interaction**](https://doi.org/10.1145/3236112.3236149) ğŸ‘¨â€ğŸ“Christine Murad,Cosmin Munteanu,L. Clark,Benjamin R. Cowan 2018 ![](https://img.shields.io/badge/pub-2018--09--03-green)![](https://img.shields.io/badge/cite-62-red)

[**Donâ€™t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization**](https://doi.org/10.18653/v1/D18-1206) ğŸ‘¨â€ğŸ“Shashi Narayan,Shay B. Cohen,Mirella Lapata 2018 ![](https://img.shields.io/badge/pub-2018--08--27-green)![](https://img.shields.io/badge/cite-704-red)

[**Social Boundaries of Appropriate Speech in HCI: A Politeness Perspective**](https://doi.org/10.14236/EWIC/HCI2018.76) ğŸ‘¨â€ğŸ“L. Clark 2018 ![](https://img.shields.io/badge/pub-2018--07--01-green)![](https://img.shields.io/badge/cite-8-red)

[**A Simple Method for Commonsense Reasoning**](https://arxiv.org/abs/2302.135401806.02847) ğŸ‘¨â€ğŸ“Trieu H. Trinh,Quoc V. Le 2018 ![](https://img.shields.io/badge/pub-2018--06--07-green)![](https://img.shields.io/badge/cite-300-red)

[**Hierarchical Neural Story Generation**](https://doi.org/10.18653/v1/P18-1082) ğŸ‘¨â€ğŸ“Angela Fan,M. Lewis,Y. Dauphin 2018 ![](https://img.shields.io/badge/pub-2018--05--01-green)![](https://img.shields.io/badge/cite-839-red)

[**GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding**](https://doi.org/10.18653/v1/W18-5446) ğŸ‘¨â€ğŸ“Alex Wang,Amanpreet Singh,Julian Michael,Felix Hill,Omer Levy,Samuel R. Bowman 2018 ![](https://img.shields.io/badge/pub-2018--04--20-green)![](https://img.shields.io/badge/cite-3499-red)

[**Patterns for How Users Overcome Obstacles in Voice User Interfaces**](https://doi.org/10.1145/3173574.3173580) ğŸ‘¨â€ğŸ“Chelsea M. Myers,Anushay Furqan,Jessica Nebolsky,Karina Caro,Jichen Zhu 2018 ![](https://img.shields.io/badge/pub-2018--04--19-green)![](https://img.shields.io/badge/cite-151-red)

[**A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents**](https://doi.org/10.18653/v1/N18-2097) ğŸ‘¨â€ğŸ“Arman Cohan,Franck Dernoncourt,Doo Soon Kim,Trung Bui,Seokhwan Kim,W. Chang,Nazli Goharian 2018 ![](https://img.shields.io/badge/pub-2018--04--01-green)![](https://img.shields.io/badge/cite-408-red)

[**Steering the conversation: A linguistic exploration of natural language interactions with a digital assistant during simulated driving.**](https://doi.org/10.1016/j.apergo.2017.04.003) ğŸ‘¨â€ğŸ“D. Large,L. Clark,Annie Quandt,G. Burnett,L. Skrypchuk 2017 ![](https://img.shields.io/badge/pub-2017--09--01-green)![](https://img.shields.io/badge/cite-55-red)

[**The E2E Dataset: New Challenges For End-to-End Generation**](https://doi.org/10.18653/v1/W17-5525) ğŸ‘¨â€ğŸ“Jekaterina Novikova,Ondrej Dusek,Verena Rieser 2017 ![](https://img.shields.io/badge/pub-2017--06--28-green)![](https://img.shields.io/badge/cite-290-red)

[**Attention is All you Need**](https://arxiv.org/abs/2302.135401706.03762) ğŸ‘¨â€ğŸ“Ashish Vaswani,Noam M. Shazeer,Niki Parmar,Jakob Uszkoreit,Llion Jones,Aidan N. Gomez,Lukasz Kaiser,Illia Polosukhin 2017 ![](https://img.shields.io/badge/pub-2017--06--12-green)![](https://img.shields.io/badge/cite-51971-red)

[**Get To The Point: Summarization with Pointer-Generator Networks**](https://doi.org/10.18653/v1/P17-1099) ğŸ‘¨â€ğŸ“A. See,Peter J. Liu,Christopher D. Manning 2017 ![](https://img.shields.io/badge/pub-2017--04--01-green)![](https://img.shields.io/badge/cite-2927-red)

[**Categorical Reparameterization with Gumbel-Softmax**](https://arxiv.org/abs/2302.135401611.01144) ğŸ‘¨â€ğŸ“Eric Jang,S. Gu,Ben Poole 2016 ![](https://img.shields.io/badge/pub-2016--11--03-green)![](https://img.shields.io/badge/cite-3360-red)

[**The Oxford handbook of information structure**](https://doi.org/10.1093/OXFORDHB/9780199642670.001.0001) ğŸ‘¨â€ğŸ“C. FÃ©ry,S. Ishihara 2016 ![](https://img.shields.io/badge/pub-2016--07--28-green)![](https://img.shields.io/badge/cite-94-red)

[**Zur Stellung von Modalpartikeln in der gesprochenen Sprache**](https://doi.org/10.37307/j.1868-775x.2016.02.02) ğŸ‘¨â€ğŸ“Daniel Gutzmann,Katharina Turgay 2016 ![](https://img.shields.io/badge/pub-2016--06--10-green)![](https://img.shields.io/badge/cite-2-red)

[**Assessing Cognitive Distraction in the Automobile**](https://doi.org/10.1177/0018720815575149) ğŸ‘¨â€ğŸ“D. Strayer,Jonna Turrill,J. Cooper,James R. Coleman,Nathan Medeiros-Ward,F. Biondi 2015 ![](https://img.shields.io/badge/pub-2015--12--01-green)![](https://img.shields.io/badge/cite-147-red)

[**Teaching Machines to Read and Comprehend**](https://arxiv.org/abs/2302.135401506.03340) ğŸ‘¨â€ğŸ“K. Hermann,TomÃ¡s KociskÃ½,Edward Grefenstette,Lasse Espeholt,Will Kay,Mustafa Suleyman,P. Blunsom 2015 ![](https://img.shields.io/badge/pub-2015--06--10-green)![](https://img.shields.io/badge/cite-2785-red)

[**Empirical Evidence for a Diminished Sense of Agency in Speech Interfaces**](https://doi.org/10.1145/2702123.2702379) ğŸ‘¨â€ğŸ“Hannah Limerick,James W. Moore,D. Coyle 2015 ![](https://img.shields.io/badge/pub-2015--04--18-green)![](https://img.shields.io/badge/cite-48-red)

[**A Model of Coherence Based on Distributed Sentence Representation**](https://doi.org/10.3115/v1/D14-1218) ğŸ‘¨â€ğŸ“Jiwei Li,E. Hovy 2014 ![](https://img.shields.io/badge/pub-2014--10--01-green)![](https://img.shields.io/badge/cite-140-red)

[**Measuring linguistically-induced cognitive load during driving using the ConTRe task**](https://doi.org/10.1145/2516540.2516546) ğŸ‘¨â€ğŸ“V. Demberg,A. Sayeed,Angela Castronovo,Christian A. MÃ¼ller 2013 ![](https://img.shields.io/badge/pub-2013--10--28-green)![](https://img.shields.io/badge/cite-32-red)

[**Modeling Local Coherence: An Entity-Based Approach**](https://doi.org/10.1162/coli.2008.34.1.1) ğŸ‘¨â€ğŸ“R. Barzilay,Mirella Lapata 2008 ![](https://img.shields.io/badge/pub-2008--03--01-green)![](https://img.shields.io/badge/cite-732-red)

[**Safety and Usability of Speech Interfaces for In-Vehicle Tasks while Driving: A Brief Literature Review**](https://api.semanticscholar.org/39bbe946650c6893a816d29b350ed7a3642add5f) ğŸ‘¨â€ğŸ“Adriana Baron,P. Green 2006 ![](https://img.shields.io/badge/pub-2006--02--01-green)![](https://img.shields.io/badge/cite-122-red)

[**Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization**](https://arxiv.org/abs/2302.13540cs/0405039) ğŸ‘¨â€ğŸ“R. Barzilay,Lillian Lee 2004 ![](https://img.shields.io/badge/pub-2004--05--01-green)![](https://img.shields.io/badge/cite-410-red)

[**Grammatik der deutschen Sprache**](https://doi.org/10.1515/9783110872163) ğŸ‘¨â€ğŸ“B. Strecker,Ludger Hoffmann,G. Zifonun 1997 ![](https://img.shields.io/badge/pub-1997--12--31-green)![](https://img.shields.io/badge/cite-455-red)

[**Generated Knowledge Prompting for Commonsense Reasoning**](https://api.semanticscholar.org/12a763cb52f650710900790ca0bc43e5d5b88be6) 2021 

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification**](https://api.semanticscholar.org/6f0aba8102d63938ce0b48ec23ff5ddd8110f2e8) 2021 

[**RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction**](https://api.semanticscholar.org/743dcf234cffd54c4e096a10a284dd81572b16ea) 2022 

[**GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks**](https://api.semanticscholar.org/e147cc46b7f441a68706ca53549d45e9a9843fb6) 2023 

[**Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning**](https://api.semanticscholar.org/096c2791c3dd4b123333e324ce88cd97661ffd3f) 2022 

[**A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT**](https://api.semanticscholar.org/08b85bce712168998004ee80ce4e475390413c74) 2023 

[**Learning to Transfer Prompts for Text Generation**](https://api.semanticscholar.org/42117d01d498eb9f8c21b788c3565bc6855d620b) 2022 

[**Multitask Prompted Training Enables Zero-Shot Task Generalization**](https://api.semanticscholar.org/17dd3555fd1ccf1141cf984347fa1b3fd6b009ca) 2021 

[**Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models**](https://api.semanticscholar.org/fcfc9648561a221750b8085790ad9ba1bebb1800) 2021 

[**Unified Structure Generation for Universal Information Extraction**](https://api.semanticscholar.org/5382c28b9f2dd30f15c836bea92382091b1d886f) 2022 

[**Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation**](https://api.semanticscholar.org/eb53979c96eacec543620af2b899a3772eb6d32f) 2023 

[**Successive Prompting for Decomposing Complex Questions**](https://api.semanticscholar.org/c90151f00b1ac4abf1cc353849b453aa21cc2df3) 2022 

[**SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based Sentiment Analysis**](https://api.semanticscholar.org/2145582245) ğŸ‘¨â€ğŸ“ 2021 

[**Scientific Language Models for Biomedical Knowledge Base Completion: An Empirical Study**](https://api.semanticscholar.org/5bebacad8c1ba330314c87405a86d321f1cfda4b) 2021 

[**Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries**](https://api.semanticscholar.org/51ae2c451a1a05293334a509b71c9c9e0377d35c) 2020 

[**PromptChainer: Chaining Large Language Model Prompts through Visual Programming**](https://api.semanticscholar.org/0f733817e82026f7c29909a51cb4df7d2685f0e7) 2022 

[**Toxicity Detection with Generative Prompt-based Inference**](https://api.semanticscholar.org/2afb07359e9c67499e1f373ac6f1520d3ea9c46a) 2022 

[**Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales**](https://api.semanticscholar.org/03eb8b41de5b201c0535fc3b8a91033abe645325) 2023 

[**Ignore Previous Prompt: Attack Techniques For Language Models**](https://api.semanticscholar.org/9716a2876d08fce9d8e5c5ba4d7b1a9af44806d6) 2022 

[**COPEN: Probing Conceptual Knowledge in Pre-trained Language Models**](https://api.semanticscholar.org/bcec7d17e68aceb91d020dd796ece075694f77c6) 2022 

[**Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding**](https://api.semanticscholar.org/17dcfef70619c0423e0527f0c9d90f4858125f5f) 2022 

[**Representing Text for Joint Embedding of Text and Knowledge Bases**](https://doi.org/10.18653/v1/D15-1174) ğŸ‘¨â€ğŸ“Kristina Toutanova,Danqi Chen,P. Pantel,Hoifung Poon,Pallavi Choudhury,Michael Gamon 2015 ![](https://img.shields.io/badge/cite-550-red)

[**How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks**](https://api.semanticscholar.org/1f040c3a8d49f8e54169a0e07013692c7d58de4b) 2023 

[**Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction**](https://api.semanticscholar.org/85061c524fdd5ec75f06a3329352621bb8d05f43) 2021 

[**SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks**](https://api.semanticscholar.org/b50c27607d7a858297232310bbec9819ade875a8) 2023 

[**LabelPrompt: Effective Prompt-based Learning for Relation Classification**](https://api.semanticscholar.org/b2d783c0ed3bd2c631b99b1487399016a5f00d5f) 2023 

[**Time-Aware Language Models as Temporal Knowledge Bases**](https://api.semanticscholar.org/ac8d33e4c0a45e227a47353f3f26fbb231482dc1) 2021 

[**Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften**](https://doi.org/10.1007/978-3-662-64762-2) ğŸ‘¨â€ğŸ“N. DÃ¶ring 2016 ![](https://img.shields.io/badge/cite-864-red)

[**The Influence of Syntax on the Perception of In-Vehicle Prompts and Driving Performance**](https://doi.org/10.1007/978-981-15-8395-7_26) ğŸ‘¨â€ğŸ“D. Stier,U. Heid,Patricia Kittel,Maria Schmidt,W. Minker 2020 ![](https://img.shields.io/badge/cite-4-red)

[**Menschliche Kommunikation : Formen, StÃ¶rungen, Parodoxien**](https://api.semanticscholar.org/8871dab83c31fce0b01c3574bcb8687cb5d0b0b1) ğŸ‘¨â€ğŸ“P. Watzlawick,Janet Holmick Beavin,Don D. Jackson 1996 ![](https://img.shields.io/badge/cite-387-red)

[**DialogSum: A Real-Life Scenario Dialogue Summarization Dataset**](https://doi.org/10.18653/v1/2021.findings-acl.449) ğŸ‘¨â€ğŸ“Yulong Chen,Yang Liu,Liang Chen,Yue Zhang 2021 ![](https://img.shields.io/badge/cite-58-red)

[**Soziolinguistik**](https://doi.org/10.1007/978-3-476-05861-4) ğŸ‘¨â€ğŸ“JÃ¼rgen SpitzmÃ¼ller 2022 ![](https://img.shields.io/badge/cite-1-red)

[**Prefix-Tuning: Optimizing Continuous Prompts for Generation**](https://doi.org/10.18653/v1/2021.acl-long.353) ğŸ‘¨â€ğŸ“Xiang Lisa Li,Percy Liang 2021 ![](https://img.shields.io/badge/cite-824-red)

[**Discourse-Aware Unsupervised Summarization for Long Scientific Documents**](https://doi.org/10.18653/v1/2021.eacl-main.93) ğŸ‘¨â€ğŸ“Yue Dong,Andrei Mircea,J. C. Cheung 2021 ![](https://img.shields.io/badge/cite-20-red)

[**Properties of spoken and written language.**](https://api.semanticscholar.org/f29972840d1437890af055831d654cbff4bd4058) ğŸ‘¨â€ğŸ“W. Chafe,J. Danielewicz 1987 ![](https://img.shields.io/badge/cite-428-red)

[**ChemProt-3.0: a global chemical biology diseases mapping**](https://doi.org/10.1093/database/bav123) ğŸ‘¨â€ğŸ“Jens Vindahl 2016 ![](https://img.shields.io/badge/cite-87-red)

[**One Voice Fits All? Social Implications and Research Challenges of Designing Voices for Smart Devices**](https://api.semanticscholar.org/624f21e273c74335044806e0e1669ce5f26587c4) ğŸ‘¨â€ğŸ“Julia Cambre,Chinmay Kulkarni 2019 ![](https://img.shields.io/badge/cite-35-red)

[**Promptagator: Few-shot Dense Retrieval From 8 Examples**](https://api.semanticscholar.org/e86009d9f9b1cdf083a48d087552bc4153784451) 2022 

[**EinfÃ¼hrung in die Grammatik der deutschen Gegenwartssprache**](https://doi.org/10.1515/9783110918861) ğŸ‘¨â€ğŸ“K. Sommerfeldt,G. Starke,W. Hackel 1998 ![](https://img.shields.io/badge/cite-26-red)

[**From discourse structures to text summaries**](https://api.semanticscholar.org/1daf375141571501ca8c30b62d7c14269d566762) ğŸ‘¨â€ğŸ“D. Marcu 1997 ![](https://img.shields.io/badge/cite-330-red)

[**PRIMER: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization**](https://api.semanticscholar.org/2a7023e7d1dbd6ea0d98efd09a1f18d8599fe78f) ğŸ‘¨â€ğŸ“Wen Xiao,Iz Beltagy,G. Carenini,Arman Cohan 2021 ![](https://img.shields.io/badge/cite-19-red)

[**AdaPrompt: Adaptive Prompt-based Finetuning for Relation Extraction**](https://api.semanticscholar.org/2404aecd866cfa15fee6ada095667980a63c4172) ğŸ‘¨â€ğŸ“Xiang Chen,Xin Xie,Ningyu Zhang,Jiahuan Yan,Shumin Deng,Chuanqi Tan,Fei Huang,Luo Si,Huajun Chen 2021 ![](https://img.shields.io/badge/cite-31-red)

[**Prompt Combines Paraphrase: Enhancing Biomedical â€œPre-training, Prompt and Predictingâ€ Models by Explaining Rare Biomedical Concepts**](https://api.semanticscholar.org/4e305fe2ef347caddd8936bc0a8c462e33f6e2da) ğŸ‘¨â€ğŸ“Hao Wang 2021 ![](https://img.shields.io/badge/cite-1-red)

[**Zur Abfolge nominaler Satzglieder im Deutschen**](https://api.semanticscholar.org/d93a04ab220196e6bbe3c8ff39b40ff6a8b7ca5a) ğŸ‘¨â€ğŸ“J. Lenerz 1977 ![](https://img.shields.io/badge/cite-367-red)

[**Unified Knowledge Prompt Pre-training for Customer Service Dialogues**](https://api.semanticscholar.org/d0bdabbecba66084af3e4135e656f5277097fb7c) 2022 

[**Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints**](https://api.semanticscholar.org/3f83582c08a62e5bd02398fafc93f7eaf1e4b84e) 2023 

[**Self-Instruct: Aligning Language Model with Self Generated Instructions**](https://api.semanticscholar.org/bbe93c90b7b87939cd064c805858feca61a3234d) 2022 

[**One Embedder, Any Task: Instruction-Finetuned Text Embeddings**](https://api.semanticscholar.org/9f61d366b9d00becb25f7823997c626c6b1d5c16) 2022 

[**Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis**](https://api.semanticscholar.org/cd6fba0c9c34a2c9ff1ed17d2f9f50d8a3399669) 2023 

[**Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition**](https://api.semanticscholar.org/5aa4e5b90827f1c16bed100982e2a1871925d445) 2023 

[**QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition**](https://api.semanticscholar.org/b159dffadb69940e14693e812bdaa32e3957717f) 2022 

[**Materialized Knowledge Bases from Commonsense Transformers**](https://api.semanticscholar.org/66a660bc912fd212db40ded34d34f28e4860a676) 2021 

[**Good Visual Guidance Makes A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction**](https://api.semanticscholar.org/81ad863f8bc438455cb973ae20778a949a54d2b7) 2022 

[**Investigating Prompt Engineering in Diffusion Models**](https://api.semanticscholar.org/d2cfabde7383704e876373e9da9891714b0bd62b) 2022 

[**Language Model Crossover: Variation through Few-Shot Prompting**](https://api.semanticscholar.org/49fede098a0d2a48e8100b30189224fc6f5eb25b) 2023 

[**How Much Knowledge Can You Pack into the Parameters of a Language Model?**](https://api.semanticscholar.org/80376bdec5f534be78ba82821f540590ebce5559) 2020 

[**LightNER: A Lightweight Tuning Paradigm for Low-resource NER via Pluggable Prompting**](https://api.semanticscholar.org/3c12482e523b283cb1a3433b962e9ffc2ed5c65b) 2021 

[**How Context Affects Language Models' Factual Predictions**](https://api.semanticscholar.org/c44120f765fc43994c5cfb4e12e4f62999efeae6) 2020 

[**Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data**](https://api.semanticscholar.org/08433ddb8c799c00008bc71a6252ee473585f7e3) 2022 

[**Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models**](https://api.semanticscholar.org/69619a2a47faee7a29ec596db13172e2a42ff921) 2023 

[**Language Models are Unsupervised Multitask Learners**](https://api.semanticscholar.org/9405cc0d6169988371b2755e573cc28650d14dfe) ğŸ‘¨â€ğŸ“Alec Radford,Jeff Wu,Rewon Child,D. Luan,Dario Amodei,Ilya Sutskever 2019 ![](https://img.shields.io/badge/cite-8849-red)

[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://doi.org/10.18653/v1/N19-1423) ğŸ‘¨â€ğŸ“Jacob Devlin,Ming-Wei Chang,Kenton Lee,Kristina Toutanova 2019 ![](https://img.shields.io/badge/cite-47696-red)

[**of the Association for Computational Linguistics:**](https://doi.org/10.1016/b0-08-044854-2/05234-2) ğŸ‘¨â€ğŸ“Vladimir Meza Ruiz,Rashmi Gangadharaiah,Maria Leonor Pacheco,Danqi Chen,Ryan Cotterell 2001 ![](https://img.shields.io/badge/cite-4067-red)

[**Probing Simile Knowledge from Pre-trained Language Models**](https://api.semanticscholar.org/37e664778284314b05fd26177ce14f631ac1550e) 2022 

[**Progressive Prompts: Continual Learning for Language Models**](https://api.semanticscholar.org/86478f285356b5c8d27423e6b939634d9e010fba) 2023 

[**More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models**](https://api.semanticscholar.org/8fdd34153d1035d09dd4a6efa9cb0c91d23d0045) 2023 

[**How Does In-Context Learning Help Prompt Tuning?**](https://api.semanticscholar.org/8c75f0f2393ac08f1749e6177f31a0f8842dae0f) 2023 

[**DocPrompting: Generating Code by Retrieving the Docs**](https://api.semanticscholar.org/0a39442979d6e678dd36bb443ad529c14e86a86e) 2022 

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://api.semanticscholar.org/780a7f5e8ba9b4b451e3dfee1bcfb0f68aba5050) 2023 

[**PLACES: Prompting Language Models for Social Conversation Synthesis**](https://api.semanticscholar.org/5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691) 2023 

[**EvoPrompting: Language Models for Code-Level Neural Architecture Search**](https://api.semanticscholar.org/35d083ff4dc2805c477d0aedc8158fc7a1aefeda) 2023 

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classiï¬cation Rolling Review submission**](https://api.semanticscholar.org/80366efe644f9fa5d1e89775eb7cb135ca46582f) 2021 

[**Legal Prompt Engineering for Multilingual Legal Judgement Prediction**](https://api.semanticscholar.org/ec27f85979899a4193a8ec3b932ddb677c59be62) 2022 

[**Visual Prompt Tuning**](https://api.semanticscholar.org/adb272fbdea3631059cf88ab764bb6c2ce29f965) 2022 

[**Prompting for Multimodal Hateful Meme Classification**](https://api.semanticscholar.org/ae766548699f27e669932de14e1c0f47b2828536) 2023 

[**Batch Prompting: Efficient Inference with Large Language Model APIs**](https://api.semanticscholar.org/e659fa1e79a2a151be331125c14339988542aac3) 2023 



<img width="200%" src="./figures/hr.gif" />

# ğŸ“ Citation

If you find our work helps, please star our project and cite our paper. Thanks a lot!

```
ç»¼è¿°è®ºæ–‡å¯ä»¥æ”¾åœ¨è¿™ä¸ªä½ç½®
```
<img width="200%" src="./figures/hr.gif" />

# âœ‰ï¸ Contact

This repo is maintained by [EgoAlpha Lab](https://github.com/EgoAlpha). Questions and discussions are welcome via `cyfedu1024@gmail.com` or `cyfedu1024@163.com`.

We are willing to communicate with your research team or confirm in variety of fields.

<img width="200%" src="./figures/hr.gif" />

# ğŸ™ Acknowledgements

Thanks to the PhD students from [EgoAlpha Lab](https://github.com/EgoAlpha) and other workers who participated in this repo. We will improve the project in the follow-up period and maintain this community well. More researchers are welcome to join us and make more contributions to the community.

<img width="200%" src="./figures/hr.gif" />

# ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Contributors

## Main Contributors
* [Yu Liu]()
* [Yifei Cao](https://github.com/cyfedu1024)
* [Jizhe Yu]()
* [Yuan Yao]()
* [He Qi]()


<!-- ## Guest Contributors
* [No] -->

<img width="200%" src="./figures/hr.gif" />

# ğŸ“” License

This project is open source and available under the MIT

<div align="center">
<img src="./figures/rocket.png"/>
</div>
