# üìÑ Chain of Thought

## Paper List

<div style="line-height:0.2em;">


[**REFINER: Reasoning Feedback on Intermediate Representations**](https://arxiv.org/abs/2304.01904) Ôºà**2023.04.04**Ôºâ

<font color="gray">Debjit Paul, Mete Ismayilzada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)

---

[**Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data**](https://doi.org/10.48550/arXiv.2302.12822) Ôºà**2023.02.24**Ôºâ

<font color="gray">Kashun Shum, Shizhe Diao, Tong Zhang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Active Prompting with Chain-of-Thought for Large Language Models**](https://doi.org/10.48550/arXiv.2302.12246) Ôºà**2023.02.23**Ôºâ

<font color="gray">Shizhe Diao, Pengcheng Wang, Yong Lin, Tong Zhang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-61-blue)](https://github.com/shizhediao/active-cot)

---

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2302.00923) Ôºà**2023.02.02**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, G. Karypis, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3.1k-blue)](https://github.com/amazon-science/mm-cot)

---

[**Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models**](https://doi.org/10.48550/arXiv.2302.00618) Ôºà**2023.02.01**Ôºâ

<font color="gray">Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Faithful Chain-of-Thought Reasoning**](https://doi.org/10.48550/arXiv.2301.13379) Ôºà**2023.01.31**Ôºâ

<font color="gray">QING LYU, Shreya Havaldar, Adam Stein, Li Zhang, D. Rao, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-36-blue)](https://github.com/veronica320/faithful-cot)

---

[**Large Language Models Are Reasoning Teachers**](https://doi.org/10.48550/arXiv.2212.10071) Ôºà**2022.12.20**Ôºâ

<font color="gray">Namgyu Ho, Laura Schmid, Se-Young Yun .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**Solving math word problems with process- and outcome-based feedback**](https://doi.org/10.48550/arXiv.2211.14275) Ôºà**2022.11.25**Ôºâ

<font color="gray">J. Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Complementary Explanations for Effective In-Context Learning**](https://doi.org/10.48550/arXiv.2211.13892) Ôºà**2022.11.25**Ôºâ

<font color="gray">Xi Ye, Srini Iyer, Asli Celikyilmaz, V. Stoyanov, Greg Durrett, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks**](https://doi.org/10.48550/arXiv.2211.12588) Ôºà**2022.11.22**Ôºâ

<font color="gray">Wenhu Chen, Xueguang Ma, Xinyi Wang, William W. Cohen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-22-green)  [![](https://img.shields.io/badge/Github%20Stars-57-blue)](https://github.com/wenhuchen/program-of-thoughts)

---

[**Ignore Previous Prompt: Attack Techniques For Language Models**](https://doi.org/10.48550/arXiv.2211.09527) Ôºà**2022.11.17**Ôºâ

<font color="gray">F'abio Perez, Ian Ribeiro .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-70-blue)](https://github.com/agencyenterprise/promptinject)

---

[**COPEN: Probing Conceptual Knowledge in Pre-trained Language Models**](https://doi.org/10.48550/arXiv.2211.04079) Ôºà**2022.11.08**Ôºâ

<font color="gray">Hao Peng, Xiaozhi Wang, Shengding Hu, Hailong Jin, Lei Hou, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-15-blue)](https://github.com/thu-keg/copen)

---

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) Ôºà**2022.10.17**Ôºâ

<font color="gray">Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-29-green)  [![](https://img.shields.io/badge/Github%20Stars-66-blue)](https://github.com/suzgunmirac/big-bench-hard)

---

[**Large Language Models are few(1)-shot Table Reasoners**](https://doi.org/10.48550/arXiv.2210.06710) Ôºà**2022.10.13**Ôºâ

<font color="gray">Wenhu Chen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-10-green)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/wenhuchen/tablecot)

---

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) Ôºà**2022.10.07**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Alexander J. Smola .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)  [![](https://img.shields.io/badge/Github%20Stars-311-blue)](https://github.com/amazon-research/auto-cot)

---

[**Measuring and Narrowing the Compositionality Gap in Language Models**](https://doi.org/10.48550/arXiv.2210.03350) Ôºà**2022.10.07**Ôºâ

<font color="gray">Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-28-green)  [![](https://img.shields.io/badge/Github%20Stars-165-blue)](https://github.com/ofirpress/self-ask)

---

[**Language Models are Multilingual Chain-of-Thought Reasoners**](https://doi.org/10.48550/arXiv.2210.03057) Ôºà**2022.10.06**Ôºâ

<font color="gray">Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-22-green)  [![](https://img.shields.io/badge/Github%20Stars-68-blue)](https://github.com/google-research/url-nlp)

---

[**Decomposed Prompting: A Modular Approach for Solving Complex Tasks**](https://doi.org/10.48550/arXiv.2210.02406) Ôºà**2022.10.05**Ôºâ

<font color="gray">Tushar Khot, H. Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-25-green)  [![](https://img.shields.io/badge/Github%20Stars-20-blue)](https://github.com/allenai/decomp)

---

[**GLM-130B: An Open Bilingual Pre-trained Model**](https://doi.org/10.48550/arXiv.2210.02414) Ôºà**2022.10.05**Ôºâ

<font color="gray">Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-19-green)  [![](https://img.shields.io/badge/Github%20Stars-2.5k-blue)](https://github.com/thudm/glm-130b)

---

[**Complexity-Based Prompting for Multi-Step Reasoning**](https://doi.org/10.48550/arXiv.2210.00720) Ôºà**2022.10.03**Ôºâ

<font color="gray">Yao Fu, Hao-Chun Peng, Ashish Sabharwal, Peter Clark, Tushar Khot .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)

---

[**Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought**](https://doi.org/10.48550/arXiv.2210.01240) Ôºà**2022.10.03**Ôºâ

<font color="gray">Abulhair Saparov, He He .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-24-blue)](https://github.com/asaparov/prontoqa)

---

[**Compositional Semantic Parsing with Large Language Models**](https://doi.org/10.48550/arXiv.2209.15003) Ôºà**2022.09.29**Ôºâ

<font color="gray">Andrew Drozdov, Nathanael Scharli, Ekin Akyuurek, Nathan Scales, Xinying Song, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-16-green)

---

[**Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering**](https://doi.org/10.48550/arXiv.2209.09513) Ôºà**2022.09.20**Ôºâ

<font color="gray">Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)  [![](https://img.shields.io/badge/Github%20Stars-210-blue)](https://github.com/lupantech/ScienceQA)

---

[**Rationale-Augmented Ensembles in Language Models**](https://doi.org/10.48550/arXiv.2207.00747) Ôºà**2022.07.02**Ôºâ

<font color="gray">Xuezhi Wang, Jason Wei, D. Schuurmans, Quoc Le, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-26-green)

---

[**On the Advance of Making Language Models Better Reasoners**](https://doi.org/10.48550/arXiv.2206.02336) Ôºà**2022.06.06**Ôºâ

<font color="gray">Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-40-green)

---

[**Large Language Models are Zero-Shot Reasoners**](https://arxiv.org/abs/2205.11916) Ôºà**2022.05.24**Ôºâ

<font color="gray">Takeshi Kojima, S. Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-187-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-309-red)  [![](https://img.shields.io/badge/Github%20Stars-150-blue)](https://github.com/kojima-takeshi188/zero_shot_cot)

---

[**Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2205.10625) Ôºà**2022.05.21**Ôºâ

<font color="gray">Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-90-green)

---

[**Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning**](https://doi.org/10.48550/arXiv.2205.09712) Ôºà**2022.05.19**Ôºâ

<font color="gray">Antonia Creswell, M. Shanahan, I. Higgins .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-38-green)

---

[**Can language models learn from explanations in context?**](https://doi.org/10.48550/arXiv.2204.02329) Ôºà**2022.04.05**Ôºâ

<font color="gray">Andrew Kyle Lampinen, I. Dasgupta, Stephanie C. Y. Chan, Kory Matthewson, Michael Henry Tessler, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-61-green)

---

[**STaR: Bootstrapping Reasoning With Reasoning**](https://doi.org/10.48550/arXiv.2203.14465) Ôºà**2022.03.28**Ôºâ

<font color="gray">E. Zelikman, Yuhuai Wu, Noah D. Goodman .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-56-green)

---

[**Self-Consistency Improves Chain of Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2203.11171) Ôºà**2022.03.21**Ôºâ

<font color="gray">Xuezhi Wang, Jason Wei, D. Schuurmans, Quoc Le, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-133-green)

---

[**Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data**](https://doi.org/10.48550/arXiv.2203.08773) Ôºà**2022.03.16**Ôºâ

<font color="gray">Shuo Wang, Yichong Xu, Yuwei Fang, Yang Liu, S. Sun, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-102-blue)](https://github.com/microsoft/reina)

---

[**Chain of Thought Prompting Elicits Reasoning in Large Language Models**](https://arxiv.org/abs/2201.11903) Ôºà**2022.01.28**Ôºâ

<font color="gray">Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-396-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-584-red)

---

[**Show Your Work: Scratchpads for Intermediate Computation with Language Models**](https://arxiv.org/abs/2112.00114) Ôºà**2021.11.30**Ôºâ

<font color="gray">Maxwell Nye, Anders Andreassen, Guy Gur-Ari, H. Michalewski, Jacob Austin, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-123-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-94-red)

---

[**Few-Shot Self-Rationalization with Natural Language Prompts**](https://doi.org/10.18653/v1/2022.findings-naacl.31) Ôºà**2021.11.16**Ôºâ

<font color="gray">Ana Marasoviƒá, Iz Beltagy, Doug Downey, Matthew E. Peters .  - „ÄêNAACL-HLT„Äë</font>

![](https://img.shields.io/badge/Citations-29-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-44-red)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/allenai/feb)

---

[**Training Verifiers to Solve Math Word Problems**](https://arxiv.org/abs/2110.14168) Ôºà**2021.10.27**Ôºâ

<font color="gray">Karl Cobbe, V. Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-181-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-110-red)  [![](https://img.shields.io/badge/Github%20Stars-331-blue)](https://github.com/openai/grade-school-math)


</div>

# CONTINUE...