# üìÑ Chain of Thought

## Paper List

<div style="line-height:0.2em;">


[**Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting**](https://doi.org/10.48550/arXiv.2305.04388) Ôºà**2023.05.07**Ôºâ

<font color="gray">Miles Turpin, Julian Michael, Ethan Perez, Sam Bowman .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/milesaturpin/cot-unfaithfulness)

---

[**Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models**](https://doi.org/10.48550/arXiv.2305.04091) Ôºà**2023.05.06**Ôºâ

<font color="gray">Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-119-blue)](https://github.com/agi-edgerunners/plan-and-solve-prompting)

---

[**Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework**](https://doi.org/10.48550/arXiv.2305.03268) Ôºà**2023.05.05**Ôºâ

<font color="gray">Ruochen Zhao, Xingxuan Li, Shafiq R. Joty, Chengwei Qin, Lidong Bing .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/ruochenzhao/verify-and-edit)

---

[**Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings**](https://doi.org/10.48550/arXiv.2305.02317) Ôºà**2023.05.03**Ôºâ

<font color="gray">Daniel Rose, Vaishnavi Himakunthala, Andy Ouyang, Ryan He, Alex Mei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SCOTT: Self-Consistent Chain-of-Thought Distillation**](https://doi.org/10.48550/arXiv.2305.01879) Ôºà**2023.05.03**Ôºâ

<font color="gray">Peifeng Wang, Zhengyang Wang, Zheng Li, Yifan Gao, Bing Yin, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models**](https://arxiv.org/abs/2304.11657) Ôºà**2023.04.23**Ôºâ

<font color="gray">Jiashuo Sun, Yi Luo, Yeyun Gong, Chen Lin, Yelong Shen, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)  [![](https://img.shields.io/badge/Github%20Stars-56-blue)](https://github.com/gasolsun36/iter-cot)

---

[**Chain of Thought Prompt Tuning in Vision Language Models**](https://arxiv.org/abs/2304.07919) Ôºà**2023.04.16**Ôºâ

<font color="gray">Jiaxin Ge, Hongyin Luo, Siyuan Qian, Yulu Gan, Jie Fu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media**](https://doi.org/10.48550/arXiv.2304.03087) Ôºà**2023.04.06**Ôºâ

<font color="gray">Bowen Zhang, Xianghua Fu, Daijun Ding, Hutchin Huang, Yangyang Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data**](https://doi.org/10.48550/arXiv.2302.12822) Ôºà**2023.02.24**Ôºâ

<font color="gray">Kashun Shum, Shizhe Diao, Tong Zhang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Active Prompting with Chain-of-Thought for Large Language Models**](https://doi.org/10.48550/arXiv.2302.12246) Ôºà**2023.02.23**Ôºâ

<font color="gray">Shizhe Diao, Pengcheng Wang, Yong Lin, Tong Zhang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-100-blue)](https://github.com/shizhediao/active-cot)

---

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2302.00923) Ôºà**2023.02.02**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, G. Karypis, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3.3k-blue)](https://github.com/amazon-science/mm-cot)

---

[**Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models**](https://doi.org/10.48550/arXiv.2302.00618) Ôºà**2023.02.01**Ôºâ

<font color="gray">Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Faithful Chain-of-Thought Reasoning**](https://doi.org/10.48550/arXiv.2301.13379) Ôºà**2023.01.31**Ôºâ

<font color="gray">QING LYU, Shreya Havaldar, Adam Stein, Li Zhang, D. Rao, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-54-blue)](https://github.com/veronica320/faithful-cot)

---

[**Large Language Models Are Reasoning Teachers**](https://doi.org/10.48550/arXiv.2212.10071) Ôºà**2022.12.20**Ôºâ

<font color="gray">Namgyu Ho, Laura Schmid, Se-Young Yun .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**Solving math word problems with process- and outcome-based feedback**](https://doi.org/10.48550/arXiv.2211.14275) Ôºà**2022.11.25**Ôºâ

<font color="gray">J. Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Complementary Explanations for Effective In-Context Learning**](https://doi.org/10.48550/arXiv.2211.13892) Ôºà**2022.11.25**Ôºâ

<font color="gray">Xi Ye, Srini Iyer, Asli Celikyilmaz, V. Stoyanov, Greg Durrett, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks**](https://doi.org/10.48550/arXiv.2211.12588) Ôºà**2022.11.22**Ôºâ

<font color="gray">Wenhu Chen, Xueguang Ma, Xinyi Wang, William W. Cohen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-22-green)  [![](https://img.shields.io/badge/Github%20Stars-82-blue)](https://github.com/wenhuchen/program-of-thoughts)

---

[**Ignore Previous Prompt: Attack Techniques For Language Models**](https://doi.org/10.48550/arXiv.2211.09527) Ôºà**2022.11.17**Ôºâ

<font color="gray">F'abio Perez, Ian Ribeiro .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-116-blue)](https://github.com/agencyenterprise/promptinject)

---

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) Ôºà**2022.10.17**Ôºâ

<font color="gray">Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-29-green)  [![](https://img.shields.io/badge/Github%20Stars-103-blue)](https://github.com/suzgunmirac/big-bench-hard)

---

[**Large Language Models are few(1)-shot Table Reasoners**](https://doi.org/10.48550/arXiv.2210.06710) Ôºà**2022.10.13**Ôºâ

<font color="gray">Wenhu Chen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-10-green)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/wenhuchen/tablecot)

---

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) Ôºà**2022.10.07**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Alexander J. Smola .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)  [![](https://img.shields.io/badge/Github%20Stars-450-blue)](https://github.com/amazon-research/auto-cot)

---

[**Language Models are Multilingual Chain-of-Thought Reasoners**](https://doi.org/10.48550/arXiv.2210.03057) Ôºà**2022.10.06**Ôºâ

<font color="gray">Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-22-green)  [![](https://img.shields.io/badge/Github%20Stars-86-blue)](https://github.com/google-research/url-nlp)

---

[**Decomposed Prompting: A Modular Approach for Solving Complex Tasks**](https://doi.org/10.48550/arXiv.2210.02406) Ôºà**2022.10.05**Ôºâ

<font color="gray">Tushar Khot, H. Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-25-green)  [![](https://img.shields.io/badge/Github%20Stars-34-blue)](https://github.com/allenai/decomp)

---

[**Complexity-Based Prompting for Multi-Step Reasoning**](https://doi.org/10.48550/arXiv.2210.00720) Ôºà**2022.10.03**Ôºâ

<font color="gray">Yao Fu, Hao-Chun Peng, Ashish Sabharwal, Peter Clark, Tushar Khot .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)

---

[**Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought**](https://doi.org/10.48550/arXiv.2210.01240) Ôºà**2022.10.03**Ôºâ

<font color="gray">Abulhair Saparov, He He .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-34-blue)](https://github.com/asaparov/prontoqa)

---

[**Compositional Semantic Parsing with Large Language Models**](https://doi.org/10.48550/arXiv.2209.15003) Ôºà**2022.09.29**Ôºâ

<font color="gray">Andrew Drozdov, Nathanael Scharli, Ekin Akyuurek, Nathan Scales, Xinying Song, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-16-green)

---

[**Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering**](https://doi.org/10.48550/arXiv.2209.09513) Ôºà**2022.09.20**Ôºâ

<font color="gray">Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)  [![](https://img.shields.io/badge/Github%20Stars-289-blue)](https://github.com/lupantech/ScienceQA)

---

[**FOLIO: Natural Language Reasoning with First-Order Logic**](https://doi.org/10.48550/arXiv.2209.00840) Ôºà**2022.09.02**Ôºâ

<font color="gray">Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-53-blue)](https://github.com/yale-lily/folio)

---

[**Faithful Reasoning Using Large Language Models**](https://doi.org/10.48550/arXiv.2208.14271) Ôºà**2022.08.30**Ôºâ

<font color="gray">Antonia Creswell, M. Shanahan .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)

---

[**Rationale-Augmented Ensembles in Language Models**](https://doi.org/10.48550/arXiv.2207.00747) Ôºà**2022.07.02**Ôºâ

<font color="gray">Xuezhi Wang, Jason Wei, D. Schuurmans, Quoc Le, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-26-green)

---

[**On the Advance of Making Language Models Better Reasoners**](https://doi.org/10.48550/arXiv.2206.02336) Ôºà**2022.06.06**Ôºâ

<font color="gray">Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-40-green)

---

[**Large Language Models are Zero-Shot Reasoners**](https://arxiv.org/abs/2205.11916) Ôºà**2022.05.24**Ôºâ

<font color="gray">Takeshi Kojima, S. Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-187-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-396-red)  [![](https://img.shields.io/badge/Github%20Stars-199-blue)](https://github.com/kojima-takeshi188/zero_shot_cot)

---

[**Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2205.10625) Ôºà**2022.05.21**Ôºâ

<font color="gray">Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-90-green)

---

[**Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning**](https://doi.org/10.48550/arXiv.2205.09712) Ôºà**2022.05.19**Ôºâ

<font color="gray">Antonia Creswell, M. Shanahan, I. Higgins .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-38-green)

---

[**Can language models learn from explanations in context?**](https://doi.org/10.48550/arXiv.2204.02329) Ôºà**2022.04.05**Ôºâ

<font color="gray">Andrew Kyle Lampinen, I. Dasgupta, Stephanie C. Y. Chan, Kory Matthewson, Michael Henry Tessler, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-61-green)

---

[**STaR: Bootstrapping Reasoning With Reasoning**](https://doi.org/10.48550/arXiv.2203.14465) Ôºà**2022.03.28**Ôºâ

<font color="gray">E. Zelikman, Yuhuai Wu, Noah D. Goodman .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-56-green)  [![](https://img.shields.io/badge/Github%20Stars-15-blue)](https://github.com/ezelikman/STaR)

---

[**Self-Consistency Improves Chain of Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2203.11171) Ôºà**2022.03.21**Ôºâ

<font color="gray">Xuezhi Wang, Jason Wei, D. Schuurmans, Quoc Le, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-133-green)

---

[**Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data**](https://doi.org/10.48550/arXiv.2203.08773) Ôºà**2022.03.16**Ôºâ

<font color="gray">Shuo Wang, Yichong Xu, Yuwei Fang, Yang Liu, S. Sun, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-103-blue)](https://github.com/microsoft/reina)

---

[**Chain of Thought Prompting Elicits Reasoning in Large Language Models**](https://arxiv.org/abs/2201.11903) Ôºà**2022.01.28**Ôºâ

<font color="gray">Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-396-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-767-red)  [![](https://img.shields.io/badge/Github%20Stars-656-blue)](https://github.com/lupantech/chameleon-llm)

---

[**Show Your Work: Scratchpads for Intermediate Computation with Language Models**](https://arxiv.org/abs/2112.00114) Ôºà**2021.11.30**Ôºâ

<font color="gray">Maxwell Nye, Anders Andreassen, Guy Gur-Ari, H. Michalewski, Jacob Austin, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-123-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-104-red)

---

[**Few-Shot Self-Rationalization with Natural Language Prompts**](https://doi.org/10.18653/v1/2022.findings-naacl.31) Ôºà**2021.11.16**Ôºâ

<font color="gray">Ana Marasoviƒá, Iz Beltagy, Doug Downey, Matthew E. Peters .  - „ÄêNAACL-HLT„Äë</font>

![](https://img.shields.io/badge/Citations-29-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-43-red)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/allenai/feb)

---

[**Training Verifiers to Solve Math Word Problems**](https://arxiv.org/abs/2110.14168) Ôºà**2021.10.27**Ôºâ

<font color="gray">Karl Cobbe, V. Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-181-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-130-red)  [![](https://img.shields.io/badge/Github%20Stars-392-blue)](https://github.com/openai/grade-school-math)


</div>

# CONTINUE...