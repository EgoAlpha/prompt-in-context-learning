# üìÑ Chain of Thought

## Paper List

<div style="line-height:0.2em;">


[**Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models**](https://doi.org/10.48550/arXiv.2302.00618) Ôºà**2023.02.01**Ôºâ

<font color="gray">Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Large Language Models Are Reasoning Teachers**](https://doi.org/10.48550/arXiv.2212.10071) Ôºà**2022.12.20**Ôºâ

<font color="gray">Namgyu Ho, Laura Schmid, Se-Young Yun .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-55-blue)](https://github.com/zinengtang/VidLanKD)

---

[**The Impact of Symbolic Representations on In-context Learning for Few-shot Reasoning**](https://doi.org/10.48550/arXiv.2212.08686) Ôºà**2022.12.16**Ôºâ

<font color="gray">Hanlin Zhang, Yi-Fan Zhang, Li Erran Li, Eric Xing .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Complementary Explanations for Effective In-Context Learning**](https://doi.org/10.48550/arXiv.2211.13892) Ôºà**2022.11.25**Ôºâ

<font color="gray">Xi Ye, Srini Iyer, Asli Celikyilmaz, V. Stoyanov, Greg Durrett, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**Prompting GPT-3 To Be Reliable**](https://doi.org/10.48550/arXiv.2210.09150) Ôºà**2022.10.17**Ôºâ

<font color="gray">Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-47-blue)](https://github.com/noviscl/gpt3-reliability)

---

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) Ôºà**2022.10.17**Ôºâ

<font color="gray">Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-27-green)  [![](https://img.shields.io/badge/Github%20Stars-64-blue)](https://github.com/suzgunmirac/big-bench-hard)

---

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) Ôºà**2022.10.07**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Alexander J. Smola .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-23-green)  [![](https://img.shields.io/badge/Github%20Stars-288-blue)](https://github.com/amazon-research/auto-cot)

---

[**Measuring and Narrowing the Compositionality Gap in Language Models**](https://doi.org/10.48550/arXiv.2210.03350) Ôºà**2022.10.07**Ôºâ

<font color="gray">Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-27-green)  [![](https://img.shields.io/badge/Github%20Stars-163-blue)](https://github.com/ofirpress/self-ask)

---

[**Language Models are Multilingual Chain-of-Thought Reasoners**](https://doi.org/10.48550/arXiv.2210.03057) Ôºà**2022.10.06**Ôºâ

<font color="gray">Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-64-blue)](https://github.com/google-research/url-nlp)

---

[**Decomposed Prompting: A Modular Approach for Solving Complex Tasks**](https://doi.org/10.48550/arXiv.2210.02406) Ôºà**2022.10.05**Ôºâ

<font color="gray">Tushar Khot, H. Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-25-green)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/allenai/decomp)

---

[**Complexity-Based Prompting for Multi-Step Reasoning**](https://doi.org/10.48550/arXiv.2210.00720) Ôºà**2022.10.03**Ôºâ

<font color="gray">Yao Fu, Hao-Chun Peng, Ashish Sabharwal, Peter Clark, Tushar Khot .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/allenai/decomp)

---

[**Compositional Semantic Parsing with Large Language Models**](https://doi.org/10.48550/arXiv.2209.15003) Ôºà**2022.09.29**Ôºâ

<font color="gray">Andrew Drozdov, Nathanael Scharli, Ekin Akyuurek, Nathan Scales, Xinying Song, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-16-green)  [![](https://img.shields.io/badge/Github%20Stars-375-blue)](https://github.com/vacancy/NSCL-PyTorch-Release)

---

[**Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering**](https://doi.org/10.48550/arXiv.2209.09513) Ôºà**2022.09.20**Ôºâ

<font color="gray">Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-17-green)  [![](https://img.shields.io/badge/Github%20Stars-200-blue)](https://github.com/lupantech/ScienceQA)

---

[**Rationale-Augmented Ensembles in Language Models**](https://doi.org/10.48550/arXiv.2207.00747) Ôºà**2022.07.02**Ôºâ

<font color="gray">Xuezhi Wang, Jason Wei, D. Schuurmans, Quoc Le, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-26-green)

---

[**On the Advance of Making Language Models Better Reasoners**](https://doi.org/10.48550/arXiv.2206.02336) Ôºà**2022.06.06**Ôºâ

<font color="gray">Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-40-green)  [![](https://img.shields.io/badge/Github%20Stars-38-blue)](https://github.com/jind11/MMM-MCQA)

---

[**Large Language Models are Zero-Shot Reasoners**](https://arxiv.org/abs/2205.11916) Ôºà**2022.05.24**Ôºâ

<font color="gray">Takeshi Kojima, S. Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-185-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-301-red)  [![](https://img.shields.io/badge/Github%20Stars-142-blue)](https://github.com/kojima-takeshi188/zero_shot_cot)

---

[**Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2205.10625) Ôºà**2022.05.21**Ôºâ

<font color="gray">Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-85-green)

---

[**Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning**](https://doi.org/10.48550/arXiv.2205.09712) Ôºà**2022.05.19**Ôºâ

<font color="gray">Antonia Creswell, M. Shanahan, I. Higgins .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-38-green)

---

[**PaLM: Scaling Language Modeling with Pathways**](https://arxiv.org/abs/2204.02311) Ôºà**2022.04.05**Ôºâ

<font color="gray">Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-612-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-659-red)  [![](https://img.shields.io/badge/Github%20Stars-658-blue)](https://github.com/lucidrains/CoCa-pytorch)

---

[**Can language models learn from explanations in context?**](https://doi.org/10.48550/arXiv.2204.02329) Ôºà**2022.04.05**Ôºâ

<font color="gray">Andrew Kyle Lampinen, I. Dasgupta, Stephanie C. Y. Chan, Kory Matthewson, Michael Henry Tessler, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-61-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/sajedjalil/ChatGPT-Software-Testing-Study)

---

[**Training language models to follow instructions with human feedback**](https://doi.org/10.48550/arXiv.2203.02155) Ôºà**2022.03.04**Ôºâ

<font color="gray">Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-426-green)  [![](https://img.shields.io/badge/Github%20Stars-852-blue)](https://github.com/openai/following-instructions-human-feedback)

---

[**Chain of Thought Prompting Elicits Reasoning in Large Language Models**](https://arxiv.org/abs/2201.11903) Ôºà**2022.01.28**Ôºâ

<font color="gray">Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-384-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-558-red)  [![](https://img.shields.io/badge/Github%20Stars-142-blue)](https://github.com/kojima-takeshi188/zero_shot_cot)

---

[**Show Your Work: Scratchpads for Intermediate Computation with Language Models**](https://arxiv.org/abs/2112.00114) Ôºà**2021.11.30**Ôºâ

<font color="gray">Maxwell Nye, Anders Andreassen, Guy Gur-Ari, H. Michalewski, Jacob Austin, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-121-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-93-red)

---

[**Few-Shot Self-Rationalization with Natural Language Prompts**](https://doi.org/10.18653/v1/2022.findings-naacl.31) Ôºà**2021.11.16**Ôºâ

<font color="gray">Ana Marasoviƒá, Iz Beltagy, Doug Downey, Matthew E. Peters .  - „ÄêNAACL-HLT„Äë</font>

![](https://img.shields.io/badge/Citations-29-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-42-red)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/allenai/feb)

---

[**Training Verifiers to Solve Math Word Problems**](https://arxiv.org/abs/2110.14168) Ôºà**2021.10.27**Ôºâ

<font color="gray">Karl Cobbe, V. Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-175-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-105-red)  [![](https://img.shields.io/badge/Github%20Stars-321-blue)](https://github.com/openai/grade-school-math)

---

[**Evaluating Large Language Models Trained on Code**](https://arxiv.org/abs/2107.03374) Ôºà**2021.07.07**Ôºâ

<font color="gray">Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-604-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-567-red)  [![](https://img.shields.io/badge/Github%20Stars-515-blue)](https://github.com/openai/human-eval)

---

[**Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity**](https://doi.org/10.18653/v1/2022.acl-long.556) Ôºà**2021.04.18**Ôºâ

<font color="gray">Yao Lu, Max Bartolo, Alastair Moore, S. Riedel, Pontus Stenetorp .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-168-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-182-red)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/chicagohai/active-example-selection)

---

[**Making Pre-trained Language Models Better Few-shot Learners**](https://doi.org/10.18653/v1/2021.acl-long.295) Ôºà**2021.01.01**Ôºâ

<font color="gray">Tianyu Gao, Adam Fisch, Danqi Chen .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-642-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-704-red)  [![](https://img.shields.io/badge/Github%20Stars-631-blue)](https://github.com/princeton-nlp/LM-BFF)

---

[**Active Prompting with Chain-of-Thought for Large Language Models**](https://doi.org/10.48550/arXiv.2302.12246) 



![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-58-blue)](https://github.com/shizhediao/active-cot)

---

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://api.semanticscholar.org/780a7f5e8ba9b4b451e3dfee1bcfb0f68aba5050) 

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, G. Karypis, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-3.0k-blue)](https://github.com/amazon-science/mm-cot)

---

[**Faithful Chain-of-Thought Reasoning**](https://api.semanticscholar.org/ea0688f9e7dfb0d3c2249486af65209c25809544) 



![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-36-blue)](https://github.com/veronica320/faithful-cot)

---

[**Language Models are Unsupervised Multitask Learners**](https://api.semanticscholar.org/9405cc0d6169988371b2755e573cc28650d14dfe) 

<font color="gray">Alec Radford, Jeff Wu, Rewon Child, D. Luan, Dario Amodei, etc </font>

![](https://img.shields.io/badge/Citations-8878-green)  [![](https://img.shields.io/badge/Github%20Stars-7.9k-blue)](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/language_model/gpt)


</div>

# CONTINUE...
