# üìÑ Chain of Thought

## Paper List

<div style="line-height:0.2em;">


[**CodeFusion: A Pre-trained Diffusion Model for Code Generation**](https://arxiv.org/abs/2310.17680) Ôºà**2023.10.26**Ôºâ

<font color="gray">Mukul Singh, J. Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Models Cannot Self-Correct Reasoning Yet**](https://doi.org/10.48550/arXiv.2310.01798) Ôºà**2023.10.03**Ôºâ

<font color="gray">Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, A. Yu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)

---

[**A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future**](https://doi.org/10.48550/arXiv.2309.15402) Ôºà**2023.09.27**Ôºâ

<font color="gray">Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models**](https://doi.org/10.48550/arXiv.2309.12307) Ôºà**2023.09.21**Ôºâ

<font color="gray">Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai, Zhijian Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1.2k-blue)](https://github.com/dvlab-research/longlora)

---

[**Graph of Thoughts: Solving Elaborate Problems with Large Language Models**](https://doi.org/10.48550/arXiv.2308.09687) Ôºà**2023.08.18**Ôºâ

<font color="gray">Maciej Besta, Nils Blach, Ale≈° Kub√≠ƒçek, R. Gerstenberger, Lukas Gianinazzi, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-1.1k-blue)](https://github.com/spcl/graph-of-thoughts)

---

[**Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering**](https://doi.org/10.48550/arXiv.2308.07411) Ôºà**2023.08.14**Ôºâ

<font color="gray">Edward Junprung .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Cumulative Reasoning with Large Language Models**](https://doi.org/10.48550/arXiv.2308.04371) Ôºà**2023.08.08**Ôºâ

<font color="gray">Yifan Zhang, Jingqin Yang, Yang Yuan, A. Yao .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-90-blue)](https://github.com/iiis-ai/cumulative-reasoning)

---

[**AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?**](https://doi.org/10.48550/arXiv.2307.16368) Ôºà**2023.07.31**Ôºâ

<font color="gray">Qipeng Zhao, Ce Zhang, Shijie Wang, Changcheng Fu, Nakul Agarwal, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chain-Of-Thought Prompting Under Streaming Batch: A Case Study**](https://doi.org/10.48550/arXiv.2306.00550) Ôºà**2023.06.01**Ôºâ

<font color="gray">Yuxin Tang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Majority Rule: better patching via Self-Consistency**](https://doi.org/10.48550/arXiv.2306.00108) Ôºà**2023.05.31**Ôºâ

<font color="gray">Toufique Ahmed, Prem Devanbu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Strategic Reasoning with Language Models**](https://doi.org/10.48550/arXiv.2305.19165) Ôºà**2023.05.30**Ôºâ

<font color="gray">Kanishk Gandhi, Dorsa Sadigh, Noah D. Goodman .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2305.18507) Ôºà**2023.05.29**Ôºâ

<font color="gray">Y. Hu, Haotong Yang, Zhouchen Lin, Muhan Zhang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning**](https://doi.org/10.48550/arXiv.2305.18170) Ôºà**2023.05.29**Ôºâ

<font color="gray">Zhanming Jie, Wei Lu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/allanj/dynamic-pal)

---

[**Tab-CoT: Zero-shot Tabular Chain of Thought**](https://doi.org/10.48550/arXiv.2305.17812) Ôºà**2023.05.28**Ôºâ

<font color="gray">Ziqi Jin, Wei Lu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/xalp/tab-cot)

---

[**Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2305.16582) Ôºà**2023.05.26**Ôºâ

<font color="gray">Yao Yao, Z. Li, Hai Zhao .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting**](https://doi.org/10.48550/arXiv.2305.16896) Ôºà**2023.05.26**Ôºâ

<font color="gray">Tatsuro Inaba, Hirokazu Kiyomaru, Fei Cheng, S. Kurohashi .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/inabatatsuro/multitool-cot)

---

[**Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance**](https://doi.org/10.48550/arXiv.2305.17306) Ôºà**2023.05.26**Ôºâ

<font color="gray">Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao-Chun Peng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-1.5k-blue)](https://github.com/franxyao/chain-of-thought-hub)

---

[**Demo2Code: From Summarizing Demonstrations to Synthesizing Code via Extended Chain-of-Thought**](https://doi.org/10.48550/arXiv.2305.16744) Ôºà**2023.05.26**Ôºâ

<font color="gray">Huaxiaoyue Wang, Gonzalo Gonzalez-Pumariega, Yash Sharma, Sanjiban Choudhury .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective**](https://arxiv.org/abs/2305.15408) Ôºà**2023.05.24**Ôºâ

<font color="gray">Guhao Feng, Yuntian Gu, Bohang Zhang, Haotian Ye, Di He, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-26-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/guyuntian/CoT_benchmark)

---

[**Revisiting Parallel Context Windows: A Frustratingly Simple Alternative and Chain-of-Thought Deterioration**](https://arxiv.org/abs/2305.15262) Ôºà**2023.05.24**Ôºâ

<font color="gray">Kejuan Yang, Xiao Liu, Kaiwen Men, Aohan Zeng, Yuxiao Dong, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**In-Context Demonstration Selection with Cross Entropy Difference**](https://arxiv.org/abs/2305.14726) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Exploring Chain-of-Thought Style Prompting for Text-to-SQL**](https://doi.org/10.48550/arXiv.2305.14215) Ôºà**2023.05.23**Ôºâ

<font color="gray">Chang-You Tai, Ziru Chen, Tianshu Zhang, Xiang Deng, Huan Sun .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**"Is the Pope Catholic?" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures**](https://doi.org/10.48550/arXiv.2305.13826) Ôºà**2023.05.23**Ôºâ

<font color="gray">Zae Myung Kim, David E. Taylor, Dongyeop Kang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction**](https://doi.org/10.48550/arXiv.2305.13903) Ôºà**2023.05.23**Ôºâ

<font color="gray">Vaishnavi Himakunthala, Andy Ouyang, Daniel Rose, Ryan He, Alex Mei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models**](https://arxiv.org/abs/2305.14323) Ôºà**2023.05.23**Ôºâ

<font color="gray">Z. Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne Xin Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/rucaibox/chatcot)

---

[**The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning**](https://doi.org/10.48550/arXiv.2305.14045) Ôºà**2023.05.23**Ôºâ

<font color="gray">Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-81-blue)](https://github.com/kaist-lklab/cot-collection)

---

[**Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method**](https://doi.org/10.48550/arXiv.2305.13412) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yiming Wang, Zhuosheng Zhang, Rui Wang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-16-blue)](https://github.com/alsace08/sumcot)

---

[**LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4**](https://arxiv.org/abs/2305.12147) Ôºà**2023.05.20**Ôºâ

<font color="gray">Hanmeng Liu, Zhiyang Teng, Leyang Cui, Chaoli Zhang, Qiji Zhou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-33-blue)](https://github.com/csitfun/logicot)

---

[**SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs**](https://doi.org/10.48550/arXiv.2305.11461) Ôºà**2023.05.19**Ôºâ

<font color="gray">IokTong Lei, ZhiDong Deng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought**](https://doi.org/10.48550/arXiv.2305.11499) Ôºà**2023.05.19**Ôºâ

<font color="gray">Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chain-of-thought prompting for responding to in-depth dialogue questions with LLM**](https://doi.org/10.48550/arXiv.2305.11792) Ôºà**2023.05.19**Ôºâ

<font color="gray">Hongru Wang, Rui Wang, Fei Mi, Zezhong Wang, Rui-Lan Xu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/rulegreen/dialogue_cot)

---

[**Reasoning Implicit Sentiment with Chain-of-Thought Prompting**](https://doi.org/10.48550/arXiv.2305.11255) Ôºà**2023.05.18**Ôºâ

<font color="gray">Hao Fei, Bobo Li, Qianchu Liu, Lidong Bing, Fei Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-117-blue)](https://github.com/scofield7419/thor-isa)

---

[**Tree of Thoughts: Deliberate Problem Solving with Large Language Models**](https://doi.org/10.48550/arXiv.2305.10601) Ôºà**2023.05.17**Ôºâ

<font color="gray">Shunyu Yao, Dian Yu, Jeffrey Zhao, I. Shafran, T. Griffiths, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-3.1k-blue)](https://github.com/ysymyth/tree-of-thought-llm)

---

[**Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models**](https://doi.org/10.48550/arXiv.2305.10276) Ôºà**2023.05.17**Ôºâ

<font color="gray">Hanxu Hu, Hongyuan Lu, Huajian Zhang, Wai Lam, Yue Zhang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/hanxuhu/chain-of-symbol-planning)

---

[**Structured Chain-of-Thought Prompting for Code Generation**](https://arxiv.org/abs/2305.06599) Ôºà**2023.05.11**Ôºâ

<font color="gray">Jia Li, Ge Li, Yongming Li, Zhi Jin </font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-15-red)

---

[**Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting**](https://doi.org/10.48550/arXiv.2305.04388) Ôºà**2023.05.07**Ôºâ

<font color="gray">Miles Turpin, Julian Michael, Ethan Perez, Sam Bowman .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-20-blue)](https://github.com/milesaturpin/cot-unfaithfulness)

---

[**Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models**](https://doi.org/10.48550/arXiv.2305.04091) Ôºà**2023.05.06**Ôºâ

<font color="gray">Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-323-blue)](https://github.com/agi-edgerunners/plan-and-solve-prompting)

---

[**Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework**](https://doi.org/10.48550/arXiv.2305.03268) Ôºà**2023.05.05**Ôºâ

<font color="gray">Ruochen Zhao, Xingxuan Li, Shafiq R. Joty, Chengwei Qin, Lidong Bing .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-15-blue)](https://github.com/ruochenzhao/verify-and-edit)

---

[**T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering**](https://doi.org/10.48550/arXiv.2305.03453) Ôºà**2023.05.05**Ôºâ

<font color="gray">Lei Wang, Yilang Hu, Jiabang He, Xingdong Xu, Ning Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**An automatically discovered chain-of-thought prompt generalizes to novel models and datasets**](https://doi.org/10.48550/arXiv.2305.02897) Ôºà**2023.05.04**Ôºâ

<font color="gray">Konstantin Hebenstreit, Robert Praas, Louis P Kiesewetter, M. Samwald .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings**](https://doi.org/10.48550/arXiv.2305.02317) Ôºà**2023.05.03**Ôºâ

<font color="gray">Daniel Rose, Vaishnavi Himakunthala, Andy Ouyang, Ryan He, Alex Mei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SCOTT: Self-Consistent Chain-of-Thought Distillation**](https://doi.org/10.48550/arXiv.2305.01879) Ôºà**2023.05.03**Ôºâ

<font color="gray">Peifeng Wang, Zhengyang Wang, Zheng Li, Yifan Gao, Bing Yin, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models**](https://arxiv.org/abs/2304.11657) Ôºà**2023.04.23**Ôºâ

<font color="gray">Jiashuo Sun, Yi Luo, Yeyun Gong, Chen Lin, Yelong Shen, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-22-red)  [![](https://img.shields.io/badge/Github%20Stars-65-blue)](https://github.com/gasolsun36/iter-cot)

---

[**Chain of Thought Prompt Tuning in Vision Language Models**](https://arxiv.org/abs/2304.07919) Ôºà**2023.04.16**Ôºâ

<font color="gray">Jiaxin Ge, Hongyin Luo, Siyuan Qian, Yulu Gan, Jie Fu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)

---

[**Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media**](https://doi.org/10.48550/arXiv.2304.03087) Ôºà**2023.04.06**Ôºâ

<font color="gray">Bowen Zhang, Xianghua Fu, Daijun Ding, Hutchin Huang, Yangyang Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Active Prompting with Chain-of-Thought for Large Language Models**](https://doi.org/10.48550/arXiv.2302.12246) Ôºà**2023.02.23**Ôºâ

<font color="gray">Shizhe Diao, Pengcheng Wang, Yong Lin, Tong Zhang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-146-blue)](https://github.com/shizhediao/active-cot)

---

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2302.00923) Ôºà**2023.02.02**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, G. Karypis, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3.3k-blue)](https://github.com/amazon-science/mm-cot)

---

[**Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models**](https://doi.org/10.48550/arXiv.2302.00618) Ôºà**2023.02.01**Ôºâ

<font color="gray">Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Faithful Chain-of-Thought Reasoning**](https://doi.org/10.48550/arXiv.2301.13379) Ôºà**2023.01.31**Ôºâ

<font color="gray">QING LYU, Shreya Havaldar, Adam Stein, Li Zhang, D. Rao, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-66-blue)](https://github.com/veronica320/faithful-cot)

---

[**Large Language Models Are Reasoning Teachers**](https://doi.org/10.48550/arXiv.2212.10071) Ôºà**2022.12.20**Ôºâ

<font color="gray">Namgyu Ho, Laura Schmid, Se-Young Yun .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-89-blue)](https://github.com/itsnamgyu/reasoning-teacher)

---

[**Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks**](https://doi.org/10.48550/arXiv.2211.12588) Ôºà**2022.11.22**Ôºâ

<font color="gray">Wenhu Chen, Xueguang Ma, Xinyi Wang, William W. Cohen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-22-green)  [![](https://img.shields.io/badge/Github%20Stars-114-blue)](https://github.com/wenhuchen/program-of-thoughts)

---

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) Ôºà**2022.10.17**Ôºâ

<font color="gray">Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-29-green)  [![](https://img.shields.io/badge/Github%20Stars-121-blue)](https://github.com/suzgunmirac/big-bench-hard)

---

[**Large Language Models are few(1)-shot Table Reasoners**](https://doi.org/10.48550/arXiv.2210.06710) Ôºà**2022.10.13**Ôºâ

<font color="gray">Wenhu Chen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-10-green)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/wenhuchen/tablecot)

---

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) Ôºà**2022.10.07**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Alexander J. Smola .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)  [![](https://img.shields.io/badge/Github%20Stars-490-blue)](https://github.com/amazon-research/auto-cot)

---

[**Language Models are Multilingual Chain-of-Thought Reasoners**](https://doi.org/10.48550/arXiv.2210.03057) Ôºà**2022.10.06**Ôºâ

<font color="gray">Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-22-green)  [![](https://img.shields.io/badge/Github%20Stars-101-blue)](https://github.com/google-research/url-nlp)

---

[**Decomposed Prompting: A Modular Approach for Solving Complex Tasks**](https://doi.org/10.48550/arXiv.2210.02406) Ôºà**2022.10.05**Ôºâ

<font color="gray">Tushar Khot, H. Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-25-green)  [![](https://img.shields.io/badge/Github%20Stars-40-blue)](https://github.com/allenai/decomp)

---

[**Complexity-Based Prompting for Multi-Step Reasoning**](https://doi.org/10.48550/arXiv.2210.00720) Ôºà**2022.10.03**Ôºâ

<font color="gray">Yao Fu, Hao-Chun Peng, Ashish Sabharwal, Peter Clark, Tushar Khot .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)

---

[**Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought**](https://doi.org/10.48550/arXiv.2210.01240) Ôºà**2022.10.03**Ôºâ

<font color="gray">Abulhair Saparov, He He .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-38-blue)](https://github.com/asaparov/prontoqa)

---

[**Compositional Semantic Parsing with Large Language Models**](https://doi.org/10.48550/arXiv.2209.15003) Ôºà**2022.09.29**Ôºâ

<font color="gray">Andrew Drozdov, Nathanael Scharli, Ekin Akyuurek, Nathan Scales, Xinying Song, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-16-green)

---

[**Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering**](https://doi.org/10.48550/arXiv.2209.09513) Ôºà**2022.09.20**Ôºâ

<font color="gray">Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)  [![](https://img.shields.io/badge/Github%20Stars-314-blue)](https://github.com/lupantech/ScienceQA)

---

[**FOLIO: Natural Language Reasoning with First-Order Logic**](https://doi.org/10.48550/arXiv.2209.00840) Ôºà**2022.09.02**Ôºâ

<font color="gray">Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-54-blue)](https://github.com/yale-lily/folio)

---

[**Faithful Reasoning Using Large Language Models**](https://doi.org/10.48550/arXiv.2208.14271) Ôºà**2022.08.30**Ôºâ

<font color="gray">Antonia Creswell, M. Shanahan .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)

---

[**Rationale-Augmented Ensembles in Language Models**](https://doi.org/10.48550/arXiv.2207.00747) Ôºà**2022.07.02**Ôºâ

<font color="gray">Xuezhi Wang, Jason Wei, D. Schuurmans, Quoc Le, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-26-green)

---

[**On the Advance of Making Language Models Better Reasoners**](https://doi.org/10.48550/arXiv.2206.02336) Ôºà**2022.06.06**Ôºâ

<font color="gray">Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-40-green)

---

[**Large Language Models are Zero-Shot Reasoners**](https://arxiv.org/abs/2205.11916) Ôºà**2022.05.24**Ôºâ

<font color="gray">Takeshi Kojima, S. Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-187-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-431-red)  [![](https://img.shields.io/badge/Github%20Stars-205-blue)](https://github.com/kojima-takeshi188/zero_shot_cot)

---

[**Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2205.10625) Ôºà**2022.05.21**Ôºâ

<font color="gray">Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-90-green)

---

[**Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning**](https://doi.org/10.48550/arXiv.2205.09712) Ôºà**2022.05.19**Ôºâ

<font color="gray">Antonia Creswell, M. Shanahan, I. Higgins .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-38-green)

---

[**Can language models learn from explanations in context?**](https://doi.org/10.48550/arXiv.2204.02329) Ôºà**2022.04.05**Ôºâ

<font color="gray">Andrew Kyle Lampinen, I. Dasgupta, Stephanie C. Y. Chan, Kory Matthewson, Michael Henry Tessler, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-61-green)

---

[**STaR: Bootstrapping Reasoning With Reasoning**](https://doi.org/10.48550/arXiv.2203.14465) Ôºà**2022.03.28**Ôºâ

<font color="gray">E. Zelikman, Yuhuai Wu, Noah D. Goodman .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-56-green)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/ezelikman/STaR)

---

[**Self-Consistency Improves Chain of Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2203.11171) Ôºà**2022.03.21**Ôºâ

<font color="gray">Xuezhi Wang, Jason Wei, D. Schuurmans, Quoc Le, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-133-green)

---

[**Iteratively Prompt Pre-trained Language Models for Chain of Thought**](https://arxiv.org/abs/2203.08383) Ôºà**2022.03.16**Ôºâ

<font color="gray">Boshi Wang, Xiang Deng, Huan Sun .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-47-red)  [![](https://img.shields.io/badge/Github%20Stars-13-blue)](https://github.com/sunlab-osu/iterprompt)

---

[**Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data**](https://doi.org/10.48550/arXiv.2203.08773) Ôºà**2022.03.16**Ôºâ

<font color="gray">Shuo Wang, Yichong Xu, Yuwei Fang, Yang Liu, S. Sun, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-103-blue)](https://github.com/microsoft/reina)

---

[**Chain of Thought Prompting Elicits Reasoning in Large Language Models**](https://arxiv.org/abs/2201.11903) Ôºà**2022.01.28**Ôºâ

<font color="gray">Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-396-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-849-red)  [![](https://img.shields.io/badge/Github%20Stars-8.0k-blue)](https://github.com/microsoft/guidance)

---

[**Show Your Work: Scratchpads for Intermediate Computation with Language Models**](https://arxiv.org/abs/2112.00114) Ôºà**2021.11.30**Ôºâ

<font color="gray">Maxwell Nye, Anders Andreassen, Guy Gur-Ari, H. Michalewski, Jacob Austin, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-123-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-107-red)

---

[**Few-Shot Self-Rationalization with Natural Language Prompts**](https://doi.org/10.18653/v1/2022.findings-naacl.31) Ôºà**2021.11.16**Ôºâ

<font color="gray">Ana Marasoviƒá, Iz Beltagy, Doug Downey, Matthew E. Peters .  - „ÄêNAACL-HLT„Äë</font>

![](https://img.shields.io/badge/Citations-29-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-45-red)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/allenai/feb)

---

[**AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts**](https://doi.org/10.1145/3491102.3517582) Ôºà**2021.10.04**Ôºâ

<font color="gray">Tongshuang Sherry Wu, Michael Terry, Carrie J. Cai .  - „ÄêInternational Conference on Human Factors in Computing Systems„Äë</font>

![](https://img.shields.io/badge/Citations-45-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-67-red)


</div>

# CONTINUE...