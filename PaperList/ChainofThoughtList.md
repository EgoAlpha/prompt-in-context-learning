# üìÑ Chain of Thought

## Paper List

<div style="line-height:0.2em;">


[**An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models**](https://arxiv.org/abs/2406.05130) Ôºà**2024.06.07**Ôºâ

<font color="gray">Xiongtao Zhou, Jie He, Yuhua Ke, Guangyao Zhu, V'ictor Guti'errez-Basulto, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Cantor: Inspiring Multimodal Chain-of-Thought of MLLM**](https://doi.org/10.48550/arXiv.2404.16033) Ôºà**2024.04.24**Ôºâ

<font color="gray">Timin Gao, Peixian Chen, Mengdan Zhang, Chaoyou Fu, Yunhang Shen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**nicolay-r at SemEval-2024 Task 3: Using Flan-T5 for Reasoning Emotion Cause in Conversations with Chain-of-Thought on Emotion States**](https://arxiv.org/abs/2404.03361) Ôºà**2024.04.04**Ôºâ

<font color="gray">Nicolay Rusnachenko, Huizhi Liang </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/nicolay-r/thor-ecac)

---

[**Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models**](https://arxiv.org/abs/2404.03622) Ôºà**2024.04.04**Ôºâ

<font color="gray">Wenshan Wu, Shaoguang Mao, Yadong Zhang, Yan Xia, Li Dong, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-25-red)

---

[**Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought**](https://arxiv.org/abs/2404.03414) Ôºà**2024.04.04**Ôºâ

<font color="gray">Jooyoung Lee, Fan Yang, Thanh Tran, Qian Hu, Emre Barut, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)

---

[**Visual CoT: Unleashing Chain-of-Thought Reasoning in Multi-Modal Language Models**](https://arxiv.org/abs/2403.16999) Ôºà**2024.03.25**Ôºâ

<font color="gray">Hao Shao, Shengju Qian, Han Xiao, Guanglu Song, Zhuofan Zong, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)  [![](https://img.shields.io/badge/Github%20Stars-63-blue)](https://github.com/deepcs233/visual-cot)

---

[**A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students' Formative Assessment Responses in Science**](https://arxiv.org/abs/2403.14565) Ôºà**2024.03.21**Ôºâ

<font color="gray">Clayton Cohn, Nicole M. Hutchins, Tuan Le, Gautam Biswas </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning**](https://arxiv.org/abs/2403.07376) Ôºà**2024.03.12**Ôºâ

<font color="gray">Bingqian Lin, Yunshuang Nie, Ziming Wei, Jiaqi Chen, Shikui Ma, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-18-blue)](https://github.com/expectorlin/navcot)

---

[**ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis**](https://arxiv.org/abs/2403.06932) Ôºà**2024.03.11**Ôºâ

<font color="gray">Yanming Liu, Xinyue Peng, Tianyu Du, Jianwei Yin, Weihao Liu, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)  [![](https://img.shields.io/badge/Github%20Stars-27-blue)](https://github.com/oceanntwt/era-cot)

---

[**Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought**](https://arxiv.org/abs/2403.05518) Ôºà**2024.03.08**Ôºâ

<font color="gray">James Chua, Edward Rees, Hunar Batra, Samuel R. Bowman, Julian Michael, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chain-of-Thought Unfaithfulness as Disguised Accuracy**](https://doi.org/10.48550/arXiv.2402.14897) Ôºà**2024.02.22**Ôºâ

<font color="gray">Oliver Bentham, Nathan Stringham, Ana Marasovi'c .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chain-of-Thought Reasoning Without Prompting**](https://doi.org/10.48550/arXiv.2402.10200) Ôºà**2024.02.15**Ôºâ

<font color="gray">Xuezhi Wang, Denny Zhou .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding**](https://doi.org/10.48550/arXiv.2401.04398) Ôºà**2024.01.09**Ôºâ

<font color="gray">Zilong Wang, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Vincent Perot, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**A Logically Consistent Chain-of-Thought Approach for Stance Detection**](https://arxiv.org/abs/2312.16054) Ôºà**2023.12.26**Ôºâ

<font color="gray">Bowen Zhang, Daijun Ding, Liwen Jing, Hutchin Huang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Assessing the Impact of Prompting, Persona, and Chain of Thought Methods on ChatGPT's Arithmetic Capabilities**](https://arxiv.org/abs/2312.15006) Ôºà**2023.12.22**Ôºâ

<font color="gray">Yuhao Chen, Chloe Wong, Hanwen Yang, Juan Aguenza, Sai Bhujangari, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model**](https://arxiv.org/abs/2312.11370) Ôºà**2023.12.18**Ôºâ

<font color="gray">Jiahui Gao, Renjie Pi, Jipeng Zhang, Jiacheng Ye, Wanjun Zhong, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-106-blue)](https://github.com/pipilurj/g-llava)

---

[**ProCoT: Stimulating Critical Thinking and Writing of Students through Engagement with Large Language Models (LLMs)**](https://arxiv.org/abs/2312.09801) Ôºà**2023.12.15**Ôºâ

<font color="gray">Tosin P. Adewumi, Lama Alkhaled, Claudia Buck, Sergio Hernandez, Saga Brilioth, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)

---

[**Multi-modal Latent Space Learning for Chain-of-Thought Reasoning in Language Models**](https://arxiv.org/abs/2312.08762) Ôºà**2023.12.14**Ôºâ

<font color="gray">Liqi He, Zuchao Li, Xiantao Cai, Ping Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Control Risk for Potential Misuse of Artificial Intelligence in Science**](https://arxiv.org/abs/2312.06632) Ôºà**2023.12.11**Ôºâ

<font color="gray">Jiyan He, Weitao Feng, Yaosen Min, Jingwei Yi, Kunsheng Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)  [![](https://img.shields.io/badge/Github%20Stars-11-blue)](https://github.com/scimt/scimt-benchmark)

---

[**Chain-of-Thought in Neural Code Generation: From and For Lightweight Language Models**](https://arxiv.org/abs/2312.05562) Ôºà**2023.12.09**Ôºâ

<font color="gray">Guang Yang, Yu Zhou, Xiang Chen, Xiangyu Zhang, Terry Yue Zhuo, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/ntdxyg/cotton)

---

[**Latent Skill Discovery for Chain-of-Thought Reasoning**](https://arxiv.org/abs/2312.04684) Ôºà**2023.12.07**Ôºâ

<font color="gray">Zifan Xu, Haozhu Wang, Dmitriy Bespalov, Peter Stone, Yanjun Qi </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Computation of the optimal error exponent function for fixed-length lossy source coding in discrete memoryless sources**](https://arxiv.org/abs/2312.03784) Ôºà**2023.12.06**Ôºâ

<font color="gray">Yutaka Jitsumatsu </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**WonderJourney: Going from Anywhere to Everywhere**](https://arxiv.org/abs/2312.03884) Ôºà**2023.12.06**Ôºâ

<font color="gray">Hong-Xing Yu, Haoyi Duan, Junhwa Hur, Kyle Sargent, Michael Rubinstein, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-31-red)

---

[**Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models**](https://doi.org/10.48550/arXiv.2312.01714) Ôºà**2023.12.04**Ôºâ

<font color="gray">Bingshuai Liu, Chenyang Lyu, Zijun Min, Zhanyu Wang, Jinsong Su, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication**](https://doi.org/10.48550/arXiv.2312.01823) Ôºà**2023.12.04**Ôºâ

<font color="gray">Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng Guo, Junqi Dai, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-14-blue)](https://github.com/yinzhangyue/eot)

---

[**Training Chain-of-Thought via Latent-Variable Inference**](https://doi.org/10.48550/arXiv.2312.02179) Ôºà**2023.11.28**Ôºâ

<font color="gray">Du Phan, Matthew D. Hoffman, David Dohan, Sholto Douglas, Tuan Anh Le, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Compositional Chain-of-Thought Prompting for Large Multimodal Models**](https://doi.org/10.48550/arXiv.2311.17076) Ôºà**2023.11.27**Ôºâ

<font color="gray">Chancharik Mitra, Brandon Huang, Trevor Darrell, Roei Herzig .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-34-blue)](https://github.com/chancharikmitra/ccot)

---

[**Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions**](https://doi.org/10.48550/arXiv.2311.13982) Ôºà**2023.11.23**Ôºâ

<font color="gray">S. Cao, Jiajie Zhang, Jiaxin Shi, Xin Lv, Zijun Yao, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/thu-keg/probtree)

---

[**Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**](https://doi.org/10.48550/arXiv.2311.11797) Ôºà**2023.11.20**Ôºâ

<font color="gray">Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-316-blue)](https://github.com/zoeyyao27/cot-igniting-agent)

---

[**An Embodied Generalist Agent in 3D World**](https://doi.org/10.48550/arXiv.2311.12871) Ôºà**2023.11.18**Ôºâ

<font color="gray">Jiangyong Huang, Silong Yong, Xiaojian Ma, Xiongkun Linghu, Puhao Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-282-blue)](https://github.com/embodied-generalist/embodied-generalist)

---

[**TaCo: Enhancing Cross-Lingual Transfer for Low-Resource Languages in LLMs through Translation-Assisted Chain-of-Thought Processes**](https://doi.org/10.48550/arXiv.2311.10797) Ôºà**2023.11.17**Ôºâ

<font color="gray">Bibek Upadhayay, Vahid Behzadan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-11-blue)](https://github.com/unhsaillab/taco)

---

[**MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning**](https://doi.org/10.48550/arXiv.2311.10537) Ôºà**2023.11.16**Ôºâ

<font color="gray">Xiangru Tang, Anni Zou, Zhuosheng Zhang, Yilun Zhao, Xingyao Zhang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-188-blue)](https://github.com/gersteinlab/medagents)

---

[**Contrastive Chain-of-Thought Prompting**](https://doi.org/10.48550/arXiv.2311.09277) Ôºà**2023.11.15**Ôºâ

<font color="gray">Yew Ken Chia, Guizhen Chen, Anh Tuan Luu, Soujanya Poria, Lidong Bing .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-46-blue)](https://github.com/damo-nlp-sg/contrastive-cot)

---

[**Towards Verifiable Text Generation with Symbolic References**](https://doi.org/10.48550/arXiv.2311.09188) Ôºà**2023.11.15**Ôºâ

<font color="gray">Lucas Torroba Hennigen, Zejiang Shen, Aniruddha Nrusimha, Bernhard Gapp, David Sontag, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task**](https://doi.org/10.48550/arXiv.2311.09193) Ôºà**2023.11.15**Ôºâ

<font color="gray">Yifan Wu, Pengchuan Zhang, Wenhan Xiong, Barlas Oƒüuz, James C. Gee, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Learning skillful medium-range global weather forecasting.**](https://doi.org/10.1126/science.adi2336) Ôºà**2023.11.14**Ôºâ

<font color="gray">Remi Lam, Alvaro Sanchez-Gonzalez, Matthew Willson, Peter Wirnsberger, Meire Fortunato, etc .  - „ÄêScience„Äë</font>

![](https://img.shields.io/badge/Citations-8-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-549-red)

---

[**Fast Chain-of-Thought: A Glance of Future from Parallel Decoding Leads to Answers Faster**](https://doi.org/10.48550/arXiv.2311.08263) Ôºà**2023.11.14**Ôºâ

<font color="gray">Hongxuan Zhang, Zhining Liu, Jiaqi Zheng, Chenyi Zhuang, Jinjie Gu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-268-blue)](https://github.com/alipay/PainlessInferenceAcceleration)

---

[**Empowering Multi-step Reasoning across Languages via Tree-of-Thoughts**](https://doi.org/10.48550/arXiv.2311.08097) Ôºà**2023.11.14**Ôºâ

<font color="gray">Leonardo Ranaldi, F. M. Zanzotto .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning**](https://doi.org/10.48550/arXiv.2311.08505) Ôºà**2023.11.14**Ôºâ

<font color="gray">Xin Su, Tiep Le, Steven Bethard, Phillip Howard .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction**](https://doi.org/10.48550/arXiv.2311.05922) Ôºà**2023.11.10**Ôºâ

<font color="gray">Xilai Ma, Jing Li, Min Zhang .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Chain of Images for Intuitively Reasoning**](https://doi.org/10.48550/arXiv.2311.09241) Ôºà**2023.11.09**Ôºâ

<font color="gray">Fanxu Meng, Haotong Yang, Yiding Wang, Muhan Zhang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/graphpku/coi)

---

[**Can LLMs Follow Simple Rules?**](https://doi.org/10.48550/arXiv.2311.04235) Ôºà**2023.11.06**Ôºâ

<font color="gray">Norman Mu, Sarah Chen, Zifan Wang, Sizhe Chen, David Karamardian, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-199-blue)](https://github.com/normster/llm_rules)

---

[**Levels of AGI: Operationalizing Progress on the Path to AGI**](https://doi.org/10.48550/arXiv.2311.02462) Ôºà**2023.11.04**Ôºâ

<font color="gray">Meredith Ringel Morris, Jascha Narain Sohl-Dickstein, Noah Fiedel, T. Warkentin, Allan Dafoe, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Implicit Chain of Thought Reasoning via Knowledge Distillation**](https://doi.org/10.48550/arXiv.2311.01460) Ôºà**2023.11.02**Ôºâ

<font color="gray">Yuntian Deng, Kiran Prasad, Roland Fernandez, P. Smolensky, Vishrav Chaudhary, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection**](https://doi.org/10.48550/arXiv.2310.20256) Ôºà**2023.10.31**Ôºâ

<font color="gray">Tao Yang, Tianyuan Shi, Fanqi Wan, Xiaojun Quan, Qifan Wang, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-11-blue)](https://github.com/taoyang225/psycot)

---

[**Chain-of-Thought Embeddings for Stance Detection on Social Media**](https://doi.org/10.48550/arXiv.2310.19750) Ôºà**2023.10.30**Ôºâ

<font color="gray">Joseph Gatto, Omar Sharif, S. Preum .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-898-blue)](https://github.com/lastmile-ai/aiconfig)

---

[**ACT-SQL: In-Context Learning for Text-to-SQL with Automatically-Generated Chain-of-Thought**](https://doi.org/10.48550/arXiv.2310.17342) Ôºà**2023.10.26**Ôºâ

<font color="gray">Hanchong Zhang, Ruisheng Cao, Lu Chen, Hongshen Xu, Kai Yu .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-14-blue)](https://github.com/x-lance/text2sql-gpt)

---

[**CodeFusion: A Pre-trained Diffusion Model for Code Generation**](https://arxiv.org/abs/2310.17680) Ôºà**2023.10.26**Ôºâ

<font color="gray">Mukul Singh, J. Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-39-red)

---

[**DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2310.16436) Ôºà**2023.10.25**Ôºâ

<font color="gray">Ge Zheng, Bin Yang, Jiajin Tang, Hong-Yu Zhou, Sibei Yang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)

---

[**R3 Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context**](https://doi.org/10.48550/arXiv.2310.16535) Ôºà**2023.10.25**Ôºâ

<font color="gray">Qingyuan Tian, Hanlun Zhu, Lei Wang, Yang Li, Yunshi Lan .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning**](https://doi.org/10.48550/arXiv.2310.16049) Ôºà**2023.10.24**Ôºâ

<font color="gray">Zayne Sprague, Xi Ye, Kaj Bostrom, Swarat Chaudhuri, Greg Durrett .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/zayne-sprague/musr)

---

[**CPSeg: Finer-grained Image Semantic Segmentation via Chain-of-Thought Language Prompting**](https://doi.org/10.48550/arXiv.2310.16069) Ôºà**2023.10.24**Ôºâ

<font color="gray">Lei Li .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts**](https://doi.org/10.48550/arXiv.2310.14628) Ôºà**2023.10.23**Ôºâ

<font color="gray">Tengxiao Liu, Qipeng Guo, Yuqing Yang, Xiangkun Hu, Yue Zhang, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-22-blue)](https://github.com/tengxiaoliu/xot)

---

[**Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning across Languages**](https://doi.org/10.48550/arXiv.2310.14799) Ôºà**2023.10.23**Ôºâ

<font color="gray">Libo Qin, Qiguang Chen, Fuxuan Wei, Shijue Huang, Wanxiang Che .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/lightchen233/cross-lingual-prompting)

---

[**Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study on Syllogism**](https://doi.org/10.48550/arXiv.2310.14868) Ôºà**2023.10.23**Ôºâ

<font color="gray">Mengyu Ye, Tatsuki Kuribayashi, Jun Suzuki, Goro Kobayashi, Hiroaki Funayama .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine Chain-of-Thought Prompting for Multi-domain NLU Tasks**](https://doi.org/10.48550/arXiv.2310.14623) Ôºà**2023.10.23**Ôºâ

<font color="gray">Hoang Nguyen, Ye Liu, Chenwei Zhang, Tao Zhang, Philip S. Yu .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/nhhoang96/cof-cot)

---

[**Retrieval-Augmented Chain-of-Thought in Semi-structured Domains**](https://doi.org/10.48550/arXiv.2310.14435) Ôºà**2023.10.22**Ôºâ

<font color="gray">Vaibhav Mavi, Abulhair Saparov, Chen Zhao .  - „ÄêNLLP„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Why Can Large Language Models Generate Correct Chain-of-Thoughts?**](https://doi.org/10.48550/arXiv.2310.13571) Ôºà**2023.10.20**Ôºâ

<font color="gray">Rasul Tutunov, Antoine Grosnit, Juliusz Ziomek, Jun Wang, Haitham Bou-Ammar .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning**](https://doi.org/10.48550/arXiv.2310.13552) Ôºà**2023.10.20**Ôºâ

<font color="gray">Jinyuan Wang, Junlong Li, Hai Zhao .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-16-blue)](https://github.com/noewangjy/sp-cot)

---

[**Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding**](https://doi.org/10.48550/arXiv.2310.11721) Ôºà**2023.10.18**Ôºâ

<font color="gray">Caoyun Fan, Jidong Tian, Yitian Li, Wenqing Chen, Hao He, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models**](https://doi.org/10.48550/arXiv.2310.12049) Ôºà**2023.10.18**Ôºâ

<font color="gray">Patrick Y. Wu, Jonathan Nagler, Joshua A. Tucker, Solomon Messing .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for Code Generation**](https://doi.org/10.48550/arXiv.2310.10698) Ôºà**2023.10.16**Ôºâ

<font color="gray">Yingwei Ma, Yue Yu, Shanshan Li, Yu Jiang, Yong Guo, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models**](https://doi.org/10.48550/arXiv.2310.06692) Ôºà**2023.10.10**Ôºâ

<font color="gray">Anni Zou, Zhuosheng Zhang, Hai Zhao, Xiangru Tang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Towards Better Chain-of-Thought Prompting Strategies: A Survey**](https://doi.org/10.48550/arXiv.2310.04959) Ôºà**2023.10.08**Ôºâ

<font color="gray">Zihan Yu, Liang He, Zhen Wu, Xinyu Dai, Jiajun Chen .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-8-green)

---

[**Large Language Models Cannot Self-Correct Reasoning Yet**](https://doi.org/10.48550/arXiv.2310.01798) Ôºà**2023.10.03**Ôºâ

<font color="gray">Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, A. Yu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/mbzuai-clear/ioe-prompting)

---

[**A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future**](https://doi.org/10.48550/arXiv.2309.15402) Ôºà**2023.09.27**Ôºâ

<font color="gray">Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic**](https://doi.org/10.48550/arXiv.2309.13339) Ôºà**2023.09.23**Ôºâ

<font color="gray">Xufeng Zhao, Mengdi Li, Wenhao Lu, C. Weber, Jae Hee Lee, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/xf-zhao/lot)

---

[**LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models**](https://doi.org/10.48550/arXiv.2309.12307) Ôºà**2023.09.21**Ôºâ

<font color="gray">Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai, Zhijian Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2.5k-blue)](https://github.com/dvlab-research/longlora)

---

[**FedLogic: Interpretable Federated Multi-Domain Chain-of-Thought Prompt Selection for Large Language Models**](https://doi.org/10.48550/arXiv.2308.15324) Ôºà**2023.08.29**Ôºâ

<font color="gray">Pengwei Xing, Songtao Lu, Han Yu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Graph of Thoughts: Solving Elaborate Problems with Large Language Models**](https://doi.org/10.48550/arXiv.2308.09687) Ôºà**2023.08.18**Ôºâ

<font color="gray">Maciej Besta, Nils Blach, Ale≈° Kub√≠ƒçek, R. Gerstenberger, Lukas Gianinazzi, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-2.0k-blue)](https://github.com/spcl/graph-of-thoughts)

---

[**Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering**](https://doi.org/10.48550/arXiv.2308.07411) Ôºà**2023.08.14**Ôºâ

<font color="gray">Edward Junprung .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Cumulative Reasoning with Large Language Models**](https://doi.org/10.48550/arXiv.2308.04371) Ôºà**2023.08.08**Ôºâ

<font color="gray">Yifan Zhang, Jingqin Yang, Yang Yuan, A. Yao .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-265-blue)](https://github.com/iiis-ai/cumulative-reasoning)

---

[**Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics**](https://doi.org/10.48550/arXiv.2307.02502) Ôºà**2023.07.04**Ôºâ

<font color="gray">M. Swan, Takashi Kido, Eric Roland, R. P. D. Santos .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Chain-Of-Thought Prompting Under Streaming Batch: A Case Study**](https://doi.org/10.48550/arXiv.2306.00550) Ôºà**2023.06.01**Ôºâ

<font color="gray">Yuxin Tang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Majority Rule: better patching via Self-Consistency**](https://doi.org/10.48550/arXiv.2306.00108) Ôºà**2023.05.31**Ôºâ

<font color="gray">Toufique Ahmed, Prem Devanbu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Strategic Reasoning with Language Models**](https://doi.org/10.48550/arXiv.2305.19165) Ôºà**2023.05.30**Ôºâ

<font color="gray">Kanishk Gandhi, Dorsa Sadigh, Noah D. Goodman .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2305.18507) Ôºà**2023.05.29**Ôºâ

<font color="gray">Y. Hu, Haotong Yang, Zhouchen Lin, Muhan Zhang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning**](https://doi.org/10.48550/arXiv.2305.18170) Ôºà**2023.05.29**Ôºâ

<font color="gray">Zhanming Jie, Wei Lu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/allanj/dynamic-pal)

---

[**Tab-CoT: Zero-shot Tabular Chain of Thought**](https://doi.org/10.48550/arXiv.2305.17812) Ôºà**2023.05.28**Ôºâ

<font color="gray">Ziqi Jin, Wei Lu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-25-blue)](https://github.com/xalp/tab-cot)

---

[**Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2305.16582) Ôºà**2023.05.26**Ôºâ

<font color="gray">Yao Yao, Z. Li, Hai Zhao .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting**](https://doi.org/10.48550/arXiv.2305.16896) Ôºà**2023.05.26**Ôºâ

<font color="gray">Tatsuro Inaba, Hirokazu Kiyomaru, Fei Cheng, S. Kurohashi .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/inabatatsuro/multitool-cot)

---

[**Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance**](https://doi.org/10.48550/arXiv.2305.17306) Ôºà**2023.05.26**Ôºâ

<font color="gray">Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao-Chun Peng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-2.4k-blue)](https://github.com/franxyao/chain-of-thought-hub)

---

[**Demo2Code: From Summarizing Demonstrations to Synthesizing Code via Extended Chain-of-Thought**](https://doi.org/10.48550/arXiv.2305.16744) Ôºà**2023.05.26**Ôºâ

<font color="gray">Huaxiaoyue Wang, Gonzalo Gonzalez-Pumariega, Yash Sharma, Sanjiban Choudhury .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-12-blue)](https://github.com/portal-cornell/robotouille)

---

[**Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective**](https://arxiv.org/abs/2305.15408) Ôºà**2023.05.24**Ôºâ

<font color="gray">Guhao Feng, Yuntian Gu, Bohang Zhang, Haotian Ye, Di He, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-54-red)

---

[**Revisiting Parallel Context Windows: A Frustratingly Simple Alternative and Chain-of-Thought Deterioration**](https://arxiv.org/abs/2305.15262) Ôºà**2023.05.24**Ôºâ

<font color="gray">Kejuan Yang, Xiao Liu, Kaiwen Men, Aohan Zeng, Yuxiao Dong, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**In-Context Demonstration Selection with Cross Entropy Difference**](https://arxiv.org/abs/2305.14726) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)  [![](https://img.shields.io/badge/Github%20Stars-3.4k-blue)](https://github.com/microsoft/lmops)

---

[**Exploring Chain-of-Thought Style Prompting for Text-to-SQL**](https://doi.org/10.48550/arXiv.2305.14215) Ôºà**2023.05.23**Ôºâ

<font color="gray">Chang-You Tai, Ziru Chen, Tianshu Zhang, Xiang Deng, Huan Sun .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**"Is the Pope Catholic?" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures**](https://doi.org/10.48550/arXiv.2305.13826) Ôºà**2023.05.23**Ôºâ

<font color="gray">Zae Myung Kim, David E. Taylor, Dongyeop Kang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction**](https://doi.org/10.48550/arXiv.2305.13903) Ôºà**2023.05.23**Ôºâ

<font color="gray">Vaishnavi Himakunthala, Andy Ouyang, Daniel Rose, Ryan He, Alex Mei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models**](https://arxiv.org/abs/2305.14323) Ôºà**2023.05.23**Ôºâ

<font color="gray">Z. Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne Xin Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-27-red)  [![](https://img.shields.io/badge/Github%20Stars-41-blue)](https://github.com/rucaibox/chatcot)

---

[**The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning**](https://doi.org/10.48550/arXiv.2305.14045) Ôºà**2023.05.23**Ôºâ

<font color="gray">Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-193-blue)](https://github.com/kaistai/cot-collection)

---

[**Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method**](https://doi.org/10.48550/arXiv.2305.13412) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yiming Wang, Zhuosheng Zhang, Rui Wang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-48-blue)](https://github.com/alsace08/sumcot)

---

[**LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4**](https://arxiv.org/abs/2305.12147) Ôºà**2023.05.20**Ôºâ

<font color="gray">Hanmeng Liu, Zhiyang Teng, Leyang Cui, Chaoli Zhang, Qiji Zhou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs**](https://doi.org/10.48550/arXiv.2305.11461) Ôºà**2023.05.19**Ôºâ

<font color="gray">IokTong Lei, ZhiDong Deng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought**](https://doi.org/10.48550/arXiv.2305.11499) Ôºà**2023.05.19**Ôºâ

<font color="gray">Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chain-of-thought prompting for responding to in-depth dialogue questions with LLM**](https://doi.org/10.48550/arXiv.2305.11792) Ôºà**2023.05.19**Ôºâ

<font color="gray">Hongru Wang, Rui Wang, Fei Mi, Zezhong Wang, Rui-Lan Xu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Reasoning Implicit Sentiment with Chain-of-Thought Prompting**](https://doi.org/10.48550/arXiv.2305.11255) Ôºà**2023.05.18**Ôºâ

<font color="gray">Hao Fei, Bobo Li, Qianchu Liu, Lidong Bing, Fei Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-73-blue)](https://github.com/scofield7419/thor-isa)

---

[**Tree of Thoughts: Deliberate Problem Solving with Large Language Models**](https://doi.org/10.48550/arXiv.2305.10601) Ôºà**2023.05.17**Ôºâ

<font color="gray">Shunyu Yao, Dian Yu, Jeffrey Zhao, I. Shafran, T. Griffiths, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-4.4k-blue)](https://github.com/princeton-nlp/tree-of-thought-llm)

---

[**Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models**](https://doi.org/10.48550/arXiv.2305.10276) Ôºà**2023.05.17**Ôºâ

<font color="gray">Hanxu Hu, Hongyuan Lu, Huajian Zhang, Wai Lam, Yue Zhang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/hanxuhu/chain-of-symbol-planning)

---

[**Structured Chain-of-Thought Prompting for Code Generation**](https://arxiv.org/abs/2305.06599) Ôºà**2023.05.11**Ôºâ

<font color="gray">Jia Li, Ge Li, Yongming Li, Zhi Jin </font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-15-red)

---

[**Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting**](https://doi.org/10.48550/arXiv.2305.04388) Ôºà**2023.05.07**Ôºâ

<font color="gray">Miles Turpin, Julian Michael, Ethan Perez, Sam Bowman .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-29-blue)](https://github.com/milesaturpin/cot-unfaithfulness)

---

[**Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models**](https://doi.org/10.48550/arXiv.2305.04091) Ôºà**2023.05.06**Ôºâ

<font color="gray">Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-545-blue)](https://github.com/agi-edgerunners/plan-and-solve-prompting)

---

[**Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework**](https://doi.org/10.48550/arXiv.2305.03268) Ôºà**2023.05.05**Ôºâ

<font color="gray">Ruochen Zhao, Xingxuan Li, Shafiq R. Joty, Chengwei Qin, Lidong Bing .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-37-blue)](https://github.com/ruochenzhao/verify-and-edit)

---

[**T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering**](https://doi.org/10.48550/arXiv.2305.03453) Ôºà**2023.05.05**Ôºâ

<font color="gray">Lei Wang, Yilang Hu, Jiabang He, Xingdong Xu, Ning Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**An automatically discovered chain-of-thought prompt generalizes to novel models and datasets**](https://doi.org/10.48550/arXiv.2305.02897) Ôºà**2023.05.04**Ôºâ

<font color="gray">Konstantin Hebenstreit, Robert Praas, Louis P Kiesewetter, M. Samwald .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings**](https://doi.org/10.48550/arXiv.2305.02317) Ôºà**2023.05.03**Ôºâ

<font color="gray">Daniel Rose, Vaishnavi Himakunthala, Andy Ouyang, Ryan He, Alex Mei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SCOTT: Self-Consistent Chain-of-Thought Distillation**](https://doi.org/10.48550/arXiv.2305.01879) Ôºà**2023.05.03**Ôºâ

<font color="gray">Peifeng Wang, Zhengyang Wang, Zheng Li, Yifan Gao, Bing Yin, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-34-blue)](https://github.com/wangpf3/consistent-cot-distillation)

---

[**Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes**](https://doi.org/10.48550/arXiv.2305.02301) Ôºà**2023.05.03**Ôºâ

<font color="gray">Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-59-green)

---

[**Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models**](https://arxiv.org/abs/2304.11657) Ôºà**2023.04.23**Ôºâ

<font color="gray">Jiashuo Sun, Yi Luo, Yeyun Gong, Chen Lin, Yelong Shen, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-36-red)  [![](https://img.shields.io/badge/Github%20Stars-77-blue)](https://github.com/gasolsun36/iter-cot)

---

[**Chain of Thought Prompt Tuning in Vision Language Models**](https://arxiv.org/abs/2304.07919) Ôºà**2023.04.16**Ôºâ

<font color="gray">Jiaxin Ge, Hongyin Luo, Siyuan Qian, Yulu Gan, Jie Fu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-40-red)

---

[**Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media**](https://doi.org/10.48550/arXiv.2304.03087) Ôºà**2023.04.06**Ôºâ

<font color="gray">Bowen Zhang, Xianghua Fu, Daijun Ding, Hutchin Huang, Yangyang Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Narrator: Towards Natural Control of Human-Scene Interaction Generation via Relationship Reasoning**](https://doi.org/10.48550/arXiv.2303.09410) Ôºà**2023.03.16**Ôºâ

<font color="gray">Haibiao Xuan, Xiongzheng Li, Jinsong Zhang, Hongwen Zhang, Yebin Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Active Prompting with Chain-of-Thought for Large Language Models**](https://doi.org/10.48550/arXiv.2302.12246) Ôºà**2023.02.23**Ôºâ

<font color="gray">Shizhe Diao, Pengcheng Wang, Yong Lin, Tong Zhang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-203-blue)](https://github.com/shizhediao/active-cot)

---

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2302.00923) Ôºà**2023.02.02**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, G. Karypis, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3.7k-blue)](https://github.com/amazon-science/mm-cot)

---

[**Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models**](https://doi.org/10.48550/arXiv.2302.00618) Ôºà**2023.02.01**Ôºâ

<font color="gray">Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Faithful Chain-of-Thought Reasoning**](https://doi.org/10.48550/arXiv.2301.13379) Ôºà**2023.01.31**Ôºâ

<font color="gray">QING LYU, Shreya Havaldar, Adam Stein, Li Zhang, D. Rao, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-150-blue)](https://github.com/veronica320/faithful-cot)

---

[**Large Language Models Are Reasoning Teachers**](https://doi.org/10.48550/arXiv.2212.10071) Ôºà**2022.12.20**Ôºâ

<font color="gray">Namgyu Ho, Laura Schmid, Se-Young Yun .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-297-blue)](https://github.com/itsnamgyu/reasoning-teacher)

---

[**Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks**](https://doi.org/10.48550/arXiv.2211.12588) Ôºà**2022.11.22**Ôºâ

<font color="gray">Wenhu Chen, Xueguang Ma, Xinyi Wang, William W. Cohen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-22-green)  [![](https://img.shields.io/badge/Github%20Stars-210-blue)](https://github.com/wenhuchen/program-of-thoughts)

---

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) Ôºà**2022.10.17**Ôºâ

<font color="gray">Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-29-green)  [![](https://img.shields.io/badge/Github%20Stars-388-blue)](https://github.com/suzgunmirac/big-bench-hard)

---

[**Large Language Models are few(1)-shot Table Reasoners**](https://doi.org/10.48550/arXiv.2210.06710) Ôºà**2022.10.13**Ôºâ

<font color="gray">Wenhu Chen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-10-green)  [![](https://img.shields.io/badge/Github%20Stars-33-blue)](https://github.com/wenhuchen/tablecot)

---

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) Ôºà**2022.10.07**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Alexander J. Smola .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)  [![](https://img.shields.io/badge/Github%20Stars-1.3k-blue)](https://github.com/amazon-science/auto-cot)

---

[**Language Models are Multilingual Chain-of-Thought Reasoners**](https://doi.org/10.48550/arXiv.2210.03057) Ôºà**2022.10.06**Ôºâ

<font color="gray">Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-22-green)  [![](https://img.shields.io/badge/Github%20Stars-173-blue)](https://github.com/google-research/url-nlp)

---

[**Decomposed Prompting: A Modular Approach for Solving Complex Tasks**](https://doi.org/10.48550/arXiv.2210.02406) Ôºà**2022.10.05**Ôºâ

<font color="gray">Tushar Khot, H. Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-25-green)  [![](https://img.shields.io/badge/Github%20Stars-80-blue)](https://github.com/allenai/decomp)

---

[**Complexity-Based Prompting for Multi-Step Reasoning**](https://doi.org/10.48550/arXiv.2210.00720) Ôºà**2022.10.03**Ôºâ

<font color="gray">Yao Fu, Hao-Chun Peng, Ashish Sabharwal, Peter Clark, Tushar Khot .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)

---

[**Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought**](https://doi.org/10.48550/arXiv.2210.01240) Ôºà**2022.10.03**Ôºâ

<font color="gray">Abulhair Saparov, He He .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-97-blue)](https://github.com/asaparov/prontoqa)

---

[**Compositional Semantic Parsing with Large Language Models**](https://doi.org/10.48550/arXiv.2209.15003) Ôºà**2022.09.29**Ôºâ

<font color="gray">Andrew Drozdov, Nathanael Scharli, Ekin Akyuurek, Nathan Scales, Xinying Song, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-16-green)

---

[**Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering**](https://doi.org/10.48550/arXiv.2209.09513) Ôºà**2022.09.20**Ôºâ

<font color="gray">Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)  [![](https://img.shields.io/badge/Github%20Stars-564-blue)](https://github.com/lupantech/ScienceQA)

---

[**FOLIO: Natural Language Reasoning with First-Order Logic**](https://doi.org/10.48550/arXiv.2209.00840) Ôºà**2022.09.02**Ôºâ

<font color="gray">Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-104-blue)](https://github.com/yale-lily/folio)

---

[**Faithful Reasoning Using Large Language Models**](https://doi.org/10.48550/arXiv.2208.14271) Ôºà**2022.08.30**Ôºâ

<font color="gray">Antonia Creswell, M. Shanahan .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)

---

[**Rationale-Augmented Ensembles in Language Models**](https://doi.org/10.48550/arXiv.2207.00747) Ôºà**2022.07.02**Ôºâ

<font color="gray">Xuezhi Wang, Jason Wei, D. Schuurmans, Quoc Le, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-26-green)

---

[**On the Advance of Making Language Models Better Reasoners**](https://doi.org/10.48550/arXiv.2206.02336) Ôºà**2022.06.06**Ôºâ

<font color="gray">Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-40-green)

---

[**Large Language Models are Zero-Shot Reasoners**](https://arxiv.org/abs/2205.11916) Ôºà**2022.05.24**Ôºâ

<font color="gray">Takeshi Kojima, S. Gu, Machel Reid, Yutaka Matsuo, Yusuke Iwasawa .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-187-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-928-red)

---

[**Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2205.10625) Ôºà**2022.05.21**Ôºâ

<font color="gray">Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-90-green)  [![](https://img.shields.io/badge/Github%20Stars-451-blue)](https://github.com/RUCAIBox/LLMBox)

---

[**Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning**](https://doi.org/10.48550/arXiv.2205.09712) Ôºà**2022.05.19**Ôºâ

<font color="gray">Antonia Creswell, M. Shanahan, I. Higgins .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-38-green)

---

[**Can language models learn from explanations in context?**](https://doi.org/10.48550/arXiv.2204.02329) Ôºà**2022.04.05**Ôºâ

<font color="gray">Andrew Kyle Lampinen, I. Dasgupta, Stephanie C. Y. Chan, Kory Matthewson, Michael Henry Tessler, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-61-green)

---

[**STaR: Bootstrapping Reasoning With Reasoning**](https://doi.org/10.48550/arXiv.2203.14465) Ôºà**2022.03.28**Ôºâ

<font color="gray">E. Zelikman, Yuhuai Wu, Noah D. Goodman .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-56-green)  [![](https://img.shields.io/badge/Github%20Stars-77-blue)](https://github.com/ezelikman/STaR)

---

[**Self-Consistency Improves Chain of Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2203.11171) Ôºà**2022.03.21**Ôºâ

<font color="gray">Xuezhi Wang, Jason Wei, D. Schuurmans, Quoc Le, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-133-green)  [![](https://img.shields.io/badge/Github%20Stars-898-blue)](https://github.com/lastmile-ai/aiconfig/tree/main/cookbooks/Multi-LLM-Consistency)

---

[**Iteratively Prompt Pre-trained Language Models for Chain of Thought**](https://arxiv.org/abs/2203.08383) Ôºà**2022.03.16**Ôºâ

<font color="gray">Boshi Wang, Xiang Deng, Huan Sun .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-74-red)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/sunlab-osu/iterprompt)

---

[**Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data**](https://doi.org/10.48550/arXiv.2203.08773) Ôºà**2022.03.16**Ôºâ

<font color="gray">Shuo Wang, Yichong Xu, Yuwei Fang, Yang Liu, S. Sun, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-116-blue)](https://github.com/microsoft/reina)

---

[**Chain of Thought Prompting Elicits Reasoning in Large Language Models**](https://arxiv.org/abs/2201.11903) Ôºà**2022.01.28**Ôºâ

<font color="gray">Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, E. Chi, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-396-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2.2k-red)  [![](https://img.shields.io/badge/Github%20Stars-18.1k-blue)](https://github.com/guidance-ai/guidance)

---

[**Show Your Work: Scratchpads for Intermediate Computation with Language Models**](https://arxiv.org/abs/2112.00114) Ôºà**2021.11.30**Ôºâ

<font color="gray">Maxwell Nye, Anders Andreassen, Guy Gur-Ari, H. Michalewski, Jacob Austin, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-123-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-171-red)

---

[**Few-Shot Self-Rationalization with Natural Language Prompts**](https://doi.org/10.18653/v1/2022.findings-naacl.31) Ôºà**2021.11.16**Ôºâ

<font color="gray">Ana Marasoviƒá, Iz Beltagy, Doug Downey, Matthew E. Peters .  - „ÄêNAACL-HLT„Äë</font>

![](https://img.shields.io/badge/Citations-29-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-58-red)  [![](https://img.shields.io/badge/Github%20Stars-13-blue)](https://github.com/allenai/feb)

---

[**AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts**](https://doi.org/10.1145/3491102.3517582) Ôºà**2021.10.04**Ôºâ

<font color="gray">Tongshuang Sherry Wu, Michael Terry, Carrie J. Cai .  - „ÄêInternational Conference on Human Factors in Computing Systems„Äë</font>

![](https://img.shields.io/badge/Citations-45-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-172-red)


</div>

# CONTINUE...