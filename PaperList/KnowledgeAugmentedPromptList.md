# üìÑ Knowledge Augmented Prompts

## Paper List

<div style="line-height:0.2em;">


[**Mitigating Temporal Misalignment by Discarding Outdated Facts**](https://arxiv.org/abs/2305.14824) Ôºà**2023.05.24**Ôºâ

<font color="gray">Michael J.Q. Zhang, Eunsol Choi </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Are Pre-trained Language Models Useful for Model Ensemble in Chinese Grammatical Error Correction?**](https://arxiv.org/abs/2305.15183) Ôºà**2023.05.24**Ôºâ

<font color="gray">Chenming Tang, Xiuyu Wu, Yunfang Wu </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Referral Augmentation for Zero-Shot Information Retrieval**](https://arxiv.org/abs/2305.15098) Ôºà**2023.05.24**Ôºâ

<font color="gray">Michael Tang, Shunyu Yao, John Yang, Karthik Narasimhan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Decomposing Complex Queries for Tip-of-the-tongue Retrieval**](https://arxiv.org/abs/2305.15053) Ôºà**2023.05.24**Ôºâ

<font color="gray">Kevin Lin, Kyle Lo, Joseph E. Gonzalez, Dan Klein </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**How to Distill your BERT: An Empirical Study on the Impact of Weight Initialisation and Distillation Objectives**](https://arxiv.org/abs/2305.15032) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xinpeng Wang, Leonie Weissweiler, Hinrich Schutze, Barbara Plank </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/mainlp/how-to-distill-your-bert)

---

[**ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification**](https://arxiv.org/abs/2305.15024) Ôºà**2023.05.24**Ôºâ

<font color="gray">Biao Zhao, Weiqiang Jin, Javier Del Ser, Guang Yang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LLMDet: A Large Language Models Detection Tool**](https://arxiv.org/abs/2305.15004) Ôºà**2023.05.24**Ôºâ

<font color="gray">Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng, Tat-Seng Chua </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**OverPrompt: Enhancing ChatGPT Capabilities through an Efficient In-Context Learning Approach**](https://arxiv.org/abs/2305.14973) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiazheng Li, Runcong Zhao, Yulan He, Lin Gui </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification**](https://arxiv.org/abs/2305.14963) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yau-Shian Wang, Ta-Chung Chi, Ruohong Zhang, Yiming Yang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Adversarial Demonstration Attacks on Large Language Models**](https://arxiv.org/abs/2305.14950) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiongxiao Wang, Zichen Liu, Keun Hee Park, Muhao Chen, Chaowei Xiao </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Frugal Prompting for Dialog Models**](https://arxiv.org/abs/2305.14919) Ôºà**2023.05.24**Ôºâ

<font color="gray">Bishal Santra, Sakya Basak, Abhinandan De, Manish Gupta, Pawan Goyal </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Coverage-based Example Selection for In-Context Learning**](https://arxiv.org/abs/2305.14907) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shivanshu Gupta, Sameer Singh, Matt Gardner </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Machine Reading Comprehension using Case-based Reasoning**](https://arxiv.org/abs/2305.14815) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dung Thai, Dhruv Agarwal, Mudit Chaudhary, R. Das, M. Zaheer, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Exploring Diverse In-Context Configurations for Image Captioning**](https://arxiv.org/abs/2305.14800) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xu Yang, Yongliang Wu, Mingzhuo Yang, Haokun Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2.1k-blue)](https://github.com/mlfoundations/open_flamingo)

---

[**Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification**](https://arxiv.org/abs/2305.14794) Ôºà**2023.05.24**Ôºâ

<font color="gray">Chengyu Dong, Zihan Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Bi-Drop: Generalizable Fine-tuning for Pre-trained Language Models via Adaptive Subnetwork Optimization**](https://arxiv.org/abs/2305.14760) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shoujie Tong, Heming Xia, Damai Dai, Tianyu Liu, Binghuai Lin, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**In-Context Demonstration Selection with Cross Entropy Difference**](https://arxiv.org/abs/2305.14726) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**A Causal View of Entity Bias in (Large) Language Models**](https://arxiv.org/abs/2305.14695) Ôºà**2023.05.24**Ôºâ

<font color="gray">Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**KNN-LM Does Not Improve Open-ended Text Generation**](https://arxiv.org/abs/2305.14625) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shufan Wang, Yixiao Song, Andrew Drozdov, Aparna Garimella, Varun Manjunatha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning**](https://arxiv.org/abs/2305.14160) Ôºà**2023.05.23**Ôºâ

<font color="gray">Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Improving Language Models via Plug-and-Play Retrieval Feedback**](https://arxiv.org/abs/2305.14002) Ôºà**2023.05.23**Ôºâ

<font color="gray">Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, Ashish Sabharwal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Concept-aware Training Improves In-context Learning Ability of Language Models**](https://arxiv.org/abs/2305.13775) Ôºà**2023.05.23**Ôºâ

<font color="gray">Michal vStef'anik, Marek Kadlvc'ik </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker**](https://arxiv.org/abs/2305.13729) Ôºà**2023.05.23**Ôºâ

<font color="gray">Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, Jong C. Park </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**RetICL: Sequential Retrieval of In-Context Examples with Reinforcement Learning**](https://arxiv.org/abs/2305.14502) Ôºà**2023.05.23**Ôºâ

<font color="gray">Alexander Scarlatos, Andrew Lan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**From Characters to Words: Hierarchical Pre-trained Language Model for Open-vocabulary Language Understanding**](https://arxiv.org/abs/2305.14571) Ôºà**2023.05.23**Ôºâ

<font color="gray">Li Sun, Florian Luisier, Kayhan Batmanghelich, Dinei Florencio, Cha Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders**](https://arxiv.org/abs/2305.14499) Ôºà**2023.05.23**Ôºâ

<font color="gray">Livio Baldini Soares, Daniel Gillick, Jeremy R. Cole, Tom Kwiatkowski </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Knowledge-Retrieval Task-Oriented Dialog Systems with Semi-Supervision**](https://arxiv.org/abs/2305.13199) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yucheng Cai, Hong Liu, Zhijian Ou, Y. Huang, Junlan Feng </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Sentence Representations via Gaussian Embedding**](https://arxiv.org/abs/2305.12990) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shohei Yoda, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer**](https://arxiv.org/abs/2305.12761) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shuang Li, Xuming Hu, Aiwei Liu, Yawen Yang, Fukun Ma, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches**](https://arxiv.org/abs/2305.12749) Ôºà**2023.05.22**Ôºâ

<font color="gray">Zihan Wang, Tianle Wang, Dheeraj Mekala, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Can We Edit Factual Knowledge by In-Context Learning?**](https://arxiv.org/abs/2305.12740) Ôºà**2023.05.22**Ôºâ

<font color="gray">Ce Zheng, Lei Li, Qingxiu Dong, Yuxuan Fan, Zhiyong Wu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-16-blue)](https://github.com/zce1112zslx/ike)

---

[**Iterative Forward Tuning Boosts In-context Learning in Language Models**](https://arxiv.org/abs/2305.13016) Ôºà**2023.05.22**Ôºâ

<font color="gray">Jiaxi Yang, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Infor-Coef: Information Bottleneck-based Dynamic Token Downsampling for Compact and Efficient language model**](https://arxiv.org/abs/2305.12458) Ôºà**2023.05.21**Ôºâ

<font color="gray">Wenxin Tan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text**](https://arxiv.org/abs/2305.12599) Ôºà**2023.05.21**Ôºâ

<font color="gray">Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/strong-ai-lab/logical-equivalence-driven-amr-data-augmentation-for-representation-learning)

---

[**Automated Few-shot Classification with Instruction-Finetuned Language Models**](https://arxiv.org/abs/2305.12576) Ôºà**2023.05.21**Ôºâ

<font color="gray">Rami Aly, Xingjian Shi, Kaixiang Lin, Aston Zhang, A. Wilson </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Retrieving Texts based on Abstract Descriptions**](https://arxiv.org/abs/2305.12517) Ôºà**2023.05.21**Ôºâ

<font color="gray">Shauli Ravfogel, Valentina Pyatkin, Amir D. N. Cohen, Avshalom Manevich, Yoav Goldberg </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers**](https://arxiv.org/abs/2305.12567) Ôºà**2023.05.21**Ôºâ

<font color="gray">Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/gonglinyuan/metro_t0)

---

[**IR Models and the COVID-19 Pandemic: A Comparative Study of Performance and Challenges (preprint)**](https://arxiv.org/abs/2305.12528) Ôºà**2023.05.21**Ôºâ

<font color="gray">Moksh Shukla, Niti Jain, Shubham Gupta </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Decouple knowledge from paramters for plug-and-play language modeling**](https://doi.org/10.48550/arXiv.2305.11564) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xin Cheng, Yankai Lin, Xiuying Chen, Dongyan Zhao, Rui Yan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/hannibal046/pluglm)

---

[**SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs**](https://doi.org/10.48550/arXiv.2305.11461) Ôºà**2023.05.19**Ôºâ

<font color="gray">IokTong Lei, ZhiDong Deng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions**](https://doi.org/10.48550/arXiv.2305.11460) Ôºà**2023.05.19**Ôºâ

<font color="gray">Shiyao Ding, Takayuki Ito .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning**](https://doi.org/10.48550/arXiv.2305.11759) Ôºà**2023.05.19**Ôºâ

<font color="gray">Mustafa Safa Ozdayi, Charith S. Peris, Jack G. M. FitzGerald, Christophe Dupuy, Jimit Majmudar, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models**](https://doi.org/10.48550/arXiv.2305.11414) Ôºà**2023.05.19**Ôºâ

<font color="gray">Sixing Yu, J. P. Mu√±oz, A. Jannesari .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning**](https://doi.org/10.48550/arXiv.2305.11383) Ôºà**2023.05.19**Ôºâ

<font color="gray">Po-Nien Kung, Nanyun Peng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**AutoTrial: Prompting Language Models for Clinical Trial Design**](https://doi.org/10.48550/arXiv.2305.11366) Ôºà**2023.05.19**Ôºâ

<font color="gray">Zifeng Wang, Cao Xiao, Jimeng Sun .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Democratized Diffusion Language Model**](https://doi.org/10.48550/arXiv.2305.10818) Ôºà**2023.05.18**Ôºâ

<font color="gray">Nikita Balagansky, Daniil Gavrilov .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Learning In-context Learning for Named Entity Recognition**](https://doi.org/10.48550/arXiv.2305.11038) Ôºà**2023.05.18**Ôºâ

<font color="gray">Jiawei Chen, Yaojie Lu, Hongyu Lin, Jie Lou, Wei Jia, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings**](https://doi.org/10.48550/arXiv.2305.10786) Ôºà**2023.05.18**Ôºâ

<font color="gray">Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Chong Deng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ahead-of-Time P-Tuning**](https://doi.org/10.48550/arXiv.2305.10835) Ôºà**2023.05.18**Ôºâ

<font color="gray">Daniil Gavrilov, Nikita Balagansky .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ReGen: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval**](https://doi.org/10.48550/arXiv.2305.10703) Ôºà**2023.05.18**Ôºâ

<font color="gray">Yue Yu, Yuchen Zhuang, Rongzhi Zhang, Yu Meng, Jiaming Shen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/yueyu1030/ReGen)

---

[**LIMA: Less Is More for Alignment**](https://doi.org/10.48550/arXiv.2305.11206) Ôºà**2023.05.18**Ôºâ

<font color="gray">Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Efficient Prompting via Dynamic In-Context Learning**](https://doi.org/10.48550/arXiv.2305.11170) Ôºà**2023.05.18**Ôºâ

<font color="gray">Wangchunshu Zhou, Yuchen Jiang, Ryan Cotterell, Mrinmaya Sachan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The Web Can Be Your Oyster for Improving Large Language Models**](https://doi.org/10.48550/arXiv.2305.10998) Ôºà**2023.05.18**Ôºâ

<font color="gray">Junyi Li, Tianyi Tang, Wayne Xin Zhao, Jingyuan Wang, J. Nie, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**TOME: A Two-stage Approach for Model-based Retrieval**](https://doi.org/10.48550/arXiv.2305.11161) Ôºà**2023.05.18**Ôºâ

<font color="gray">Ruiyang Ren, Wayne Xin Zhao, J. Liu, Huaqin Wu, Ji-rong Wen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt**](https://doi.org/10.48550/arXiv.2305.11186) Ôºà**2023.05.17**Ôºâ

<font color="gray">Zhaozhuo Xu, Zirui Liu, Beidi Chen, Yuxin Tang, Jue Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SPSQL: Step-by-step Parsing Based Framework for Text-to-SQL Generation**](https://doi.org/10.48550/arXiv.2305.11061) Ôºà**2023.05.10**Ôºâ

<font color="gray">Ran Shen, Gang Sun, Hao Shen, Yiling Li, Liangfeng Jin, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model**](https://arxiv.org/abs/2304.06248) Ôºà**2023.04.13**Ôºâ

<font color="gray">Hao Fei, Shengqiong Wu, Jingye Li, Bobo Li, Fei Li, etc </font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-26-blue)](https://github.com/chocowu/lasuie)

---

[**Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation**](https://doi.org/10.48550/arXiv.2302.01441) Ôºà**2023.02.02**Ôºâ

<font color="gray">Yiren Liu, H. Kilicoglu .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**REPLUG: Retrieval-Augmented Black-Box Language Models**](https://doi.org/10.48550/arXiv.2301.12652) Ôºà**2023.01.30**Ôºâ

<font color="gray">Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Self-Instruct: Aligning Language Model with Self Generated Instructions**](https://doi.org/10.48550/arXiv.2212.10560) Ôºà**2022.12.20**Ôºâ

<font color="gray">Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-2.3k-blue)](https://github.com/yizhongw/self-instruct)

---

[**One Embedder, Any Task: Instruction-Finetuned Text Embeddings**](https://doi.org/10.48550/arXiv.2212.09741) Ôºà**2022.12.19**Ôºâ

<font color="gray">Hongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-606-blue)](https://github.com/HKUNLP/instructor-embedding)

---

[**The Impact of Symbolic Representations on In-context Learning for Few-shot Reasoning**](https://doi.org/10.48550/arXiv.2212.08686) Ôºà**2022.12.16**Ôºâ

<font color="gray">Hanlin Zhang, Yi-Fan Zhang, Li Erran Li, Eric P. Xing .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/hlzhang109/lmlp)

---

[**Don‚Äôt Prompt, Search! Mining-based Zero-Shot Learning with Language Models**](https://doi.org/10.48550/arXiv.2210.14803) Ôºà**2022.10.26**Ôºâ

<font color="gray">Mozes van de Kar, M. Xia, Danqi Chen, Mikel Artetxe .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding**](https://doi.org/10.48550/arXiv.2210.08536) Ôºà**2022.10.16**Ôºâ

<font color="gray">J. Wang, Wenkang Huang, Qiuhui Shi, Hongbin Wang, Minghui Qiu, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/wjn1996/kp-plm)

---

[**Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding**](https://doi.org/10.48550/arXiv.2210.03304) Ôºà**2022.10.07**Ôºâ

<font color="gray">Zhichao Yang, Shufan Wang, Bhanu Pratap Singh Rawat, Avijit Mitra, Hong Yu .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-28-blue)](https://github.com/whaleloops/KEPT)

---

[**Promptagator: Few-shot Dense Retrieval From 8 Examples**](https://doi.org/10.48550/arXiv.2209.11755) Ôºà**2022.09.23**Ôºâ

<font color="gray">Zhuyun Dai, Vincent Zhao, Ji Ma, Yi Luan, Jianmo Ni, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-16-green)

---

[**Unified Knowledge Prompt Pre-training for Customer Service Dialogues**](https://doi.org/10.1145/3511808.3557718) Ôºà**2022.08.31**Ôºâ

<font color="gray">Keqing He, Jingang Wang, Chaobo Sun, Wei Wu .  - „ÄêInternational Conference on Information and Knowledge Management„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)

---

[**DocPrompting: Generating Code by Retrieving the Docs**](https://arxiv.org/abs/2207.05987) Ôºà**2022.07.13**Ôºâ

<font color="gray">Shuyan Zhou, Uri Alon, Frank F. Xu, Zhiruo Wang, Zhengbao Jiang, etc </font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-24-red)  [![](https://img.shields.io/badge/Github%20Stars-164-blue)](https://github.com/shuyanzhou/docprompting)

---

[**Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning**](https://doi.org/10.1145/3534678.3539382) Ôºà**2022.06.19**Ôºâ

<font color="gray">Xiaolei Wang, Kun Zhou, Ji-rong Wen, Wayne Xin Zhao .  - „ÄêKnowledge Discovery and Data Mining„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-35-red)  [![](https://img.shields.io/badge/Github%20Stars-49-blue)](https://github.com/rucaibox/unicrs)

---

[**Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning**](https://doi.org/10.48550/arXiv.2205.14704) Ôºà**2022.05.29**Ôºâ

<font color="gray">Xiang Chen, Lei Li, Ningyu Zhang, Xiaozhuan Liang, Shumin Deng, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-389-blue)](https://github.com/zjunlp/promptkg)

---

[**Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt Tuning**](https://doi.org/10.1145/3477495.3531746) Ôºà**2022.05.04**Ôºâ

<font color="gray">Xiang Chen, Lei Li, Ningyu Zhang, Chuanqi Tan, Fei Huang, etc .  - „ÄêAnnual International ACM SIGIR Conference on Research and Development in Information Retrieval„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-27-red)  [![](https://img.shields.io/badge/Github%20Stars-389-blue)](https://github.com/zjunlp/PromptKG/tree/main/research/RetrievalRE)

---

[**Contrastive Demonstration Tuning for Pre-trained Language Models**](https://doi.org/10.48550/arXiv.2204.04392) Ôºà**2022.04.09**Ôºâ

<font color="gray">Xiaozhuan Liang, Ningyu Zhang, Ningyu Zhang, Siyuan Cheng, Zhen Bi, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-389-blue)](https://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning)

---

[**Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)**](https://doi.org/10.1145/3523227.3546767) Ôºà**2022.03.24**Ôºâ

<font color="gray">Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, Yongfeng Zhang .  - „ÄêACM Conference on Recommender Systems„Äë</font>

![](https://img.shields.io/badge/Citations-22-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-64-red)  [![](https://img.shields.io/badge/Github%20Stars-128-blue)](https://github.com/jeykigung/P5)

---

[**Multi-Stage Prompting for Knowledgeable Dialogue Generation**](https://doi.org/10.48550/arXiv.2203.08745) Ôºà**2022.03.16**Ôºâ

<font color="gray">Zihan Liu, M. Patwary, R. Prenger, Shrimai Prabhumoye, Wei Ping, etc .  - „ÄêFindings„Äë</font>

![](https://img.shields.io/badge/Citations-12-green)  [![](https://img.shields.io/badge/Github%20Stars-5.1k-blue)](https://github.com/NVIDIA/Megatron-LM)

---

[**Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data**](https://doi.org/10.48550/arXiv.2203.08773) Ôºà**2022.03.16**Ôºâ

<font color="gray">Shuo Wang, Yichong Xu, Yuwei Fang, Yang Liu, S. Sun, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-103-blue)](https://github.com/microsoft/reina)

---

[**AdaPrompt: Adaptive Model Training for Prompt-based NLP**](https://arxiv.org/abs/2202.04824) Ôºà**2022.02.10**Ôºâ

<font color="gray">Yulong Chen, Yang Liu, Li Dong, Shuohang Wang, Chenguang Zhu, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-11-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-58-red)

---

[**Generated Knowledge Prompting for Commonsense Reasoning**](https://doi.org/10.18653/v1/2022.acl-long.225) Ôºà**2021.10.15**Ôºâ

<font color="gray">Jiacheng Liu, Alisa Liu, Ximing Lu, S. Welleck, Peter West, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-37-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-155-red)  [![](https://img.shields.io/badge/Github%20Stars-53-blue)](https://github.com/liujch1998/gkp)

---

[**Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction**](https://doi.org/10.18653/v1/2021.emnlp-main.92) Ôºà**2021.09.08**Ôºâ

<font color="gray">Oscar Sainz, Oier Lopez de Lacalle, Gorka Labaka, Ander Barrena, Eneko Agirre .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-36-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-112-red)  [![](https://img.shields.io/badge/Github%20Stars-139-blue)](https://github.com/osainz59/Ask2Transformers)

---

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification**](https://doi.org/10.18653/v1/2022.acl-long.158) Ôºà**2021.08.04**Ôºâ

<font color="gray">Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Juan-Zi Li, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-95-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-237-red)  [![](https://img.shields.io/badge/Github%20Stars-166-blue)](https://github.com/thunlp/knowledgeableprompttuning)

---

[**PTR: Prompt Tuning with Rules for Text Classification**](https://doi.org/10.1016/j.aiopen.2022.11.003) Ôºà**2021.05.24**Ôºâ

<font color="gray">Xu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, Maosong Sun .  - „ÄêAI Open„Äë</font>

![](https://img.shields.io/badge/Citations-172-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-247-red)  [![](https://img.shields.io/badge/Github%20Stars-140-blue)](https://github.com/thunlp/PTR)

---

[**Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks**](https://arxiv.org/abs/2005.11401) Ôºà**2020.05.22**Ôºâ

<font color="gray">Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, etc .  - „ÄêNeural Information Processing Systems„Äë</font>

![](https://img.shields.io/badge/Citations-551-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-719-red)  [![](https://img.shields.io/badge/Github%20Stars-101.5k-blue)](https://github.com/huggingface/transformers)

---

[**REALM: Retrieval-Augmented Language Model Pre-Training**](https://arxiv.org/abs/2002.08909) Ôºà**2020.02.10**Ôºâ

<font color="gray">Kelvin Guu, Kenton Lee, Z. Tung, Panupong Pasupat, Ming-Wei Chang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-542-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-845-red)  [![](https://img.shields.io/badge/Github%20Stars-1.4k-blue)](https://github.com/google-research/language/tree/master/language/realm)

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

[**Prompt as a Knowledge Probe for Chinese Spelling Check**](https://doi.org/10.1007/978-3-031-10989-8_41) 

<font color="gray">Kun Peng, Nannan Sun, Jiahao Cao, Rui Liu, Jiaqian Ren, etc .  - „ÄêKnowledge Science, Engineering and Management„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text ClassiÔ¨Åcation Rolling Review submission**](https://api.semanticscholar.org/80366efe644f9fa5d1e89775eb7cb135ca46582f) 



![](https://img.shields.io/badge/Citations-0-green)


</div>

# CONTINUE...