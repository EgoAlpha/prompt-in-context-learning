# 📄 Knowledge Augmented Prompts

## Paper List

<div style="line-height:0.2em;">


[**Mitigating Temporal Misalignment by Discarding Outdated Facts**](https://arxiv.org/abs/2305.14824) （**2023.05.24**）

<font color="gray">Michael J.Q. Zhang, Eunsol Choi </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Are Pre-trained Language Models Useful for Model Ensemble in Chinese Grammatical Error Correction?**](https://arxiv.org/abs/2305.15183) （**2023.05.24**）

<font color="gray">Chenming Tang, Xiuyu Wu, Yunfang Wu </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Referral Augmentation for Zero-Shot Information Retrieval**](https://arxiv.org/abs/2305.15098) （**2023.05.24**）

<font color="gray">Michael Tang, Shunyu Yao, John Yang, Karthik Narasimhan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Decomposing Complex Queries for Tip-of-the-tongue Retrieval**](https://arxiv.org/abs/2305.15053) （**2023.05.24**）

<font color="gray">Kevin Lin, Kyle Lo, Joseph E. Gonzalez, Dan Klein </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**How to Distill your BERT: An Empirical Study on the Impact of Weight Initialisation and Distillation Objectives**](https://arxiv.org/abs/2305.15032) （**2023.05.24**）

<font color="gray">Xinpeng Wang, Leonie Weissweiler, Hinrich Schutze, Barbara Plank </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/mainlp/how-to-distill-your-bert)

---

[**ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification**](https://arxiv.org/abs/2305.15024) （**2023.05.24**）

<font color="gray">Biao Zhao, Weiqiang Jin, Javier Del Ser, Guang Yang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LLMDet: A Large Language Models Detection Tool**](https://arxiv.org/abs/2305.15004) （**2023.05.24**）

<font color="gray">Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng, Tat-Seng Chua </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**OverPrompt: Enhancing ChatGPT Capabilities through an Efficient In-Context Learning Approach**](https://arxiv.org/abs/2305.14973) （**2023.05.24**）

<font color="gray">Jiazheng Li, Runcong Zhao, Yulan He, Lin Gui </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification**](https://arxiv.org/abs/2305.14963) （**2023.05.24**）

<font color="gray">Yau-Shian Wang, Ta-Chung Chi, Ruohong Zhang, Yiming Yang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Adversarial Demonstration Attacks on Large Language Models**](https://arxiv.org/abs/2305.14950) （**2023.05.24**）

<font color="gray">Jiongxiao Wang, Zichen Liu, Keun Hee Park, Muhao Chen, Chaowei Xiao </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Frugal Prompting for Dialog Models**](https://arxiv.org/abs/2305.14919) （**2023.05.24**）

<font color="gray">Bishal Santra, Sakya Basak, Abhinandan De, Manish Gupta, Pawan Goyal </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Coverage-based Example Selection for In-Context Learning**](https://arxiv.org/abs/2305.14907) （**2023.05.24**）

<font color="gray">Shivanshu Gupta, Sameer Singh, Matt Gardner </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Machine Reading Comprehension using Case-based Reasoning**](https://arxiv.org/abs/2305.14815) （**2023.05.24**）

<font color="gray">Dung Thai, Dhruv Agarwal, Mudit Chaudhary, R. Das, M. Zaheer, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Exploring Diverse In-Context Configurations for Image Captioning**](https://arxiv.org/abs/2305.14800) （**2023.05.24**）

<font color="gray">Xu Yang, Yongliang Wu, Mingzhuo Yang, Haokun Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2.1k-blue)](https://github.com/mlfoundations/open_flamingo)

---

[**Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification**](https://arxiv.org/abs/2305.14794) （**2023.05.24**）

<font color="gray">Chengyu Dong, Zihan Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Bi-Drop: Generalizable Fine-tuning for Pre-trained Language Models via Adaptive Subnetwork Optimization**](https://arxiv.org/abs/2305.14760) （**2023.05.24**）

<font color="gray">Shoujie Tong, Heming Xia, Damai Dai, Tianyu Liu, Binghuai Lin, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**In-Context Demonstration Selection with Cross Entropy Difference**](https://arxiv.org/abs/2305.14726) （**2023.05.24**）

<font color="gray">Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**A Causal View of Entity Bias in (Large) Language Models**](https://arxiv.org/abs/2305.14695) （**2023.05.24**）

<font color="gray">Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**KNN-LM Does Not Improve Open-ended Text Generation**](https://arxiv.org/abs/2305.14625) （**2023.05.24**）

<font color="gray">Shufan Wang, Yixiao Song, Andrew Drozdov, Aparna Garimella, Varun Manjunatha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning**](https://arxiv.org/abs/2305.14160) （**2023.05.23**）

<font color="gray">Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Improving Language Models via Plug-and-Play Retrieval Feedback**](https://arxiv.org/abs/2305.14002) （**2023.05.23**）

<font color="gray">Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, Ashish Sabharwal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Concept-aware Training Improves In-context Learning Ability of Language Models**](https://arxiv.org/abs/2305.13775) （**2023.05.23**）

<font color="gray">Michal vStef'anik, Marek Kadlvc'ik </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker**](https://arxiv.org/abs/2305.13729) （**2023.05.23**）

<font color="gray">Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, Jong C. Park </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**RetICL: Sequential Retrieval of In-Context Examples with Reinforcement Learning**](https://arxiv.org/abs/2305.14502) （**2023.05.23**）

<font color="gray">Alexander Scarlatos, Andrew Lan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**From Characters to Words: Hierarchical Pre-trained Language Model for Open-vocabulary Language Understanding**](https://arxiv.org/abs/2305.14571) （**2023.05.23**）

<font color="gray">Li Sun, Florian Luisier, Kayhan Batmanghelich, Dinei Florencio, Cha Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders**](https://arxiv.org/abs/2305.14499) （**2023.05.23**）

<font color="gray">Livio Baldini Soares, Daniel Gillick, Jeremy R. Cole, Tom Kwiatkowski </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Knowledge-Retrieval Task-Oriented Dialog Systems with Semi-Supervision**](https://arxiv.org/abs/2305.13199) （**2023.05.22**）

<font color="gray">Yucheng Cai, Hong Liu, Zhijian Ou, Y. Huang, Junlan Feng </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Sentence Representations via Gaussian Embedding**](https://arxiv.org/abs/2305.12990) （**2023.05.22**）

<font color="gray">Shohei Yoda, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer**](https://arxiv.org/abs/2305.12761) （**2023.05.22**）

<font color="gray">Shuang Li, Xuming Hu, Aiwei Liu, Yawen Yang, Fukun Ma, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches**](https://arxiv.org/abs/2305.12749) （**2023.05.22**）

<font color="gray">Zihan Wang, Tianle Wang, Dheeraj Mekala, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Can We Edit Factual Knowledge by In-Context Learning?**](https://arxiv.org/abs/2305.12740) （**2023.05.22**）

<font color="gray">Ce Zheng, Lei Li, Qingxiu Dong, Yuxuan Fan, Zhiyong Wu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-16-blue)](https://github.com/zce1112zslx/ike)

---

[**Iterative Forward Tuning Boosts In-context Learning in Language Models**](https://arxiv.org/abs/2305.13016) （**2023.05.22**）

<font color="gray">Jiaxi Yang, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Infor-Coef: Information Bottleneck-based Dynamic Token Downsampling for Compact and Efficient language model**](https://arxiv.org/abs/2305.12458) （**2023.05.21**）

<font color="gray">Wenxin Tan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text**](https://arxiv.org/abs/2305.12599) （**2023.05.21**）

<font color="gray">Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/strong-ai-lab/logical-equivalence-driven-amr-data-augmentation-for-representation-learning)

---

[**Automated Few-shot Classification with Instruction-Finetuned Language Models**](https://arxiv.org/abs/2305.12576) （**2023.05.21**）

<font color="gray">Rami Aly, Xingjian Shi, Kaixiang Lin, Aston Zhang, A. Wilson </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Retrieving Texts based on Abstract Descriptions**](https://arxiv.org/abs/2305.12517) （**2023.05.21**）

<font color="gray">Shauli Ravfogel, Valentina Pyatkin, Amir D. N. Cohen, Avshalom Manevich, Yoav Goldberg </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers**](https://arxiv.org/abs/2305.12567) （**2023.05.21**）

<font color="gray">Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/gonglinyuan/metro_t0)

---

[**IR Models and the COVID-19 Pandemic: A Comparative Study of Performance and Challenges (preprint)**](https://arxiv.org/abs/2305.12528) （**2023.05.21**）

<font color="gray">Moksh Shukla, Niti Jain, Shubham Gupta </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Decouple knowledge from paramters for plug-and-play language modeling**](https://doi.org/10.48550/arXiv.2305.11564) （**2023.05.19**）

<font color="gray">Xin Cheng, Yankai Lin, Xiuying Chen, Dongyan Zhao, Rui Yan .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/hannibal046/pluglm)

---

[**SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs**](https://doi.org/10.48550/arXiv.2305.11461) （**2023.05.19**）

<font color="gray">IokTong Lei, ZhiDong Deng .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions**](https://doi.org/10.48550/arXiv.2305.11460) （**2023.05.19**）

<font color="gray">Shiyao Ding, Takayuki Ito .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning**](https://doi.org/10.48550/arXiv.2305.11759) （**2023.05.19**）

<font color="gray">Mustafa Safa Ozdayi, Charith S. Peris, Jack G. M. FitzGerald, Christophe Dupuy, Jimit Majmudar, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models**](https://doi.org/10.48550/arXiv.2305.11414) （**2023.05.19**）

<font color="gray">Sixing Yu, J. P. Muñoz, A. Jannesari .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning**](https://doi.org/10.48550/arXiv.2305.11383) （**2023.05.19**）

<font color="gray">Po-Nien Kung, Nanyun Peng .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**AutoTrial: Prompting Language Models for Clinical Trial Design**](https://doi.org/10.48550/arXiv.2305.11366) （**2023.05.19**）

<font color="gray">Zifeng Wang, Cao Xiao, Jimeng Sun .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Democratized Diffusion Language Model**](https://doi.org/10.48550/arXiv.2305.10818) （**2023.05.18**）

<font color="gray">Nikita Balagansky, Daniil Gavrilov .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Learning In-context Learning for Named Entity Recognition**](https://doi.org/10.48550/arXiv.2305.11038) （**2023.05.18**）

<font color="gray">Jiawei Chen, Yaojie Lu, Hongyu Lin, Jie Lou, Wei Jia, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings**](https://doi.org/10.48550/arXiv.2305.10786) （**2023.05.18**）

<font color="gray">Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Chong Deng, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ahead-of-Time P-Tuning**](https://doi.org/10.48550/arXiv.2305.10835) （**2023.05.18**）

<font color="gray">Daniil Gavrilov, Nikita Balagansky .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ReGen: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval**](https://doi.org/10.48550/arXiv.2305.10703) （**2023.05.18**）

<font color="gray">Yue Yu, Yuchen Zhuang, Rongzhi Zhang, Yu Meng, Jiaming Shen, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/yueyu1030/ReGen)

---

[**LIMA: Less Is More for Alignment**](https://doi.org/10.48550/arXiv.2305.11206) （**2023.05.18**）

<font color="gray">Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Efficient Prompting via Dynamic In-Context Learning**](https://doi.org/10.48550/arXiv.2305.11170) （**2023.05.18**）

<font color="gray">Wangchunshu Zhou, Yuchen Jiang, Ryan Cotterell, Mrinmaya Sachan .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The Web Can Be Your Oyster for Improving Large Language Models**](https://doi.org/10.48550/arXiv.2305.10998) （**2023.05.18**）

<font color="gray">Junyi Li, Tianyi Tang, Wayne Xin Zhao, Jingyuan Wang, J. Nie, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**TOME: A Two-stage Approach for Model-based Retrieval**](https://doi.org/10.48550/arXiv.2305.11161) （**2023.05.18**）

<font color="gray">Ruiyang Ren, Wayne Xin Zhao, J. Liu, Huaqin Wu, Ji-rong Wen, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt**](https://doi.org/10.48550/arXiv.2305.11186) （**2023.05.17**）

<font color="gray">Zhaozhuo Xu, Zirui Liu, Beidi Chen, Yuxin Tang, Jue Wang, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SPSQL: Step-by-step Parsing Based Framework for Text-to-SQL Generation**](https://doi.org/10.48550/arXiv.2305.11061) （**2023.05.10**）

<font color="gray">Ran Shen, Gang Sun, Hao Shen, Yiling Li, Liangfeng Jin, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model**](https://arxiv.org/abs/2304.06248) （**2023.04.13**）

<font color="gray">Hao Fei, Shengqiong Wu, Jingye Li, Bobo Li, Fei Li, etc </font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-26-blue)](https://github.com/chocowu/lasuie)

---

[**Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation**](https://doi.org/10.48550/arXiv.2302.01441) （**2023.02.02**）

<font color="gray">Yiren Liu, H. Kilicoglu .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**REPLUG: Retrieval-Augmented Black-Box Language Models**](https://doi.org/10.48550/arXiv.2301.12652) （**2023.01.30**）

<font color="gray">Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Self-Instruct: Aligning Language Model with Self Generated Instructions**](https://doi.org/10.48550/arXiv.2212.10560) （**2022.12.20**）

<font color="gray">Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-2.3k-blue)](https://github.com/yizhongw/self-instruct)

---

[**One Embedder, Any Task: Instruction-Finetuned Text Embeddings**](https://doi.org/10.48550/arXiv.2212.09741) （**2022.12.19**）

<font color="gray">Hongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-606-blue)](https://github.com/HKUNLP/instructor-embedding)

---

[**The Impact of Symbolic Representations on In-context Learning for Few-shot Reasoning**](https://doi.org/10.48550/arXiv.2212.08686) （**2022.12.16**）

<font color="gray">Hanlin Zhang, Yi-Fan Zhang, Li Erran Li, Eric P. Xing .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/hlzhang109/lmlp)

---

[**Don’t Prompt, Search! Mining-based Zero-Shot Learning with Language Models**](https://doi.org/10.48550/arXiv.2210.14803) （**2022.10.26**）

<font color="gray">Mozes van de Kar, M. Xia, Danqi Chen, Mikel Artetxe .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding**](https://doi.org/10.48550/arXiv.2210.08536) （**2022.10.16**）

<font color="gray">J. Wang, Wenkang Huang, Qiuhui Shi, Hongbin Wang, Minghui Qiu, etc .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/wjn1996/kp-plm)

---

[**Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding**](https://doi.org/10.48550/arXiv.2210.03304) （**2022.10.07**）

<font color="gray">Zhichao Yang, Shufan Wang, Bhanu Pratap Singh Rawat, Avijit Mitra, Hong Yu .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-28-blue)](https://github.com/whaleloops/KEPT)

---

[**Promptagator: Few-shot Dense Retrieval From 8 Examples**](https://doi.org/10.48550/arXiv.2209.11755) （**2022.09.23**）

<font color="gray">Zhuyun Dai, Vincent Zhao, Ji Ma, Yi Luan, Jianmo Ni, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-16-green)

---

[**Unified Knowledge Prompt Pre-training for Customer Service Dialogues**](https://doi.org/10.1145/3511808.3557718) （**2022.08.31**）

<font color="gray">Keqing He, Jingang Wang, Chaobo Sun, Wei Wu .  - 【International Conference on Information and Knowledge Management】</font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)

---

[**DocPrompting: Generating Code by Retrieving the Docs**](https://arxiv.org/abs/2207.05987) （**2022.07.13**）

<font color="gray">Shuyan Zhou, Uri Alon, Frank F. Xu, Zhiruo Wang, Zhengbao Jiang, etc </font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-24-red)  [![](https://img.shields.io/badge/Github%20Stars-164-blue)](https://github.com/shuyanzhou/docprompting)

---

[**Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning**](https://doi.org/10.1145/3534678.3539382) （**2022.06.19**）

<font color="gray">Xiaolei Wang, Kun Zhou, Ji-rong Wen, Wayne Xin Zhao .  - 【Knowledge Discovery and Data Mining】</font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-35-red)  [![](https://img.shields.io/badge/Github%20Stars-49-blue)](https://github.com/rucaibox/unicrs)

---

[**Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning**](https://doi.org/10.48550/arXiv.2205.14704) （**2022.05.29**）

<font color="gray">Xiang Chen, Lei Li, Ningyu Zhang, Xiaozhuan Liang, Shumin Deng, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-389-blue)](https://github.com/zjunlp/promptkg)

---

[**Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt Tuning**](https://doi.org/10.1145/3477495.3531746) （**2022.05.04**）

<font color="gray">Xiang Chen, Lei Li, Ningyu Zhang, Chuanqi Tan, Fei Huang, etc .  - 【Annual International ACM SIGIR Conference on Research and Development in Information Retrieval】</font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-27-red)  [![](https://img.shields.io/badge/Github%20Stars-389-blue)](https://github.com/zjunlp/PromptKG/tree/main/research/RetrievalRE)

---

[**Contrastive Demonstration Tuning for Pre-trained Language Models**](https://doi.org/10.48550/arXiv.2204.04392) （**2022.04.09**）

<font color="gray">Xiaozhuan Liang, Ningyu Zhang, Ningyu Zhang, Siyuan Cheng, Zhen Bi, etc .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-389-blue)](https://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning)

---

[**Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)**](https://doi.org/10.1145/3523227.3546767) （**2022.03.24**）

<font color="gray">Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, Yongfeng Zhang .  - 【ACM Conference on Recommender Systems】</font>

![](https://img.shields.io/badge/Citations-22-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-64-red)  [![](https://img.shields.io/badge/Github%20Stars-128-blue)](https://github.com/jeykigung/P5)

---

[**Multi-Stage Prompting for Knowledgeable Dialogue Generation**](https://doi.org/10.48550/arXiv.2203.08745) （**2022.03.16**）

<font color="gray">Zihan Liu, M. Patwary, R. Prenger, Shrimai Prabhumoye, Wei Ping, etc .  - 【Findings】</font>

![](https://img.shields.io/badge/Citations-12-green)  [![](https://img.shields.io/badge/Github%20Stars-5.1k-blue)](https://github.com/NVIDIA/Megatron-LM)

---

[**Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data**](https://doi.org/10.48550/arXiv.2203.08773) （**2022.03.16**）

<font color="gray">Shuo Wang, Yichong Xu, Yuwei Fang, Yang Liu, S. Sun, etc .  - 【Annual Meeting of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-103-blue)](https://github.com/microsoft/reina)

---

[**AdaPrompt: Adaptive Model Training for Prompt-based NLP**](https://arxiv.org/abs/2202.04824) （**2022.02.10**）

<font color="gray">Yulong Chen, Yang Liu, Li Dong, Shuohang Wang, Chenguang Zhu, etc .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-11-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-58-red)

---

[**Generated Knowledge Prompting for Commonsense Reasoning**](https://doi.org/10.18653/v1/2022.acl-long.225) （**2021.10.15**）

<font color="gray">Jiacheng Liu, Alisa Liu, Ximing Lu, S. Welleck, Peter West, etc .  - 【Annual Meeting of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-37-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-155-red)  [![](https://img.shields.io/badge/Github%20Stars-53-blue)](https://github.com/liujch1998/gkp)

---

[**Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction**](https://doi.org/10.18653/v1/2021.emnlp-main.92) （**2021.09.08**）

<font color="gray">Oscar Sainz, Oier Lopez de Lacalle, Gorka Labaka, Ander Barrena, Eneko Agirre .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-36-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-112-red)  [![](https://img.shields.io/badge/Github%20Stars-139-blue)](https://github.com/osainz59/Ask2Transformers)

---

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification**](https://doi.org/10.18653/v1/2022.acl-long.158) （**2021.08.04**）

<font color="gray">Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Juan-Zi Li, etc .  - 【Annual Meeting of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-95-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-237-red)  [![](https://img.shields.io/badge/Github%20Stars-166-blue)](https://github.com/thunlp/knowledgeableprompttuning)

---

[**PTR: Prompt Tuning with Rules for Text Classification**](https://doi.org/10.1016/j.aiopen.2022.11.003) （**2021.05.24**）

<font color="gray">Xu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, Maosong Sun .  - 【AI Open】</font>

![](https://img.shields.io/badge/Citations-172-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-247-red)  [![](https://img.shields.io/badge/Github%20Stars-140-blue)](https://github.com/thunlp/PTR)

---

[**Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks**](https://arxiv.org/abs/2005.11401) （**2020.05.22**）

<font color="gray">Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, etc .  - 【Neural Information Processing Systems】</font>

![](https://img.shields.io/badge/Citations-551-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-719-red)  [![](https://img.shields.io/badge/Github%20Stars-101.5k-blue)](https://github.com/huggingface/transformers)

---

[**REALM: Retrieval-Augmented Language Model Pre-Training**](https://arxiv.org/abs/2002.08909) （**2020.02.10**）

<font color="gray">Kelvin Guu, Kenton Lee, Z. Tung, Panupong Pasupat, Ming-Wei Chang .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-542-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-845-red)  [![](https://img.shields.io/badge/Github%20Stars-1.4k-blue)](https://github.com/google-research/language/tree/master/language/realm)

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

[**Prompt as a Knowledge Probe for Chinese Spelling Check**](https://doi.org/10.1007/978-3-031-10989-8_41) 

<font color="gray">Kun Peng, Nannan Sun, Jiahao Cao, Rui Liu, Jiaqian Ren, etc .  - 【Knowledge Science, Engineering and Management】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classiﬁcation Rolling Review submission**](https://api.semanticscholar.org/80366efe644f9fa5d1e89775eb7cb135ca46582f) 



![](https://img.shields.io/badge/Citations-0-green)


</div>

# CONTINUE...