# üìÑ Evaluation and Reliability

## Paper List

<div style="line-height:0.2em;">


[**AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models**](https://arxiv.org/abs/2304.06364) Ôºà**2023.04.13**Ôºâ

<font color="gray">Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-15-red)  [![](https://img.shields.io/badge/Github%20Stars-174-blue)](https://github.com/microsoft/agieval)

---

[**GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment**](https://arxiv.org/abs/2303.16634) Ôºà**2023.03.29**Ôºâ

<font color="gray">Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-33-red)

---

[**How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks**](https://doi.org/10.48550/arXiv.2303.00293) Ôºà**2023.03.01**Ôºâ

<font color="gray">Xuanting Chen, Junjie Ye, Can Zu, Nuo Xu, Rui Zheng, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints**](https://doi.org/10.48550/arXiv.2302.09185) Ôºà**2023.02.17**Ôºâ

<font color="gray">Albert Lu, Hongxin Zhang, Yanzhe Zhang, Xuezhi Wang, Diyi Yang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-20-blue)](https://github.com/salt-nlp/bound-cap-llm)

---

[**Evaluating the Robustness of Discrete Prompts**](https://doi.org/10.48550/arXiv.2302.05619) Ôºà**2023.02.11**Ôºâ

<font color="gray">Yoichi Ishibashi, D. Bollegala, Katsuhito Sudoh, Satoshi Nakamura .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/livnlp/prompt-robustness)

---

[**Controlling for Stereotypes in Multimodal Language Model Evaluation**](https://doi.org/10.48550/arXiv.2302.01582) Ôºà**2023.02.03**Ôºâ

<font color="gray">Manuj Malik, Richard Johansson .  - „ÄêBlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Models Can Be Easily Distracted by Irrelevant Context**](https://doi.org/10.48550/arXiv.2302.00093) Ôºà**2023.01.31**Ôºâ

<font color="gray">Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/google-research-datasets/gsm-ic)

---

[**Emergent Analogical Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2212.09196) Ôºà**2022.12.19**Ôºâ

<font color="gray">Taylor W. Webb, K. Holyoak, Hongjing Lu .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-14-blue)](https://github.com/taylorwwebb/emergent_analogies_llm)

---

[**Discovering Language Model Behaviors with Model-Written Evaluations**](https://doi.org/10.48550/arXiv.2212.09251) Ôºà**2022.12.19**Ôºâ

<font color="gray">Ethan Perez, Sam Ringer, Kamilƒó Luko≈°i≈´tƒó, Karina Nguyen, Edwin Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-8-green)  [![](https://img.shields.io/badge/Github%20Stars-120-blue)](https://github.com/anthropics/evals)

---

[**Constitutional AI: Harmlessness from AI Feedback**](https://doi.org/10.48550/arXiv.2212.08073) Ôºà**2022.12.15**Ôºâ

<font color="gray">Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, John Kernion, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-85-blue)](https://github.com/anthropics/constitutionalharmlessnesspaper)

---

[**On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning**](https://doi.org/10.48550/arXiv.2212.08061) Ôºà**2022.12.15**Ôºâ

<font color="gray">Omar Shaikh, Hongxin Zhang, William B. Held, Michael Bernstein, Diyi Yang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Demystifying Prompts in Language Models via Perplexity Estimation**](https://doi.org/10.48550/arXiv.2212.04037) Ôºà**2022.12.08**Ôºâ

<font color="gray">Hila Gonen, Srini Iyer, Terra Blevins, Noah A. Smith, Luke Zettlemoyer .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**Solving math word problems with process- and outcome-based feedback**](https://doi.org/10.48550/arXiv.2211.14275) Ôºà**2022.11.25**Ôºâ

<font color="gray">J. Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Holistic Evaluation of Language Models**](https://doi.org/10.48550/arXiv.2211.09110) Ôºà**2022.11.16**Ôºâ

<font color="gray">Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-40-green)  [![](https://img.shields.io/badge/Github%20Stars-549-blue)](https://github.com/stanford-crfm/helm)

---

[**Can language models handle recursively nested grammatical structures? A case study on comparing models and humans**](https://doi.org/10.48550/arXiv.2210.15303) Ôºà**2022.10.27**Ôºâ

<font color="gray">Andrew Kyle Lampinen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Prompting GPT-3 To Be Reliable**](https://doi.org/10.48550/arXiv.2210.09150) Ôºà**2022.10.17**Ôºâ

<font color="gray">Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-55-blue)](https://github.com/noviscl/gpt3-reliability)

---

[**An Interpretability Evaluation Benchmark for Pre-trained Language Models**](https://doi.org/10.48550/arXiv.2207.13948) Ôºà**2022.07.28**Ôºâ

<font color="gray">Ya-Ming Shen, Lijie Wang, Ying Chen, Xinyan Xiao, Jing Liu, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Re-Examining Calibration: The Case of Question Answering**](https://arxiv.org/abs/2205.12507) Ôºà**2022.05.25**Ôºâ

<font color="gray">Chenglei Si, Chen Zhao, Sewon Min, Jordan L. Boyd-Graber .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/noviscl/calibrateqa)

---

[**Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing**](https://doi.org/10.48550/arXiv.2205.12253) Ôºà**2022.05.24**Ôºâ

<font color="gray">Linlu Qiu, Peter Shaw, Panupong Pasupat, Tianze Shi, Jonathan Herzig, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-11-green)

---

[**The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning**](https://arxiv.org/abs/2205.03401) Ôºà**2022.05.06**Ôºâ

<font color="gray">Xi Ye, Greg Durrett </font>

![](https://img.shields.io/badge/Citations-10-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-35-red)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/xiye17/textualexplincontext)

---

[**Training Verifiers to Solve Math Word Problems**](https://arxiv.org/abs/2110.14168) Ôºà**2021.10.27**Ôºâ

<font color="gray">Karl Cobbe, V. Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-181-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-118-red)  [![](https://img.shields.io/badge/Github%20Stars-373-blue)](https://github.com/openai/grade-school-math)

---

[**BBQ: A hand-built bias benchmark for question answering**](https://doi.org/10.18653/v1/2022.findings-acl.165) Ôºà**2021.10.15**Ôºâ

<font color="gray">Alicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, etc .  - „ÄêFindings„Äë</font>

![](https://img.shields.io/badge/Citations-19-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-37-red)  [![](https://img.shields.io/badge/Github%20Stars-22-blue)](https://github.com/nyu-mll/bbq)

---

[**BARTScore: Evaluating Generated Text as Text Generation**](https://arxiv.org/abs/2106.11520) Ôºà**2021.06.22**Ôºâ

<font color="gray">Weizhe Yuan, Graham Neubig, Pengfei Liu .  - „ÄêNeural Information Processing Systems„Äë</font>

![](https://img.shields.io/badge/Citations-172-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-163-red)  [![](https://img.shields.io/badge/Github%20Stars-221-blue)](https://github.com/neulab/BARTScore)

---

[**Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning**](https://doi.org/10.18653/v1/2021.acl-long.102) Ôºà**2021.06.13**Ôºâ

<font color="gray">Bill Yuchen Lin, Seyeon Lee, Xiaoyang Qiao, Xiang Ren .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-20-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-62-red)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/INK-USC/XCSR)

---

[**Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity**](https://doi.org/10.18653/v1/2022.acl-long.556) Ôºà**2021.04.18**Ôºâ

<font color="gray">Yao Lu, Max Bartolo, Alastair Moore, S. Riedel, Pontus Stenetorp .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-170-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-193-red)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/chicagohai/active-example-selection)


</div>

# CONTINUE...