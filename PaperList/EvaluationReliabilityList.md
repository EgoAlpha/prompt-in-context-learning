# üìÑ Evaluation and Reliability

## Paper List

<div style="line-height:0.2em;">


[**Language Model Crossover: Variation through Few-Shot Prompting**](https://doi.org/10.48550/arXiv.2302.12170) Ôºà**2023.02.23**Ôºâ

<font color="gray">Elliot Meyerson, M. Nelson, Herbie Bradley, Arash Moradi, Amy K. Hoover, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Evaluating the Robustness of Discrete Prompts**](https://doi.org/10.48550/arXiv.2302.05619) Ôºà**2023.02.11**Ôºâ

<font color="gray">Yoichi Ishibashi, D. Bollegala, Katsuhito Sudoh, Satoshi Nakamura .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/livnlp/prompt-robustness)

---

[**PLACES: Prompting Language Models for Social Conversation Synthesis**](https://doi.org/10.48550/arXiv.2302.03269) Ôºà**2023.02.07**Ôºâ

<font color="gray">Maximillian Chen, A. Papangelis, Chenyang Tao, Seokhwan Kim, Andrew Rosenbaum, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/alexa/places)

---

[**Controlling for Stereotypes in Multimodal Language Model Evaluation**](https://doi.org/10.48550/arXiv.2302.01582) Ôºà**2023.02.03**Ôºâ

<font color="gray">Manuj Malik, Richard Johansson .  - „ÄêBlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Models Can Be Easily Distracted by Irrelevant Context**](https://doi.org/10.48550/arXiv.2302.00093) Ôºà**2023.01.31**Ôºâ

<font color="gray">Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/google-research-datasets/gsm-ic)

---

[**Emergent Analogical Reasoning in Large Language Models**](https://doi.org/10.48550/arXiv.2212.09196) Ôºà**2022.12.19**Ôºâ

<font color="gray">Taylor W. Webb, K. Holyoak, Hongjing Lu .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/taylorwwebb/emergent_analogies_llm)

---

[**Discovering Language Model Behaviors with Model-Written Evaluations**](https://doi.org/10.48550/arXiv.2212.09251) Ôºà**2022.12.19**Ôºâ

<font color="gray">Ethan Perez, Sam Ringer, Kamilƒó Luko≈°i≈´tƒó, Karina Nguyen, Edwin Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-101-blue)](https://github.com/anthropics/evals)

---

[**Constitutional AI: Harmlessness from AI Feedback**](https://doi.org/10.48550/arXiv.2212.08073) Ôºà**2022.12.15**Ôºâ

<font color="gray">Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, John Kernion, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-15-green)  [![](https://img.shields.io/badge/Github%20Stars-64-blue)](https://github.com/anthropics/constitutionalharmlessnesspaper)

---

[**On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning**](https://doi.org/10.48550/arXiv.2212.08061) Ôºà**2022.12.15**Ôºâ

<font color="gray">Omar Shaikh, Hongxin Zhang, William B. Held, Michael Bernstein, Diyi Yang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Solving math word problems with process- and outcome-based feedback**](https://doi.org/10.48550/arXiv.2211.14275) Ôºà**2022.11.25**Ôºâ

<font color="gray">J. Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks**](https://doi.org/10.48550/arXiv.2211.12588) Ôºà**2022.11.22**Ôºâ

<font color="gray">Wenhu Chen, Xueguang Ma, Xinyi Wang, William W. Cohen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  [![](https://img.shields.io/badge/Github%20Stars-57-blue)](https://github.com/wenhuchen/program-of-thoughts)

---

[**Holistic Evaluation of Language Models**](https://doi.org/10.48550/arXiv.2211.09110) Ôºà**2022.11.16**Ôºâ

<font color="gray">Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-33-green)  [![](https://img.shields.io/badge/Github%20Stars-337-blue)](https://github.com/stanford-crfm/helm)

---

[**Large Language Models with Controllable Working Memory**](https://doi.org/10.48550/arXiv.2211.05110) Ôºà**2022.11.09**Ôºâ

<font color="gray">Daliang Li, A. Rawat, M. Zaheer, Xin Wang, M. Lukasik, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-238-blue)](https://github.com/golosio/annabell)

---

[**Solving Math Word Problem via Cooperative Reasoning induced Language Models**](https://doi.org/10.48550/arXiv.2210.16257) Ôºà**2022.10.28**Ôºâ

<font color="gray">Xinyu Zhu, Junjie Wang, Lin Zhang, Yuxiang Zhang, Ruyi Gan, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Can language models handle recursively nested grammatical structures? A case study on comparing models and humans**](https://doi.org/10.48550/arXiv.2210.15303) Ôºà**2022.10.27**Ôºâ

<font color="gray">Andrew Kyle Lampinen .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Prompting GPT-3 To Be Reliable**](https://doi.org/10.48550/arXiv.2210.09150) Ôºà**2022.10.17**Ôºâ

<font color="gray">Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-47-blue)](https://github.com/noviscl/gpt3-reliability)

---

[**Ask Me Anything: A simple strategy for prompting language models**](https://doi.org/10.48550/arXiv.2210.02441) Ôºà**2022.10.05**Ôºâ

<font color="gray">Simran Arora, A. Narayan, Mayee F. Chen, Laurel J. Orr, Neel Guha, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-12-green)  [![](https://img.shields.io/badge/Github%20Stars-388-blue)](https://github.com/hazyresearch/ama_prompting)

---

[**An Interpretability Evaluation Benchmark for Pre-trained Language Models**](https://doi.org/10.48550/arXiv.2207.13948) Ôºà**2022.07.28**Ôºâ

<font color="gray">Ya-Ming Shen, Lijie Wang, Ying Chen, Xinyan Xiao, Jing Liu, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-453-blue)](https://github.com/michiyasunaga/qagnn)

---

[**Re-Examining Calibration: The Case of Question Answering**](https://arxiv.org/abs/2205.12507) Ôºà**2022.05.25**Ôºâ

<font color="gray">Chenglei Si, Chen Zhao, Sewon Min, Jordan L. Boyd-Graber .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/noviscl/calibrateqa)

---

[**Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing**](https://doi.org/10.48550/arXiv.2205.12253) Ôºà**2022.05.24**Ôºâ

<font color="gray">Linlu Qiu, Peter Shaw, Panupong Pasupat, Tianze Shi, Jonathan Herzig, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-11-green)

---

[**Toxicity Detection with Generative Prompt-based Inference**](https://doi.org/10.48550/arXiv.2205.12390) Ôºà**2022.05.24**Ôºâ

<font color="gray">Yau-Shian Wang, Y. Chang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Prototypical Calibration for Few-shot Learning of Language Models**](https://doi.org/10.48550/arXiv.2205.10183) Ôºà**2022.05.20**Ôºâ

<font color="gray">Zhixiong Han, Y. Hao, Li Dong, Yutao Sun, Furu Wei .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback**](https://doi.org/10.48550/arXiv.2204.05862) Ôºà**2022.04.12**Ôºâ

<font color="gray">Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-60-green)  [![](https://img.shields.io/badge/Github%20Stars-525-blue)](https://github.com/anthropics/hh-rlhf)

---

[**Training language models to follow instructions with human feedback**](https://doi.org/10.48550/arXiv.2203.02155) Ôºà**2022.03.04**Ôºâ

<font color="gray">Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-426-green)  [![](https://img.shields.io/badge/Github%20Stars-852-blue)](https://github.com/openai/following-instructions-human-feedback)

---

[**True Few-Shot Learning with Prompts‚ÄîA Real-World Perspective**](https://doi.org/10.1162/tacl_a_00485) Ôºà**2021.11.26**Ôºâ

<font color="gray">Timo Schick, Hinrich Sch√ºtze .  - „ÄêTransactions of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-14-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-54-red)

---

[**Training Verifiers to Solve Math Word Problems**](https://arxiv.org/abs/2110.14168) Ôºà**2021.10.27**Ôºâ

<font color="gray">Karl Cobbe, V. Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-175-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-105-red)  [![](https://img.shields.io/badge/Github%20Stars-321-blue)](https://github.com/openai/grade-school-math)

---

[**BBQ: A hand-built bias benchmark for question answering**](https://doi.org/10.18653/v1/2022.findings-acl.165) Ôºà**2021.10.15**Ôºâ

<font color="gray">Alicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, etc .  - „ÄêFindings„Äë</font>

![](https://img.shields.io/badge/Citations-19-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-37-red)  [![](https://img.shields.io/badge/Github%20Stars-21-blue)](https://github.com/nyu-mll/bbq)

---

[**Do Prompt-Based Models Really Understand the Meaning of Their Prompts?**](https://doi.org/10.18653/v1/2022.naacl-main.167) Ôºà**2021.09.02**Ôºâ

<font color="gray">Albert Webson, Ellie Pavlick .  - „ÄêNorth American Chapter of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-69-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-133-red)  [![](https://img.shields.io/badge/Github%20Stars-67-blue)](https://github.com/awebson/prompt_semantics)

---

[**Evaluating the Robustness of Neural Language Models to Input Perturbations**](https://doi.org/10.18653/v1/2021.emnlp-main.117) Ôºà**2021.08.27**Ôºâ

<font color="gray">M. Moradi, M. Samwald .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-21-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-59-red)  [![](https://img.shields.io/badge/Github%20Stars-12-blue)](https://github.com/mmoradi-iut/nlp-perturbation)

---

[**BARTScore: Evaluating Generated Text as Text Generation**](https://arxiv.org/abs/2106.11520) Ôºà**2021.06.22**Ôºâ

<font color="gray">Weizhe Yuan, Graham Neubig, Pengfei Liu .  - „ÄêNeural Information Processing Systems„Äë</font>

![](https://img.shields.io/badge/Citations-171-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-157-red)  [![](https://img.shields.io/badge/Github%20Stars-210-blue)](https://github.com/neulab/BARTScore)

---

[**Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning**](https://doi.org/10.18653/v1/2021.acl-long.102) Ôºà**2021.06.13**Ôºâ

<font color="gray">Bill Yuchen Lin, Seyeon Lee, Xiaoyang Qiao, Xiang Ren .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-20-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-67-red)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/INK-USC/XCSR)

---

[**Calibrate Before Use: Improving Few-Shot Performance of Language Models**](https://arxiv.org/abs/2102.09690) Ôºà**2021.02.19**Ôºâ

<font color="gray">Tony Zhao, Eric Wallace, Shi Feng, D. Klein, Sameer Singh .  - „ÄêInternational Conference on Machine Learning„Äë</font>

![](https://img.shields.io/badge/Citations-281-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-295-red)  [![](https://img.shields.io/badge/Github%20Stars-242-blue)](https://github.com/tonyzhaozh/few-shot-learning)

---

[**BERTScore: Evaluating Text Generation with BERT**](https://arxiv.org/abs/1904.09675) Ôºà**2019.04.21**Ôºâ

<font color="gray">Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, Yoav Artzi .  - „ÄêInternational Conference on Learning Representations„Äë</font>

![](https://img.shields.io/badge/Citations-1644-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-759-red)  [![](https://img.shields.io/badge/Github%20Stars-1.1k-blue)](https://github.com/Tiiiger/bert_score)


</div>

# CONTINUE...
