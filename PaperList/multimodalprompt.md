# üìÑ Multimodal Prompt

## Paper List

<div style="line-height:0.2em;">


[**Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models**](https://arxiv.org/abs/2303.04671) Ôºà**2023.03.08**Ôºâ

<font color="gray">Chenfei Wu, Sheng-Kai Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-111-red)  [![](https://img.shields.io/badge/Github%20Stars-13.9k-blue)](https://github.com/microsoft/visual-chatgpt)

---

[**Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning**](https://arxiv.org/abs/2303.02861) Ôºà**2023.03.06**Ôºâ

<font color="gray">Zhen Wang, R. Panda, Leonid Karlinsky, R. Feris, Huan Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2302.00923) Ôºà**2023.02.02**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, G. Karypis, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3.0k-blue)](https://github.com/amazon-science/mm-cot)

---

[**CoHOZ: Contrasive Multimodal prompt Tuning for Hierarchical Open-set Zero-shot Recognition**](https://doi.org/10.1145/3503161.3548021) Ôºà**2022.10.10**Ôºâ

<font color="gray">Ning Liao, Yifeng Liu, Li Xiaobo, Chenyi Lei, Guoxin Wang, etc .  - „ÄêProceedings of the 30th ACM International Conference on Multimedia„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**VIMA: General Robot Manipulation with Multimodal Prompts**](https://doi.org/10.48550/arXiv.2210.03094) Ôºà**2022.10.06**Ôºâ

<font color="gray">Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-15-green)  [![](https://img.shields.io/badge/Github%20Stars-75-blue)](https://github.com/vimalabs/VIMABench)

---

[**Learning to Prompt for Vision-Language Models**](https://doi.org/10.1007/s11263-022-01653-1) Ôºà**2022.09.01**Ôºâ

<font color="gray">Kaiyang Zhou, Jingkang Yang, Chen Change Loy, Ziwei Liu </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-399-red)  [![](https://img.shields.io/badge/Github%20Stars-762-blue)](https://github.com/kaiyangzhou/coop)

---

[**Visual Prompt Tuning**](https://doi.org/10.48550/arXiv.2203.12119) Ôºà**2022.03.23**Ôºâ

<font color="gray">Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, S. Belongie, etc .  - „ÄêEuropean Conference on Computer Vision„Äë</font>

![](https://img.shields.io/badge/Citations-104-green)  [![](https://img.shields.io/badge/Github%20Stars-350-blue)](https://github.com/KMnP/vpt)

---

[**Multimodal Few-Shot Learning with Frozen Language Models**](https://arxiv.org/abs/2106.13884) Ôºà**2021.06.25**Ôºâ

<font color="gray">Maria Tsimpoukelli, Jacob Menick, Serkan Cabi, S. Eslami, Oriol Vinyals, etc .  - „ÄêNeural Information Processing Systems„Äë</font>

![](https://img.shields.io/badge/Citations-173-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-401-red)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/ivonajdenkoska/multimodal-meta-learn)

---

[**Similarity-Aware Multimodal Prompt Learning for Fake News Detection**](https://doi.org/10.2139/ssrn.4347542) 

<font color="gray">Ye Jiang, Xiaomin Yu, Yimin Wang, Xiaoman Xu, Xingyi Song, etc .  - „ÄêSSRN Electronic Journal„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)


</div>

# CONTINUE...