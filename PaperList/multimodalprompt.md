# üìÑ Multimodal Prompt

## Paper List

<div style="line-height:0.2em;">


[**CLIP goes 3D: Leveraging Prompt Tuning for Language Grounded 3D Recognition**](https://arxiv.org/abs/2303.11313) Ôºà**2023.03.20**Ôºâ



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-62-blue)](https://github.com/deeptibhegde/clip-goes-3d)

---

[**Visual Prompt Multi-Modal Tracking**](https://arxiv.org/abs/2303.10826) Ôºà**2023.03.20**Ôºâ



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)  [![](https://img.shields.io/badge/Github%20Stars-27-blue)](https://github.com/jiawen-zhu/vipt)

---

[**Audio Visual Language Maps for Robot Navigation**](https://doi.org/10.48550/arXiv.2303.07522) Ôºà**2023.03.13**Ôºâ

<font color="gray">Chen Huang, Oier Mees, Andy Zeng, W. Burgard .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models**](https://arxiv.org/abs/2303.04671) Ôºà**2023.03.08**Ôºâ

<font color="gray">Chenfei Wu, Sheng-Kai Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-193-red)  [![](https://img.shields.io/badge/Github%20Stars-22.6k-blue)](https://github.com/microsoft/visual-chatgpt)

---

[**Multimodal Parameter-Efficient Few-Shot Class Incremental Learning**](https://doi.org/10.48550/arXiv.2303.04751) Ôºà**2023.03.08**Ôºâ

<font color="gray">Marco D‚ÄôAlessandro, Alberto Alonso, Enrique Calabr'es, M. Galar .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning**](https://arxiv.org/abs/2303.02861) Ôºà**2023.03.06**Ôºâ

<font color="gray">Zhen Wang, R. Panda, Leonid Karlinsky, R. Feris, Huan Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)

---

[**Multimodal Prompting with Missing Modalities for Visual Recognition**](https://doi.org/10.48550/arXiv.2303.03369) Ôºà**2023.03.06**Ôºâ

<font color="gray">Yi-Lun Lee, Yi-Hsuan Tsai, Wei-Chen Chiu, Chen-Yu Lee .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-21-blue)](https://github.com/yilunlee/missing_aware_prompts)

---

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2302.00923) Ôºà**2023.02.02**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, G. Karypis, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3.1k-blue)](https://github.com/amazon-science/mm-cot)

---

[**CoHOZ: Contrasive Multimodal prompt Tuning for Hierarchical Open-set Zero-shot Recognition**](https://doi.org/10.1145/3503161.3548021) Ôºà**2022.10.10**Ôºâ

<font color="gray">Ning Liao, Yifeng Liu, Li Xiaobo, Chenyi Lei, Guoxin Wang, etc .  - „ÄêProceedings of the 30th ACM International Conference on Multimedia„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**VIMA: General Robot Manipulation with Multimodal Prompts**](https://doi.org/10.48550/arXiv.2210.03094) Ôºà**2022.10.06**Ôºâ

<font color="gray">Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-15-green)  [![](https://img.shields.io/badge/Github%20Stars-76-blue)](https://github.com/vimalabs/VIMABench)

---

[**Learning to Prompt for Vision-Language Models**](https://doi.org/10.1007/s11263-022-01653-1) Ôºà**2022.09.01**Ôºâ

<font color="gray">Kaiyang Zhou, Jingkang Yang, Chen Change Loy, Ziwei Liu </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-405-red)  [![](https://img.shields.io/badge/Github%20Stars-768-blue)](https://github.com/kaiyangzhou/coop)

---

[**Visual Prompt Tuning**](https://doi.org/10.48550/arXiv.2203.12119) Ôºà**2022.03.23**Ôºâ

<font color="gray">Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, S. Belongie, etc .  - „ÄêEuropean Conference on Computer Vision„Äë</font>

![](https://img.shields.io/badge/Citations-104-green)  [![](https://img.shields.io/badge/Github%20Stars-359-blue)](https://github.com/KMnP/vpt)

---

[**Multimodal Few-Shot Learning with Frozen Language Models**](https://arxiv.org/abs/2106.13884) Ôºà**2021.06.25**Ôºâ

<font color="gray">Maria Tsimpoukelli, Jacob Menick, Serkan Cabi, S. Eslami, Oriol Vinyals, etc .  - „ÄêNeural Information Processing Systems„Äë</font>

![](https://img.shields.io/badge/Citations-173-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-405-red)

---

[**Similarity-Aware Multimodal Prompt Learning for Fake News Detection**](https://doi.org/10.2139/ssrn.4347542) 

<font color="gray">Ye Jiang, Xiaomin Yu, Yimin Wang, Xiaoman Xu, Xingyi Song, etc .  - „ÄêSSRN Electronic Journal„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)


</div>

# CONTINUE...