# üìÑ Multimodal Prompt

## Paper List

<div style="line-height:0.2em;">


[**Edit Everything: A Text-Guided Generative System for Images Editing**](https://arxiv.org/abs/2304.14006) Ôºà**2023.04.27**Ôºâ

<font color="gray">Defeng Xie, Ruichen Wang, Jian Ma, Chen Chen, Haonan Lu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)  [![](https://img.shields.io/badge/Github%20Stars-50-blue)](https://github.com/defengxie/edit_everything)

---

[**ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System**](https://arxiv.org/abs/2304.14407) Ôºà**2023.04.27**Ôºâ

<font color="gray">Junke Wang, Dongdong Chen, Chong Luo, Xiyang Dai, Lu Yuan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality**](https://arxiv.org/abs/2304.14178) Ôºà**2023.04.27**Ôºâ

<font color="gray">Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-253-blue)](https://github.com/x-plug/mplug-owl)

---

[**Towards Robust Prompts on Vision-Language Models**](https://arxiv.org/abs/2304.08479) Ôºà**2023.04.17**Ôºâ

<font color="gray">Jindong Gu, A. Beirami, Xuezhi Wang, Alex Beutel, Philip H. S. Torr, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)

---

[**Visual Instruction Tuning**](https://arxiv.org/abs/2304.08485) Ôºà**2023.04.17**Ôºâ

<font color="gray">Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-74-red)  [![](https://img.shields.io/badge/Github%20Stars-2.0k-blue)](https://github.com/haotian-liu/LLaVA)

---

[**Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text**](https://arxiv.org/abs/2304.06939) Ôºà**2023.04.14**Ôºâ

<font color="gray">Wanrong Zhu, Jack Hessel, Anas Awadalla, S. Gadre, Jesse Dodge, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-38-red)  [![](https://img.shields.io/badge/Github%20Stars-655-blue)](https://github.com/allenai/mmc4)

---

[**Segment Everything Everywhere All at Once**](https://doi.org/10.48550/arXiv.2304.06718) Ôºà**2023.04.13**Ôºâ

<font color="gray">Xueyan Zou, Jianwei Yang, Hao Zhang, Feng Li, Linjie Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-2.2k-blue)](https://github.com/ux-decoder/segment-everything-everywhere-all-at-once)

---

[**Efficient Multimodal Fusion via Interactive Prompting**](https://arxiv.org/abs/2304.06306) Ôºà**2023.04.13**Ôºâ

<font color="gray">Yaowei Li, Ruijie Quan, Linchao Zhu, Yezhou Yang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning**](https://arxiv.org/abs/2304.05613) Ôºà**2023.04.12**Ôºâ

<font color="gray">Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-18-red)

---

[**Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition**](https://doi.org/10.48550/arXiv.2304.04704) Ôºà**2023.04.10**Ôºâ

<font color="gray">Shuhuai Ren, Aston Zhang, Yi Zhu, Shuai Zhang, Shuai Zheng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-165-blue)](https://github.com/amazon-science/prompt-pretraining)

---

[**Video ChatCaptioner: Towards Enriched Spatiotemporal Descriptions**](https://doi.org/10.48550/arXiv.2304.04227) Ôºà**2023.04.09**Ôºâ

<font color="gray">Jun Chen, Deyao Zhu, Kilichbek Haydarov, Xiang Li, Mohamed Elhoseiny .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-290-blue)](https://github.com/vision-cair/chatcaptioner)

---

[**Vita-CLIP: Video and text adaptive CLIP via Multimodal Prompting**](https://arxiv.org/abs/2304.03307) Ôºà**2023.04.06**Ôºâ



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-19-red)  [![](https://img.shields.io/badge/Github%20Stars-25-blue)](https://github.com/talalwasim/vita-clip)

---

[**TagGPT: Large Language Models are Zero-shot Multimodal Taggers**](https://arxiv.org/abs/2304.03022) Ôºà**2023.04.06**Ôºâ



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/tencentarc/taggpt)

---

[**Segment Anything**](https://doi.org/10.48550/arXiv.2304.02643) Ôºà**2023.04.05**Ôºâ

<font color="gray">A. Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-30.8k-blue)](https://github.com/facebookresearch/segment-anything)

---

[**TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs**](https://doi.org/10.48550/arXiv.2303.16434) Ôºà**2023.03.29**Ôºâ

<font color="gray">Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-8-green)

---

[**MEDIMP: Medical Images and Prompts for renal transplant representation learning**](https://arxiv.org/abs/2303.12445) Ôºà**2023.03.22**Ôºâ

<font color="gray">Leo Milecki, Vicky Kalogeiton, Sylvain Bodard, Dany Anglicheau, Jean-Michel Correas, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**CLIP goes 3D: Leveraging Prompt Tuning for Language Grounded 3D Recognition**](https://arxiv.org/abs/2303.11313) Ôºà**2023.03.20**Ôºâ



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-25-red)  [![](https://img.shields.io/badge/Github%20Stars-134-blue)](https://github.com/deeptibhegde/clip-goes-3d)

---

[**MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action**](https://doi.org/10.48550/arXiv.2303.11381) Ôºà**2023.03.20**Ôºâ

<font color="gray">Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-632-blue)](https://github.com/microsoft/MM-REACT)

---

[**Visual Prompt Multi-Modal Tracking**](https://arxiv.org/abs/2303.10826) Ôºà**2023.03.20**Ôºâ



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)  [![](https://img.shields.io/badge/Github%20Stars-95-blue)](https://github.com/jiawen-zhu/vipt)

---

[**Audio Visual Language Maps for Robot Navigation**](https://doi.org/10.48550/arXiv.2303.07522) Ôºà**2023.03.13**Ôºâ

<font color="gray">Chen Huang, Oier Mees, Andy Zeng, W. Burgard .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions**](https://doi.org/10.48550/arXiv.2303.06594) Ôºà**2023.03.12**Ôºâ

<font color="gray">Deyao Zhu, Jun Chen, Kilichbek Haydarov, Xiaoqian Shen, Wenxuan Zhang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-289-blue)](https://github.com/vision-cair/chatcaptioner)

---

[**Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models**](https://arxiv.org/abs/2303.04671) Ôºà**2023.03.08**Ôºâ

<font color="gray">Chenfei Wu, Sheng-Kai Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-331-red)  [![](https://img.shields.io/badge/Github%20Stars-32.3k-blue)](https://github.com/microsoft/visual-chatgpt)

---

[**Multimodal Parameter-Efficient Few-Shot Class Incremental Learning**](https://doi.org/10.48550/arXiv.2303.04751) Ôºà**2023.03.08**Ôºâ

<font color="gray">Marco D‚ÄôAlessandro, Alberto Alonso, Enrique Calabr'es, M. Galar .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning**](https://arxiv.org/abs/2303.02861) Ôºà**2023.03.06**Ôºâ

<font color="gray">Zhen Wang, R. Panda, Leonid Karlinsky, R. Feris, Huan Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-35-red)

---

[**Multimodal Prompting with Missing Modalities for Visual Recognition**](https://doi.org/10.48550/arXiv.2303.03369) Ôºà**2023.03.06**Ôºâ

<font color="gray">Yi-Lun Lee, Yi-Hsuan Tsai, Wei-Chen Chiu, Chen-Yu Lee .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-48-blue)](https://github.com/yilunlee/missing_aware_prompts)

---

[**Multimodal Chain-of-Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2302.00923) Ôºà**2023.02.02**Ôºâ

<font color="gray">Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, G. Karypis, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-3.3k-blue)](https://github.com/amazon-science/mm-cot)

---

[**LVP-M3: Language-aware Visual Prompt for Multilingual Multimodal Machine Translation**](https://doi.org/10.48550/arXiv.2210.15461) Ôºà**2022.10.19**Ôºâ

<font color="gray">Hongcheng Guo, Jiaheng Liu, Haoyang Huang, Jian Yang, Zhoujun Li, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**CoHOZ: Contrasive Multimodal prompt Tuning for Hierarchical Open-set Zero-shot Recognition**](https://doi.org/10.1145/3503161.3548021) Ôºà**2022.10.10**Ôºâ

<font color="gray">Ning Liao, Yifeng Liu, Li Xiaobo, Chenyi Lei, Guoxin Wang, etc .  - „ÄêProceedings of the 30th ACM International Conference on Multimedia„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**VIMA: General Robot Manipulation with Multimodal Prompts**](https://doi.org/10.48550/arXiv.2210.03094) Ôºà**2022.10.06**Ôºâ

<font color="gray">Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-15-green)  [![](https://img.shields.io/badge/Github%20Stars-88-blue)](https://github.com/vimalabs/VIMABench)

---

[**Learning to Prompt for Vision-Language Models**](https://doi.org/10.1007/s11263-022-01653-1) Ôºà**2022.09.01**Ôºâ

<font color="gray">Kaiyang Zhou, Jingkang Yang, Chen Change Loy, Ziwei Liu </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-459-red)  [![](https://img.shields.io/badge/Github%20Stars-893-blue)](https://github.com/kaiyangzhou/coop)

---

[**Visual Prompt Tuning**](https://doi.org/10.48550/arXiv.2203.12119) Ôºà**2022.03.23**Ôºâ

<font color="gray">Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, S. Belongie, etc .  - „ÄêEuropean Conference on Computer Vision„Äë</font>

![](https://img.shields.io/badge/Citations-104-green)  [![](https://img.shields.io/badge/Github%20Stars-483-blue)](https://github.com/KMnP/vpt)

---

[**Multimodal Few-Shot Learning with Frozen Language Models**](https://arxiv.org/abs/2106.13884) Ôºà**2021.06.25**Ôºâ

<font color="gray">Maria Tsimpoukelli, Jacob Menick, Serkan Cabi, S. Eslami, Oriol Vinyals, etc .  - „ÄêNeural Information Processing Systems„Äë</font>

![](https://img.shields.io/badge/Citations-173-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-423-red)

---

[**Similarity-Aware Multimodal Prompt Learning for Fake News Detection**](https://doi.org/10.2139/ssrn.4347542) 

<font color="gray">Ye Jiang, Xiaomin Yu, Yimin Wang, Xiaoman Xu, Xingyi Song, etc .  - „ÄêSSRN Electronic Journal„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)


</div>

# CONTINUE...