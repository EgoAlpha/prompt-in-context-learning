<div style="line-height:0.2em;">


[**Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive**](https://arxiv.org/abs/2402.13228) （**2024.02.20**）

<font color="gray">Arka Pal, Deep Karkhanis, Samuel Dooley, Manley Roberts, Siddartha Naidu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs**](https://doi.org/10.48550/arXiv.2402.07872) （**2024.02.12**）

<font color="gray">Soroush Nasiriany, Fei Xia, Wenhao Yu, Ted Xiao, Jacky Liang, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models**](https://doi.org/10.48550/arXiv.2402.05935) （**2024.02.08**）

<font color="gray">Peng Gao, Renrui Zhang, Chris Liu, Longtian Qiu, Siyuan Huang, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**EmojiCrypt: Prompt Encryption for Secure Communication with Large Language Models**](https://doi.org/10.48550/arXiv.2402.05868) （**2024.02.08**）

<font color="gray">Guo Lin, Wenyue Hua, Yongfeng Zhang .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Model Meets Graph Neural Network in Knowledge Distillation**](https://doi.org/10.48550/arXiv.2402.05894) （**2024.02.08**）

<font color="gray">Shengxiang Hu, Guobing Zou, Song Yang, Yanglan Gan, Bofeng Zhang, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models**](https://doi.org/10.48550/arXiv.2310.06117) （**2023.10.09**）

<font color="gray">Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, E. Chi, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-9-green)

---

[**Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading**](https://doi.org/10.48550/arXiv.2310.05029) （**2023.10.08**）

<font color="gray">Howard Chen, Ramakanth Pasunuru, Jason Weston, Asli Celikyilmaz .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chain-of-Verification Reduces Hallucination in Large Language Models**](https://doi.org/10.48550/arXiv.2309.11495) （**2023.09.20**）

<font color="gray">S. Dhuliawala, M. Komeili, Jing Xu, Roberta Raileanu, Xian Li, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-704-blue)](https://github.com/lastmile-ai/aiconfig/tree/main/cookbooks/Chain-of-Verification)

---

[**PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training**](https://doi.org/10.48550/arXiv.2309.10400) （**2023.09.19**）

<font color="gray">Dawei Zhu, Nan Yang, Liang Wang, Yifan Song, Wenhao Wu, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-54-blue)](https://github.com/dwzhu-pku/pose)

---

[**ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation**](https://doi.org/10.48550/arXiv.2308.11131) （**2023.08.22**）

<font color="gray">Jianghao Lin, Rongjie Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Giraffe: Adventures in Expanding Context Lengths in LLMs**](https://doi.org/10.48550/arXiv.2308.10882) （**2023.08.21**）

<font color="gray">Arka Pal, Deep Karkhanis, Manley Roberts, S. Dooley, Arvind Sundararajan, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-454-blue)](https://github.com/abacusai/long-context)

---

[**Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering**](https://doi.org/10.48550/arXiv.2308.07411) （**2023.08.14**）

<font color="gray">Edward Junprung .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Cumulative Reasoning with Large Language Models**](https://doi.org/10.48550/arXiv.2308.04371) （**2023.08.08**）

<font color="gray">Yifan Zhang, Jingqin Yang, Yang Yuan, A. Yao .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-216-blue)](https://github.com/iiis-ai/cumulative-reasoning)

---

[**Scaling Relationship on Learning Mathematical Reasoning with Large Language Models**](https://doi.org/10.48550/arXiv.2308.01825) （**2023.08.03**）

<font color="gray">Zheng Yuan, Hongyi Yuan, Cheng Li, Guanting Dong, Chuanqi Tan, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-11-green)  [![](https://img.shields.io/badge/Github%20Stars-134-blue)](https://github.com/ofa-sys/gsm8k-screl)

---

[**AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?**](https://doi.org/10.48550/arXiv.2307.16368) （**2023.07.31**）

<font color="gray">Qipeng Zhao, Ce Zhang, Shijie Wang, Changcheng Fu, Nakul Agarwal, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding**](https://doi.org/10.48550/arXiv.2307.15337) （**2023.07.28**）

<font color="gray">Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, Yu Wang .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-24-green)

---

[**ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning**](https://doi.org/10.48550/arXiv.2307.09474) （**2023.07.18**）

<font color="gray">Liang Zhao, En Yu, Zheng Ge, Jinrong Yang, Hao-Ran Wei, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration**](https://arxiv.org/abs/2307.05300) （**2023.07.11**）

<font color="gray">Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, etc </font>

![](https://img.shields.io/badge/Citations-39-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-54-red)  [![](https://img.shields.io/badge/Github%20Stars-271-blue)](https://github.com/mikewangwzhl/solo-performance-prompting)

---

[**Self-consistency for open-ended generations**](https://arxiv.org/abs/2307.06857) （**2023.07.11**）



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)

---

[**Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models**](https://doi.org/10.48550/arXiv.2307.03762) （**2023.07.07**）

<font color="gray">Yuxi Ma, Chi Zhang, Song-Chun Zhu .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Conformer LLMs - Convolution Augmented Large Language Models**](https://doi.org/10.48550/arXiv.2307.00461) （**2023.07.02**）

<font color="gray">Prateek Verma .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Learning Multi-Step Reasoning by Solving Arithmetic Tasks**](https://doi.org/10.48550/arXiv.2306.01707) （**2023.06.02**）

<font color="gray">Tianduo Wang, Wei Lu .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**OverPrompt: Enhancing ChatGPT Capabilities through an Efficient In-Context Learning Approach**](https://arxiv.org/abs/2305.14973) （**2023.05.24**）

<font color="gray">Jiazheng Li, Runcong Zhao, Yulan He, Lin Gui </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)

---

[**In-Context Impersonation Reveals Large Language Models' Strengths and Biases**](https://arxiv.org/abs/2305.14930) （**2023.05.24**）

<font color="gray">Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz, Zeynep Akata </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-30-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/ExplainableML/in-context-impersonation)

---

[**Frugal Prompting for Dialog Models**](https://arxiv.org/abs/2305.14919) （**2023.05.24**）

<font color="gray">Bishal Santra, Sakya Basak, Abhinandan De, Manish Gupta, Pawan Goyal </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chain-of-Questions Training with Latent Answers for Robust Multistep Question Answering**](https://arxiv.org/abs/2305.14901) （**2023.05.24**）

<font color="gray">Wang Zhu, Jesse Thomason, Robin Jia </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)

---

[**Improving Probability-based Prompt Selection Through Unified Evaluation and Analysis**](https://arxiv.org/abs/2305.14877) （**2023.05.24**）

<font color="gray">Sohee Yang, Jonghyeon Kim, Joel Jang, Seonghyeon Ye, Hyunji Lee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions**](https://arxiv.org/abs/2305.14795) （**2023.05.24**）

<font color="gray">Zexuan Zhong, Zhengxuan Wu, Christopher D. Manning, Christopher Potts, Danqi Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-18-red)  [![](https://img.shields.io/badge/Github%20Stars-62-blue)](https://github.com/princeton-nlp/mquake)

---

[**BeamSearchQA: Large Language Models are Strong Zero-Shot QA Solver**](https://arxiv.org/abs/2305.14766) （**2023.05.24**）

<font color="gray">Hao Sun, Xiao Liu, Yeyun Gong, Yan Zhang, Nan Duan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**TACR: A Table-alignment-based Cell-selection and Reasoning Model for Hybrid Question-Answering**](https://arxiv.org/abs/2305.14682) （**2023.05.24**）

<font color="gray">Jian Wu, Yicheng Xu, Yan Gao, Jian-Guang Lou, Börje F. Karlsson, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Mixture of Prompt Experts for Generalizable and Interpretable Question Answering**](https://arxiv.org/abs/2305.14628) （**2023.05.24**）

<font color="gray">Chenglei Si, Weijia Shi, Chen Zhao, Luke Zettlemoyer, Jordan L. Boyd-Graber </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)

---

[**Better Zero-Shot Reasoning with Self-Adaptive Prompting**](https://arxiv.org/abs/2305.14106) （**2023.05.23**）

<font color="gray">Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan O. Arik, Tomas Pfister </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Improving Language Models via Plug-and-Play Retrieval Feedback**](https://arxiv.org/abs/2305.14002) （**2023.05.23**）

<font color="gray">Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, Ashish Sabharwal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources**](https://arxiv.org/abs/2305.13269) （**2023.05.22**）

<font color="gray">Xingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng Ding, Shafiq R. Joty, etc </font>

![](https://img.shields.io/badge/Citations-7-green)

---

[**Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning**](https://arxiv.org/abs/2305.12295) （**2023.05.20**）

<font color="gray">Liangming Pan, Alon Albalak, Xinyi Wang, William Yang Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-60-red)  [![](https://img.shields.io/badge/Github%20Stars-139-blue)](https://github.com/teacherpeterpan/logic-llm)

---

[**SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs**](https://doi.org/10.48550/arXiv.2305.11461) （**2023.05.19**）

<font color="gray">IokTong Lei, ZhiDong Deng .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs**](https://doi.org/10.48550/arXiv.2305.11334) （**2023.05.18**）

<font color="gray">Giorgi Kokaia, Pratyush Sinha, Yutong Jiang, N. Boujemaa .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Efficient Prompting via Dynamic In-Context Learning**](https://doi.org/10.48550/arXiv.2305.11170) （**2023.05.18**）

<font color="gray">Wangchunshu Zhou, Yuchen Jiang, Ryan Cotterell, Mrinmaya Sachan .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SPSQL: Step-by-step Parsing Based Framework for Text-to-SQL Generation**](https://doi.org/10.48550/arXiv.2305.11061) （**2023.05.10**）

<font color="gray">Ran Shen, Gang Sun, Hao Shen, Yiling Li, Liangfeng Jin, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes**](https://doi.org/10.48550/arXiv.2305.02301) （**2023.05.03**）

<font color="gray">Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, etc .  - 【Annual Meeting of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-59-green)

---

[**WizardLM: Empowering Large Language Models to Follow Complex Instructions**](https://arxiv.org/abs/2304.12244) （**2023.04.24**）

<font color="gray">Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-180-red)  [![](https://img.shields.io/badge/Github%20Stars-8.1k-blue)](https://github.com/nlpxucan/wizardlm)

---

[**LLM+P: Empowering Large Language Models with Optimal Planning Proficiency**](https://arxiv.org/abs/2304.11477) （**2023.04.22**）

<font color="gray">B. Liu, Yuqian Jiang, Xiaohan Zhang, Qian Liu, Shiqi Zhang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-126-red)  [![](https://img.shields.io/badge/Github%20Stars-301-blue)](https://github.com/Cranial-XIX/llm-pddl)

---

[**Boosting Theory-of-Mind Performance in Large Language Models via Prompting**](https://doi.org/10.48550/arXiv.2304.11490) （**2023.04.22**）

<font color="gray">Shima Rahimi Moghaddam, C. Honey .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-23-green)  [![](https://img.shields.io/badge/Github%20Stars-31-blue)](https://github.com/shrahimim/boosting-theory-of-mind-in-llms-with-prompting)

---

[**Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts**](https://doi.org/10.1145/3544548.3581388) （**2023.04.19**）

<font color="gray">J. Zamfirescu-Pereira, Richmond Y. Wong, Bjoern Hartmann, Qiang Yang .  - 【International Conference on Human Factors in Computing Systems】</font>

![](https://img.shields.io/badge/Citations-24-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-147-red)

---

[**Progressive-Hint Prompting Improves Reasoning in Large Language Models**](https://arxiv.org/abs/2304.09797) （**2023.04.19**）

<font color="gray">Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, Yu Li </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-67-red)  [![](https://img.shields.io/badge/Github%20Stars-185-blue)](https://github.com/chuanyang-Zheng/Progressive-Hint)

---

[**Boosted Prompt Ensembles for Large Language Models**](https://doi.org/10.48550/arXiv.2304.05970) （**2023.04.12**）

<font color="gray">Silviu Pitis, Michael Ruogu Zhang, Andrew Wang, Jimmy Ba .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/awwang10/llmpromptboosting)

---

[**Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition**](https://arxiv.org/abs/2304.04704) （**2023.04.10**）



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-48-red)  [![](https://img.shields.io/badge/Github%20Stars-241-blue)](https://github.com/amazon-science/prompt-pretraining)

---

[**REFINER: Reasoning Feedback on Intermediate Representations**](https://arxiv.org/abs/2304.01904) （**2023.04.04**）

<font color="gray">Debjit Paul, Mete Ismayilzada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-32-red)  [![](https://img.shields.io/badge/Github%20Stars-58-blue)](https://github.com/debjitpaul/refiner)

---

[**Self-Refine: Iterative Refinement with Self-Feedback**](https://arxiv.org/abs/2303.17651) （**2023.03.30**）



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-165-red)  [![](https://img.shields.io/badge/Github%20Stars-386-blue)](https://github.com/madaan/self-refine)

---

[**Context-faithful Prompting for Large Language Models**](https://doi.org/10.48550/arXiv.2303.11315) （**2023.03.20**）

<font color="gray">Wenxuan Zhou, Sheng Zhang, Hoifung Poon, Muhao Chen .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-36-blue)](https://github.com/wzhouad/context-faithful-llm)

---

[**Reflexion: an autonomous agent with dynamic memory and self-reflection**](https://doi.org/10.48550/arXiv.2303.11366) （**2023.03.20**）

<font color="gray">Noah Shinn, Beck Labash, Ashwin Gopinath .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models**](https://doi.org/10.48550/arXiv.2303.10464) （**2023.03.18**）

<font color="gray">Vithursan Thangarasa, Abhay Gupta, William Marshall, Tianda Li, Kevin Leong, etc .  - 【Conference on Uncertainty in Artificial Intelligence】</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT**](https://doi.org/10.48550/arXiv.2302.11382) （**2023.02.21**）

<font color="gray">Jules White, Quchen Fu, Sam Hays, M. Sandborn, Carlos Olea, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks**](https://doi.org/10.48550/arXiv.2302.08043) （**2023.02.16**）

<font color="gray">Zemin Liu, Xingtong Yu, Yuan Fang, Xinming Zhang .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-112-blue)](https://github.com/Starlien95/GraphPrompt)

---

[**Progressive Prompts: Continual Learning for Language Models**](https://doi.org/10.48550/arXiv.2301.12314) （**2023.01.29**）

<font color="gray">Anastasia Razdaibiedina, Yuning Mao, Rui Hou, Madian Khabsa, M. Lewis, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-58-blue)](https://github.com/arazd/ProgressivePrompts)

---

[**Batch Prompting: Efficient Inference with Large Language Model APIs**](https://doi.org/10.48550/arXiv.2301.08721) （**2023.01.19**）

<font color="gray">Zhoujun Cheng, Jungo Kasai, Tao Yu .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-30-blue)](https://github.com/hkunlp/batch-prompting)

---

[**Successive Prompting for Decomposing Complex Questions**](https://doi.org/10.48550/arXiv.2212.04092) （**2022.12.08**）

<font color="gray">Dheeru Dua, Shivanshu Gupta, Sameer Singh, Matt Gardner .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-9-green)

---

[**Legal Prompt Engineering for Multilingual Legal Judgement Prediction**](https://doi.org/10.48550/arXiv.2212.02199) （**2022.12.05**）

<font color="gray">Dietrich Trautmann, Alina Petrova, Frank Schilder .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Investigating Prompt Engineering in Diffusion Models**](https://doi.org/10.48550/arXiv.2211.15462) （**2022.11.21**）

<font color="gray">Sam Witteveen, Martin Andrews .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**PAL: Program-aided Language Models**](https://doi.org/10.48550/arXiv.2211.10435) （**2022.11.18**）

<font color="gray">Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-25-green)  [![](https://img.shields.io/badge/Github%20Stars-555-blue)](https://github.com/srush/minichain)

---

[**Measuring and Narrowing the Compositionality Gap in Language Models**](https://doi.org/10.48550/arXiv.2210.03350) （**2022.10.07**）

<font color="gray">Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-28-green)  [![](https://img.shields.io/badge/Github%20Stars-202-blue)](https://github.com/ofirpress/self-ask)

---

[**ReAct: Synergizing Reasoning and Acting in Language Models**](https://doi.org/10.48550/arXiv.2210.03629) （**2022.10.06**）

<font color="gray">Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, I. Shafran, etc .  - 【arXiv.org】</font>

![](https://img.shields.io/badge/Citations-29-green)  [![](https://img.shields.io/badge/Github%20Stars-503-blue)](https://github.com/ysymyth/ReAct)

---

[**Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models**](https://doi.org/10.1109/TVCG.2022.3209479) （**2022.08.16**）

<font color="gray">Hendrik Strobelt, Albert Webson, Victor Sanh, Benjamin Hoover, J. Beyer, etc .  - 【IEEE Transactions on Visualization and Computer Graphics】</font>

![](https://img.shields.io/badge/Citations-10-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-35-red)

---

[**PromptChainer: Chaining Large Language Model Prompts through Visual Programming**](https://doi.org/10.1145/3491101.3519729) （**2022.03.13**）

<font color="gray">Tongshuang Sherry Wu, Ellen Jiang, Aaron Donsbach, J. Gray, A. Molina, etc .  - 【CHI Extended Abstracts】</font>

![](https://img.shields.io/badge/Citations-22-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-31-red)

---

[**Black-box Prompt Learning for Pre-trained Language Models**](https://arxiv.org/abs/2201.08531) （**2022.01.21**）

<font color="gray">Shizhe Diao, Xuechun Li, Yong Lin, Zhichao Huang, Xiao Zhou, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-17-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-53-red)  [![](https://img.shields.io/badge/Github%20Stars-48-blue)](https://github.com/shizhediao/black-box-prompt-learning)

---

[**Can Language Models be Biomedical Knowledge Bases?**](https://doi.org/10.18653/v1/2021.emnlp-main.388) （**2021.09.15**）

<font color="gray">Mujeen Sung, Jinhyuk Lee, Sean S. Yi, Minji Jeon, Sungdong Kim, etc .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-26-green)

---

[**Design Guidelines for Prompt Engineering Text-to-Image Generative Models**](https://doi.org/10.1145/3491102.3501825) （**2021.09.14**）

<font color="gray">Vivian Liu, Lydia B. Chilton .  - 【International Conference on Human Factors in Computing Systems】</font>

![](https://img.shields.io/badge/Citations-44-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-72-red)

---

[**Do Prompt-Based Models Really Understand the Meaning of Their Prompts?**](https://doi.org/10.18653/v1/2022.naacl-main.167) （**2021.09.02**）

<font color="gray">Albert Webson, Ellie Pavlick .  - 【North American Chapter of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-71-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-174-red)  [![](https://img.shields.io/badge/Github%20Stars-81-blue)](https://github.com/awebson/prompt_semantics)

---

[**SciFive: a text-to-text transformer model for biomedical literature**](https://arxiv.org/abs/2106.03598) （**2021.05.28**）

<font color="gray">Long Phan, J. Anibal, H. Tran, Shaurya Chanana, Erol Bahadroglu, etc .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-45-green)

---

[**Not All Memories are Created Equal: Learning to Forget by Expiring**](https://arxiv.org/abs/2105.06548) （**2021.05.13**）

<font color="gray">Sainbayar Sukhbaatar, Da Ju, Spencer Poff, Stephen Roller, Arthur D. Szlam, etc .  - 【International Conference on Machine Learning】</font>

![](https://img.shields.io/badge/Citations-16-green)

---

[**Long-Span Summarization via Local Attention and Content Selection**](https://doi.org/10.18653/v1/2021.acl-long.470) （**2021.05.08**）

<font color="gray">Potsawee Manakul, M. Gales .  - 【Annual Meeting of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-20-green)

---

[**Factual Probing Is [MASK]: Learning vs. Learning to Recall**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.398) （**2021.04.12**）

<font color="gray">Zexuan Zhong, Dan Friedman, Danqi Chen .  - 【North American Chapter of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-144-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-220-red)  [![](https://img.shields.io/badge/Github%20Stars-155-blue)](https://github.com/princeton-nlp/OptiPrompt)

---

[**BERTese: Learning to Speak to BERT**](https://doi.org/10.18653/v1/2021.eacl-main.316) （**2021.03.09**）

<font color="gray">Adi Haviv, Jonathan Berant, A. Globerson .  - 【Conference of the European Chapter of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-48-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-106-red)

---

[**PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains**](https://doi.org/10.1162/tacl_a_00468) （**2021.02.24**）

<font color="gray">Eyal Ben-David, Nadav Oved, Roi Reichart .  - 【International Conference on Topology, Algebra and Categories in Logic】</font>

![](https://img.shields.io/badge/Citations-28-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-105-red)  [![](https://img.shields.io/badge/Github%20Stars-49-blue)](https://github.com/eyalbd2/PADA)

---

[**PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains**](https://doi.org/10.1162/tacl_a_00468) （**2021.02.24**）

<font color="gray">Eyal Ben-David, Nadav Oved, Roi Reichart .  - 【International Conference on Topology, Algebra and Categories in Logic】</font>

![](https://img.shields.io/badge/Citations-28-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-78-red)  [![](https://img.shields.io/badge/Github%20Stars-44-blue)](https://github.com/eyalbd2/PADA)

---

[**Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm**](https://doi.org/10.1145/3411763.3451760) （**2021.02.15**）

<font color="gray">Laria Reynolds, Kyle McDonell .  - 【CHI Extended Abstracts】</font>

![](https://img.shields.io/badge/Citations-149-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-205-red)

---

[**Self-Alignment Pretraining for Biomedical Entity Representations**](https://doi.org/10.18653/V1/2021.NAACL-MAIN.334) （**2020.10.22**）

<font color="gray">Fangyu Liu, Ehsan Shareghi, Zaiqiao Meng, Marco Basaldella, N. Collier .  - 【North American Chapter of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-102-green)

---

[**Bio-Megatron: Larger Biomedical Domain Language Model**](https://doi.org/10.18653/v1/2020.emnlp-main.379) （**2020.10.12**）

<font color="gray">Hoo-Chang Shin, Yang Zhang, Evelina Bakhturina, Raul Puri, M. Patwary, etc .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-43-green)

---

[**Adapting In-Vehicle Voice Output:A User- and Situation-Adaptive Approach**](https://doi.org/10.1145/3409251.3411711) （**2020.09.21**）

<font color="gray">D. Stier, U. Heid, W. Minker .  - 【International Conference on Automotive User Interfaces and Interactive Vehicular Applications】</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries**](https://doi.org/10.18653/v1/2021.eacl-main.153) （**2020.08.20**）

<font color="gray">Benjamin Heinzerling, Kentaro Inui .  - 【Conference of the European Chapter of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-38-green)

---

[**Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing**](https://doi.org/10.1145/3458754) （**2020.07.31**）

<font color="gray">Yu Gu, Robert Tinn, Hao Cheng, Michael R. Lucas, Naoto Usuyama, etc .  - 【ACM Trans. Comput. Heal.】</font>

![](https://img.shields.io/badge/Citations-468-green)

---

[**Big Bird: Transformers for Longer Sequences**](https://arxiv.org/abs/2007.14062) （**2020.07.28**）

<font color="gray">M. Zaheer, Guru Guruganesh, Kumar Avinava Dubey, J. Ainslie, Chris Alberti, etc .  - 【Neural Information Processing Systems】</font>

![](https://img.shields.io/badge/Citations-847-green)

---

[**UnifiedQA: Crossing Format Boundaries With a Single QA System**](https://doi.org/10.18653/v1/2020.findings-emnlp.171) （**2020.05.02**）

<font color="gray">Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, etc .  - 【Findings】</font>

![](https://img.shields.io/badge/Citations-357-green)

---

[**How Can We Know What Language Models Know?**](https://doi.org/10.1162/tacl_a_00324) （**2019.11.28**）

<font color="gray">Zhengbao Jiang, Frank F. Xu, J. Araki, Graham Neubig .  - 【Transactions of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-423-green)

---

[**SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization**](https://doi.org/10.18653/v1/D19-5409) （**2019.11.27**）

<font color="gray">Bogdan Gliwa, Iwona Mochol, M. Biesek, A. Wawer .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-219-green)

---

[**Semantic Noise Matters for Neural Natural Language Generation**](https://doi.org/10.18653/v1/W19-8652) （**2019.11.01**）

<font color="gray">Ondrej Dusek, David M. Howcroft, Verena Rieser .  - 【International Conference on Natural Language Generation】</font>

![](https://img.shields.io/badge/Citations-74-green)

---

[**Fine-tune BERT with Sparse Self-Attention Mechanism**](https://doi.org/10.18653/v1/D19-1361) （**2019.11.01**）

<font color="gray">Baiyun Cui, Yingming Li, Ming Chen, Zhongfei Zhang .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-41-green)

---

[**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**](https://arxiv.org/abs/1910.10683) （**2019.10.23**）

<font color="gray">Colin Raffel, Noam M. Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, etc .  - 【Journal of machine learning research】</font>

![](https://img.shields.io/badge/Citations-6321-green)

---

[**TinyBERT: Distilling BERT for Natural Language Understanding**](https://doi.org/10.18653/v1/2020.findings-emnlp.372) （**2019.09.23**）

<font color="gray">Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, etc .  - 【Findings】</font>

![](https://img.shields.io/badge/Citations-911-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-861-red)  [![](https://img.shields.io/badge/Github%20Stars-2.6k-blue)](https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT)

---

[**Linguistic Design of In-Vehicle Prompts in Adaptive Dialog Systems: An Analysis of Potential Factors Involved in the Perception of Naturalness**](https://doi.org/10.1145/3320435.3320469) （**2019.06.07**）

<font color="gray">D. Stier, Ellen Sigloch .  - 【User Modeling, Adaptation, and Personalization】</font>

![](https://img.shields.io/badge/Citations-7-green)

---

[**BioBERT: a pre-trained biomedical language representation model for biomedical text mining**](https://doi.org/10.1093/bioinformatics/btz682) （**2019.01.25**）

<font color="gray">Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, etc .  - 【Bioinform.】</font>

![](https://img.shields.io/badge/Citations-2746-green)

---

[**Design guidelines for hands-free speech interaction**](https://doi.org/10.1145/3236112.3236149) （**2018.09.03**）

<font color="gray">Christine Murad, Cosmin Munteanu, L. Clark, Benjamin R. Cowan .  - 【MobileHCI Adjunct】</font>

![](https://img.shields.io/badge/Citations-62-green)

---

[**Attention is All you Need**](https://arxiv.org/abs/1706.03762) （**2017.06.12**）

<font color="gray">Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, etc .  - 【NIPS】</font>

![](https://img.shields.io/badge/Citations-52170-green)

---

[**Get To The Point: Summarization with Pointer-Generator Networks**](https://doi.org/10.18653/v1/P17-1099) （**2017.04.01**）

<font color="gray">A. See, Peter J. Liu, Christopher D. Manning .  - 【Annual Meeting of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-2928-green)

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

[**Representing Text for Joint Embedding of Text and Knowledge Bases**](https://doi.org/10.18653/v1/D15-1174) 

<font color="gray">Kristina Toutanova, Danqi Chen, P. Pantel, Hoifung Poon, Pallavi Choudhury, etc .  - 【Conference on Empirical Methods in Natural Language Processing】</font>

![](https://img.shields.io/badge/Citations-551-green)

---

[**The Influence of Syntax on the Perception of In-Vehicle Prompts and Driving Performance**](https://doi.org/10.1007/978-981-15-8395-7_26) 

<font color="gray">D. Stier, U. Heid, Patricia Kittel, Maria Schmidt, W. Minker .  - 【International Workshop on Spoken Dialogue Systems Technology】</font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**Soziolinguistik**](https://doi.org/10.1007/978-3-476-05861-4) 

<font color="gray">Jürgen Spitzmüller </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Prefix-Tuning: Optimizing Continuous Prompts for Generation**](https://doi.org/10.18653/v1/2021.acl-long.353) 

<font color="gray">Xiang Lisa Li, Percy Liang .  - 【Annual Meeting of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-835-green)

---

[**Prompt Combines Paraphrase: Enhancing Biomedical “Pre-training, Prompt and Predicting” Models by Explaining Rare Biomedical Concepts**](https://api.semanticscholar.org/4e305fe2ef347caddd8936bc0a8c462e33f6e2da) 

<font color="gray">Hao Wang </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Zur Abfolge nominaler Satzglieder im Deutschen**](https://api.semanticscholar.org/d93a04ab220196e6bbe3c8ff39b40ff6a8b7ca5a) 

<font color="gray">J. Lenerz </font>

![](https://img.shields.io/badge/Citations-367-green)

---

---

[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://doi.org/10.18653/v1/N19-1423) 

<font color="gray">Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova .  - 【North American Chapter of the Association for Computational Linguistics】</font>

![](https://img.shields.io/badge/Citations-47833-green)

---

[**A Prompt-Based Topic-Modeling Method for Depression Detection on Low-Resource Data**](https://doi.org/10.1109/tcss.2023.3260080) 

<font color="gray">Yanrong Guo, Jilong Liu, Lei Wang, Wei Qin, Shijie Hao, etc .  - 【IEEE Transactions on Computational Social Systems】</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**of the Association for Computational Linguistics:**](https://doi.org/10.1016/b0-08-044854-2/05234-2) 

<font color="gray">Vladimir Meza Ruiz, Rashmi Gangadharaiah, Maria Leonor Pacheco, Danqi Chen, Ryan Cotterell </font>

![](https://img.shields.io/badge/Citations-4076-green)

---

[**Prompt Engineering for Text-Based Generative Art**](https://doi.org/10.48550/arXiv.2204.13988) 

<font color="gray">J. Oppenlaender .  - 【ArXiv】</font>

![](https://img.shields.io/badge/Citations-4-green)


</div>