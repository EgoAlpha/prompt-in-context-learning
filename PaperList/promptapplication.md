# üìÑ Prompt Application

## Paper List

<div style="line-height:0.2em;">


[**Manipulating Large Language Models to Increase Product Visibility**](https://arxiv.org/abs/2404.07981) Ôºà**2024.04.11**Ôºâ

<font color="gray">Aounon Kumar, Himabindu Lakkaraju </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Generating consistent PDDL domains with Large Language Models**](https://arxiv.org/abs/2404.07751) Ôºà**2024.04.11**Ôºâ

<font color="gray">Pavel Smirnov, F. Joublin, A. Ceravola, Michael Gienger </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**High-Dimension Human Value Representation in Large Language Models**](https://arxiv.org/abs/2404.07900) Ôºà**2024.04.11**Ôºâ

<font color="gray">Samuel Cahyawijaya, Delong Chen, Yejin Bang, Leila Khalatbari, Bryan Wilie, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MetaCheckGPT -- A Multi-task Hallucination Detector Using LLM Uncertainty and Meta-models**](https://arxiv.org/abs/2404.06948) Ôºà**2024.04.10**Ôºâ

<font color="gray">Rahul Mehta, Andrew Hoblitzell, Jack O'Keefe, Hyeju Jang, Vasudeva Varma </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**From Model-centered to Human-Centered: Revision Distance as a Metric for Text Evaluation in LLMs-based Applications**](https://arxiv.org/abs/2404.07108) Ôºà**2024.04.10**Ôºâ

<font color="gray">Yongqiang Ma, Lizhi Qin, Jiawei Liu, Yangyang Kang, Yue Zhang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding**](https://arxiv.org/abs/2404.05225) Ôºà**2024.04.08**Ôºâ

<font color="gray">Chuwei Luo, Yufan Shen, Zhaoqing Zhu, Qi Zheng, Zhi Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models**](https://arxiv.org/abs/2404.05291) Ôºà**2024.04.08**Ôºâ

<font color="gray">Yutao Ouyang, Jinhan Li, Yunfei Li, Zhongyu Li, Chao Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Topic-based Watermarks for LLM-Generated Text**](https://arxiv.org/abs/2404.02138) Ôºà**2024.04.02**Ôºâ

<font color="gray">Alexander Nemecek, Yuzhou Jiang, Erman Ayday </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks**](https://arxiv.org/abs/2404.02151) Ôºà**2024.04.02**Ôºâ

<font color="gray">Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference**](https://doi.org/10.48550/arXiv.2403.20306) Ôºà**2024.03.29**Ôºâ

<font color="gray">Jovan Stojkovic, Esha Choukse, Chaojie Zhang, √ç√±igo Goiri, Josep Torrellas .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LUQ: Long-text Uncertainty Quantification for LLMs**](https://doi.org/10.48550/arXiv.2403.20279) Ôºà**2024.03.29**Ôºâ

<font color="gray">Caiqi Zhang, Fangyu Liu, Marco Basaldella, Nigel Collier .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Gecko: Versatile Text Embeddings Distilled from Large Language Models**](https://doi.org/10.48550/arXiv.2403.20327) Ôºà**2024.03.29**Ôºâ

<font color="gray">Jinhyuk Lee, Zhuyun Dai, Xiaoqi Ren, Blair Chen, Daniel Cer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models**](https://doi.org/10.48550/arXiv.2403.19548) Ôºà**2024.03.28**Ôºâ

<font color="gray">Piotr Molenda, Adian Liusie, Mark J. F. Gales .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MLDT: Multi-Level Decomposition for Complex Long-Horizon Robotic Task Planning with Open-Source Large Language Model**](https://doi.org/10.48550/arXiv.2403.18760) Ôºà**2024.03.27**Ôºâ

<font color="gray">Yike Wu, Jiatao Zhang, Nan Hu, LanLing Tang, Guilin Qi, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Comp4D: LLM-Guided Compositional 4D Scene Generation**](https://arxiv.org/abs/2403.16993) Ôºà**2024.03.25**Ôºâ

<font color="gray">Dejia Xu, Hanwen Liang, N. Bhatt, Hezhen Hu, Hanxue Liang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?**](https://arxiv.org/abs/2403.14624) Ôºà**2024.03.21**Ôºâ

<font color="gray">Renrui Zhang, Dongzhi Jiang, Yichi Zhang, Haokun Lin, Ziyu Guo, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning Ability of LLMs**](https://arxiv.org/abs/2403.13271) Ôºà**2024.03.20**Ôºâ

<font color="gray">Zhihong Sun, Chen Lyu, Bolun Li, Yao Wan, Hongyu Zhang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model**](https://arxiv.org/abs/2403.13244) Ôºà**2024.03.20**Ôºâ

<font color="gray">Peng Zhou, Jianmin Wang, Chunyan Li, Zixu Wang, Yiping Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Robots That Know When They Need Help: Affordance-Based Uncertainty for Large Language Model Planners**](https://arxiv.org/abs/2403.13198) Ôºà**2024.03.19**Ôºâ

<font color="gray">James F. Mullen, Dinesh Manocha </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ExeGPT: Constraint-Aware Resource Scheduling for LLM Inference**](https://arxiv.org/abs/2404.07947) Ôºà**2024.03.15**Ôºâ

<font color="gray">Hyungjun Oh, Kihong Kim, Jaemin Kim, Sungkyun Kim, Junyeol Lee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning**](https://arxiv.org/abs/2403.09028) Ôºà**2024.03.14**Ôºâ

<font color="gray">Ahmed Masry, Mehrad Shahmohammadi, Md. Rizwan Parvez, Enamul Hoque, Shafiq R. Joty </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference**](https://arxiv.org/abs/2403.09636) Ôºà**2024.03.14**Ôºâ

<font color="gray">Piotr Nawrot, Adrian La'ncucki, Marcin Chochowski, David Tarjan, E. M. Ponti </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Proactive Interactions for In-Vehicle Conversational Assistants Utilizing Large Language Models**](https://arxiv.org/abs/2403.09135) Ôºà**2024.03.14**Ôºâ

<font color="gray">Huifang Du, Xuejing Feng, Jun Ma, Meng Wang, Shiyu Tao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Simple and Scalable Strategies to Continually Pre-train Large Language Models**](https://arxiv.org/abs/2403.08763) Ôºà**2024.03.13**Ôºâ

<font color="gray">Adam Ibrahim, Benjamin Th'erien, Kshitij Gupta, Mats L. Richter, Quentin Anthony, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LG-Traj: LLM Guided Pedestrian Trajectory Prediction**](https://arxiv.org/abs/2403.08032) Ôºà**2024.03.12**Ôºâ

<font color="gray">Pranav Singh Chib, Pravendra Singh </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Big City Bias: Evaluating the Impact of Metropolitan Size on Computational Job Market Abilities of Language Models**](https://arxiv.org/abs/2403.08046) Ôºà**2024.03.12**Ôºâ

<font color="gray">Charlie Campanella, R. Goot .  - „ÄêNLP4HR„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**InfiCoder-Eval: Systematically Evaluating the Question-Answering Capabilities of Code Large Language Models**](https://arxiv.org/abs/2404.07940) Ôºà**2024.03.11**Ôºâ

<font color="gray">Linyi Li, Shijie Geng, Zhenwen Li, Yibo He, Hao Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Naming, Describing, and Quantifying Visual Objects in Humans and LLMs**](https://arxiv.org/abs/2403.06935) Ôºà**2024.03.11**Ôºâ

<font color="gray">Alberto Testoni, Juell Sprott, Sandro Pezzelle </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LLM4Decompile: Decompiling Binary Code with Large Language Models**](https://arxiv.org/abs/2403.05286) Ôºà**2024.03.08**Ôºâ

<font color="gray">Hanzhuo Tan, Qi Luo, Jing Li, Yuqun Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMs**](https://arxiv.org/abs/2403.05434) Ôºà**2024.03.08**Ôºâ

<font color="gray">Arijit Nag, Animesh Mukherjee, Niloy Ganguly, Soumen Chakrabarti </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference**](https://arxiv.org/abs/2403.04132) Ôºà**2024.03.07**Ôºâ

<font color="gray">Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, etc </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**SaulLM-7B: A pioneering Large Language Model for Law**](https://arxiv.org/abs/2403.03883) Ôºà**2024.03.06**Ôºâ

<font color="gray">Pierre Colombo, Telmo Pessoa Pires, Malik Boudiaf, Dominic Culver, Rui Melo, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection**](https://arxiv.org/abs/2403.02253) Ôºà**2024.03.04**Ôºâ

<font color="gray">Yuexin Li, Chengyu Huang, Shumin Deng, Mei Lin Lock, Tri Cao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models**](https://arxiv.org/abs/2402.19465) Ôºà**2024.02.29**Ôºâ

<font color="gray">Chen Qian, Jie Zhang, Wei Yao, Dongrui Liu, Zhen-fei Yin, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-13-blue)](https://github.com/chnq/tracingllm)

---

[**Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers**](https://arxiv.org/abs/2402.19479) Ôºà**2024.02.29**Ôºâ

<font color="gray">Tsai-Shien Chen, Aliaksandr Siarohin, Willi Menapace, Ekaterina Deyneka, Hsiang-wei Chao, etc </font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models**](https://arxiv.org/abs/2402.19427) Ôºà**2024.02.29**Ôºâ

<font color="gray">Soham De, Samuel L. Smith, Anushan Fernando, Aleksandar Botev, George Cristian-Muraru, etc </font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**The All-Seeing Project V2: Towards General Relation Comprehension of the Open World**](https://arxiv.org/abs/2402.19474) Ôºà**2024.02.29**Ôºâ

<font color="gray">Weiyun Wang, Yiming Ren, Hao Luo, Tiantong Li, Chenxiang Yan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs**](https://arxiv.org/abs/2402.18443) Ôºà**2024.02.28**Ôºâ

<font color="gray">Md Hafizur Rahman, Prabuddha Chakraborty </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits**](https://doi.org/10.48550/arXiv.2402.17764) Ôºà**2024.02.27**Ôºâ

<font color="gray">Shuming Ma, Hongyu Wang, Lingxiao Ma, Lei Wang, Wenhui Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**OncoGPT: A Medical Conversational Model Tailored with Oncology Domain Expertise on a Large Language Model Meta-AI (LLaMA)**](https://doi.org/10.48550/arXiv.2402.16810) Ôºà**2024.02.26**Ôºâ

<font color="gray">Fujian Jia, Xin Liu, Lixi Deng, Jiwen Gu, Chunchao Pu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs**](https://arxiv.org/abs/2402.15491) Ôºà**2024.02.23**Ôºâ

<font color="gray">Kinjal Basu, Ibrahim Abdelaziz, Subhajit Chaudhury, Soham Dan, M. Crouse, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Genie: Generative Interactive Environments**](https://arxiv.org/abs/2402.15391) Ôºà**2024.02.23**Ôºâ

<font color="gray">Jake Bruce, Michael Dennis, Ashley Edwards, Jack Parker-Holder, Yuge Shi, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Tokenization counts: the impact of tokenization on arithmetic in frontier LLMs**](https://doi.org/10.48550/arXiv.2402.14903) Ôºà**2024.02.22**Ôºâ

<font color="gray">Aaditya K. Singh, DJ Strouse .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs**](https://doi.org/10.48550/arXiv.2402.14872) Ôºà**2024.02.21**Ôºâ

<font color="gray">Xiaoxia Li, Siyuan Liang, Jiyi Zhang, Hansheng Fang, Aishan Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs**](https://doi.org/10.48550/arXiv.2402.05904) Ôºà**2024.02.08**Ôºâ

<font color="gray">Eun Cheol Choi, Emilio Ferrara .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models**](https://doi.org/10.48550/arXiv.2402.05935) Ôºà**2024.02.08**Ôºâ

<font color="gray">Peng Gao, Renrui Zhang, Chris Liu, Longtian Qiu, Siyuan Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**On the Convergence of Zeroth-Order Federated Tuning in Large Language Models**](https://doi.org/10.48550/arXiv.2402.05926) Ôºà**2024.02.08**Ôºâ

<font color="gray">Zhenqing Ling, Daoyuan Chen, Liuyi Yao, Yaliang Li, Ying Shen .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Model Meets Graph Neural Network in Knowledge Distillation**](https://doi.org/10.48550/arXiv.2402.05894) Ôºà**2024.02.08**Ôºâ

<font color="gray">Shengxiang Hu, Guobing Zou, Song Yang, Yanglan Gan, Bofeng Zhang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?**](https://doi.org/10.48550/arXiv.2401.18070) Ôºà**2024.01.31**Ôºâ

<font color="gray">Andreas Opedal, Alessandro Stolfo, Haruki Shirakami, Ying Jiao, Ryan Cotterell, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model**](https://doi.org/10.48550/arXiv.2401.16420) Ôºà**2024.01.29**Ôºâ

<font color="gray">Xiao-wen Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Bin Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-1.2k-blue)](https://github.com/internlm/internlm-xcomposer)

---

[**ChatQA: Building GPT-4 Level Conversational QA Models**](https://doi.org/10.48550/arXiv.2401.10225) Ôºà**2024.01.18**Ôºâ

<font color="gray">Zihan Liu, Wei Ping, Rajarshi Roy, Peng Xu, Chankyu Lee, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on Data-to-Text Generation**](https://doi.org/10.48550/arXiv.2401.10186) Ôºà**2024.01.18**Ôºâ

<font color="gray">Zdenƒõk Kasner, Ondvrej Duvsek .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models**](https://doi.org/10.48550/arXiv.2401.06066) Ôºà**2024.01.11**Ôºâ

<font color="gray">Damai Dai, Chengqi Deng, Chenggang Zhao, R. Xu, Huazuo Gao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-788-blue)](https://github.com/deepseek-ai/deepseek-moe)

---

[**Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection**](https://doi.org/10.48550/arXiv.2401.03737) Ôºà**2024.01.08**Ôºâ

<font color="gray">G. Fatouros, Konstantinos Metaxas, John Soldatos, D. Kyriazis .  - „ÄêSocial Science Research Network„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Instruct-Imagen: Image Generation with Multi-modal Instruction**](https://doi.org/10.48550/arXiv.2401.01952) Ôºà**2024.01.03**Ôºâ

<font color="gray">Hexiang Hu, Kelvin C.K. Chan, Yu-Chuan Su, Wenhu Chen, Yandong Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones**](https://doi.org/10.48550/arXiv.2312.16862) Ôºà**2023.12.28**Ôºâ

<font color="gray">Zhengqing Yuan, Zhaoxu Li, Lichao Sun .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-1.1k-blue)](https://github.com/dlyuangod/tinygpt-v)

---

[**MobileVLM : A Fast, Strong and Open Vision Language Assistant for Mobile Devices**](https://doi.org/10.48550/arXiv.2312.16886) Ôºà**2023.12.28**Ôºâ

<font color="gray">Xiangxiang Chu, Limeng Qiao, Xinyang Lin, Shuang Xu, Yang Yang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-535-blue)](https://github.com/meituan-automl/mobilevlm)

---

[**Generative AI for Math: Part I - MathPile: A Billion-Token-Scale Pretraining Corpus for Math**](https://doi.org/10.48550/arXiv.2312.17120) Ôºà**2023.12.28**Ôºâ

<font color="gray">Zengzhi Wang, Rui Xia, Pengfei Liu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation**](https://doi.org/10.48550/arXiv.2312.14187) Ôºà**2023.12.20**Ôºâ

<font color="gray">Zhaojian Yu, Xin Zhang, Ning Shang, Yangyu Huang, Can Xu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**A mathematical perspective on Transformers**](https://arxiv.org/abs/2312.10794) Ôºà**2023.12.17**Ôºâ

<font color="gray">Borjan Geshkovski, Cyril Letrouit, Yury Polyanskiy, Philippe Rigollet </font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/borjang/2023-transformers-rotf)

---

[**Mathematical discoveries from program search with large language models.**](https://doi.org/10.1038/s41586-023-06924-6) Ôºà**2023.12.14**Ôºâ

<font color="gray">Bernardino Romera-Paredes, M. Barekatain, Alexander Novikov, Matej Balog, M. P. Kumar, etc .  - „ÄêNature„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-133-red)

---

[**LMDrive: Closed-Loop End-to-End Driving with Large Language Models**](https://doi.org/10.48550/arXiv.2312.07488) Ôºà**2023.12.12**Ôºâ

<font color="gray">Hao Shao, Yuxuan Hu, Letian Wang, Steven L. Waslander, Yu Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**LLM360: Towards Fully Transparent Open-Source LLMs**](https://arxiv.org/abs/2312.06550) Ôºà**2023.12.11**Ôºâ

<font color="gray">Zhengzhong Liu, Aurick Qiao, W. Neiswanger, Hongyi Wang, Bowen Tan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-19-red)  [![](https://img.shields.io/badge/Github%20Stars-59-blue)](https://github.com/llm360/analysis360)

---

[**From Text to Motion: Grounding GPT-4 in a Humanoid Robot"Alter3"**](https://arxiv.org/abs/2312.06571) Ôºà**2023.12.11**Ôºâ

<font color="gray">Takahide Yoshida, A. Masumori, Takashi Ikegami </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Control Risk for Potential Misuse of Artificial Intelligence in Science**](https://arxiv.org/abs/2312.06632) Ôºà**2023.12.11**Ôºâ

<font color="gray">Jiyan He, Weitao Feng, Yaosen Min, Jingwei Yi, Kunsheng Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Sequential Modeling Enables Scalable Learning for Large Vision Models**](https://arxiv.org/abs/2312.00785) Ôºà**2023.12.01**Ôºâ

<font color="gray">Yutong Bai, Xinyang Geng, K. Mangalam, Amir Bar, Alan Yuille, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-161-red)  [![](https://img.shields.io/badge/Github%20Stars-1.4k-blue)](https://github.com/ytongbai/LVM)

---

[**MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers**](https://doi.org/10.48550/arXiv.2311.15475) Ôºà**2023.11.27**Ôºâ

<font color="gray">Yawar Siddiqui, A. Alliegro, Alexey Artemov, Tatiana Tommasi, Daniele Sirigatti, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Minimizing Factual Inconsistency and Hallucination in Large Language Models**](https://doi.org/10.48550/arXiv.2311.13878) Ôºà**2023.11.23**Ôºâ

<font color="gray">I. Muneeswaran, Shreya Saxena, Siva Prasad, M. V. S. Prakash, Advaith Shankar, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**](https://doi.org/10.48550/arXiv.2311.11797) Ôºà**2023.11.20**Ôºâ

<font color="gray">Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-252-blue)](https://github.com/zoeyyao27/cot-igniting-agent)

---

[**An Embodied Generalist Agent in 3D World**](https://doi.org/10.48550/arXiv.2311.12871) Ôºà**2023.11.18**Ôºâ

<font color="gray">Jiangyong Huang, Silong Yong, Xiaojian Ma, Xiongkun Linghu, Puhao Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-165-blue)](https://github.com/embodied-generalist/embodied-generalist)

---

[**Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning**](https://doi.org/10.48550/arXiv.2311.10709) Ôºà**2023.11.17**Ôºâ

<font color="gray">Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, S. Azadi, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Chat-UniVi: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding**](https://doi.org/10.48550/arXiv.2311.08046) Ôºà**2023.11.14**Ôºâ

<font color="gray">Peng Jin, Ryuichi Takanobu, Caiwan Zhang, Xiaochun Cao, Li Yuan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**SpectralGPT: Spectral Foundation Model**](https://doi.org/10.48550/arXiv.2311.07113) Ôºà**2023.11.13**Ôºâ

<font color="gray">D. Hong, Bing Zhang, Xuyang Li, Yuxuan Li, Chenyu Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Social Motion Prediction with Cognitive Hierarchies**](https://doi.org/10.48550/arXiv.2311.04726) Ôºà**2023.11.08**Ôºâ

<font color="gray">Wentao Zhu, Jason Qin, Yuke Lou, Hang Ye, Xiaoxuan Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Pre-training LLMs using human-like development data corpus**](https://doi.org/10.48550/arXiv.2311.04666) Ôºà**2023.11.08**Ôºâ

<font color="gray">Khushi Bhardwaj, Raj Sanjay Shah, Sashank Varma .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration**](https://doi.org/10.48550/arXiv.2311.04257) Ôºà**2023.11.07**Ôºâ

<font color="gray">Qinghao Ye, Haiyang Xu, Jiabo Ye, Mingshi Yan, Anwen Hu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-1.7k-blue)](https://github.com/x-plug/mplug-owl)

---

[**Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation**](https://doi.org/10.48550/arXiv.2311.03348) Ôºà**2023.11.06**Ôºâ

<font color="gray">Rusheb Shah, Quentin Feuillade--Montixi, Soroush Pour, Arush Tagade, Stephen Casper, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Ziya2: Data-centric Learning is All LLMs Need**](https://doi.org/10.48550/arXiv.2311.03301) Ôºà**2023.11.06**Ôºâ

<font color="gray">Ruyi Gan, Ziwei Wu, Renliang Sun, Junyu Lu, Xiaojun Wu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Levels of AGI: Operationalizing Progress on the Path to AGI**](https://doi.org/10.48550/arXiv.2311.02462) Ôºà**2023.11.04**Ôºâ

<font color="gray">Meredith Ringel Morris, Jascha Narain Sohl-Dickstein, Noah Fiedel, T. Warkentin, Allan Dafoe, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**PILL: Plug Into LLM with Adapter Expert and Attention Gate**](https://doi.org/10.48550/arXiv.2311.02126) Ôºà**2023.11.03**Ôºâ

<font color="gray">Fangyuan Zhang, Tingting Liang, Zhengyuan Wu, Yuyu Yin .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/dsaltyfish/pill)

---

[**RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation**](https://doi.org/10.48550/arXiv.2311.01455) Ôºà**2023.11.02**Ôºâ

<font color="gray">Yufei Wang, Zhou Xian, Feng Chen, Tsun-Hsuan Wang, Yian Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**TopicGPT: A Prompt-based Topic Modeling Framework**](https://doi.org/10.48550/arXiv.2311.01449) Ôºà**2023.11.02**Ôºâ

<font color="gray">Chau Minh Pham, Alexander Miserlis Hoyle, Simeng Sun, Mohit Iyyer .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-144-blue)](https://github.com/chtmp223/topicgpt)

---

[**ChipNeMo: Domain-Adapted LLMs for Chip Design**](https://doi.org/10.48550/arXiv.2311.00176) Ôºà**2023.10.31**Ôºâ

<font color="gray">Mingjie Liu, Teodor-Dumitru Ene, Robert Kirby, Chris Cheng, Nathaniel Pinckney, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-10-green)

---

[**Narratron: Collaborative Writing and Shadow-playing of Children Stories with Large Language Models**](https://doi.org/10.1145/3586182.3625120) Ôºà**2023.10.29**Ôºâ

<font color="gray">Yubo Zhao, Xiying Bao .  - „ÄêAdjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**CodeFusion: A Pre-trained Diffusion Model for Code Generation**](https://arxiv.org/abs/2310.17680) Ôºà**2023.10.26**Ôºâ

<font color="gray">Mukul Singh, J. Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**GraphGPT: Graph Instruction Tuning for Large Language Models**](https://doi.org/10.48550/arXiv.2310.13023) Ôºà**2023.10.19**Ôºâ

<font color="gray">Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-385-blue)](https://github.com/HKUDS/GraphGPT)

---

[**Creative Robot Tool Use with Large Language Models**](https://doi.org/10.48550/arXiv.2310.13065) Ôºà**2023.10.19**Ôºâ

<font color="gray">Mengdi Xu, Peide Huang, Wenhao Yu, Shiqi Liu, Xilun Zhang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models**](https://doi.org/10.48550/arXiv.2310.11954) Ôºà**2023.10.18**Ôºâ

<font color="gray">Dingyao Yu, Kaitao Song, Peiling Lu, Tianyu He, Xu Tan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-3.9k-blue)](https://github.com/microsoft/muzic)

---

[**Llemma: An Open Language Model For Mathematics**](https://doi.org/10.48550/arXiv.2310.10631) Ôºà**2023.10.16**Ôºâ

<font color="gray">Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-6.5k-blue)](https://github.com/eleutherai/gpt-neox)

---

[**BiLL-VTG: Bridging Large Language Models and Lightweight Visual Tools for Video-based Texts Generation**](https://doi.org/10.48550/arXiv.2310.10586) Ôºà**2023.10.16**Ôºâ

<font color="gray">Ji Qi, Kaixuan Ji, Jifan Yu, Duokang Wang, Bin Xu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**JMedLoRA: Medical Domain Adaptation on Japanese Large Language Models using Instruction-tuning**](https://doi.org/10.48550/arXiv.2310.10083) Ôºà**2023.10.16**Ôºâ

<font color="gray">Issey Sukeda, Masahiro Suzuki, Hiroki Sakaji, Satoshi Kodera .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Table-GPT: Table-tuned GPT for Diverse Table Tasks**](https://doi.org/10.48550/arXiv.2310.09263) Ôºà**2023.10.13**Ôºâ

<font color="gray">Peng Li, Yeye He, Dror Yashar, Weiwei Cui, Song Ge, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MemGPT: Towards LLMs as Operating Systems**](https://arxiv.org/abs/2310.08560) Ôºà**2023.10.12**Ôºâ

<font color="gray">Charles Packer, Vivian Fang, Shishir G. Patil, Kevin Lin, Sarah Wooders, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ferret: Refer and Ground Anything Anywhere at Any Granularity**](https://arxiv.org/abs/2310.07704) Ôºà**2023.10.11**Ôºâ

<font color="gray">Haoxuan You, Haotian Zhang, Zhe Gan, Xianzhi Du, Bowen Zhang, etc </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Understanding the Effects of RLHF on LLM Generalisation and Diversity**](https://arxiv.org/abs/2310.06452) Ôºà**2023.10.10**Ôºâ

<font color="gray">Robert Kirk, Ishita Mediratta, Christoforos Nalmpantis, Jelena Luketina, Eric Hambro, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-32-red)  [![](https://img.shields.io/badge/Github%20Stars-21-blue)](https://github.com/facebookresearch/rlfh-gen-div)

---

[**Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading**](https://doi.org/10.48550/arXiv.2310.05029) Ôºà**2023.10.08**Ôºâ

<font color="gray">Howard Chen, Ramakanth Pasunuru, Jason Weston, Asli Celikyilmaz .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**xVal: A Continuous Number Encoding for Large Language Models**](https://doi.org/10.48550/arXiv.2310.02989) Ôºà**2023.10.04**Ôºâ

<font color="gray">Siavash Golkar, Mariel Pettee, Michael Eickenberg, Alberto Bietti, M. Cranmer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-85-blue)](https://github.com/PolymathicAI/xVal)

---

[**How FaR Are Large Language Models From Agents with Theory-of-Mind?**](https://arxiv.org/abs/2310.03051) Ôºà**2023.10.04**Ôºâ

<font color="gray">Pei Zhou, Aman Madaan, Srividya Pranavi Potharaju, Aditya Gupta, Kevin R. McKee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-29-red)

---

[**MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens**](https://doi.org/10.48550/arXiv.2310.02239) Ôºà**2023.10.03**Ôºâ

<font color="gray">Kaizhi Zheng, Xuehai He, Xin Eric Wang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**PB-LLM: Partially Binarized Large Language Models**](https://doi.org/10.48550/arXiv.2310.00034) Ôºà**2023.09.29**Ôºâ

<font color="gray">Yuzhang Shang, Zhihang Yuan, Qiang Wu, Zhen Dong .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-107-blue)](https://github.com/hahnyuan/pb-llm)

---

[**GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond**](https://doi.org/10.48550/arXiv.2309.16583) Ôºà**2023.09.28**Ôºâ

<font color="gray">Shen Zheng, Yuyu Zhang, Yijie Zhu, Chenguang Xi, Pengyang Gao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-328-blue)](https://github.com/gpt-fathom/gpt-fathom)

---

[**Chatmap : Large Language Model Interaction with Cartographic Data**](https://doi.org/10.48550/arXiv.2310.01429) Ôºà**2023.09.28**Ôºâ

<font color="gray">Eren Unlu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Integration of Large Language Models within Cognitive Architectures for Autonomous Robots**](https://doi.org/10.48550/arXiv.2309.14945) Ôºà**2023.09.26**Ôºâ

<font color="gray">Miguel √Ångel Gonz√°lez Santamarta, F. J. Lera, √Ångel Manuel Guerrero Higueras, Vicente Matell√°n Olivera .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Effective Distillation of Table-based Reasoning Ability from LLMs**](https://doi.org/10.48550/arXiv.2309.13182) Ôºà**2023.09.22**Ôºâ

<font color="gray">Bohao Yang, Chen Tang, Kangning Zhao, Chenghao Xiao, Chenghua Lin .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs**](https://doi.org/10.48550/arXiv.2309.13007) Ôºà**2023.09.22**Ôºâ

<font color="gray">Justin Chih-Yao Chen, Swarnadeep Saha, Mohit Bansal .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-146-blue)](https://github.com/dinobby/reconcile)

---

[**Chain-of-Verification Reduces Hallucination in Large Language Models**](https://doi.org/10.48550/arXiv.2309.11495) Ôºà**2023.09.20**Ôºâ

<font color="gray">S. Dhuliawala, M. Komeili, Jing Xu, Roberta Raileanu, Xian Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-704-blue)](https://github.com/lastmile-ai/aiconfig/tree/main/cookbooks/Chain-of-Verification)

---

[**Kosmos-2.5: A Multimodal Literate Model**](https://doi.org/10.48550/arXiv.2309.11419) Ôºà**2023.09.20**Ôºâ

<font color="gray">Tengchao Lv, Yupan Huang, Jingye Chen, Lei Cui, Shuming Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DreamLLM: Synergistic Multimodal Comprehension and Creation**](https://doi.org/10.48550/arXiv.2309.11499) Ôºà**2023.09.20**Ôºâ

<font color="gray">Runpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-185-blue)](https://github.com/RunpeiDong/DreamLLM)

---

[**SwitchGPT: Adapting Large Language Models for Non-Text Outputs**](https://doi.org/10.48550/arXiv.2309.07623) Ôºà**2023.09.14**Ôºâ

<font color="gray">Xinyu Wang, Bohan Zhuang, Qi Wu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**NExT-GPT: Any-to-Any Multimodal LLM**](https://doi.org/10.48550/arXiv.2309.05519) Ôºà**2023.09.11**Ôºâ

<font color="gray">Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, Tat-Seng Chua .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-1.9k-blue)](https://github.com/NExT-GPT/NExT-GPT)

---

[**From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting**](https://doi.org/10.48550/arXiv.2309.04269) Ôºà**2023.09.08**Ôºâ

<font color="gray">Griffin Adams, Alexander R. Fabbri, Faisal Ladhak, Eric Lehman, No√©mie Elhadad .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Models as Optimizers**](https://arxiv.org/abs/2309.03409) Ôºà**2023.09.07**Ôºâ

<font color="gray">Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-220-red)

---

[**DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models**](https://doi.org/10.48550/arXiv.2309.03883) Ôºà**2023.09.07**Ôºâ

<font color="gray">Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James R. Glass, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-184-blue)](https://github.com/voidism/dola)

---

[**YaRN: Efficient Context Window Extension of Large Language Models**](https://doi.org/10.48550/arXiv.2309.00071) Ôºà**2023.08.31**Ôºâ

<font color="gray">Bowen Peng, Jeffrey Quesnelle, Honglu Fan, Enrico Shippole .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-1.0k-blue)](https://github.com/jquesnelle/yarn)

---

[**MVDream: Multi-view Diffusion for 3D Generation**](https://doi.org/10.48550/arXiv.2308.16512) Ôºà**2023.08.31**Ôºâ

<font color="gray">Yichun Shi, Peng Wang, Jianglong Ye, Mai Long, Kejie Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-10-green)

---

[**FedLogic: Interpretable Federated Multi-Domain Chain-of-Thought Prompt Selection for Large Language Models**](https://doi.org/10.48550/arXiv.2308.15324) Ôºà**2023.08.29**Ôºâ

<font color="gray">Pengwei Xing, Songtao Lu, Han Yu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**PE-MED: Prompt Enhancement for Interactive Medical Image Segmentation**](https://doi.org/10.48550/arXiv.2308.13746) Ôºà**2023.08.26**Ôºâ

<font color="gray">Ao Chang, Xing Tao, Xin Yang, Yuhao Huang, Xinrui Zhou, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DARWIN Series: Domain Specific Large Language Models for Natural Science**](https://doi.org/10.48550/arXiv.2308.13565) Ôºà**2023.08.25**Ôºâ

<font color="gray">Tong Xie, Yuwei Wan, Wei Huang, Yufei Zhou, Yixuan Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-118-blue)](https://github.com/masterai-eam/darwin)

---

[**ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation**](https://doi.org/10.48550/arXiv.2308.11131) Ôºà**2023.08.22**Ôºâ

<font color="gray">Jianghao Lin, Rongjie Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**SeqGPT: An Out-of-the-box Large Language Model for Open Domain Sequence Understanding**](https://doi.org/10.48550/arXiv.2308.10529) Ôºà**2023.08.21**Ôºâ

<font color="gray">Tianyu Yu, Chengyue Jiang, Chao Lou, Shen Huang, Xiaobin Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-66-blue)](https://github.com/alibaba-nlp/seqgpt)

---

[**Giraffe: Adventures in Expanding Context Lengths in LLMs**](https://doi.org/10.48550/arXiv.2308.10882) Ôºà**2023.08.21**Ôºâ

<font color="gray">Arka Pal, Deep Karkhanis, Manley Roberts, S. Dooley, Arvind Sundararajan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-454-blue)](https://github.com/abacusai/long-context)

---

[**ExpeL: LLM Agents Are Experiential Learners**](https://doi.org/10.48550/arXiv.2308.10144) Ôºà**2023.08.20**Ôºâ

<font color="gray">Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Y. Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/Andrewzh112/ExpeL)

---

[**Chat-3D: Data-efficiently Tuning Large Language Model for Universal Dialogue of 3D Scenes**](https://doi.org/10.48550/arXiv.2308.08769) Ôºà**2023.08.17**Ôºâ

<font color="gray">Zehan Wang, Haifeng Huang, Yang Zhao, Ziang Zhang, Zhou Zhao .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**The Devil is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation**](https://doi.org/10.48550/arXiv.2308.07286) Ôºà**2023.08.14**Ôºâ

<font color="gray">Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr√© F. T. Martins, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Accelerating LLM Inference with Staged Speculative Decoding**](https://doi.org/10.48550/arXiv.2308.04623) Ôºà**2023.08.08**Ôºâ

<font color="gray">Benjamin Spector, Christal Re .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Shepherd: A Critic for Language Model Generation**](https://doi.org/10.48550/arXiv.2308.04592) Ôºà**2023.08.08**Ôºâ

<font color="gray">Tianlu Wang, Ping Yu, Xiaoqing Tan, Sean O'Brien, Ramakanth Pasunuru, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-160-blue)](https://github.com/facebookresearch/shepherd)

---

[**AgentBench: Evaluating LLMs as Agents**](https://doi.org/10.48550/arXiv.2308.03688) Ôºà**2023.08.07**Ôºâ

<font color="gray">Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-1.6k-blue)](https://github.com/thudm/agentbench)

---

[**Scaling Relationship on Learning Mathematical Reasoning with Large Language Models**](https://doi.org/10.48550/arXiv.2308.01825) Ôºà**2023.08.03**Ôºâ

<font color="gray">Zheng Yuan, Hongyi Yuan, Cheng Li, Guanting Dong, Chuanqi Tan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-11-green)  [![](https://img.shields.io/badge/Github%20Stars-134-blue)](https://github.com/ofa-sys/gsm8k-screl)

---

[**Advancing Beyond Identification: Multi-bit Watermark for Language Models**](https://doi.org/10.48550/arXiv.2308.00221) Ôºà**2023.08.01**Ôºâ

<font color="gray">Kiyoon Yoo, W. Ahn, N. Kwak .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**A Private Watermark for Large Language Models**](https://doi.org/10.48550/arXiv.2307.16230) Ôºà**2023.07.30**Ôºâ

<font color="gray">Aiwei Liu, Leyi Pan, Xuming Hu, Shuang Li, Lijie Wen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/THU-BPM/private_watermark)

---

[**Robust Distortion-free Watermarks for Language Models**](https://doi.org/10.48550/arXiv.2307.15593) Ôºà**2023.07.28**Ôºâ

<font color="gray">Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, Percy Liang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-48-blue)](https://github.com/jthickstun/watermark)

---

[**Publisher Correction: Large language models encode clinical knowledge.**](https://doi.org/10.1038/s41586-023-06455-0) Ôºà**2023.07.27**Ôºâ

<font color="gray">K. Singhal, Shekoofeh Azizi, Tao Tu, S. S. Mahdavi, Jason Wei, etc .  - „ÄêNature„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Med-Flamingo: a Multimodal Medical Few-shot Learner**](https://doi.org/10.48550/arXiv.2307.15189) Ôºà**2023.07.27**Ôºâ

<font color="gray">Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, C. Zakka, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-335-blue)](https://github.com/snap-stanford/med-flamingo)

---

[**Med-Flamingo: a Multimodal Medical Few-shot Learner**](https://doi.org/10.48550/arXiv.2307.15189) Ôºà**2023.07.27**Ôºâ

<font color="gray">Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, C. Zakka, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-253-blue)](https://github.com/snap-stanford/med-flamingo)

---

[**CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots**](https://doi.org/10.48550/arXiv.2307.11865) Ôºà**2023.07.21**Ôºâ

<font color="gray">Nikhil Kakodkar, D. Rivkin, Bobak H. Baghi, F. Hogan, Gregory Dudek .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning**](https://doi.org/10.48550/arXiv.2307.09474) Ôºà**2023.07.18**Ôºâ

<font color="gray">Liang Zhao, En Yu, Zheng Ge, Jinrong Yang, Hao-Ran Wei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT**](https://doi.org/10.48550/arXiv.2307.08674) Ôºà**2023.07.17**Ôºâ

<font color="gray">Liangyu Zha, Junlin Zhou, Liyao Li, Rui Wang, Qingyi Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)

---

[**MasterKey: Automated Jailbreak Across Multiple Large Language Model Chatbots**](https://arxiv.org/abs/2307.08715) Ôºà**2023.07.16**Ôºâ

<font color="gray">Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, etc </font>

![](https://img.shields.io/badge/Citations-13-green)

---

[**Self-consistency for open-ended generations**](https://doi.org/10.48550/arXiv.2307.06857) Ôºà**2023.07.11**Ôºâ

<font color="gray">Siddhartha Jain, Xiaofei Ma, Anoop Deoras, Bing Xiang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens**](https://doi.org/10.48550/arXiv.2307.02486) Ôºà**2023.07.05**Ôºâ

<font color="gray">Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-17.2k-blue)](https://github.com/microsoft/unilm)

---

[**Mitigating the Learning Bias towards Repetition by Self-Contrastive Training for Open-Ended Generation**](https://doi.org/10.48550/arXiv.2307.01542) Ôºà**2023.07.04**Ôºâ

<font color="gray">Jian Guan, Minlie Huang .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/thu-coai/selfcont)

---

[**Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics**](https://doi.org/10.48550/arXiv.2307.02502) Ôºà**2023.07.04**Ôºâ

<font color="gray">M. Swan, Takashi Kido, Eric Roland, R. P. D. Santos .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Conformer LLMs - Convolution Augmented Large Language Models**](https://doi.org/10.48550/arXiv.2307.00461) Ôºà**2023.07.02**Ôºâ

<font color="gray">Prateek Verma .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Inferring the Goals of Communicating Agents from Actions and Instructions**](https://doi.org/10.48550/arXiv.2306.16207) Ôºà**2023.06.28**Ôºâ

<font color="gray">Lance Ying, Tan Zhi-Xuan, Vikash K. Mansinghka, J. Tenenbaum .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Kosmos-2: Grounding Multimodal Large Language Models to the World**](https://doi.org/10.48550/arXiv.2306.14824) Ôºà**2023.06.26**Ôºâ

<font color="gray">Zhiliang Peng, Wenhui Wang, Li Dong, Y. Hao, Shaohan Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-16.7k-blue)](https://github.com/microsoft/unilm/tree/master/kosmos-2)

---

[**AudioPaLM: A Large Language Model That Can Speak and Listen**](https://doi.org/10.48550/arXiv.2306.12925) Ôºà**2023.06.22**Ôºâ

<font color="gray">Paul K. Rubenstein, Chulayuth Asawaroengchai, D. Nguyen, Ankur Bapna, Zal√°n Borsos, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards AGI in Computer Vision: Lessons Learned from GPT and Large Language Models**](https://doi.org/10.48550/arXiv.2306.08641) Ôºà**2023.06.14**Ôºâ

<font color="gray">Lingxi Xie, Longhui Wei, Xiaopeng Zhang, Kaifeng Bi, Xiaotao Gu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models**](https://doi.org/10.48550/arXiv.2306.07971) Ôºà**2023.06.13**Ôºâ

<font color="gray">Omkar Thawakar, Abdelrahman M. Shaker, Sahal Shaji Mullappilly, Hisham Cholakkal, R. Anwer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-232-blue)](https://github.com/mbzuai-oryx/xraygpt)

---

[**Judging LLM-as-a-judge with MT-Bench and Chatbot Arena**](https://doi.org/10.48550/arXiv.2306.05685) Ôºà**2023.06.09**Ôºâ

<font color="gray">Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-102-green)  [![](https://img.shields.io/badge/Github%20Stars-31.9k-blue)](https://github.com/lm-sys/fastchat)

---

[**Judging LLM-as-a-judge with MT-Bench and Chatbot Arena**](https://doi.org/10.48550/arXiv.2306.05685) Ôºà**2023.06.09**Ôºâ

<font color="gray">Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-267-green)

---

[**PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance**](https://doi.org/10.48550/arXiv.2306.05443) Ôºà**2023.06.08**Ôºâ

<font color="gray">Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-123-blue)](https://github.com/chancefocus/pixiu)

---

[**ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory**](https://doi.org/10.48550/arXiv.2306.03901) Ôºà**2023.06.06**Ôºâ

<font color="gray">Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, J. Zhao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only**](https://doi.org/10.48550/arXiv.2306.01116) Ôºà**2023.06.01**Ôºâ

<font color="gray">Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra-Aim√©e Cojocaru, Alessandro Cappelli, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-50-green)  [![](https://img.shields.io/badge/Github%20Stars-29-blue)](https://github.com/ai21labs/factor)

---

[**Baselines for Identifying Watermarked Large Language Models**](https://doi.org/10.48550/arXiv.2305.18456) Ôºà**2023.05.29**Ôºâ

<font color="gray">Leonard Tang, Gavin Uberti, Tom Shlomi .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Undetectable Watermarks for Language Models**](https://doi.org/10.48550/arXiv.2306.09194) Ôºà**2023.05.25**Ôºâ

<font color="gray">Miranda Christ, S. Gunn, Or Zamir .  - „ÄêIACR Cryptology ePrint Archive„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Mitigating Temporal Misalignment by Discarding Outdated Facts**](https://arxiv.org/abs/2305.14824) Ôºà**2023.05.24**Ôºâ

<font color="gray">Michael J.Q. Zhang, Eunsol Choi </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/mikejqzhang/mitigating_misalignment)

---

[**Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective**](https://arxiv.org/abs/2305.15408) Ôºà**2023.05.24**Ôºâ

<font color="gray">Guhao Feng, Yuntian Gu, Bohang Zhang, Haotian Ye, Di He, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-42-red)

---

[**Peek Across: Improving Multi-Document Modeling via Cross-Document Question-Answering**](https://arxiv.org/abs/2305.15387) Ôºà**2023.05.24**Ôºâ

<font color="gray">Avi Caciularu, Matthew E. Peters, Jacob Goldberger, Ido Dagan, Arman Cohan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/aviclu/peekacross)

---

[**Context-Aware Transformer Pre-Training for Answer Sentence Selection**](https://arxiv.org/abs/2305.15358) Ôºà**2023.05.24**Ôºâ

<font color="gray">Luca Di Liello, Siddhant Garg, Alessandro Moschitti </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Gorilla: Large Language Model Connected with Massive APIs**](https://arxiv.org/abs/2305.15334) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shishir G. Patil, Tianjun Zhang, Xin Wang, Joseph E. Gonzalez </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-170-red)  [![](https://img.shields.io/badge/Github%20Stars-9.0k-blue)](https://github.com/ShishirPatil/gorilla)

---

[**Visual Programming for Text-to-Image Generation and Evaluation**](https://arxiv.org/abs/2305.15328) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jaemin Cho, Abhay Zala, Mohit Bansal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-28-red)

---

[**Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model**](https://arxiv.org/abs/2305.15265) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zirui Liu, Guanchu Wang, Shaochen Zhong, Zhaozhuo Xu, Daochen Zha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/zirui-ray-liu/wtacrs)

---

[**LMs with a Voice: Spoken Language Modeling beyond Speech Tokens**](https://arxiv.org/abs/2305.15255) Ôºà**2023.05.24**Ôºâ

<font color="gray">Eliya Nachmani, Alon Levkovitch, Julian Salazar, Chulayutsh Asawaroengchai, Soroosh Mariooryad, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator**](https://arxiv.org/abs/2305.15099) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ziwei He, Meng Yang, Minwei Feng, Jingcheng Yin, Xinbing Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-13-blue)](https://github.com/lumia-group/fouriertransformer)

---

[**CSTS: Conditional Semantic Textual Similarity**](https://arxiv.org/abs/2305.15093) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ameet Deshpande, Carlos E. Jimenez, Howard Chen, Vishvak S. Murahari, Victoria Graf, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)

---

[**STAR: Boosting Low-Resource Event Extraction by Structure-to-Text Data Generation with Large Language Models**](https://arxiv.org/abs/2305.15090) Ôºà**2023.05.24**Ôºâ

<font color="gray">Mingyu Derek Ma, Xiaoxuan Wang, Po-Nien Kung, P. Jeffrey Brantingham, Nanyun Peng, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)

---

[**Contrastive Learning of Sentence Embeddings from Scratch**](https://arxiv.org/abs/2305.15077) Ôºà**2023.05.24**Ôºâ

<font color="gray">Junlei Zhang, Zhenzhong Lan, Junxian He </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-24-blue)](https://github.com/hkust-nlp/syncse)

---

[**Meta-Learning Online Adaptation of Language Models**](https://arxiv.org/abs/2305.15076) Ôºà**2023.05.24**Ôºâ

<font color="gray">Nathan J. Hu, Eric Mitchell, Christopher D. Manning, Chelsea Finn </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-12-blue)](https://github.com/nathanhu0/CaMeLS)

---

[**Who Wrote this Code? Watermarking for Code Generation**](https://arxiv.org/abs/2305.15060) Ôºà**2023.05.24**Ôºâ

<font color="gray">Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/hongcheki/sweet-watermark)

---

[**Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering**](https://arxiv.org/abs/2305.15056) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiajie Zhang, Shulin Cao, Tingjia Zhang, Xin Lv, Jiaxin Shi, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)

---

[**Understanding Arithmetic Reasoning in Language Models using Causal Mediation Analysis**](https://arxiv.org/abs/2305.15054) Ôºà**2023.05.24**Ôºâ

<font color="gray">Alessandro Stolfo, Yonatan Belinkov, Mrinmaya Sachan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Active Learning for Natural Language Generation**](https://arxiv.org/abs/2305.15040) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yotam Perlitz, Ariel Gera, Michal Shmueli-Scheuer, Dafna Sheinwald, Noam Slonim, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)

---

[**SmartTrim: Adaptive Tokens and Parameters Pruning for Efficient Vision-Language Models**](https://arxiv.org/abs/2305.15033) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zekun Wang, Jingchang Chen, Wangchunshu Zhou, Ming Liu, Bing Qin </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**How to Distill your BERT: An Empirical Study on the Impact of Weight Initialisation and Distillation Objectives**](https://arxiv.org/abs/2305.15032) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xinpeng Wang, Leonie Weissweiler, Hinrich Schutze, Barbara Plank </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/mainlp/how-to-distill-your-bert)

---

[**ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification**](https://arxiv.org/abs/2305.15024) Ôºà**2023.05.24**Ôºâ

<font color="gray">Biao Zhao, Weiqiang Jin, Javier Del Ser, Guang Yang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-53-red)  [![](https://img.shields.io/badge/Github%20Stars-32-blue)](https://github.com/albert-jin/agricultural_textual_classification_chatgpt)

---

[**Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models**](https://arxiv.org/abs/2305.15023) Ôºà**2023.05.24**Ôºâ

<font color="gray">Gen Luo, Yiyi Zhou, Tianhe Ren, Shengxin Chen, Xiaoshuai Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-49-red)

---

[**Unlocking Temporal Question Answering for Large Language Models Using Code Execution**](https://arxiv.org/abs/2305.15014) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xingxuan Li, Liying Cheng, Qingyu Tan, Hwee Tou Ng, Shafiq Joty, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/damo-nlp-sg/mvcr)

---

[**Bactrian-X : A Multilingual Replicable Instruction-Following Model with Low-Rank Adaptation**](https://arxiv.org/abs/2305.15011) Ôºà**2023.05.24**Ôºâ

<font color="gray">Haonan Li, Fajri Koto, Minghao Wu, Alham Fikri Aji, Timothy Baldwin </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism and Synonymous Substitution**](https://arxiv.org/abs/2305.15010) Ôºà**2023.05.24**Ôºâ

<font color="gray">Hongbo Zhang, Xiang Wan, Benyou Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/stevenzhb/bioplm_injectingknowledge)

---

[**LLMDet: A Large Language Models Detection Tool**](https://arxiv.org/abs/2305.15004) Ôºà**2023.05.24**Ôºâ

<font color="gray">Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng, Tat-Seng Chua </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)

---

[**The Art of SOCRATIC QUESTIONING: Zero-shot Multimodal Reasoning with Recursive Thinking and Self-Questioning**](https://arxiv.org/abs/2305.14999) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu, Di Jin, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Reasoning with Language Model is Planning with World Model**](https://arxiv.org/abs/2305.14992) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-98-red)  [![](https://img.shields.io/badge/Github%20Stars-637-blue)](https://github.com/ber666/llm-reasoners)

---

[**Large Language Models are Effective Table-to-Text Generators, Evaluators, and Feedback Providers**](https://arxiv.org/abs/2305.14987) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)

---

[**Improving Factuality of Abstractive Summarization without Sacrificing Summary Quality**](https://arxiv.org/abs/2305.14981) Ôºà**2023.05.24**Ôºâ

<font color="gray">Tanay Dixit, Fei Wang, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/tanay2001/efactsum)

---

[**OverPrompt: Enhancing ChatGPT Capabilities through an Efficient In-Context Learning Approach**](https://arxiv.org/abs/2305.14973) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiazheng Li, Runcong Zhao, Yulan He, Lin Gui </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)

---

[**MMNet: Multi-Mask Network for Referring Image Segmentation**](https://arxiv.org/abs/2305.14969) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yichen Yan, Xingjian He, Wenxuan Wan, Jing Liu </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks**](https://arxiv.org/abs/2305.14965) Ôºà**2023.05.24**Ôºâ

<font color="gray">Abhinav Rao, Sachin Vashistha, Atharva Naik, Somak Aditya, Monojit Choudhury </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)

---

[**Editing Commonsense Knowledge in GPT**](https://arxiv.org/abs/2305.14956) Ôºà**2023.05.24**Ôºâ

<font color="gray">Anshita Gupta, Debanjan Mondal, Akshay Krishna Sheshadri, Wenlong Zhao, Xiang Lorraine Li, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low Resource Languages**](https://arxiv.org/abs/2305.14949) Ôºà**2023.05.24**Ôºâ

<font color="gray">Qi Gou, Zehua Xia, Wen-Hau Du </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Trade-Offs Between Fairness and Privacy in Language Modeling**](https://arxiv.org/abs/2305.14936) Ôºà**2023.05.24**Ôºâ

<font color="gray">Cleo Matzken, Steffen Eger, Ivan Habernal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/cleolotta/fair-and-private-lm)

---

[**Frugal Prompting for Dialog Models**](https://arxiv.org/abs/2305.14919) Ôºà**2023.05.24**Ôºâ

<font color="gray">Bishal Santra, Sakya Basak, Abhinandan De, Manish Gupta, Pawan Goyal </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection**](https://arxiv.org/abs/2305.14902) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)  [![](https://img.shields.io/badge/Github%20Stars-11-blue)](https://github.com/mbzuai-nlp/m4)

---

[**PIVOINE: Instruction Tuning for Open-world Information Extraction**](https://arxiv.org/abs/2305.14898) Ôºà**2023.05.24**Ôºâ

<font color="gray">Keming Lu, Xiaoman Pan, Kaiqiang Song, Hongming Zhang, Dong Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/lukeming-tsinghua/instruction-tuning-for-open-world-ie)

---

[**Text encoders are performance bottlenecks in contrastive vision-language models**](https://arxiv.org/abs/2305.14897) Ôºà**2023.05.24**Ôºâ

<font color="gray">Amita Kamath, Jack Hessel, Kai-Wei Chang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)

---

[**Privacy Implications of Retrieval-Based Language Models**](https://arxiv.org/abs/2305.14888) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yangsibo Huang, Samyak Gupta, Zexuan Zhong, Kai Li, Danqi Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/princeton-sysml/knnlm_privacy)

---

[**Interpretable by Design Visual Question Answering**](https://arxiv.org/abs/2305.14882) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xingyu Fu, Ben Zhou, Sihao Chen, Mark Yatskar, D. Roth </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Leveraging GPT-4 for Automatic Translation Post-Editing**](https://arxiv.org/abs/2305.14878) Ôºà**2023.05.24**Ôºâ

<font color="gray">Vikas Raunak, Amr Sharaf, Hany Hassan Awadallah, Arul Menezes </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering**](https://arxiv.org/abs/2305.14869) Ôºà**2023.05.24**Ôºâ

<font color="gray">Weiqi Wang, Tianqing Fang, Wenxuan Ding, Baixuan Xu, Xin Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/hkust-knowcomp/car)

---

[**Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers**](https://arxiv.org/abs/2305.14858) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zixuan Jiang, Jiaqi Gu, Hanqing Zhu, D. Pan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)  [![](https://img.shields.io/badge/Github%20Stars-13-blue)](https://github.com/zixuanjiang/pre-rmsnorm-transformer)

---

[**Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models**](https://doi.org/10.48550/arXiv.2305.15023) Ôºà**2023.05.24**Ôºâ

<font color="gray">Gen Luo, Yiyi Zhou, Tianhe Ren, Shen Chen, Xiaoshuai Sun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-15-green)

---

[**Towards Few-shot Entity Recognition in Document Images: A Graph Neural Network Approach Robust to Image Manipulation**](https://arxiv.org/abs/2305.14828) Ôºà**2023.05.24**Ôºâ

<font color="gray">Prashant Krishnan, Zilong Wang, Yangkun Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**Machine Reading Comprehension using Case-based Reasoning**](https://arxiv.org/abs/2305.14815) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dung Thai, Dhruv Agarwal, Mudit Chaudhary, R. Das, M. Zaheer, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification**](https://arxiv.org/abs/2305.14794) Ôºà**2023.05.24**Ôºâ

<font color="gray">Chengyu Dong, Zihan Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Text Conditional Alt-Text Generation for Twitter Images**](https://arxiv.org/abs/2305.14779) Ôºà**2023.05.24**Ôºâ

<font color="gray">Nikita Srivatsan, Sofia Samaniego, Omar Florez, Taylor Berg-Kirkpatrick </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**SSD-2: Scaling and Inference-time Fusion of Diffusion Language Models**](https://arxiv.org/abs/2305.14771) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov, Marjan Ghazvininejad </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning**](https://arxiv.org/abs/2305.14761) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, Shafiq Joty </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)  [![](https://img.shields.io/badge/Github%20Stars-31-blue)](https://github.com/vis-nlp/unichart)

---

[**Trusting Your Evidence: Hallucinate Less with Context-aware Decoding**](https://arxiv.org/abs/2305.14739) Ôºà**2023.05.24**Ôºâ

<font color="gray">Weijia Shi, Xiaochuang Han, M. Lewis, Yulia Tsvetkov, Luke Zettlemoyer, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-33-red)

---

[**In-Context Demonstration Selection with Cross Entropy Difference**](https://arxiv.org/abs/2305.14726) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-2.8k-blue)](https://github.com/microsoft/lmops)

---

[**GlobalBench: A Benchmark for Global Progress in Natural Language Processing**](https://arxiv.org/abs/2305.14716) Ôºà**2023.05.24**Ôºâ

<font color="gray">Y. Song, Catherine Cui, Simran Khanuja, Pengfei Liu, FAHIM FAISAL, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)

---

[**The student becomes the master: Matching GPT3 on Scientific Factual Error Correction**](https://arxiv.org/abs/2305.14707) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dhananjay Ashok, Atharva Kulkarni, Hai Pham, Barnab'as P'oczos </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**PruMUX: Augmenting Data Multiplexing with Model Compression**](https://arxiv.org/abs/2305.14706) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yushan Su, Vishvak S. Murahari, Karthik Narasimhan, Kai Li </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/yushansu/prumux)

---

[**Flan-MoE: Scaling Instruction-Finetuned Language Models with Sparse Mixture of Experts**](https://arxiv.org/abs/2305.14705) Ôºà**2023.05.24**Ôºâ

<font color="gray">Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-50-red)

---

[**A Causal View of Entity Bias in (Large) Language Models**](https://arxiv.org/abs/2305.14695) Ôºà**2023.05.24**Ôºâ

<font color="gray">Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Emergent inabilities? Inverse scaling over the course of pretraining**](https://arxiv.org/abs/2305.14681) Ôºà**2023.05.24**Ôºâ

<font color="gray">James A. Michaelov, B. Bergen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**InteractiveIE: Towards Assessing the Strength of Human-AI Collaboration in Improving the Performance of Information Extraction**](https://arxiv.org/abs/2305.14659) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ishani Mondal, Michelle Yuan, N Anandhavelu, Aparna Garimella, Francis Ferraro, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Reinforcement Learning finetuned Vision-Code Transformer for UI-to-Code Generation**](https://arxiv.org/abs/2305.14637) Ôºà**2023.05.24**Ôºâ

<font color="gray">Davit Soselia, Khalid Saifullah, Tianyi Zhou </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**KNN-LM Does Not Improve Open-ended Text Generation**](https://arxiv.org/abs/2305.14625) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shufan Wang, Yixiao Song, Andrew Drozdov, Aparna Garimella, Varun Manjunatha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations**](https://arxiv.org/abs/2305.14618) Ôºà**2023.05.24**Ôºâ

<font color="gray">Wenting Zhao, Justin T. Chiu, Claire Cardie, Alexander M. Rush </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)

---

[**Language Models with Rationality**](https://arxiv.org/abs/2305.14250) Ôºà**2023.05.23**Ôºâ

<font color="gray">Nora Kassner, Oyvind Tafjord, Ashish Sabharwal, Kyle Richardson, Hinrich Sch√ºtze, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)

---

[**A Trip Towards Fairness: Bias and De-Biasing in Large Language Models**](https://arxiv.org/abs/2305.13862) Ôºà**2023.05.23**Ôºâ

<font color="gray">Leonardo Ranaldi, Elena Sofia Ruzzetti, Davide Venditti, Dario Onorati, Fabio Massimo Zanzotto </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)

---

[**Question Answering as Programming for Solving Time-Sensitive Questions**](https://arxiv.org/abs/2305.14221) Ôºà**2023.05.23**Ôºâ

<font color="gray">Xinyu Zhu, Cheng Yang, Bei Chen, Siheng Li, Jian-Guang Lou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/tianhongzxy/qaap)

---

[**PaD: Program-aided Distillation Specializes Large Models in Reasoning**](https://arxiv.org/abs/2305.13888) Ôºà**2023.05.23**Ôºâ

<font color="gray">Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xingwei Long, Bowen Zhou </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)

---

[**Aligning Large Language Models through Synthetic Feedback**](https://arxiv.org/abs/2305.13735) Ôºà**2023.05.23**Ôºâ

<font color="gray">Sungdong Kim, Sanghwan Bae, Jamin Shin, Soyoung Kang, Donghyun Kwak, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-35-red)  [![](https://img.shields.io/badge/Github%20Stars-14-blue)](https://github.com/naver-ai/almost)

---

[**LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large Language Models**](https://arxiv.org/abs/2305.13718) Ôºà**2023.05.23**Ôºâ

<font color="gray">Fangkai Jiao, Zhiyang Teng, Shafiq Joty, Bosheng Ding, Aixin Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/sparkjiao/logicllm)

---

[**Masked Path Modeling for Vision-and-Language Navigation**](https://doi.org/10.48550/arXiv.2305.14268) Ôºà**2023.05.23**Ôºâ

<font color="gray">Zi-Yi Dou, Feng Gao, Nanyun Peng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models**](https://arxiv.org/abs/2305.14323) Ôºà**2023.05.23**Ôºâ

<font color="gray">Z. Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne Xin Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-22-red)  [![](https://img.shields.io/badge/Github%20Stars-32-blue)](https://github.com/rucaibox/chatcot)

---

[**Knowledge-Retrieval Task-Oriented Dialog Systems with Semi-Supervision**](https://arxiv.org/abs/2305.13199) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yucheng Cai, Hong Liu, Zhijian Ou, Y. Huang, Junlan Feng </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/thu-spmi/jsa-krtod)

---

[**Sentence Representations via Gaussian Embedding**](https://arxiv.org/abs/2305.12990) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shohei Yoda, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text**](https://arxiv.org/abs/2305.12599) Ôºà**2023.05.21**Ôºâ

<font color="gray">Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Retrieving Texts based on Abstract Descriptions**](https://arxiv.org/abs/2305.12517) Ôºà**2023.05.21**Ôºâ

<font color="gray">Shauli Ravfogel, Valentina Pyatkin, Amir D. N. Cohen, Avshalom Manevich, Yoav Goldberg </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning**](https://arxiv.org/abs/2305.12295) Ôºà**2023.05.20**Ôºâ

<font color="gray">Liangming Pan, Alon Albalak, Xinyi Wang, William Yang Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-60-red)  [![](https://img.shields.io/badge/Github%20Stars-139-blue)](https://github.com/teacherpeterpan/logic-llm)

---

[**LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4**](https://arxiv.org/abs/2305.12147) Ôºà**2023.05.20**Ôºâ

<font color="gray">Hanmeng Liu, Zhiyang Teng, Leyang Cui, Chaoli Zhang, Qiji Zhou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs**](https://doi.org/10.48550/arXiv.2305.11461) Ôºà**2023.05.19**Ôºâ

<font color="gray">IokTong Lei, ZhiDong Deng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Decouple knowledge from paramters for plug-and-play language modeling**](https://doi.org/10.48550/arXiv.2305.11564) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xin Cheng, Yankai Lin, Xiuying Chen, Dongyan Zhao, Rui Yan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought**](https://doi.org/10.48550/arXiv.2305.11499) Ôºà**2023.05.19**Ôºâ

<font color="gray">Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning**](https://doi.org/10.48550/arXiv.2305.11383) Ôºà**2023.05.19**Ôºâ

<font color="gray">Po-Nien Kung, Nanyun Peng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**AutoTrial: Prompting Language Models for Clinical Trial Design**](https://doi.org/10.48550/arXiv.2305.11366) Ôºà**2023.05.19**Ôºâ

<font color="gray">Zifeng Wang, Cao Xiao, Jimeng Sun .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings**](https://doi.org/10.48550/arXiv.2305.10786) Ôºà**2023.05.18**Ôºâ

<font color="gray">Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Chong Deng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-75-blue)](https://github.com/alibaba-damo-academy/spokennlp)

---

[**ReGen: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval**](https://doi.org/10.48550/arXiv.2305.10703) Ôºà**2023.05.18**Ôºâ

<font color="gray">Yue Yu, Yuchen Zhuang, Rongzhi Zhang, Yu Meng, Jiaming Shen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-18-blue)](https://github.com/yueyu1030/ReGen)

---

[**Efficient Prompting via Dynamic In-Context Learning**](https://doi.org/10.48550/arXiv.2305.11170) Ôºà**2023.05.18**Ôºâ

<font color="gray">Wangchunshu Zhou, Yuchen Jiang, Ryan Cotterell, Mrinmaya Sachan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The Web Can Be Your Oyster for Improving Large Language Models**](https://doi.org/10.48550/arXiv.2305.10998) Ôºà**2023.05.18**Ôºâ

<font color="gray">Junyi Li, Tianyi Tang, Wayne Xin Zhao, Jingyuan Wang, J. Nie, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/rucaibox/uniweb)

---

[**TOME: A Two-stage Approach for Model-based Retrieval**](https://doi.org/10.48550/arXiv.2305.11161) Ôºà**2023.05.18**Ôºâ

<font color="gray">Ruiyang Ren, Wayne Xin Zhao, J. Liu, Huaqin Wu, Ji-rong Wen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Emergent and Predictable Memorization in Large Language Models**](https://arxiv.org/abs/2304.11158) Ôºà**2023.04.21**Ôºâ

<font color="gray">Stella Rose Biderman, Usvsn Sai Prashanth, Lintang Sutawika, Hailey Schoelkopf, Quentin G. Anthony, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-35-red)  [![](https://img.shields.io/badge/Github%20Stars-6.5k-blue)](https://github.com/eleutherai/gpt-neox)

---

[**SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks**](https://doi.org/10.48550/arXiv.2303.00733) Ôºà**2023.03.01**Ôºâ

<font color="gray">Kai-Wei Chang, Yu-Kai Wang, Hua Shen, Iu-thing Kang, W. Tseng, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis**](https://doi.org/10.48550/arXiv.2303.00815) Ôºà**2023.03.01**Ôºâ

<font color="gray">Jingli Shi, Weihua Li, Quan-wei Bai, Yi Yang, Jianhua Jiang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**EvoPrompting: Language Models for Code-Level Neural Architecture Search**](https://doi.org/10.48550/arXiv.2302.14838) Ôºà**2023.02.28**Ôºâ

<font color="gray">Angelica Chen, David Dohan, David R. So .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models**](https://doi.org/10.48550/arXiv.2302.12173) Ôºà**2023.02.23**Ôºâ

<font color="gray">Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, C. Endres, Thorsten Holz, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales**](https://doi.org/10.48550/arXiv.2302.08961) Ôºà**2023.02.17**Ôºâ

<font color="gray">M. Ruskov .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LabelPrompt: Effective Prompt-based Learning for Relation Classification**](https://doi.org/10.48550/arXiv.2302.08068) Ôºà**2023.02.16**Ôºâ

<font color="gray">W. Zhang, Xiaoning Song, Zhenhua Feng, Tianyang Xu, Xiaojun Wu .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition**](https://doi.org/10.48550/arXiv.2302.08102) Ôºà**2023.02.16**Ôºâ

<font color="gray">Minsu Kim, Hyungil Kim, Y. Ro .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Prompting for Multimodal Hateful Meme Classification**](https://doi.org/10.48550/arXiv.2302.04156) Ôºà**2023.02.08**Ôºâ

<font color="gray">Rui Cao, R. Lee, Wen-Haw Chong, Jing Jiang .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Toxicity Detection with Generative Prompt-based Inference**](https://doi.org/10.48550/arXiv.2205.12390) Ôºà**2022.05.24**Ôºâ

<font color="gray">Yau-Shian Wang, Y. Chang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Learning to Transfer Prompts for Text Generation**](https://doi.org/10.48550/arXiv.2205.01543) Ôºà**2022.05.03**Ôºâ

<font color="gray">Junyi Li, Tianyi Tang, J. Nie, Ji-rong Wen, Wayne Xin Zhao .  - „ÄêNorth American Chapter of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-11-green)  [![](https://img.shields.io/badge/Github%20Stars-23-blue)](https://github.com/rucaibox/transfer-prompts-for-text-generation)

---

[**RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction**](https://doi.org/10.48550/arXiv.2203.09101) Ôºà**2022.03.17**Ôºâ

<font color="gray">Yew Ken Chia, Lidong Bing, Soujanya Poria, Luo Si .  - „ÄêFindings„Äë</font>

![](https://img.shields.io/badge/Citations-15-green)  [![](https://img.shields.io/badge/Github%20Stars-120-blue)](https://github.com/declare-lab/relationprompt)

---

[**QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition**](https://doi.org/10.48550/arXiv.2203.01543) Ôºà**2022.03.03**Ôºâ

<font color="gray">Andy T. Liu, Wei Xiao, Henghui Zhu, Dejiao Zhang, Shang-Wen Li, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-58-blue)](https://github.com/dayyass/QaNER)

---

[**PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts**](https://doi.org/10.18653/v1/2022.acl-demo.9) Ôºà**2022.02.02**Ôºâ

<font color="gray">Stephen H. Bach, Victor Sanh, Zheng Xin Yong, Albert Webson, Colin Raffel, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-54-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-123-red)  [![](https://img.shields.io/badge/Github%20Stars-2.4k-blue)](https://github.com/bigscience-workshop/promptsource)

---

[**Few-Shot Bot: Prompt-Based Learning for Dialogue Systems**](https://arxiv.org/abs/2110.08118) Ôºà**2021.10.15**Ôºâ

<font color="gray">Andrea Madotto, Zhaojiang Lin, Genta Indra Winata, Pascale Fung .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-79-red)  [![](https://img.shields.io/badge/Github%20Stars-742-blue)](https://github.com/tunib-ai/parallelformers)

---

[**SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based Sentiment Analysis**](https://arxiv.org/abs/2109.08306) Ôºà**2021.09.17**Ôºâ

<font color="gray">Chengxi Li, Feiyu Gao, Jiajun Bu, Lu Xu, Xiang Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-20-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-70-red)

---

[**LightNER: A Lightweight Tuning Paradigm for Low-resource NER via Pluggable Prompting**](https://arxiv.org/abs/2109.00720) Ôºà**2021.08.31**Ôºâ

<font color="gray">Xiang Chen, Lei Li, Shumin Deng, Chuanqi Tan, Changliang Xu, etc .  - „ÄêInternational Conference on Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-30-red)

---

[**Program Synthesis with Large Language Models**](https://arxiv.org/abs/2108.07732) Ôºà**2021.08.16**Ôºâ

<font color="gray">Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, H. Michalewski, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-175-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-222-red)

---

[**Evaluating Large Language Models Trained on Code**](https://arxiv.org/abs/2107.03374) Ôºà**2021.07.07**Ôºâ

<font color="gray">Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-612-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-673-red)  [![](https://img.shields.io/badge/Github%20Stars-770-blue)](https://github.com/openai/human-eval)

---

[**KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction**](https://doi.org/10.1145/3485447.3511998) Ôºà**2021.04.15**Ôºâ

<font color="gray">Xiang Chen, Ningyu Zhang, Ningyu Zhang, Xin Xie, Shumin Deng, etc .  - „ÄêThe Web Conference„Äë</font>

![](https://img.shields.io/badge/Citations-86-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-179-red)  [![](https://img.shields.io/badge/Github%20Stars-164-blue)](https://github.com/zjunlp/KnowPrompt)

---

[**Language Models as Knowledge Bases?**](https://doi.org/10.18653/v1/D19-1250) Ôºà**2019.09.01**Ôºâ

<font color="gray">Fabio Petroni, Tim Rockt√§schel, Patrick Lewis, A. Bakhtin, Yuxiang Wu, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1038-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1.3k-red)

---

[**AdaPrompt: Adaptive Prompt-based Finetuning for Relation Extraction**](https://api.semanticscholar.org/2404aecd866cfa15fee6ada095667980a63c4172) 

<font color="gray">Xiang Chen, Xin Xie, Ningyu Zhang, Jiahuan Yan, Shumin Deng, etc </font>

![](https://img.shields.io/badge/Citations-31-green)


</div>

# CONTINUE...