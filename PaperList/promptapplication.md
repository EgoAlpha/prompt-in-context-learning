# üìÑ Prompt Application

## Paper List

<div style="line-height:0.2em;">


[**IncogniText: Privacy-enhancing Conditional Text Anonymization via LLM-based Private Attribute Randomization**](https://arxiv.org/abs/2407.02956) Ôºà**2024.07.03**Ôºâ

<font color="gray">Ahmed Frikha, Nassim Walha, K. K. Nakka, Ricardo Mendes, Xue Jiang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs**](https://arxiv.org/abs/2406.20098) Ôºà**2024.06.28**Ôºâ

<font color="gray">Sukmin Yun, Haokun Lin, Rusiru Thushara, Mohammad Qazim Bhat, Yongxin Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-33-blue)](https://github.com/mbzuai-llm/web2code)

---

[**OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding**](https://arxiv.org/abs/2406.19389) Ôºà**2024.06.27**Ôºâ

<font color="gray">Tao Zhang, Xiangtai Li, Hao Fei, Haobo Yuan, Shengqiong Wu, etc </font>

![](https://img.shields.io/badge/Citations-2-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)  [![](https://img.shields.io/badge/Github%20Stars-934-blue)](https://github.com/lxtgh/omg-seg)

---

[**Adversarial Search Engine Optimization for Large Language Models**](https://arxiv.org/abs/2406.18382) Ôºà**2024.06.26**Ôºâ

<font color="gray">Fredrik Nestaas, Edoardo Debenedetti, F. Tram√®r </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**VideoLLM-online: Online Video Large Language Model for Streaming Video**](https://arxiv.org/abs/2406.11816) Ôºà**2024.06.17**Ôºâ

<font color="gray">Joya Chen, Zhaoyang Lv, Shiwei Wu, Kevin Qinghong Lin, Chenan Song, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Regularizing Hidden States Enables Learning Generalizable Reward Model for LLMs**](https://arxiv.org/abs/2406.10216) Ôºà**2024.06.14**Ôºâ

<font color="gray">Rui Yang, Ruomeng Ding, Yong Lin, Huan Zhang, Tong Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation**](https://arxiv.org/abs/2406.06525) Ôºà**2024.06.10**Ôºâ

<font color="gray">Peize Sun, Yi Jiang, Shoufa Chen, Shilong Zhang, Bingyue Peng, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-43-red)  [![](https://img.shields.io/badge/Github%20Stars-957-blue)](https://github.com/foundationvision/llamagen)

---

[**Language models emulate certain cognitive profiles: An investigation of how predictability measures interact with individual differences**](https://arxiv.org/abs/2406.04988) Ôºà**2024.06.07**Ôºâ

<font color="gray">Patrick Haller, Lena S. Bolliger, Lena A. Jager </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**PaCE: Parsimonious Concept Engineering for Large Language Models**](https://arxiv.org/abs/2406.04331) Ôºà**2024.06.06**Ôºâ

<font color="gray">Jinqi Luo, Tianjiao Ding, Kwan Ho Ryan Chan, D. Thaker, Aditya Chattopadhyay, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)  [![](https://img.shields.io/badge/Github%20Stars-15-blue)](https://github.com/peterljq/parsimonious-concept-engineering)

---

[**Yuan 2.0-M32: Mixture of Experts with Attention Router**](https://doi.org/10.48550/arXiv.2405.17976) Ôºà**2024.05.28**Ôºâ

<font color="gray">Shaohua Wu, Jiangang Luo, Xi Chen, Lingjun Li, Xudong Zhao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-160-blue)](https://github.com/ieit-yuan/yuan2.0-m32)

---

[**When Generative AI Meets Workplace Learning: Creating A Realistic & Motivating Learning Experience With A Generative PCA**](https://doi.org/10.48550/arXiv.2405.15561) Ôºà**2024.05.24**Ôºâ

<font color="gray">Andreas Bucher, Birgit Schenk, Mateusz Dolata, Gerhard Schwabe .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Measuring Impacts of Poisoning on Model Parameters and Embeddings for Large Language Models of Code**](https://doi.org/10.1145/3664646.3664764) Ôºà**2024.05.19**Ôºâ

<font color="gray">Aftab Hussain, Md Rafiqul Islam Rabin, Mohammad Amin Alipour .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**CPS-LLM: Large Language Model based Safe Usage Plan Generator for Human-in-the-Loop Human-in-the-Plant Cyber-Physical System**](https://doi.org/10.48550/arXiv.2405.11458) Ôºà**2024.05.19**Ôºâ

<font color="gray">Ayan Banerjee, Aranyak Maity, Payal Kamboj, Sandeep K. S. Gupta .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Storypark: Leveraging Large Language Models to Enhance Children Story Learning Through Child-AI collaboration Storytelling**](https://doi.org/10.48550/arXiv.2405.06495) Ôºà**2024.05.10**Ôºâ

<font color="gray">Lyumanshan Ye, Jiandong Jiang, Danni Chang, Pengfei Liu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**UniDM: A Unified Framework for Data Manipulation with Large Language Models**](https://doi.org/10.48550/arXiv.2405.06510) Ôºà**2024.05.10**Ôºâ

<font color="gray">Yichen Qian, Yongyi He, Rong Zhu, Jintao Huang, Zhijian Ma, etc .  - „ÄêConference on Machine Learning and Systems„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**FlockGPT: Guiding UAV Flocking with Linguistic Orchestration**](https://doi.org/10.48550/arXiv.2405.05872) Ôºà**2024.05.09**Ôºâ

<font color="gray">Artem Lykov, Sausar Karaf, Mikhail Martynov, Valerii Serpiva, A. Fedoseev, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning**](https://doi.org/10.48550/arXiv.2405.05615) Ôºà**2024.05.09**Ôºâ

<font color="gray">Shibo Jie, Yehui Tang, Ning Ding, Zhi-Hong Deng, Kai Han, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-38-blue)](https://github.com/jieshibo/memvp)

---

[**DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model**](https://doi.org/10.48550/arXiv.2405.04434) Ôºà**2024.05.07**Ôºâ

<font color="gray">Zhihong Shao, Damai Dai, Daya Guo, Bo Liu, Zihan Wang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-39-green)  [![](https://img.shields.io/badge/Github%20Stars-2.9k-blue)](https://github.com/deepseek-ai/deepseek-v2)

---

[**QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving**](https://doi.org/10.48550/arXiv.2405.04532) Ôºà**2024.05.07**Ôºâ

<font color="gray">Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-331-blue)](https://github.com/mit-han-lab/qserve)

---

[**Study of adoption of artificial intelligence technology-driven natural large language model-based chatbots by firms for customer service interaction**](https://doi.org/10.1108/jstpm-11-2023-0201) Ôºà**2024.05.06**Ôºâ

<font color="gray">S. Bhattacharyya .  - „ÄêJournal of Science and Technology Policy Management„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)

---

[**FairEvalLLM. A Comprehensive Framework for Benchmarking Fairness in Large Language Model Recommender Systems**](https://doi.org/10.48550/arXiv.2405.02219) Ôºà**2024.05.03**Ôºâ

<font color="gray">Yashar Deldjoo .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Single and Multi-Hop Question-Answering Datasets for Reticular Chemistry with GPT-4-Turbo**](https://doi.org/10.48550/arXiv.2405.02128) Ôºà**2024.05.03**Ôºâ

<font color="gray">Nakul Rampal, Kaiyu Wang, Matthew Burigana, Lingxiang Hou, Juri Al-Johani, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**What matters when building vision-language models?**](https://doi.org/10.48550/arXiv.2405.02246) Ôºà**2024.05.03**Ôºâ

<font color="gray">Hugo Lauren√ßon, L√©o Tronchon, Matthieu Cord, Victor Sanh .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-20-green)

---

[**Analyzing Narrative Processing in Large Language Models (LLMs): Using GPT4 to test BERT**](https://doi.org/10.48550/arXiv.2405.02024) Ôºà**2024.05.03**Ôºâ

<font color="gray">Patrick Krauss, Jannik H√∂sch, C. Metzner, Andreas K. Maier, Peter Uhrig, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows**](https://doi.org/10.1145/3613905.3651115) Ôºà**2024.05.02**Ôºâ

<font color="gray">Jasmine Y. Shih, Vishal Mohanty, Yannis Katsis, Hariharan Subramonyam .  - „ÄêCHI Extended Abstracts„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance**](https://doi.org/10.48550/arXiv.2405.00566) Ôºà**2024.05.01**Ôºâ

<font color="gray">Huan-Yi Su, Ke Wu, Yu-Hao Huang, Wu-Jun Li .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Is Bigger Edit Batch Size Always Better? - An Empirical Study on Model Editing with Llama-3**](https://doi.org/10.48550/arXiv.2405.00664) Ôºà**2024.05.01**Ôºâ

<font color="gray">Junsang Yoon, Akshat Gupta, G. Anumanchipalli .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/scalable-model-editing/unified-model-editing)

---

[**Re-Thinking Inverse Graphics With Large Language Models**](https://doi.org/10.48550/arXiv.2404.15228) Ôºà**2024.04.23**Ôºâ

<font color="gray">Peter Kulits, Haiwen Feng, Weiyang Liu, Victoria Abrevaya, Michael J. Black .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Revisiting Unnaturalness for Automated Program Repair in the Era of Large Language Models**](https://doi.org/10.48550/arXiv.2404.15236) Ôºà**2024.04.23**Ôºâ

<font color="gray">Aidan Z. H. Yang, Sophia Kolak, Vincent J. Hellendoorn, Ruben Martins, Claire Le Goues .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Quantifying Multilingual Performance of Large Language Models Across Languages**](https://doi.org/10.48550/arXiv.2404.11553) Ôºà**2024.04.17**Ôºâ

<font color="gray">Zihao Li, Yucheng Shi, Zirui Liu, Fan Yang, Ninghao Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Prompt Optimizer of Text-to-Image Diffusion Models for Abstract Concept Understanding**](https://doi.org/10.1145/3589335.3651927) Ôºà**2024.04.17**Ôºâ

<font color="gray">Zezhong Fan, Xiaohan Li, Kaushiki Nag, Chenhao Fang, Topojoy Biswas, etc .  - „ÄêThe Web Conference„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**LLMorpheus: Mutation Testing using Large Language Models**](https://doi.org/10.48550/arXiv.2404.09952) Ôºà**2024.04.15**Ôºâ

<font color="gray">Frank Tip, Jonathan Bell, Max Sch√§fer .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/githubnext/llmorpheus)

---

[**Generating consistent PDDL domains with Large Language Models**](https://arxiv.org/abs/2404.07751) Ôºà**2024.04.11**Ôºâ

<font color="gray">Pavel Smirnov, F. Joublin, A. Ceravola, Michael Gienger </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Generating consistent PDDL domains with Large Language Models**](https://doi.org/10.48550/arXiv.2404.07751) Ôºà**2024.04.11**Ôºâ

<font color="gray">Pavel Smirnov, F. Joublin, A. Ceravola, Michael Gienger .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Manipulating Large Language Models to Increase Product Visibility**](https://arxiv.org/abs/2404.07981) Ôºà**2024.04.11**Ôºâ

<font color="gray">Aounon Kumar, Himabindu Lakkaraju </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)  [![](https://img.shields.io/badge/Github%20Stars-49-blue)](https://github.com/aounon/llm-rank-optimizer)

---

[**High-Dimension Human Value Representation in Large Language Models**](https://arxiv.org/abs/2404.07900) Ôºà**2024.04.11**Ôºâ

<font color="gray">Samuel Cahyawijaya, Delong Chen, Yejin Bang, Leila Khalatbari, Bryan Wilie, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-12-blue)](https://github.com/hltchkust/univar)

---

[**MetaCheckGPT -- A Multi-task Hallucination Detector Using LLM Uncertainty and Meta-models**](https://arxiv.org/abs/2404.06948) Ôºà**2024.04.10**Ôºâ

<font color="gray">Rahul Mehta, Andrew Hoblitzell, Jack O'Keefe, Hyeju Jang, Vasudeva Varma </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Halu-NLP at SemEval-2024 Task 6: MetaCheckGPT - A Multi-task Hallucination Detection using LLM uncertainty and meta-models**](https://arxiv.org/abs/2404.06948) Ôºà**2024.04.10**Ôºâ

<font color="gray">Rahul Mehta, Andrew Hoblitzell, Jack O‚Äôkeefe, Hyeju Jang, Vasudeva Varma .  - „ÄêInternational Workshop on Semantic Evaluation„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**From Model-centered to Human-Centered: Revision Distance as a Metric for Text Evaluation in LLMs-based Applications**](https://arxiv.org/abs/2404.07108) Ôºà**2024.04.10**Ôºâ

<font color="gray">Yongqiang Ma, Lizhi Qin, Jiawei Liu, Yangyang Kang, Yue Zhang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)

---

[**LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding**](https://arxiv.org/abs/2404.05225) Ôºà**2024.04.08**Ôºâ

<font color="gray">Chuwei Luo, Yufan Shen, Zhaoqing Zhu, Qi Zheng, Zhi Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)  [![](https://img.shields.io/badge/Github%20Stars-1.2k-blue)](https://github.com/alibabaresearch/advancedliteratemachinery)

---

[**Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models**](https://arxiv.org/abs/2404.05291) Ôºà**2024.04.08**Ôºâ

<font color="gray">Yutao Ouyang, Jinhan Li, Yunfei Li, Zhongyu Li, Chao Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Topic-based Watermarks for LLM-Generated Text**](https://arxiv.org/abs/2404.02138) Ôºà**2024.04.02**Ôºâ

<font color="gray">Alexander Nemecek, Yuzhou Jiang, Erman Ayday </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks**](https://arxiv.org/abs/2404.02151) Ôºà**2024.04.02**Ôºâ

<font color="gray">Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-139-blue)](https://github.com/tml-epfl/llm-adaptive-attacks)

---

[**Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference**](https://doi.org/10.48550/arXiv.2403.20306) Ôºà**2024.03.29**Ôºâ

<font color="gray">Jovan Stojkovic, Esha Choukse, Chaojie Zhang, √ç√±igo Goiri, Josep Torrellas .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LUQ: Long-text Uncertainty Quantification for LLMs**](https://doi.org/10.48550/arXiv.2403.20279) Ôºà**2024.03.29**Ôºâ

<font color="gray">Caiqi Zhang, Fangyu Liu, Marco Basaldella, Nigel Collier .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Gecko: Versatile Text Embeddings Distilled from Large Language Models**](https://doi.org/10.48550/arXiv.2403.20327) Ôºà**2024.03.29**Ôºâ

<font color="gray">Jinhyuk Lee, Zhuyun Dai, Xiaoqi Ren, Blair Chen, Daniel Cer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models**](https://doi.org/10.48550/arXiv.2403.19548) Ôºà**2024.03.28**Ôºâ

<font color="gray">Piotr Molenda, Adian Liusie, Mark J. F. Gales .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MLDT: Multi-Level Decomposition for Complex Long-Horizon Robotic Task Planning with Open-Source Large Language Model**](https://doi.org/10.48550/arXiv.2403.18760) Ôºà**2024.03.27**Ôºâ

<font color="gray">Yike Wu, Jiatao Zhang, Nan Hu, LanLing Tang, Guilin Qi, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-14-blue)](https://github.com/wuyike2000/mldt)

---

[**Comp4D: LLM-Guided Compositional 4D Scene Generation**](https://arxiv.org/abs/2403.16993) Ôºà**2024.03.25**Ôºâ

<font color="gray">Dejia Xu, Hanwen Liang, N. Bhatt, Hezhen Hu, Hanxue Liang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?**](https://arxiv.org/abs/2403.14624) Ôºà**2024.03.21**Ôºâ

<font color="gray">Renrui Zhang, Dongzhi Jiang, Yichi Zhang, Haokun Lin, Ziyu Guo, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)

---

[**Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning Ability of LLMs**](https://arxiv.org/abs/2403.13271) Ôºà**2024.03.20**Ôºâ

<font color="gray">Zhihong Sun, Chen Lyu, Bolun Li, Yao Wan, Hongyu Zhang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model**](https://arxiv.org/abs/2403.13244) Ôºà**2024.03.20**Ôºâ

<font color="gray">Peng Zhou, Jianmin Wang, Chunyan Li, Zixu Wang, Yiping Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Robots That Know When They Need Help: Affordance-Based Uncertainty for Large Language Model Planners**](https://arxiv.org/abs/2403.13198) Ôºà**2024.03.19**Ôºâ

<font color="gray">James F. Mullen, Dinesh Manocha </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**ExeGPT: Constraint-Aware Resource Scheduling for LLM Inference**](https://arxiv.org/abs/2404.07947) Ôºà**2024.03.15**Ôºâ

<font color="gray">Hyungjun Oh, Kihong Kim, Jaemin Kim, Sungkyun Kim, Junyeol Lee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)

---

[**ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning**](https://arxiv.org/abs/2403.09028) Ôºà**2024.03.14**Ôºâ

<font color="gray">Ahmed Masry, Mehrad Shahmohammadi, Md. Rizwan Parvez, Enamul Hoque, Shafiq R. Joty </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/vis-nlp/chartinstruct)

---

[**Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference**](https://arxiv.org/abs/2403.09636) Ôºà**2024.03.14**Ôºâ

<font color="gray">Piotr Nawrot, Adrian La'ncucki, Marcin Chochowski, David Tarjan, E. M. Ponti </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-18-red)

---

[**Towards Proactive Interactions for In-Vehicle Conversational Assistants Utilizing Large Language Models**](https://arxiv.org/abs/2403.09135) Ôºà**2024.03.14**Ôºâ

<font color="gray">Huifang Du, Xuejing Feng, Jun Ma, Meng Wang, Shiyu Tao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Simple and Scalable Strategies to Continually Pre-train Large Language Models**](https://arxiv.org/abs/2403.08763) Ôºà**2024.03.13**Ôºâ

<font color="gray">Adam Ibrahim, Benjamin Th'erien, Kshitij Gupta, Mats L. Richter, Quentin Anthony, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-46-red)  [![](https://img.shields.io/badge/Github%20Stars-6.7k-blue)](https://github.com/eleutherai/gpt-neox)

---

[**LG-Traj: LLM Guided Pedestrian Trajectory Prediction**](https://arxiv.org/abs/2403.08032) Ôºà**2024.03.12**Ôºâ

<font color="gray">Pranav Singh Chib, Pravendra Singh </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Big City Bias: Evaluating the Impact of Metropolitan Size on Computational Job Market Abilities of Language Models**](https://arxiv.org/abs/2403.08046) Ôºà**2024.03.12**Ôºâ

<font color="gray">Charlie Campanella, R. Goot .  - „ÄêNLP4HR„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/charlie-campanella/big-city-bias)

---

[**InfiCoder-Eval: Systematically Evaluating the Question-Answering Capabilities of Code Large Language Models**](https://arxiv.org/abs/2404.07940) Ôºà**2024.03.11**Ôºâ

<font color="gray">Linyi Li, Shijie Geng, Zhenwen Li, Yibo He, Hao Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Naming, Describing, and Quantifying Visual Objects in Humans and LLMs**](https://arxiv.org/abs/2403.06935) Ôºà**2024.03.11**Ôºâ

<font color="gray">Alberto Testoni, Juell Sprott, Sandro Pezzelle </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/albertotestoni/ndq_visual_objects)

---

[**LLM4Decompile: Decompiling Binary Code with Large Language Models**](https://arxiv.org/abs/2403.05286) Ôºà**2024.03.08**Ôºâ

<font color="gray">Hanzhuo Tan, Qi Luo, Jing Li, Yuqun Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)  [![](https://img.shields.io/badge/Github%20Stars-2.7k-blue)](https://github.com/albertan017/LLM4Decompile)

---

[**Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMs**](https://arxiv.org/abs/2403.05434) Ôºà**2024.03.08**Ôºâ

<font color="gray">Arijit Nag, Animesh Mukherjee, Niloy Ganguly, Soumen Chakrabarti </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference**](https://arxiv.org/abs/2403.04132) Ôºà**2024.03.07**Ôºâ

<font color="gray">Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-40-red)  [![](https://img.shields.io/badge/Github%20Stars-35.6k-blue)](https://github.com/lm-sys/fastchat)

---

[**SaulLM-7B: A pioneering Large Language Model for Law**](https://arxiv.org/abs/2403.03883) Ôºà**2024.03.06**Ôºâ

<font color="gray">Pierre Colombo, Telmo Pessoa Pires, Malik Boudiaf, Dominic Culver, Rui Melo, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection**](https://arxiv.org/abs/2403.02253) Ôºà**2024.03.04**Ôºâ

<font color="gray">Yuexin Li, Chengyu Huang, Shumin Deng, Mei Lin Lock, Tri Cao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models**](https://arxiv.org/abs/2402.19465) Ôºà**2024.02.29**Ôºâ

<font color="gray">Chen Qian, Jie Zhang, Wei Yao, Dongrui Liu, Zhen-fei Yin, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)  [![](https://img.shields.io/badge/Github%20Stars-23-blue)](https://github.com/chnq/tracingllm)

---

[**Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers**](https://arxiv.org/abs/2402.19479) Ôºà**2024.02.29**Ôºâ

<font color="gray">Tsai-Shien Chen, Aliaksandr Siarohin, Willi Menapace, Ekaterina Deyneka, Hsiang-wei Chao, etc </font>

![](https://img.shields.io/badge/Citations-3-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-32-red)  [![](https://img.shields.io/badge/Github%20Stars-438-blue)](https://github.com/snap-research/panda-70m)

---

[**Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models**](https://arxiv.org/abs/2402.19427) Ôºà**2024.02.29**Ôºâ

<font color="gray">Soham De, Samuel L. Smith, Anushan Fernando, Aleksandar Botev, George Cristian-Muraru, etc </font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-74-red)  [![](https://img.shields.io/badge/Github%20Stars-565-blue)](https://github.com/google-deepmind/recurrentgemma)

---

[**The All-Seeing Project V2: Towards General Relation Comprehension of the Open World**](https://arxiv.org/abs/2402.19474) Ôºà**2024.02.29**Ôºâ

<font color="gray">Weiyun Wang, Yiming Ren, Hao Luo, Tiantong Li, Chenxiang Yan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-18-red)  [![](https://img.shields.io/badge/Github%20Stars-416-blue)](https://github.com/opengvlab/all-seeing)

---

[**LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs**](https://arxiv.org/abs/2402.18443) Ôºà**2024.02.28**Ôºâ

<font color="gray">Md Hafizur Rahman, Prabuddha Chakraborty </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits**](https://doi.org/10.48550/arXiv.2402.17764) Ôºà**2024.02.27**Ôºâ

<font color="gray">Shuming Ma, Hongyu Wang, Lingxiao Ma, Lei Wang, Wenhui Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-202-blue)](https://github.com/microsoft/bitblas)

---

[**OncoGPT: A Medical Conversational Model Tailored with Oncology Domain Expertise on a Large Language Model Meta-AI (LLaMA)**](https://doi.org/10.48550/arXiv.2402.16810) Ôºà**2024.02.26**Ôºâ

<font color="gray">Fujian Jia, Xin Liu, Lixi Deng, Jiwen Gu, Chunchao Pu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs**](https://arxiv.org/abs/2402.15491) Ôºà**2024.02.23**Ôºâ

<font color="gray">Kinjal Basu, Ibrahim Abdelaziz, Subhajit Chaudhury, Soham Dan, M. Crouse, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/ibm/api-blend)

---

[**Genie: Generative Interactive Environments**](https://arxiv.org/abs/2402.15391) Ôºà**2024.02.23**Ôºâ

<font color="gray">Jake Bruce, Michael Dennis, Ashley Edwards, Jack Parker-Holder, Yuge Shi, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-103-red)

---

[**Tokenization counts: the impact of tokenization on arithmetic in frontier LLMs**](https://doi.org/10.48550/arXiv.2402.14903) Ôºà**2024.02.22**Ôºâ

<font color="gray">Aaditya K. Singh, DJ Strouse .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/aadityasingh/tokenizationcounts)

---

[**Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs**](https://doi.org/10.48550/arXiv.2402.14872) Ôºà**2024.02.21**Ôºâ

<font color="gray">Xiaoxia Li, Siyuan Liang, Jiyi Zhang, Hansheng Fang, Aishan Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages**](https://doi.org/10.48550/arXiv.2402.12204) Ôºà**2024.02.19**Ôºâ

<font color="gray">Yuan Zhang, Yile Wang, Zijun Liu, Shuo Wang, Xiaolong Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-25.7k-blue)](https://github.com/hiyouga/llama-factory)

---

[**Refined Direct Preference Optimization with Synthetic Data for Behavioral Alignment of LLMs**](https://doi.org/10.48550/arXiv.2402.08005) Ôºà**2024.02.12**Ôºâ

<font color="gray">V√≠ctor Gallego .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-11-blue)](https://github.com/vicgalle/refined-dpo)

---

[**FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs**](https://doi.org/10.48550/arXiv.2402.05904) Ôºà**2024.02.08**Ôºâ

<font color="gray">Eun Cheol Choi, Emilio Ferrara .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-25.7k-blue)](https://github.com/hiyouga/llama-factory)

---

[**SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models**](https://doi.org/10.48550/arXiv.2402.05935) Ôºà**2024.02.08**Ôºâ

<font color="gray">Peng Gao, Renrui Zhang, Chris Liu, Longtian Qiu, Siyuan Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-2.6k-blue)](https://github.com/alpha-vllm/llama2-accessory)

---

[**On the Convergence of Zeroth-Order Federated Tuning in Large Language Models**](https://doi.org/10.48550/arXiv.2402.05926) Ôºà**2024.02.08**Ôºâ

<font color="gray">Zhenqing Ling, Daoyuan Chen, Liuyi Yao, Yaliang Li, Ying Shen .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Model Meets Graph Neural Network in Knowledge Distillation**](https://doi.org/10.48550/arXiv.2402.05894) Ôºà**2024.02.08**Ôºâ

<font color="gray">Shengxiang Hu, Guobing Zou, Song Yang, Yanglan Gan, Bofeng Zhang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Panacea: Pareto Alignment via Preference Adaptation for LLMs**](https://doi.org/10.48550/arXiv.2402.02030) Ôºà**2024.02.03**Ôºâ

<font color="gray">Yifan Zhong, Chengdong Ma, Xiaoyuan Zhang, Ziran Yang, Qingfu Zhang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?**](https://doi.org/10.48550/arXiv.2401.18070) Ôºà**2024.01.31**Ôºâ

<font color="gray">Andreas Opedal, Alessandro Stolfo, Haruki Shirakami, Ying Jiao, Ryan Cotterell, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model**](https://doi.org/10.48550/arXiv.2401.16420) Ôºà**2024.01.29**Ôºâ

<font color="gray">Xiao-wen Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Bin Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-2.0k-blue)](https://github.com/internlm/internlm-xcomposer)

---

[**True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning**](https://doi.org/10.48550/arXiv.2401.14151) Ôºà**2024.01.25**Ôºâ

<font color="gray">Weihao Tan, Wentao Zhang, Shanqi Liu, Longtao Zheng, Xinrun Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-32-blue)](https://github.com/weihaotan/twosome)

---

[**ChatQA: Building GPT-4 Level Conversational QA Models**](https://doi.org/10.48550/arXiv.2401.10225) Ôºà**2024.01.18**Ôºâ

<font color="gray">Zihan Liu, Wei Ping, Rajarshi Roy, Peng Xu, Chankyu Lee, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on Data-to-Text Generation**](https://doi.org/10.48550/arXiv.2401.10186) Ôºà**2024.01.18**Ôºâ

<font color="gray">Zdenƒõk Kasner, Ondvrej Duvsek .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models**](https://doi.org/10.48550/arXiv.2401.06066) Ôºà**2024.01.11**Ôºâ

<font color="gray">Damai Dai, Chengqi Deng, Chenggang Zhao, R. Xu, Huazuo Gao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-917-blue)](https://github.com/deepseek-ai/deepseek-moe)

---

[**Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection**](https://doi.org/10.48550/arXiv.2401.03737) Ôºà**2024.01.08**Ôºâ

<font color="gray">G. Fatouros, Konstantinos Metaxas, John Soldatos, D. Kyriazis .  - „ÄêSocial Science Research Network„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Instruct-Imagen: Image Generation with Multi-modal Instruction**](https://doi.org/10.48550/arXiv.2401.01952) Ôºà**2024.01.03**Ôºâ

<font color="gray">Hexiang Hu, Kelvin C.K. Chan, Yu-Chuan Su, Wenhu Chen, Yandong Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones**](https://doi.org/10.48550/arXiv.2312.16862) Ôºà**2023.12.28**Ôºâ

<font color="gray">Zhengqing Yuan, Zhaoxu Li, Lichao Sun .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-1.2k-blue)](https://github.com/dlyuangod/tinygpt-v)

---

[**MobileVLM : A Fast, Strong and Open Vision Language Assistant for Mobile Devices**](https://doi.org/10.48550/arXiv.2312.16886) Ôºà**2023.12.28**Ôºâ

<font color="gray">Xiangxiang Chu, Limeng Qiao, Xinyang Lin, Shuang Xu, Yang Yang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-880-blue)](https://github.com/meituan-automl/mobilevlm)

---

[**Generative AI for Math: Part I - MathPile: A Billion-Token-Scale Pretraining Corpus for Math**](https://doi.org/10.48550/arXiv.2312.17120) Ôºà**2023.12.28**Ôºâ

<font color="gray">Zengzhi Wang, Rui Xia, Pengfei Liu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation**](https://doi.org/10.48550/arXiv.2312.14187) Ôºà**2023.12.20**Ôºâ

<font color="gray">Zhaojian Yu, Xin Zhang, Ning Shang, Yangyu Huang, Can Xu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)

---

[**A mathematical perspective on Transformers**](https://arxiv.org/abs/2312.10794) Ôºà**2023.12.17**Ôºâ

<font color="gray">Borjan Geshkovski, Cyril Letrouit, Yury Polyanskiy, Philippe Rigollet </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-42-red)  [![](https://img.shields.io/badge/Github%20Stars-23-blue)](https://github.com/borjang/2023-transformers-rotf)

---

[**Mathematical discoveries from program search with large language models.**](https://doi.org/10.1038/s41586-023-06924-6) Ôºà**2023.12.14**Ôºâ

<font color="gray">Bernardino Romera-Paredes, M. Barekatain, Alexander Novikov, Matej Balog, M. P. Kumar, etc .  - „ÄêNature„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-164-red)

---

[**LMDrive: Closed-Loop End-to-End Driving with Large Language Models**](https://doi.org/10.48550/arXiv.2312.07488) Ôºà**2023.12.12**Ôºâ

<font color="gray">Hao Shao, Yuxuan Hu, Letian Wang, Steven L. Waslander, Yu Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-537-blue)](https://github.com/opendilab/lmdrive)

---

[**LLM360: Towards Fully Transparent Open-Source LLMs**](https://arxiv.org/abs/2312.06550) Ôºà**2023.12.11**Ôºâ

<font color="gray">Zhengzhong Liu, Aurick Qiao, W. Neiswanger, Hongyi Wang, Bowen Tan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-31-red)  [![](https://img.shields.io/badge/Github%20Stars-75-blue)](https://github.com/llm360/analysis360)

---

[**From Text to Motion: Grounding GPT-4 in a Humanoid Robot"Alter3"**](https://arxiv.org/abs/2312.06571) Ôºà**2023.12.11**Ôºâ

<font color="gray">Takahide Yoshida, A. Masumori, Takashi Ikegami </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)

---

[**Control Risk for Potential Misuse of Artificial Intelligence in Science**](https://arxiv.org/abs/2312.06632) Ôºà**2023.12.11**Ôºâ

<font color="gray">Jiyan He, Weitao Feng, Yaosen Min, Jingwei Yi, Kunsheng Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)  [![](https://img.shields.io/badge/Github%20Stars-11-blue)](https://github.com/scimt/scimt-benchmark)

---

[**Sequential Modeling Enables Scalable Learning for Large Vision Models**](https://arxiv.org/abs/2312.00785) Ôºà**2023.12.01**Ôºâ

<font color="gray">Yutong Bai, Xinyang Geng, K. Mangalam, Amir Bar, Alan Yuille, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-219-red)  [![](https://img.shields.io/badge/Github%20Stars-1.7k-blue)](https://github.com/ytongbai/LVM)

---

[**MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers**](https://doi.org/10.48550/arXiv.2311.15475) Ôºà**2023.11.27**Ôºâ

<font color="gray">Yawar Siddiqui, A. Alliegro, Alexey Artemov, Tatiana Tommasi, Daniele Sirigatti, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-646-blue)](https://github.com/lucidrains/meshgpt-pytorch)

---

[**Minimizing Factual Inconsistency and Hallucination in Large Language Models**](https://doi.org/10.48550/arXiv.2311.13878) Ôºà**2023.11.23**Ôºâ

<font color="gray">I. Muneeswaran, Shreya Saxena, Siva Prasad, M. V. S. Prakash, Advaith Shankar, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**](https://doi.org/10.48550/arXiv.2311.11797) Ôºà**2023.11.20**Ôºâ

<font color="gray">Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-316-blue)](https://github.com/zoeyyao27/cot-igniting-agent)

---

[**An Embodied Generalist Agent in 3D World**](https://doi.org/10.48550/arXiv.2311.12871) Ôºà**2023.11.18**Ôºâ

<font color="gray">Jiangyong Huang, Silong Yong, Xiaojian Ma, Xiongkun Linghu, Puhao Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-282-blue)](https://github.com/embodied-generalist/embodied-generalist)

---

[**Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning**](https://doi.org/10.48550/arXiv.2311.10709) Ôºà**2023.11.17**Ôºâ

<font color="gray">Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, S. Azadi, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Chat-UniVi: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding**](https://doi.org/10.48550/arXiv.2311.08046) Ôºà**2023.11.14**Ôºâ

<font color="gray">Peng Jin, Ryuichi Takanobu, Caiwan Zhang, Xiaochun Cao, Li Yuan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-711-blue)](https://github.com/pku-yuangroup/chat-univi)

---

[**SpectralGPT: Spectral Foundation Model**](https://doi.org/10.48550/arXiv.2311.07113) Ôºà**2023.11.13**Ôºâ

<font color="gray">D. Hong, Bing Zhang, Xuyang Li, Yuxuan Li, Chenyu Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Social Motion Prediction with Cognitive Hierarchies**](https://doi.org/10.48550/arXiv.2311.04726) Ôºà**2023.11.08**Ôºâ

<font color="gray">Wentao Zhu, Jason Qin, Yuke Lou, Hang Ye, Xiaoxuan Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Pre-training LLMs using human-like development data corpus**](https://doi.org/10.48550/arXiv.2311.04666) Ôºà**2023.11.08**Ôºâ

<font color="gray">Khushi Bhardwaj, Raj Sanjay Shah, Sashank Varma .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration**](https://doi.org/10.48550/arXiv.2311.04257) Ôºà**2023.11.07**Ôºâ

<font color="gray">Qinghao Ye, Haiyang Xu, Jiabo Ye, Mingshi Yan, Anwen Hu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  [![](https://img.shields.io/badge/Github%20Stars-2.0k-blue)](https://github.com/x-plug/mplug-owl)

---

[**Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation**](https://doi.org/10.48550/arXiv.2311.03348) Ôºà**2023.11.06**Ôºâ

<font color="gray">Rusheb Shah, Quentin Feuillade--Montixi, Soroush Pour, Arush Tagade, Stephen Casper, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Ziya2: Data-centric Learning is All LLMs Need**](https://doi.org/10.48550/arXiv.2311.03301) Ôºà**2023.11.06**Ôºâ

<font color="gray">Ruyi Gan, Ziwei Wu, Renliang Sun, Junyu Lu, Xiaojun Wu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Levels of AGI: Operationalizing Progress on the Path to AGI**](https://doi.org/10.48550/arXiv.2311.02462) Ôºà**2023.11.04**Ôºâ

<font color="gray">Meredith Ringel Morris, Jascha Narain Sohl-Dickstein, Noah Fiedel, T. Warkentin, Allan Dafoe, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**PILL: Plug Into LLM with Adapter Expert and Attention Gate**](https://doi.org/10.48550/arXiv.2311.02126) Ôºà**2023.11.03**Ôºâ

<font color="gray">Fangyuan Zhang, Tingting Liang, Zhengyuan Wu, Yuyu Yin .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/dsaltyfish/pill)

---

[**RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation**](https://doi.org/10.48550/arXiv.2311.01455) Ôºà**2023.11.02**Ôºâ

<font color="gray">Yufei Wang, Zhou Xian, Feng Chen, Tsun-Hsuan Wang, Yian Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**TopicGPT: A Prompt-based Topic Modeling Framework**](https://doi.org/10.48550/arXiv.2311.01449) Ôºà**2023.11.02**Ôºâ

<font color="gray">Chau Minh Pham, Alexander Miserlis Hoyle, Simeng Sun, Mohit Iyyer .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-188-blue)](https://github.com/chtmp223/topicgpt)

---

[**ChipNeMo: Domain-Adapted LLMs for Chip Design**](https://doi.org/10.48550/arXiv.2311.00176) Ôºà**2023.10.31**Ôºâ

<font color="gray">Mingjie Liu, Teodor-Dumitru Ene, Robert Kirby, Chris Cheng, Nathaniel Pinckney, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-10-green)

---

[**Narratron: Collaborative Writing and Shadow-playing of Children Stories with Large Language Models**](https://doi.org/10.1145/3586182.3625120) Ôºà**2023.10.29**Ôºâ

<font color="gray">Yubo Zhao, Xiying Bao .  - „ÄêAdjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**CodeFusion: A Pre-trained Diffusion Model for Code Generation**](https://arxiv.org/abs/2310.17680) Ôºà**2023.10.26**Ôºâ

<font color="gray">Mukul Singh, J. Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-39-red)

---

[**GraphGPT: Graph Instruction Tuning for Large Language Models**](https://doi.org/10.48550/arXiv.2310.13023) Ôºà**2023.10.19**Ôºâ

<font color="gray">Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-475-blue)](https://github.com/HKUDS/GraphGPT)

---

[**Creative Robot Tool Use with Large Language Models**](https://doi.org/10.48550/arXiv.2310.13065) Ôºà**2023.10.19**Ôºâ

<font color="gray">Mengdi Xu, Peide Huang, Wenhao Yu, Shiqi Liu, Xilun Zhang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models**](https://doi.org/10.48550/arXiv.2310.11954) Ôºà**2023.10.18**Ôºâ

<font color="gray">Dingyao Yu, Kaitao Song, Peiling Lu, Tianyu He, Xu Tan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4.4k-blue)](https://github.com/microsoft/muzic)

---

[**Llemma: An Open Language Model For Mathematics**](https://doi.org/10.48550/arXiv.2310.10631) Ôºà**2023.10.16**Ôºâ

<font color="gray">Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-6.7k-blue)](https://github.com/eleutherai/gpt-neox)

---

[**BiLL-VTG: Bridging Large Language Models and Lightweight Visual Tools for Video-based Texts Generation**](https://doi.org/10.48550/arXiv.2310.10586) Ôºà**2023.10.16**Ôºâ

<font color="gray">Ji Qi, Kaixuan Ji, Jifan Yu, Duokang Wang, Bin Xu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**JMedLoRA: Medical Domain Adaptation on Japanese Large Language Models using Instruction-tuning**](https://doi.org/10.48550/arXiv.2310.10083) Ôºà**2023.10.16**Ôºâ

<font color="gray">Issey Sukeda, Masahiro Suzuki, Hiroki Sakaji, Satoshi Kodera .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Table-GPT: Table-tuned GPT for Diverse Table Tasks**](https://doi.org/10.48550/arXiv.2310.09263) Ôºà**2023.10.13**Ôºâ

<font color="gray">Peng Li, Yeye He, Dror Yashar, Weiwei Cui, Song Ge, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MemGPT: Towards LLMs as Operating Systems**](https://arxiv.org/abs/2310.08560) Ôºà**2023.10.12**Ôºâ

<font color="gray">Charles Packer, Vivian Fang, Shishir G. Patil, Kevin Lin, Sarah Wooders, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-120-red)  [![](https://img.shields.io/badge/Github%20Stars-10.8k-blue)](https://github.com/cpacker/memgpt)

---

[**Ferret: Refer and Ground Anything Anywhere at Any Granularity**](https://arxiv.org/abs/2310.07704) Ôºà**2023.10.11**Ôºâ

<font color="gray">Haoxuan You, Haotian Zhang, Zhe Gan, Xianzhi Du, Bowen Zhang, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-110-red)  [![](https://img.shields.io/badge/Github%20Stars-8.2k-blue)](https://github.com/apple/ml-ferret)

---

[**Understanding the Effects of RLHF on LLM Generalisation and Diversity**](https://arxiv.org/abs/2310.06452) Ôºà**2023.10.10**Ôºâ

<font color="gray">Robert Kirk, Ishita Mediratta, Christoforos Nalmpantis, Jelena Luketina, Eric Hambro, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-41-red)  [![](https://img.shields.io/badge/Github%20Stars-30-blue)](https://github.com/facebookresearch/rlfh-gen-div)

---

[**Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading**](https://doi.org/10.48550/arXiv.2310.05029) Ôºà**2023.10.08**Ôºâ

<font color="gray">Howard Chen, Ramakanth Pasunuru, Jason Weston, Asli Celikyilmaz .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**xVal: A Continuous Number Encoding for Large Language Models**](https://doi.org/10.48550/arXiv.2310.02989) Ôºà**2023.10.04**Ôºâ

<font color="gray">Siavash Golkar, Mariel Pettee, Michael Eickenberg, Alberto Bietti, M. Cranmer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-107-blue)](https://github.com/PolymathicAI/xVal)

---

[**How FaR Are Large Language Models From Agents with Theory-of-Mind?**](https://arxiv.org/abs/2310.03051) Ôºà**2023.10.04**Ôºâ

<font color="gray">Pei Zhou, Aman Madaan, Srividya Pranavi Potharaju, Aditya Gupta, Kevin R. McKee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-33-red)

---

[**MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens**](https://doi.org/10.48550/arXiv.2310.02239) Ôºà**2023.10.03**Ôºâ

<font color="gray">Kaizhi Zheng, Xuehai He, Xin Eric Wang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-832-blue)](https://github.com/eric-ai-lab/minigpt-5)

---

[**PB-LLM: Partially Binarized Large Language Models**](https://doi.org/10.48550/arXiv.2310.00034) Ôºà**2023.09.29**Ôºâ

<font color="gray">Yuzhang Shang, Zhihang Yuan, Qiang Wu, Zhen Dong .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-139-blue)](https://github.com/hahnyuan/pb-llm)

---

[**GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond**](https://doi.org/10.48550/arXiv.2309.16583) Ôºà**2023.09.28**Ôºâ

<font color="gray">Shen Zheng, Yuyu Zhang, Yijie Zhu, Chenguang Xi, Pengyang Gao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-345-blue)](https://github.com/gpt-fathom/gpt-fathom)

---

[**Chatmap : Large Language Model Interaction with Cartographic Data**](https://doi.org/10.48550/arXiv.2310.01429) Ôºà**2023.09.28**Ôºâ

<font color="gray">Eren Unlu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Integration of Large Language Models within Cognitive Architectures for Autonomous Robots**](https://doi.org/10.48550/arXiv.2309.14945) Ôºà**2023.09.26**Ôºâ

<font color="gray">Miguel √Ångel Gonz√°lez Santamarta, F. J. Lera, √Ångel Manuel Guerrero Higueras, Vicente Matell√°n Olivera .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Effective Distillation of Table-based Reasoning Ability from LLMs**](https://doi.org/10.48550/arXiv.2309.13182) Ôºà**2023.09.22**Ôºâ

<font color="gray">Bohao Yang, Chen Tang, Kangning Zhao, Chenghao Xiao, Chenghua Lin .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/bernard-yang/distilltablecot)

---

[**ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs**](https://doi.org/10.48550/arXiv.2309.13007) Ôºà**2023.09.22**Ôºâ

<font color="gray">Justin Chih-Yao Chen, Swarnadeep Saha, Mohit Bansal .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-161-blue)](https://github.com/dinobby/reconcile)

---

[**Chain-of-Verification Reduces Hallucination in Large Language Models**](https://doi.org/10.48550/arXiv.2309.11495) Ôºà**2023.09.20**Ôºâ

<font color="gray">S. Dhuliawala, M. Komeili, Jing Xu, Roberta Raileanu, Xian Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-898-blue)](https://github.com/lastmile-ai/aiconfig/tree/main/cookbooks/Chain-of-Verification)

---

[**Kosmos-2.5: A Multimodal Literate Model**](https://doi.org/10.48550/arXiv.2309.11419) Ôºà**2023.09.20**Ôºâ

<font color="gray">Tengchao Lv, Yupan Huang, Jingye Chen, Lei Cui, Shuming Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DreamLLM: Synergistic Multimodal Comprehension and Creation**](https://doi.org/10.48550/arXiv.2309.11499) Ôºà**2023.09.20**Ôºâ

<font color="gray">Runpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-352-blue)](https://github.com/RunpeiDong/DreamLLM)

---

[**SwitchGPT: Adapting Large Language Models for Non-Text Outputs**](https://doi.org/10.48550/arXiv.2309.07623) Ôºà**2023.09.14**Ôºâ

<font color="gray">Xinyu Wang, Bohan Zhuang, Qi Wu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**NExT-GPT: Any-to-Any Multimodal LLM**](https://doi.org/10.48550/arXiv.2309.05519) Ôºà**2023.09.11**Ôºâ

<font color="gray">Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, Tat-Seng Chua .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-3.1k-blue)](https://github.com/NExT-GPT/NExT-GPT)

---

[**From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting**](https://doi.org/10.48550/arXiv.2309.04269) Ôºà**2023.09.08**Ôºâ

<font color="gray">Griffin Adams, Alexander R. Fabbri, Faisal Ladhak, Eric Lehman, No√©mie Elhadad .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Models as Optimizers**](https://arxiv.org/abs/2309.03409) Ôºà**2023.09.07**Ôºâ

<font color="gray">Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-270-red)

---

[**DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models**](https://doi.org/10.48550/arXiv.2309.03883) Ôºà**2023.09.07**Ôºâ

<font color="gray">Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James R. Glass, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-365-blue)](https://github.com/voidism/dola)

---

[**YaRN: Efficient Context Window Extension of Large Language Models**](https://doi.org/10.48550/arXiv.2309.00071) Ôºà**2023.08.31**Ôºâ

<font color="gray">Bowen Peng, Jeffrey Quesnelle, Honglu Fan, Enrico Shippole .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-1.3k-blue)](https://github.com/jquesnelle/yarn)

---

[**MVDream: Multi-view Diffusion for 3D Generation**](https://doi.org/10.48550/arXiv.2308.16512) Ôºà**2023.08.31**Ôºâ

<font color="gray">Yichun Shi, Peng Wang, Jianglong Ye, Mai Long, Kejie Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-10-green)  [![](https://img.shields.io/badge/Github%20Stars-713-blue)](https://github.com/bytedance/mvdream)

---

[**FedLogic: Interpretable Federated Multi-Domain Chain-of-Thought Prompt Selection for Large Language Models**](https://doi.org/10.48550/arXiv.2308.15324) Ôºà**2023.08.29**Ôºâ

<font color="gray">Pengwei Xing, Songtao Lu, Han Yu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**PE-MED: Prompt Enhancement for Interactive Medical Image Segmentation**](https://doi.org/10.48550/arXiv.2308.13746) Ôºà**2023.08.26**Ôºâ

<font color="gray">Ao Chang, Xing Tao, Xin Yang, Yuhao Huang, Xinrui Zhou, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DARWIN Series: Domain Specific Large Language Models for Natural Science**](https://doi.org/10.48550/arXiv.2308.13565) Ôºà**2023.08.25**Ôºâ

<font color="gray">Tong Xie, Yuwei Wan, Wei Huang, Yufei Zhou, Yixuan Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-165-blue)](https://github.com/masterai-eam/darwin)

---

[**ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation**](https://doi.org/10.48550/arXiv.2308.11131) Ôºà**2023.08.22**Ôºâ

<font color="gray">Jianghao Lin, Rongjie Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-24-blue)](https://github.com/lavieenrose365/rella)

---

[**SeqGPT: An Out-of-the-box Large Language Model for Open Domain Sequence Understanding**](https://doi.org/10.48550/arXiv.2308.10529) Ôºà**2023.08.21**Ôºâ

<font color="gray">Tianyu Yu, Chengyue Jiang, Chao Lou, Shen Huang, Xiaobin Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-196-blue)](https://github.com/alibaba-nlp/seqgpt)

---

[**Giraffe: Adventures in Expanding Context Lengths in LLMs**](https://doi.org/10.48550/arXiv.2308.10882) Ôºà**2023.08.21**Ôºâ

<font color="gray">Arka Pal, Deep Karkhanis, Manley Roberts, S. Dooley, Arvind Sundararajan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-567-blue)](https://github.com/abacusai/long-context)

---

[**ExpeL: LLM Agents Are Experiential Learners**](https://doi.org/10.48550/arXiv.2308.10144) Ôºà**2023.08.20**Ôºâ

<font color="gray">Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Y. Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-62-blue)](https://github.com/LeapLabTHU/ExpeL)

---

[**Chat-3D: Data-efficiently Tuning Large Language Model for Universal Dialogue of 3D Scenes**](https://doi.org/10.48550/arXiv.2308.08769) Ôºà**2023.08.17**Ôºâ

<font color="gray">Zehan Wang, Haifeng Huang, Yang Zhao, Ziang Zhang, Zhou Zhao .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-50-blue)](https://github.com/Chat-3D/Chat-3D)

---

[**The Devil is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation**](https://doi.org/10.48550/arXiv.2308.07286) Ôºà**2023.08.14**Ôºâ

<font color="gray">Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr√© F. T. Martins, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/xuuhuang/lost_in_the_src)

---

[**Accelerating LLM Inference with Staged Speculative Decoding**](https://doi.org/10.48550/arXiv.2308.04623) Ôºà**2023.08.08**Ôºâ

<font color="gray">Benjamin Spector, Christal Re .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Shepherd: A Critic for Language Model Generation**](https://doi.org/10.48550/arXiv.2308.04592) Ôºà**2023.08.08**Ôºâ

<font color="gray">Tianlu Wang, Ping Yu, Xiaoqing Tan, Sean O'Brien, Ramakanth Pasunuru, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-201-blue)](https://github.com/facebookresearch/shepherd)

---

[**AgentBench: Evaluating LLMs as Agents**](https://doi.org/10.48550/arXiv.2308.03688) Ôºà**2023.08.07**Ôºâ

<font color="gray">Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-2.0k-blue)](https://github.com/thudm/agentbench)

---

[**Scaling Relationship on Learning Mathematical Reasoning with Large Language Models**](https://doi.org/10.48550/arXiv.2308.01825) Ôºà**2023.08.03**Ôºâ

<font color="gray">Zheng Yuan, Hongyi Yuan, Cheng Li, Guanting Dong, Chuanqi Tan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-11-green)  [![](https://img.shields.io/badge/Github%20Stars-187-blue)](https://github.com/ofa-sys/gsm8k-screl)

---

[**Advancing Beyond Identification: Multi-bit Watermark for Language Models**](https://doi.org/10.48550/arXiv.2308.00221) Ôºà**2023.08.01**Ôºâ

<font color="gray">Kiyoon Yoo, W. Ahn, N. Kwak .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**A Private Watermark for Large Language Models**](https://doi.org/10.48550/arXiv.2307.16230) Ôºà**2023.07.30**Ôºâ

<font color="gray">Aiwei Liu, Leyi Pan, Xuming Hu, Shuang Li, Lijie Wen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Robust Distortion-free Watermarks for Language Models**](https://doi.org/10.48550/arXiv.2307.15593) Ôºà**2023.07.28**Ôºâ

<font color="gray">Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, Percy Liang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-62-blue)](https://github.com/jthickstun/watermark)

---

[**Publisher Correction: Large language models encode clinical knowledge.**](https://doi.org/10.1038/s41586-023-06455-0) Ôºà**2023.07.27**Ôºâ

<font color="gray">K. Singhal, Shekoofeh Azizi, Tao Tu, S. S. Mahdavi, Jason Wei, etc .  - „ÄêNature„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Med-Flamingo: a Multimodal Medical Few-shot Learner**](https://doi.org/10.48550/arXiv.2307.15189) Ôºà**2023.07.27**Ôºâ

<font color="gray">Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, C. Zakka, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-367-blue)](https://github.com/snap-stanford/med-flamingo)

---

[**Med-Flamingo: a Multimodal Medical Few-shot Learner**](https://doi.org/10.48550/arXiv.2307.15189) Ôºà**2023.07.27**Ôºâ

<font color="gray">Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, C. Zakka, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-367-blue)](https://github.com/snap-stanford/med-flamingo)

---

[**CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots**](https://doi.org/10.48550/arXiv.2307.11865) Ôºà**2023.07.21**Ôºâ

<font color="gray">Nikhil Kakodkar, D. Rivkin, Bobak H. Baghi, F. Hogan, Gregory Dudek .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning**](https://doi.org/10.48550/arXiv.2307.09474) Ôºà**2023.07.18**Ôºâ

<font color="gray">Liang Zhao, En Yu, Zheng Ge, Jinrong Yang, Hao-Ran Wei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT**](https://doi.org/10.48550/arXiv.2307.08674) Ôºà**2023.07.17**Ôºâ

<font color="gray">Liangyu Zha, Junlin Zhou, Liyao Li, Rui Wang, Qingyi Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)

---

[**MasterKey: Automated Jailbreak Across Multiple Large Language Model Chatbots**](https://arxiv.org/abs/2307.08715) Ôºà**2023.07.16**Ôºâ

<font color="gray">Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, etc </font>

![](https://img.shields.io/badge/Citations-13-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-21-red)

---

[**Self-consistency for open-ended generations**](https://doi.org/10.48550/arXiv.2307.06857) Ôºà**2023.07.11**Ôºâ

<font color="gray">Siddhartha Jain, Xiaofei Ma, Anoop Deoras, Bing Xiang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens**](https://doi.org/10.48550/arXiv.2307.02486) Ôºà**2023.07.05**Ôºâ

<font color="gray">Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-19.1k-blue)](https://github.com/microsoft/unilm)

---

[**Mitigating the Learning Bias towards Repetition by Self-Contrastive Training for Open-Ended Generation**](https://doi.org/10.48550/arXiv.2307.01542) Ôºà**2023.07.04**Ôºâ

<font color="gray">Jian Guan, Minlie Huang .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/thu-coai/selfcont)

---

[**Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics**](https://doi.org/10.48550/arXiv.2307.02502) Ôºà**2023.07.04**Ôºâ

<font color="gray">M. Swan, Takashi Kido, Eric Roland, R. P. D. Santos .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Conformer LLMs - Convolution Augmented Large Language Models**](https://doi.org/10.48550/arXiv.2307.00461) Ôºà**2023.07.02**Ôºâ

<font color="gray">Prateek Verma .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Inferring the Goals of Communicating Agents from Actions and Instructions**](https://doi.org/10.48550/arXiv.2306.16207) Ôºà**2023.06.28**Ôºâ

<font color="gray">Lance Ying, Tan Zhi-Xuan, Vikash K. Mansinghka, J. Tenenbaum .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Kosmos-2: Grounding Multimodal Large Language Models to the World**](https://doi.org/10.48550/arXiv.2306.14824) Ôºà**2023.06.26**Ôºâ

<font color="gray">Zhiliang Peng, Wenhui Wang, Li Dong, Y. Hao, Shaohan Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-19.1k-blue)](https://github.com/microsoft/unilm/tree/master/kosmos-2)

---

[**AudioPaLM: A Large Language Model That Can Speak and Listen**](https://doi.org/10.48550/arXiv.2306.12925) Ôºà**2023.06.22**Ôºâ

<font color="gray">Paul K. Rubenstein, Chulayuth Asawaroengchai, D. Nguyen, Ankur Bapna, Zal√°n Borsos, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards AGI in Computer Vision: Lessons Learned from GPT and Large Language Models**](https://doi.org/10.48550/arXiv.2306.08641) Ôºà**2023.06.14**Ôºâ

<font color="gray">Lingxi Xie, Longhui Wei, Xiaopeng Zhang, Kaifeng Bi, Xiaotao Gu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models**](https://doi.org/10.48550/arXiv.2306.07971) Ôºà**2023.06.13**Ôºâ

<font color="gray">Omkar Thawakar, Abdelrahman M. Shaker, Sahal Shaji Mullappilly, Hisham Cholakkal, R. Anwer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-438-blue)](https://github.com/mbzuai-oryx/xraygpt)

---

[**Judging LLM-as-a-judge with MT-Bench and Chatbot Arena**](https://doi.org/10.48550/arXiv.2306.05685) Ôºà**2023.06.09**Ôºâ

<font color="gray">Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-102-green)  [![](https://img.shields.io/badge/Github%20Stars-35.6k-blue)](https://github.com/lm-sys/fastchat)

---

[**Judging LLM-as-a-judge with MT-Bench and Chatbot Arena**](https://doi.org/10.48550/arXiv.2306.05685) Ôºà**2023.06.09**Ôºâ

<font color="gray">Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-267-green)  [![](https://img.shields.io/badge/Github%20Stars-35.6k-blue)](https://github.com/lm-sys/fastchat)

---

[**PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance**](https://doi.org/10.48550/arXiv.2306.05443) Ôºà**2023.06.08**Ôºâ

<font color="gray">Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-449-blue)](https://github.com/chancefocus/pixiu)

---

[**ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory**](https://doi.org/10.48550/arXiv.2306.03901) Ôºà**2023.06.06**Ôºâ

<font color="gray">Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, J. Zhao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only**](https://doi.org/10.48550/arXiv.2306.01116) Ôºà**2023.06.01**Ôºâ

<font color="gray">Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra-Aim√©e Cojocaru, Alessandro Cappelli, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-50-green)  [![](https://img.shields.io/badge/Github%20Stars-36-blue)](https://github.com/ai21labs/factor)

---

[**Baselines for Identifying Watermarked Large Language Models**](https://doi.org/10.48550/arXiv.2305.18456) Ôºà**2023.05.29**Ôºâ

<font color="gray">Leonard Tang, Gavin Uberti, Tom Shlomi .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Undetectable Watermarks for Language Models**](https://doi.org/10.48550/arXiv.2306.09194) Ôºà**2023.05.25**Ôºâ

<font color="gray">Miranda Christ, S. Gunn, Or Zamir .  - „ÄêIACR Cryptology ePrint Archive„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Mitigating Temporal Misalignment by Discarding Outdated Facts**](https://arxiv.org/abs/2305.14824) Ôºà**2023.05.24**Ôºâ

<font color="gray">Michael J.Q. Zhang, Eunsol Choi </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/mikejqzhang/mitigating_misalignment)

---

[**Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective**](https://arxiv.org/abs/2305.15408) Ôºà**2023.05.24**Ôºâ

<font color="gray">Guhao Feng, Yuntian Gu, Bohang Zhang, Haotian Ye, Di He, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-54-red)

---

[**Peek Across: Improving Multi-Document Modeling via Cross-Document Question-Answering**](https://arxiv.org/abs/2305.15387) Ôºà**2023.05.24**Ôºâ

<font color="gray">Avi Caciularu, Matthew E. Peters, Jacob Goldberger, Ido Dagan, Arman Cohan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/aviclu/peekacross)

---

[**Context-Aware Transformer Pre-Training for Answer Sentence Selection**](https://arxiv.org/abs/2305.15358) Ôºà**2023.05.24**Ôºâ

<font color="gray">Luca Di Liello, Siddhant Garg, Alessandro Moschitti </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Gorilla: Large Language Model Connected with Massive APIs**](https://arxiv.org/abs/2305.15334) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shishir G. Patil, Tianjun Zhang, Xin Wang, Joseph E. Gonzalez </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-238-red)  [![](https://img.shields.io/badge/Github%20Stars-10.7k-blue)](https://github.com/ShishirPatil/gorilla)

---

[**Visual Programming for Text-to-Image Generation and Evaluation**](https://arxiv.org/abs/2305.15328) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jaemin Cho, Abhay Zala, Mohit Bansal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-28-red)

---

[**Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model**](https://arxiv.org/abs/2305.15265) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zirui Liu, Guanchu Wang, Shaochen Zhong, Zhaozhuo Xu, Daochen Zha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/zirui-ray-liu/wtacrs)

---

[**LMs with a Voice: Spoken Language Modeling beyond Speech Tokens**](https://arxiv.org/abs/2305.15255) Ôºà**2023.05.24**Ôºâ

<font color="gray">Eliya Nachmani, Alon Levkovitch, Julian Salazar, Chulayutsh Asawaroengchai, Soroosh Mariooryad, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)

---

[**Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator**](https://arxiv.org/abs/2305.15099) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ziwei He, Meng Yang, Minwei Feng, Jingcheng Yin, Xinbing Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-19-red)  [![](https://img.shields.io/badge/Github%20Stars-25-blue)](https://github.com/lumia-group/fouriertransformer)

---

[**CSTS: Conditional Semantic Textual Similarity**](https://arxiv.org/abs/2305.15093) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ameet Deshpande, Carlos E. Jimenez, Howard Chen, Vishvak S. Murahari, Victoria Graf, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-22-red)

---

[**STAR: Boosting Low-Resource Event Extraction by Structure-to-Text Data Generation with Large Language Models**](https://arxiv.org/abs/2305.15090) Ôºà**2023.05.24**Ôºâ

<font color="gray">Mingyu Derek Ma, Xiaoxuan Wang, Po-Nien Kung, P. Jeffrey Brantingham, Nanyun Peng, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)

---

[**Contrastive Learning of Sentence Embeddings from Scratch**](https://arxiv.org/abs/2305.15077) Ôºà**2023.05.24**Ôºâ

<font color="gray">Junlei Zhang, Zhenzhong Lan, Junxian He </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)  [![](https://img.shields.io/badge/Github%20Stars-33-blue)](https://github.com/hkust-nlp/syncse)

---

[**Meta-Learning Online Adaptation of Language Models**](https://arxiv.org/abs/2305.15076) Ôºà**2023.05.24**Ôºâ

<font color="gray">Nathan J. Hu, Eric Mitchell, Christopher D. Manning, Chelsea Finn </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-25-red)  [![](https://img.shields.io/badge/Github%20Stars-21-blue)](https://github.com/nathanhu0/CaMeLS)

---

[**Who Wrote this Code? Watermarking for Code Generation**](https://arxiv.org/abs/2305.15060) Ôºà**2023.05.24**Ôºâ

<font color="gray">Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/hongcheki/sweet-watermark)

---

[**Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering**](https://arxiv.org/abs/2305.15056) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiajie Zhang, Shulin Cao, Tingjia Zhang, Xin Lv, Jiaxin Shi, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)

---

[**Understanding Arithmetic Reasoning in Language Models using Causal Mediation Analysis**](https://arxiv.org/abs/2305.15054) Ôºà**2023.05.24**Ôºâ

<font color="gray">Alessandro Stolfo, Yonatan Belinkov, Mrinmaya Sachan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)

---

[**Active Learning for Natural Language Generation**](https://arxiv.org/abs/2305.15040) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yotam Perlitz, Ariel Gera, Michal Shmueli-Scheuer, Dafna Sheinwald, Noam Slonim, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)

---

[**SmartTrim: Adaptive Tokens and Parameters Pruning for Efficient Vision-Language Models**](https://arxiv.org/abs/2305.15033) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zekun Wang, Jingchang Chen, Wangchunshu Zhou, Ming Liu, Bing Qin </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**How to Distill your BERT: An Empirical Study on the Impact of Weight Initialisation and Distillation Objectives**](https://arxiv.org/abs/2305.15032) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xinpeng Wang, Leonie Weissweiler, Hinrich Schutze, Barbara Plank </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/mainlp/how-to-distill-your-bert)

---

[**ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification**](https://arxiv.org/abs/2305.15024) Ôºà**2023.05.24**Ôºâ

<font color="gray">Biao Zhao, Weiqiang Jin, Javier Del Ser, Guang Yang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-93-red)  [![](https://img.shields.io/badge/Github%20Stars-38-blue)](https://github.com/albert-jin/agricultural_textual_classification_chatgpt)

---

[**Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models**](https://arxiv.org/abs/2305.15023) Ôºà**2023.05.24**Ôºâ

<font color="gray">Gen Luo, Yiyi Zhou, Tianhe Ren, Shengxin Chen, Xiaoshuai Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-63-red)  [![](https://img.shields.io/badge/Github%20Stars-491-blue)](https://github.com/luogen1996/lavin)

---

[**Unlocking Temporal Question Answering for Large Language Models Using Code Execution**](https://arxiv.org/abs/2305.15014) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xingxuan Li, Liying Cheng, Qingyu Tan, Hwee Tou Ng, Shafiq Joty, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/damo-nlp-sg/mvcr)

---

[**Bactrian-X : A Multilingual Replicable Instruction-Following Model with Low-Rank Adaptation**](https://arxiv.org/abs/2305.15011) Ôºà**2023.05.24**Ôºâ

<font color="gray">Haonan Li, Fajri Koto, Minghao Wu, Alham Fikri Aji, Timothy Baldwin </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism and Synonymous Substitution**](https://arxiv.org/abs/2305.15010) Ôºà**2023.05.24**Ôºâ

<font color="gray">Hongbo Zhang, Xiang Wan, Benyou Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/stevenzhb/bioplm_injectingknowledge)

---

[**LLMDet: A Large Language Models Detection Tool**](https://arxiv.org/abs/2305.15004) Ôºà**2023.05.24**Ôºâ

<font color="gray">Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng, Tat-Seng Chua </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)

---

[**The Art of SOCRATIC QUESTIONING: Zero-shot Multimodal Reasoning with Recursive Thinking and Self-Questioning**](https://arxiv.org/abs/2305.14999) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu, Di Jin, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)

---

[**Reasoning with Language Model is Planning with World Model**](https://arxiv.org/abs/2305.14992) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-149-red)  [![](https://img.shields.io/badge/Github%20Stars-965-blue)](https://github.com/ber666/llm-reasoners)

---

[**Large Language Models are Effective Table-to-Text Generators, Evaluators, and Feedback Providers**](https://arxiv.org/abs/2305.14987) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)

---

[**Improving Factuality of Abstractive Summarization without Sacrificing Summary Quality**](https://arxiv.org/abs/2305.14981) Ôºà**2023.05.24**Ôºâ

<font color="gray">Tanay Dixit, Fei Wang, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-15-red)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/tanay2001/efactsum)

---

[**OverPrompt: Enhancing ChatGPT Capabilities through an Efficient In-Context Learning Approach**](https://arxiv.org/abs/2305.14973) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiazheng Li, Runcong Zhao, Yulan He, Lin Gui </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**MMNet: Multi-Mask Network for Referring Image Segmentation**](https://arxiv.org/abs/2305.14969) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yichen Yan, Xingjian He, Wenxuan Wan, Jing Liu </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks**](https://arxiv.org/abs/2305.14965) Ôºà**2023.05.24**Ôºâ

<font color="gray">Abhinav Rao, Sachin Vashistha, Atharva Naik, Somak Aditya, Monojit Choudhury </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Editing Commonsense Knowledge in GPT**](https://arxiv.org/abs/2305.14956) Ôºà**2023.05.24**Ôºâ

<font color="gray">Anshita Gupta, Debanjan Mondal, Akshay Krishna Sheshadri, Wenlong Zhao, Xiang Lorraine Li, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)

---

[**Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low Resource Languages**](https://arxiv.org/abs/2305.14949) Ôºà**2023.05.24**Ôºâ

<font color="gray">Qi Gou, Zehua Xia, Wen-Hau Du </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Trade-Offs Between Fairness and Privacy in Language Modeling**](https://arxiv.org/abs/2305.14936) Ôºà**2023.05.24**Ôºâ

<font color="gray">Cleo Matzken, Steffen Eger, Ivan Habernal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/cleolotta/fair-and-private-lm)

---

[**Frugal Prompting for Dialog Models**](https://arxiv.org/abs/2305.14919) Ôºà**2023.05.24**Ôºâ

<font color="gray">Bishal Santra, Sakya Basak, Abhinandan De, Manish Gupta, Pawan Goyal </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/bsantraigi/frugal-prompting)

---

[**M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection**](https://arxiv.org/abs/2305.14902) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-65-blue)](https://github.com/mbzuai-nlp/semeval2024-task8)

---

[**PIVOINE: Instruction Tuning for Open-world Information Extraction**](https://arxiv.org/abs/2305.14898) Ôºà**2023.05.24**Ôºâ

<font color="gray">Keming Lu, Xiaoman Pan, Kaiqiang Song, Hongming Zhang, Dong Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)  [![](https://img.shields.io/badge/Github%20Stars-20-blue)](https://github.com/lukeming-tsinghua/instruction-tuning-for-open-world-ie)

---

[**Text encoders are performance bottlenecks in contrastive vision-language models**](https://arxiv.org/abs/2305.14897) Ôºà**2023.05.24**Ôºâ

<font color="gray">Amita Kamath, Jack Hessel, Kai-Wei Chang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Privacy Implications of Retrieval-Based Language Models**](https://arxiv.org/abs/2305.14888) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yangsibo Huang, Samyak Gupta, Zexuan Zhong, Kai Li, Danqi Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-34-blue)](https://github.com/princeton-sysml/knnlm_privacy)

---

[**Interpretable by Design Visual Question Answering**](https://arxiv.org/abs/2305.14882) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xingyu Fu, Ben Zhou, Sihao Chen, Mark Yatskar, D. Roth </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**Leveraging GPT-4 for Automatic Translation Post-Editing**](https://arxiv.org/abs/2305.14878) Ôºà**2023.05.24**Ôºâ

<font color="gray">Vikas Raunak, Amr Sharaf, Hany Hassan Awadallah, Arul Menezes </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-26-red)

---

[**CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering**](https://arxiv.org/abs/2305.14869) Ôºà**2023.05.24**Ôºâ

<font color="gray">Weiqi Wang, Tianqing Fang, Wenxuan Ding, Baixuan Xu, Xin Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/hkust-knowcomp/car)

---

[**Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers**](https://arxiv.org/abs/2305.14858) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zixuan Jiang, Jiaqi Gu, Hanqing Zhu, D. Pan </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-18-blue)](https://github.com/zixuanjiang/pre-rmsnorm-transformer)

---

[**Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models**](https://doi.org/10.48550/arXiv.2305.15023) Ôºà**2023.05.24**Ôºâ

<font color="gray">Gen Luo, Yiyi Zhou, Tianhe Ren, Shen Chen, Xiaoshuai Sun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-15-green)  [![](https://img.shields.io/badge/Github%20Stars-491-blue)](https://github.com/luogen1996/lavin)

---

[**Towards Few-shot Entity Recognition in Document Images: A Graph Neural Network Approach Robust to Image Manipulation**](https://arxiv.org/abs/2305.14828) Ôºà**2023.05.24**Ôºâ

<font color="gray">Prashant Krishnan, Zilong Wang, Yangkun Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Machine Reading Comprehension using Case-based Reasoning**](https://arxiv.org/abs/2305.14815) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dung Thai, Dhruv Agarwal, Mudit Chaudhary, R. Das, M. Zaheer, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)

---

[**Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification**](https://arxiv.org/abs/2305.14794) Ôºà**2023.05.24**Ôºâ

<font color="gray">Chengyu Dong, Zihan Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Text Conditional Alt-Text Generation for Twitter Images**](https://arxiv.org/abs/2305.14779) Ôºà**2023.05.24**Ôºâ

<font color="gray">Nikita Srivatsan, Sofia Samaniego, Omar Florez, Taylor Berg-Kirkpatrick </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**SSD-2: Scaling and Inference-time Fusion of Diffusion Language Models**](https://arxiv.org/abs/2305.14771) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov, Marjan Ghazvininejad </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning**](https://arxiv.org/abs/2305.14761) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, Shafiq Joty </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-21-red)  [![](https://img.shields.io/badge/Github%20Stars-53-blue)](https://github.com/vis-nlp/unichart)

---

[**Trusting Your Evidence: Hallucinate Less with Context-aware Decoding**](https://arxiv.org/abs/2305.14739) Ôºà**2023.05.24**Ôºâ

<font color="gray">Weijia Shi, Xiaochuang Han, M. Lewis, Yulia Tsvetkov, Luke Zettlemoyer, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-52-red)

---

[**In-Context Demonstration Selection with Cross Entropy Difference**](https://arxiv.org/abs/2305.14726) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)  [![](https://img.shields.io/badge/Github%20Stars-3.4k-blue)](https://github.com/microsoft/lmops)

---

[**GlobalBench: A Benchmark for Global Progress in Natural Language Processing**](https://arxiv.org/abs/2305.14716) Ôºà**2023.05.24**Ôºâ

<font color="gray">Y. Song, Catherine Cui, Simran Khanuja, Pengfei Liu, FAHIM FAISAL, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)

---

[**The student becomes the master: Matching GPT3 on Scientific Factual Error Correction**](https://arxiv.org/abs/2305.14707) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dhananjay Ashok, Atharva Kulkarni, Hai Pham, Barnab'as P'oczos </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**PruMUX: Augmenting Data Multiplexing with Model Compression**](https://arxiv.org/abs/2305.14706) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yushan Su, Vishvak S. Murahari, Karthik Narasimhan, Kai Li </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/yushansu/prumux)

---

[**Flan-MoE: Scaling Instruction-Finetuned Language Models with Sparse Mixture of Experts**](https://arxiv.org/abs/2305.14705) Ôºà**2023.05.24**Ôºâ

<font color="gray">Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-90-red)

---

[**A Causal View of Entity Bias in (Large) Language Models**](https://arxiv.org/abs/2305.14695) Ôºà**2023.05.24**Ôºâ

<font color="gray">Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/luka-group/causal-view-of-entity-bias)

---

[**Emergent inabilities? Inverse scaling over the course of pretraining**](https://arxiv.org/abs/2305.14681) Ôºà**2023.05.24**Ôºâ

<font color="gray">James A. Michaelov, B. Bergen </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**InteractiveIE: Towards Assessing the Strength of Human-AI Collaboration in Improving the Performance of Information Extraction**](https://arxiv.org/abs/2305.14659) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ishani Mondal, Michelle Yuan, N Anandhavelu, Aparna Garimella, Francis Ferraro, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Reinforcement Learning finetuned Vision-Code Transformer for UI-to-Code Generation**](https://arxiv.org/abs/2305.14637) Ôºà**2023.05.24**Ôºâ

<font color="gray">Davit Soselia, Khalid Saifullah, Tianyi Zhou </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**KNN-LM Does Not Improve Open-ended Text Generation**](https://arxiv.org/abs/2305.14625) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shufan Wang, Yixiao Song, Andrew Drozdov, Aparna Garimella, Varun Manjunatha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations**](https://arxiv.org/abs/2305.14618) Ôºà**2023.05.24**Ôºâ

<font color="gray">Wenting Zhao, Justin T. Chiu, Claire Cardie, Alexander M. Rush </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)

---

[**Language Models with Rationality**](https://arxiv.org/abs/2305.14250) Ôºà**2023.05.23**Ôºâ

<font color="gray">Nora Kassner, Oyvind Tafjord, Ashish Sabharwal, Kyle Richardson, Hinrich Sch√ºtze, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)

---

[**A Trip Towards Fairness: Bias and De-Biasing in Large Language Models**](https://arxiv.org/abs/2305.13862) Ôºà**2023.05.23**Ôºâ

<font color="gray">Leonardo Ranaldi, Elena Sofia Ruzzetti, Davide Venditti, Dario Onorati, Fabio Massimo Zanzotto </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)

---

[**Question Answering as Programming for Solving Time-Sensitive Questions**](https://arxiv.org/abs/2305.14221) Ôºà**2023.05.23**Ôºâ

<font color="gray">Xinyu Zhu, Cheng Yang, Bei Chen, Siheng Li, Jian-Guang Lou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/tianhongzxy/qaap)

---

[**PaD: Program-aided Distillation Specializes Large Models in Reasoning**](https://arxiv.org/abs/2305.13888) Ôºà**2023.05.23**Ôºâ

<font color="gray">Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xingwei Long, Bowen Zhou </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)

---

[**Aligning Large Language Models through Synthetic Feedback**](https://arxiv.org/abs/2305.13735) Ôºà**2023.05.23**Ôºâ

<font color="gray">Sungdong Kim, Sanghwan Bae, Jamin Shin, Soyoung Kang, Donghyun Kwak, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-38-red)  [![](https://img.shields.io/badge/Github%20Stars-22-blue)](https://github.com/naver-ai/almost)

---

[**LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large Language Models**](https://arxiv.org/abs/2305.13718) Ôºà**2023.05.23**Ôºâ

<font color="gray">Fangkai Jiao, Zhiyang Teng, Shafiq Joty, Bosheng Ding, Aixin Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**Masked Path Modeling for Vision-and-Language Navigation**](https://doi.org/10.48550/arXiv.2305.14268) Ôºà**2023.05.23**Ôºâ

<font color="gray">Zi-Yi Dou, Feng Gao, Nanyun Peng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models**](https://arxiv.org/abs/2305.14323) Ôºà**2023.05.23**Ôºâ

<font color="gray">Z. Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne Xin Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-27-red)  [![](https://img.shields.io/badge/Github%20Stars-41-blue)](https://github.com/rucaibox/chatcot)

---

[**DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules**](https://arxiv.org/abs/2305.13406) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yanchen Liu, William Held, Diyi Yang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/salt-nlp/dada)

---

[**Knowledge-Retrieval Task-Oriented Dialog Systems with Semi-Supervision**](https://arxiv.org/abs/2305.13199) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yucheng Cai, Hong Liu, Zhijian Ou, Y. Huang, Junlan Feng </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/thu-spmi/jsa-krtod)

---

[**Sentence Representations via Gaussian Embedding**](https://arxiv.org/abs/2305.12990) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shohei Yoda, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LM-Switch: Lightweight Language Model Conditioning in Word Embedding Space**](https://arxiv.org/abs/2305.12798) Ôºà**2023.05.22**Ôºâ

<font color="gray">Chi Han, Jialiang Xu, Manling Li, Y. Fung, Chenkai Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)

---

[**MacLaSa: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space**](https://arxiv.org/abs/2305.12785) Ôºà**2023.05.22**Ôºâ

<font color="gray">Hanxing Ding, Liang Pang, Z. Wei, Huawei Shen, Xueqi Cheng, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/trustedllm/maclasa)

---

[**Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer**](https://arxiv.org/abs/2305.12761) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shuang Li, Xuming Hu, Aiwei Liu, Yawen Yang, Fukun Ma, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/thu-bpm/softmv)

---

[**A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches**](https://arxiv.org/abs/2305.12749) Ôºà**2023.05.22**Ôºâ

<font color="gray">Zihan Wang, Tianle Wang, Dheeraj Mekala, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/zihanwangki/x-tc)

---

[**Keeping Up with the Language Models: Robustness-Bias Interplay in NLI Data and Models**](https://arxiv.org/abs/2305.12620) Ôºà**2023.05.22**Ôºâ

<font color="gray">Ioana Baldini, Chhavi Yadav, Payel Das, K. Varshney </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis**](https://arxiv.org/abs/2305.13230) Ôºà**2023.05.22**Ôºâ

<font color="gray">Fuzhao Xue, Yao Fu, Wangchunshu Zhou, Zangwei Zheng, Yang You </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-56-red)

---

[**Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A Preliminary Study on Writing Assistance**](https://arxiv.org/abs/2305.13225) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yue Zhang, Leyang Cui, Deng Cai, Xinting Huang, Tao Fang, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)

---

[**InheritSumm: A General, Versatile and Compact Summarizer by Distilling from GPT**](https://arxiv.org/abs/2305.13083) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yichong Xu, Ruochen Xu, Dan Iter, Yang Liu, Shuo Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Making Language Models Better Tool Learners with Execution Feedback**](https://arxiv.org/abs/2305.13068) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shuofei Qiao, Honghao Gui, Huajun Chen, Ningyu Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-32-blue)](https://github.com/zjunlp/trice)

---

[**GPT-SW3: An Autoregressive Language Model for the Nordic Languages**](https://arxiv.org/abs/2305.12987) Ôºà**2023.05.22**Ôºâ

<font color="gray">Ariel Ekgren, Amaru Cuba Gyllensten, F. Stollenwerk, Joey Ohman, Tim Isbister, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination**](https://arxiv.org/abs/2305.12945) Ôºà**2023.05.22**Ôºâ

<font color="gray">Dongfang Li, Jindi Yu, Baotian Hu, Zhenran Xu, Min Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/hitsz-tmg/explaincpe)

---

[**Infor-Coef: Information Bottleneck-based Dynamic Token Downsampling for Compact and Efficient language model**](https://arxiv.org/abs/2305.12458) Ôºà**2023.05.21**Ôºâ

<font color="gray">Wenxin Tan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text**](https://arxiv.org/abs/2305.12599) Ôºà**2023.05.21**Ôºâ

<font color="gray">Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Retrieving Texts based on Abstract Descriptions**](https://arxiv.org/abs/2305.12517) Ôºà**2023.05.21**Ôºâ

<font color="gray">Shauli Ravfogel, Valentina Pyatkin, Amir D. N. Cohen, Avshalom Manevich, Yoav Goldberg </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**Pruning Pre-trained Language Models with Principled Importance and Self-regularization**](https://arxiv.org/abs/2305.12394) Ôºà**2023.05.21**Ôºâ

<font color="gray">Siyu Ren, Kenny Q. Zhu </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/drsy/pins)

---

[**Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers**](https://arxiv.org/abs/2305.12567) Ôºà**2023.05.21**Ôºâ

<font color="gray">Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-20-blue)](https://github.com/gonglinyuan/metro_t0)

---

[**Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs**](https://arxiv.org/abs/2305.12191) Ôºà**2023.05.20**Ôºâ

<font color="gray">Yatin Nandwani, Vineet Kumar, Dinesh Raghu, Sachindra Joshi, L. Lastras </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/ynandwan/pmi-faith)

---

[**Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning**](https://arxiv.org/abs/2305.12295) Ôºà**2023.05.20**Ôºâ

<font color="gray">Liangming Pan, Alon Albalak, Xinyi Wang, William Yang Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-74-red)  [![](https://img.shields.io/badge/Github%20Stars-201-blue)](https://github.com/teacherpeterpan/logic-llm)

---

[**LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4**](https://arxiv.org/abs/2305.12147) Ôºà**2023.05.20**Ôºâ

<font color="gray">Hanmeng Liu, Zhiyang Teng, Leyang Cui, Chaoli Zhang, Qiji Zhou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Self-QA: Unsupervised Knowledge Guided Language Model Alignment**](https://arxiv.org/abs/2305.11952) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xuanyu Zhang, Qing Yang </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)  [![](https://img.shields.io/badge/Github%20Stars-930-blue)](https://github.com/duxiaoman-di/xuanyuan)

---

[**SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs**](https://doi.org/10.48550/arXiv.2305.11461) Ôºà**2023.05.19**Ôºâ

<font color="gray">IokTong Lei, ZhiDong Deng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions**](https://doi.org/10.48550/arXiv.2305.11460) Ôºà**2023.05.19**Ôºâ

<font color="gray">Shiyao Ding, Takayuki Ito .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases**](https://arxiv.org/abs/2305.12018) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xin Liu, Muhammad Khalifa, Lu Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)  [![](https://img.shields.io/badge/Github%20Stars-14-blue)](https://github.com/launchnlp/bolt)

---

[**STOAT: Structured Data to Analytical Text With Controls**](https://doi.org/10.48550/arXiv.2305.11826) Ôºà**2023.05.19**Ôºâ

<font color="gray">Deepanway Ghosal, Preksha Nema, A. Raghuveer .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Decouple knowledge from paramters for plug-and-play language modeling**](https://doi.org/10.48550/arXiv.2305.11564) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xin Cheng, Yankai Lin, Xiuying Chen, Dongyan Zhao, Rui Yan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona**](https://doi.org/10.48550/arXiv.2305.11482) Ôºà**2023.05.19**Ôºâ

<font color="gray">Yihong Tang, Bo Wang, Miao Fang, Dongming Zhao, Kun Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/toyhom/clv)

---

[**XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters**](https://arxiv.org/abs/2305.12002) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xuanyu Zhang, Qing Yang, Dongliang Xu </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-23-red)  [![](https://img.shields.io/badge/Github%20Stars-930-blue)](https://github.com/duxiaoman-di/xuanyuan)

---

[**Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning**](https://doi.org/10.48550/arXiv.2305.11759) Ôºà**2023.05.19**Ôºâ

<font color="gray">Mustafa Safa Ozdayi, Charith S. Peris, Jack G. M. FitzGerald, Christophe Dupuy, Jimit Majmudar, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-24-blue)](https://github.com/amazon-science/controlling-llm-memorization)

---

[**RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought**](https://doi.org/10.48550/arXiv.2305.11499) Ôºà**2023.05.19**Ôºâ

<font color="gray">Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LLM Itself Can Read and Generate CXR Images**](https://doi.org/10.48550/arXiv.2305.11490) Ôºà**2023.05.19**Ôºâ

<font color="gray">Suhyeon Lee, Won Jun Kim, Jong-Chul Ye .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Post Hoc Explanations of Language Models Can Improve Language Models**](https://doi.org/10.48550/arXiv.2305.11426) Ôºà**2023.05.19**Ôºâ

<font color="gray">Satyapriya, Krishna, Jiaqi Ma, Dylan Slack, Asma Ghandeharioun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models**](https://doi.org/10.48550/arXiv.2305.11414) Ôºà**2023.05.19**Ôºâ

<font color="gray">Sixing Yu, J. P. Mu√±oz, A. Jannesari .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning**](https://doi.org/10.48550/arXiv.2305.11383) Ôºà**2023.05.19**Ôºâ

<font color="gray">Po-Nien Kung, Nanyun Peng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**AutoTrial: Prompting Language Models for Clinical Trial Design**](https://doi.org/10.48550/arXiv.2305.11366) Ôºà**2023.05.19**Ôºâ

<font color="gray">Zifeng Wang, Cao Xiao, Jimeng Sun .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Democratized Diffusion Language Model**](https://doi.org/10.48550/arXiv.2305.10818) Ôºà**2023.05.18**Ôºâ

<font color="gray">Nikita Balagansky, Daniil Gavrilov .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Ahead-of-Time P-Tuning**](https://doi.org/10.48550/arXiv.2305.10835) Ôºà**2023.05.18**Ôºâ

<font color="gray">Daniil Gavrilov, Nikita Balagansky .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation**](https://doi.org/10.48550/arXiv.2305.11130) Ôºà**2023.05.18**Ôºâ

<font color="gray">Junkai Zhou, Liang Pang, Huawei Shen, Xueqi Cheng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/934865517zjk/simoap)

---

[**How does the task complexity of masked pretraining objectives affect downstream performance?**](https://doi.org/10.48550/arXiv.2305.10992) Ôºà**2023.05.18**Ôºâ

<font color="gray">Atsuki Yamaguchi, Hiroaki Ozaki, Terufumi Morishita, Gaku Morio, Yasuhiro Sogawa .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/hitachi-nlp/mlm-probe-acl2023)

---

[**Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings**](https://doi.org/10.48550/arXiv.2305.10786) Ôºà**2023.05.18**Ôºâ

<font color="gray">Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Chong Deng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-97-blue)](https://github.com/alibaba-damo-academy/spokennlp)

---

[**ReGen: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval**](https://doi.org/10.48550/arXiv.2305.10703) Ôºà**2023.05.18**Ôºâ

<font color="gray">Yue Yu, Yuchen Zhuang, Rongzhi Zhang, Yu Meng, Jiaming Shen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-18-blue)](https://github.com/yueyu1030/ReGen)

---

[**Efficient Prompting via Dynamic In-Context Learning**](https://doi.org/10.48550/arXiv.2305.11170) Ôºà**2023.05.18**Ôºâ

<font color="gray">Wangchunshu Zhou, Yuchen Jiang, Ryan Cotterell, Mrinmaya Sachan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LIMA: Less Is More for Alignment**](https://doi.org/10.48550/arXiv.2305.11206) Ôºà**2023.05.18**Ôºâ

<font color="gray">Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-2.6k-blue)](https://github.com/alpha-vllm/llama2-accessory)

---

[**SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities**](https://doi.org/10.48550/arXiv.2305.11000) Ôºà**2023.05.18**Ôºâ

<font color="gray">Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, P. Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-1.0k-blue)](https://github.com/0nutation/speechgpt)

---

[**The Web Can Be Your Oyster for Improving Large Language Models**](https://doi.org/10.48550/arXiv.2305.10998) Ôºà**2023.05.18**Ôºâ

<font color="gray">Junyi Li, Tianyi Tang, Wayne Xin Zhao, Jingyuan Wang, J. Nie, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/rucaibox/uniweb)

---

[**TOME: A Two-stage Approach for Model-based Retrieval**](https://doi.org/10.48550/arXiv.2305.11161) Ôºà**2023.05.18**Ôºâ

<font color="gray">Ruiyang Ren, Wayne Xin Zhao, J. Liu, Huaqin Wu, Ji-rong Wen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**When Gradient Descent Meets Derivative-Free Optimization: A Match Made in Black-Box Scenario**](https://doi.org/10.48550/arXiv.2305.10013) Ôºà**2023.05.17**Ôºâ

<font color="gray">Chengcheng Han, Liqing Cui, Renyu Zhu, J. Wang, Nuo Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Emergent and Predictable Memorization in Large Language Models**](https://arxiv.org/abs/2304.11158) Ôºà**2023.04.21**Ôºâ

<font color="gray">Stella Rose Biderman, Usvsn Sai Prashanth, Lintang Sutawika, Hailey Schoelkopf, Quentin G. Anthony, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-41-red)  [![](https://img.shields.io/badge/Github%20Stars-6.7k-blue)](https://github.com/eleutherai/gpt-neox)

---

[**Improving Multiparty Interactions with a Robot Using Large Language Models**](https://doi.org/10.1145/3544549.3585602) Ôºà**2023.04.19**Ôºâ

<font color="gray">Prasanth Murali, Ian Steenstra, Hye Sun Yun, Ameneh Shamekhi, T. Bickmore .  - „ÄêCHI Extended Abstracts„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-21-red)

---

[**Large Language Models Can Be Used to Estimate the Latent Positions of Politicians**](https://arxiv.org/abs/2303.12057) Ôºà**2023.03.21**Ôºâ

<font color="gray">Patrick Y. Wu, Joshua A. Tucker, Jonathan Nagler, Solomon Messing </font>

![](https://img.shields.io/badge/Citations-9-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks**](https://doi.org/10.48550/arXiv.2303.00733) Ôºà**2023.03.01**Ôºâ

<font color="gray">Kai-Wei Chang, Yu-Kai Wang, Hua Shen, Iu-thing Kang, W. Tseng, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis**](https://doi.org/10.48550/arXiv.2303.00815) Ôºà**2023.03.01**Ôºâ

<font color="gray">Jingli Shi, Weihua Li, Quan-wei Bai, Yi Yang, Jianhua Jiang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**EvoPrompting: Language Models for Code-Level Neural Architecture Search**](https://doi.org/10.48550/arXiv.2302.14838) Ôºà**2023.02.28**Ôºâ

<font color="gray">Angelica Chen, David Dohan, David R. So .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models**](https://doi.org/10.48550/arXiv.2302.12173) Ôºà**2023.02.23**Ôºâ

<font color="gray">Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, C. Endres, Thorsten Holz, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales**](https://doi.org/10.48550/arXiv.2302.08961) Ôºà**2023.02.17**Ôºâ

<font color="gray">M. Ruskov .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LabelPrompt: Effective Prompt-based Learning for Relation Classification**](https://doi.org/10.48550/arXiv.2302.08068) Ôºà**2023.02.16**Ôºâ

<font color="gray">W. Zhang, Xiaoning Song, Zhenhua Feng, Tianyang Xu, Xiaojun Wu .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition**](https://doi.org/10.48550/arXiv.2302.08102) Ôºà**2023.02.16**Ôºâ

<font color="gray">Minsu Kim, Hyungil Kim, Y. Ro .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Prompting for Multimodal Hateful Meme Classification**](https://doi.org/10.48550/arXiv.2302.04156) Ôºà**2023.02.08**Ôºâ

<font color="gray">Rui Cao, R. Lee, Wen-Haw Chong, Jing Jiang .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Toxicity Detection with Generative Prompt-based Inference**](https://doi.org/10.48550/arXiv.2205.12390) Ôºà**2022.05.24**Ôºâ

<font color="gray">Yau-Shian Wang, Y. Chang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Learning to Transfer Prompts for Text Generation**](https://doi.org/10.48550/arXiv.2205.01543) Ôºà**2022.05.03**Ôºâ

<font color="gray">Junyi Li, Tianyi Tang, J. Nie, Ji-rong Wen, Wayne Xin Zhao .  - „ÄêNorth American Chapter of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-11-green)  [![](https://img.shields.io/badge/Github%20Stars-25-blue)](https://github.com/rucaibox/transfer-prompts-for-text-generation)

---

[**RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction**](https://doi.org/10.48550/arXiv.2203.09101) Ôºà**2022.03.17**Ôºâ

<font color="gray">Yew Ken Chia, Lidong Bing, Soujanya Poria, Luo Si .  - „ÄêFindings„Äë</font>

![](https://img.shields.io/badge/Citations-15-green)  [![](https://img.shields.io/badge/Github%20Stars-121-blue)](https://github.com/declare-lab/relationprompt)

---

[**QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition**](https://doi.org/10.48550/arXiv.2203.01543) Ôºà**2022.03.03**Ôºâ

<font color="gray">Andy T. Liu, Wei Xiao, Henghui Zhu, Dejiao Zhang, Shang-Wen Li, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-63-blue)](https://github.com/dayyass/QaNER)

---

[**PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts**](https://doi.org/10.18653/v1/2022.acl-demo.9) Ôºà**2022.02.02**Ôºâ

<font color="gray">Stephen H. Bach, Victor Sanh, Zheng Xin Yong, Albert Webson, Colin Raffel, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-54-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-137-red)  [![](https://img.shields.io/badge/Github%20Stars-2.6k-blue)](https://github.com/bigscience-workshop/promptsource)

---

[**Few-Shot Bot: Prompt-Based Learning for Dialogue Systems**](https://arxiv.org/abs/2110.08118) Ôºà**2021.10.15**Ôºâ

<font color="gray">Andrea Madotto, Zhaojiang Lin, Genta Indra Winata, Pascale Fung .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-82-red)  [![](https://img.shields.io/badge/Github%20Stars-765-blue)](https://github.com/tunib-ai/parallelformers)

---

[**SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based Sentiment Analysis**](https://arxiv.org/abs/2109.08306) Ôºà**2021.09.17**Ôºâ

<font color="gray">Chengxi Li, Feiyu Gao, Jiajun Bu, Lu Xu, Xiang Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-20-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-73-red)

---

[**LightNER: A Lightweight Tuning Paradigm for Low-resource NER via Pluggable Prompting**](https://arxiv.org/abs/2109.00720) Ôºà**2021.08.31**Ôºâ

<font color="gray">Xiang Chen, Lei Li, Shumin Deng, Chuanqi Tan, Changliang Xu, etc .  - „ÄêInternational Conference on Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-38-red)

---

[**Program Synthesis with Large Language Models**](https://arxiv.org/abs/2108.07732) Ôºà**2021.08.16**Ôºâ

<font color="gray">Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, H. Michalewski, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-175-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-251-red)

---

[**Evaluating Large Language Models Trained on Code**](https://arxiv.org/abs/2107.03374) Ôºà**2021.07.07**Ôºâ

<font color="gray">Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-612-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1.2k-red)  [![](https://img.shields.io/badge/Github%20Stars-2.1k-blue)](https://github.com/openai/human-eval)

---

[**KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction**](https://doi.org/10.1145/3485447.3511998) Ôºà**2021.04.15**Ôºâ

<font color="gray">Xiang Chen, Ningyu Zhang, Ningyu Zhang, Xin Xie, Shumin Deng, etc .  - „ÄêThe Web Conference„Äë</font>

![](https://img.shields.io/badge/Citations-86-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-216-red)  [![](https://img.shields.io/badge/Github%20Stars-191-blue)](https://github.com/zjunlp/KnowPrompt)

---

[**Language Models as Knowledge Bases?**](https://doi.org/10.18653/v1/D19-1250) Ôºà**2019.09.01**Ôºâ

<font color="gray">Fabio Petroni, Tim Rockt√§schel, Patrick Lewis, A. Bakhtin, Yuxiang Wu, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1038-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1.4k-red)

---

[**Leveraging Commonsense Knowledge from Large Language Models for Task and Motion Planning**](https://api.semanticscholar.org/4ebf49a7c053bf1d22fcce17bc8c80db827e8f99) 

<font color="gray">Yan Ding, Xiaohan Zhang </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**AdaPrompt: Adaptive Prompt-based Finetuning for Relation Extraction**](https://api.semanticscholar.org/2404aecd866cfa15fee6ada095667980a63c4172) 

<font color="gray">Xiang Chen, Xin Xie, Ningyu Zhang, Jiahuan Yan, Shumin Deng, etc </font>

![](https://img.shields.io/badge/Citations-31-green)

---

[**SmartMoE: Efficiently Training Sparsely-Activated Models through Combining Offline and Online Parallelization**](https://api.semanticscholar.org/5c6a17850c9ad6bf6dc8992ec598cd932ce42208) 

<font color="gray">Mingshu Zhai, Jiaao He, Zixuan Ma, Zan Zong, Runqing Zhang, etc .  - „ÄêUSENIX Annual Technical Conference„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**ChatGPT-Based Learning Platform for Creation of Different Attack Model Signatures and Development of Defense Algorithm for Cyberattack Detection**](https://doi.org/10.1109/TLT.2024.3417252) 

<font color="gray">T. Santhi, K. Srinivasan .  - „ÄêIEEE Transactions on Learning Technologies„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)


</div>

# CONTINUE...