# üìÑ Prompt Application

## Paper List

<div style="line-height:0.2em;">


[**Narratron: Collaborative Writing and Shadow-playing of Children Stories with Large Language Models**](https://doi.org/10.1145/3586182.3625120) Ôºà**2023.10.29**Ôºâ

<font color="gray">Yubo Zhao, Xiying Bao .  - „ÄêAdjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**CodeFusion: A Pre-trained Diffusion Model for Code Generation**](https://arxiv.org/abs/2310.17680) Ôºà**2023.10.26**Ôºâ

<font color="gray">Mukul Singh, J. Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**GraphGPT: Graph Instruction Tuning for Large Language Models**](https://doi.org/10.48550/arXiv.2310.13023) Ôºà**2023.10.19**Ôºâ

<font color="gray">Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-98-blue)](https://github.com/HKUDS/GraphGPT)

---

[**Creative Robot Tool Use with Large Language Models**](https://doi.org/10.48550/arXiv.2310.13065) Ôºà**2023.10.19**Ôºâ

<font color="gray">Mengdi Xu, Peide Huang, Wenhao Yu, Shiqi Liu, Xilun Zhang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models**](https://doi.org/10.48550/arXiv.2310.11954) Ôºà**2023.10.18**Ôºâ

<font color="gray">Dingyao Yu, Kaitao Song, Peiling Lu, Tianyu He, Xu Tan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**BiLL-VTG: Bridging Large Language Models and Lightweight Visual Tools for Video-based Texts Generation**](https://doi.org/10.48550/arXiv.2310.10586) Ôºà**2023.10.16**Ôºâ

<font color="gray">Ji Qi, Kaixuan Ji, Jifan Yu, Duokang Wang, Bin Xu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**JMedLoRA: Medical Domain Adaptation on Japanese Large Language Models using Instruction-tuning**](https://doi.org/10.48550/arXiv.2310.10083) Ôºà**2023.10.16**Ôºâ

<font color="gray">Issey Sukeda, Masahiro Suzuki, Hiroki Sakaji, Satoshi Kodera .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Table-GPT: Table-tuned GPT for Diverse Table Tasks**](https://doi.org/10.48550/arXiv.2310.09263) Ôºà**2023.10.13**Ôºâ

<font color="gray">Peng Li, Yeye He, Dror Yashar, Weiwei Cui, Song Ge, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MemGPT: Towards LLMs as Operating Systems**](https://arxiv.org/abs/2310.08560) Ôºà**2023.10.12**Ôºâ

<font color="gray">Charles Packer, Vivian Fang, Shishir G. Patil, Kevin Lin, Sarah Wooders, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ferret: Refer and Ground Anything Anywhere at Any Granularity**](https://arxiv.org/abs/2310.07704) Ôºà**2023.10.11**Ôºâ

<font color="gray">Haoxuan You, Haotian Zhang, Zhe Gan, Xianzhi Du, Bowen Zhang, etc </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Understanding the Effects of RLHF on LLM Generalisation and Diversity**](https://arxiv.org/abs/2310.06452) Ôºà**2023.10.10**Ôºâ

<font color="gray">Robert Kirk, Ishita Mediratta, Christoforos Nalmpantis, Jelena Luketina, Eric Hambro, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading**](https://doi.org/10.48550/arXiv.2310.05029) Ôºà**2023.10.08**Ôºâ

<font color="gray">Howard Chen, Ramakanth Pasunuru, Jason Weston, Asli Celikyilmaz .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**xVal: A Continuous Number Encoding for Large Language Models**](https://doi.org/10.48550/arXiv.2310.02989) Ôºà**2023.10.04**Ôºâ

<font color="gray">Siavash Golkar, Mariel Pettee, Michael Eickenberg, Alberto Bietti, M. Cranmer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-65-blue)](https://github.com/PolymathicAI/xVal)

---

[**How FaR Are Large Language Models From Agents with Theory-of-Mind?**](https://arxiv.org/abs/2310.03051) Ôºà**2023.10.04**Ôºâ

<font color="gray">Pei Zhou, Aman Madaan, Srividya Pranavi Potharaju, Aditya Gupta, Kevin R. McKee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens**](https://doi.org/10.48550/arXiv.2310.02239) Ôºà**2023.10.03**Ôºâ

<font color="gray">Kaizhi Zheng, Xuehai He, Xin Eric Wang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**PB-LLM: Partially Binarized Large Language Models**](https://doi.org/10.48550/arXiv.2310.00034) Ôºà**2023.09.29**Ôºâ

<font color="gray">Yuzhang Shang, Zhihang Yuan, Qiang Wu, Zhen Dong .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Integration of Large Language Models within Cognitive Architectures for Autonomous Robots**](https://doi.org/10.48550/arXiv.2309.14945) Ôºà**2023.09.26**Ôºâ

<font color="gray">Miguel √Ångel Gonz√°lez Santamarta, F. J. Lera, √Ångel Manuel Guerrero Higueras, Vicente Matell√°n Olivera .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Effective Distillation of Table-based Reasoning Ability from LLMs**](https://doi.org/10.48550/arXiv.2309.13182) Ôºà**2023.09.22**Ôºâ

<font color="gray">Bohao Yang, Chen Tang, Kangning Zhao, Chenghao Xiao, Chenghua Lin .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs**](https://doi.org/10.48550/arXiv.2309.13007) Ôºà**2023.09.22**Ôºâ

<font color="gray">Justin Chih-Yao Chen, Swarnadeep Saha, Mohit Bansal .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**Chain-of-Verification Reduces Hallucination in Large Language Models**](https://doi.org/10.48550/arXiv.2309.11495) Ôºà**2023.09.20**Ôºâ

<font color="gray">S. Dhuliawala, M. Komeili, Jing Xu, Roberta Raileanu, Xian Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Kosmos-2.5: A Multimodal Literate Model**](https://doi.org/10.48550/arXiv.2309.11419) Ôºà**2023.09.20**Ôºâ

<font color="gray">Tengchao Lv, Yupan Huang, Jingye Chen, Lei Cui, Shuming Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/kyegomez/Kosmos2.5)

---

[**DreamLLM: Synergistic Multimodal Comprehension and Creation**](https://doi.org/10.48550/arXiv.2309.11499) Ôºà**2023.09.20**Ôºâ

<font color="gray">Runpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-185-blue)](https://github.com/RunpeiDong/DreamLLM)

---

[**SwitchGPT: Adapting Large Language Models for Non-Text Outputs**](https://doi.org/10.48550/arXiv.2309.07623) Ôºà**2023.09.14**Ôºâ

<font color="gray">Xinyu Wang, Bohan Zhuang, Qi Wu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**NExT-GPT: Any-to-Any Multimodal LLM**](https://doi.org/10.48550/arXiv.2309.05519) Ôºà**2023.09.11**Ôºâ

<font color="gray">Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, Tat-Seng Chua .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-1.9k-blue)](https://github.com/NExT-GPT/NExT-GPT)

---

[**From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting**](https://doi.org/10.48550/arXiv.2309.04269) Ôºà**2023.09.08**Ôºâ

<font color="gray">Griffin Adams, Alexander R. Fabbri, Faisal Ladhak, Eric Lehman, No√©mie Elhadad .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Models as Optimizers**](https://arxiv.org/abs/2309.03409) Ôºà**2023.09.07**Ôºâ

<font color="gray">Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models**](https://doi.org/10.48550/arXiv.2309.03883) Ôºà**2023.09.07**Ôºâ

<font color="gray">Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James R. Glass, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-184-blue)](https://github.com/voidism/dola)

---

[**YaRN: Efficient Context Window Extension of Large Language Models**](https://doi.org/10.48550/arXiv.2309.00071) Ôºà**2023.08.31**Ôºâ

<font color="gray">Bowen Peng, Jeffrey Quesnelle, Honglu Fan, Enrico Shippole .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-655-blue)](https://github.com/jquesnelle/yarn)

---

[**MVDream: Multi-view Diffusion for 3D Generation**](https://doi.org/10.48550/arXiv.2308.16512) Ôºà**2023.08.31**Ôºâ

<font color="gray">Yichun Shi, Peng Wang, Jianglong Ye, Mai Long, Kejie Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-10-green)

---

[**PE-MED: Prompt Enhancement for Interactive Medical Image Segmentation**](https://doi.org/10.48550/arXiv.2308.13746) Ôºà**2023.08.26**Ôºâ

<font color="gray">Ao Chang, Xing Tao, Xin Yang, Yuhao Huang, Xinrui Zhou, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DARWIN Series: Domain Specific Large Language Models for Natural Science**](https://doi.org/10.48550/arXiv.2308.13565) Ôºà**2023.08.25**Ôºâ

<font color="gray">Tong Xie, Yuwei Wan, Wei Huang, Yufei Zhou, Yixuan Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation**](https://doi.org/10.48550/arXiv.2308.11131) Ôºà**2023.08.22**Ôºâ

<font color="gray">Jianghao Lin, Rongjie Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**SeqGPT: An Out-of-the-box Large Language Model for Open Domain Sequence Understanding**](https://doi.org/10.48550/arXiv.2308.10529) Ôºà**2023.08.21**Ôºâ

<font color="gray">Tianyu Yu, Chengyue Jiang, Chao Lou, Shen Huang, Xiaobin Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-66-blue)](https://github.com/alibaba-nlp/seqgpt)

---

[**Giraffe: Adventures in Expanding Context Lengths in LLMs**](https://doi.org/10.48550/arXiv.2308.10882) Ôºà**2023.08.21**Ôºâ

<font color="gray">Arka Pal, Deep Karkhanis, Manley Roberts, S. Dooley, Arvind Sundararajan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-454-blue)](https://github.com/abacusai/long-context)

---

[**ExpeL: LLM Agents Are Experiential Learners**](https://doi.org/10.48550/arXiv.2308.10144) Ôºà**2023.08.20**Ôºâ

<font color="gray">Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Y. Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/Andrewzh112/ExpeL)

---

[**The Devil is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation**](https://doi.org/10.48550/arXiv.2308.07286) Ôºà**2023.08.14**Ôºâ

<font color="gray">Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr√© F. T. Martins, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Accelerating LLM Inference with Staged Speculative Decoding**](https://doi.org/10.48550/arXiv.2308.04623) Ôºà**2023.08.08**Ôºâ

<font color="gray">Benjamin Spector, Christal Re .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Shepherd: A Critic for Language Model Generation**](https://doi.org/10.48550/arXiv.2308.04592) Ôºà**2023.08.08**Ôºâ

<font color="gray">Tianlu Wang, Ping Yu, Xiaoqing Tan, Sean O'Brien, Ramakanth Pasunuru, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-160-blue)](https://github.com/facebookresearch/shepherd)

---

[**AgentBench: Evaluating LLMs as Agents**](https://doi.org/10.48550/arXiv.2308.03688) Ôºà**2023.08.07**Ôºâ

<font color="gray">Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-972-blue)](https://github.com/thudm/agentbench)

---

[**Scaling Relationship on Learning Mathematical Reasoning with Large Language Models**](https://doi.org/10.48550/arXiv.2308.01825) Ôºà**2023.08.03**Ôºâ

<font color="gray">Zheng Yuan, Hongyi Yuan, Cheng Li, Guanting Dong, Chuanqi Tan, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-11-green)  [![](https://img.shields.io/badge/Github%20Stars-96-blue)](https://github.com/ofa-sys/gsm8k-screl)

---

[**Advancing Beyond Identification: Multi-bit Watermark for Language Models**](https://doi.org/10.48550/arXiv.2308.00221) Ôºà**2023.08.01**Ôºâ

<font color="gray">Kiyoon Yoo, W. Ahn, N. Kwak .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?**](https://doi.org/10.48550/arXiv.2307.16368) Ôºà**2023.07.31**Ôºâ

<font color="gray">Qipeng Zhao, Ce Zhang, Shijie Wang, Changcheng Fu, Nakul Agarwal, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**A Private Watermark for Large Language Models**](https://doi.org/10.48550/arXiv.2307.16230) Ôºà**2023.07.30**Ôºâ

<font color="gray">Aiwei Liu, Leyi Pan, Xuming Hu, Shuang Li, Lijie Wen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/THU-BPM/private_watermark)

---

[**Robust Distortion-free Watermarks for Language Models**](https://doi.org/10.48550/arXiv.2307.15593) Ôºà**2023.07.28**Ôºâ

<font color="gray">Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, Percy Liang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/jthickstun/watermark)

---

[**Publisher Correction: Large language models encode clinical knowledge.**](https://doi.org/10.1038/s41586-023-06455-0) Ôºà**2023.07.27**Ôºâ

<font color="gray">K. Singhal, Shekoofeh Azizi, Tao Tu, S. S. Mahdavi, Jason Wei, etc .  - „ÄêNature„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Med-Flamingo: a Multimodal Medical Few-shot Learner**](https://doi.org/10.48550/arXiv.2307.15189) Ôºà**2023.07.27**Ôºâ

<font color="gray">Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, C. Zakka, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-253-blue)](https://github.com/snap-stanford/med-flamingo)

---

[**Med-Flamingo: a Multimodal Medical Few-shot Learner**](https://doi.org/10.48550/arXiv.2307.15189) Ôºà**2023.07.27**Ôºâ

<font color="gray">Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, C. Zakka, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-253-blue)](https://github.com/snap-stanford/med-flamingo)

---

[**ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning**](https://doi.org/10.48550/arXiv.2307.09474) Ôºà**2023.07.18**Ôºâ

<font color="gray">Liang Zhao, En Yu, Zheng Ge, Jinrong Yang, Hao-Ran Wei, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT**](https://doi.org/10.48550/arXiv.2307.08674) Ôºà**2023.07.17**Ôºâ

<font color="gray">Liangyu Zha, Junlin Zhou, Liyao Li, Rui Wang, Qingyi Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)

---

[**Self-consistency for open-ended generations**](https://doi.org/10.48550/arXiv.2307.06857) Ôºà**2023.07.11**Ôºâ

<font color="gray">Siddhartha Jain, Xiaofei Ma, Anoop Deoras, Bing Xiang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens**](https://doi.org/10.48550/arXiv.2307.02486) Ôºà**2023.07.05**Ôºâ

<font color="gray">Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-15.2k-blue)](https://github.com/microsoft/unilm)

---

[**Mitigating the Learning Bias towards Repetition by Self-Contrastive Training for Open-Ended Generation**](https://doi.org/10.48550/arXiv.2307.01542) Ôºà**2023.07.04**Ôºâ

<font color="gray">Jian Guan, Minlie Huang .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/thu-coai/selfcont)

---

[**Conformer LLMs - Convolution Augmented Large Language Models**](https://doi.org/10.48550/arXiv.2307.00461) Ôºà**2023.07.02**Ôºâ

<font color="gray">Prateek Verma .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Inferring the Goals of Communicating Agents from Actions and Instructions**](https://doi.org/10.48550/arXiv.2306.16207) Ôºà**2023.06.28**Ôºâ

<font color="gray">Lance Ying, Tan Zhi-Xuan, Vikash K. Mansinghka, J. Tenenbaum .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Kosmos-2: Grounding Multimodal Large Language Models to the World**](https://doi.org/10.48550/arXiv.2306.14824) Ôºà**2023.06.26**Ôºâ

<font color="gray">Zhiliang Peng, Wenhui Wang, Li Dong, Y. Hao, Shaohan Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-15.2k-blue)](https://github.com/microsoft/unilm/tree/master/kosmos-2)

---

[**AudioPaLM: A Large Language Model That Can Speak and Listen**](https://doi.org/10.48550/arXiv.2306.12925) Ôºà**2023.06.22**Ôºâ

<font color="gray">Paul K. Rubenstein, Chulayuth Asawaroengchai, D. Nguyen, Ankur Bapna, Zal√°n Borsos, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards AGI in Computer Vision: Lessons Learned from GPT and Large Language Models**](https://doi.org/10.48550/arXiv.2306.08641) Ôºà**2023.06.14**Ôºâ

<font color="gray">Lingxi Xie, Longhui Wei, Xiaopeng Zhang, Kaifeng Bi, Xiaotao Gu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models**](https://doi.org/10.48550/arXiv.2306.07971) Ôºà**2023.06.13**Ôºâ

<font color="gray">Omkar Thawakar, Abdelrahman M. Shaker, Sahal Shaji Mullappilly, Hisham Cholakkal, R. Anwer, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-232-blue)](https://github.com/mbzuai-oryx/xraygpt)

---

[**Judging LLM-as-a-judge with MT-Bench and Chatbot Arena**](https://doi.org/10.48550/arXiv.2306.05685) Ôºà**2023.06.09**Ôºâ

<font color="gray">Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-102-green)  [![](https://img.shields.io/badge/Github%20Stars-27.2k-blue)](https://github.com/lm-sys/fastchat)

---

[**Judging LLM-as-a-judge with MT-Bench and Chatbot Arena**](https://doi.org/10.48550/arXiv.2306.05685) Ôºà**2023.06.09**Ôºâ

<font color="gray">Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-267-green)

---

[**PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance**](https://doi.org/10.48550/arXiv.2306.05443) Ôºà**2023.06.08**Ôºâ

<font color="gray">Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-123-blue)](https://github.com/chancefocus/pixiu)

---

[**ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory**](https://doi.org/10.48550/arXiv.2306.03901) Ôºà**2023.06.06**Ôºâ

<font color="gray">Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, J. Zhao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only**](https://doi.org/10.48550/arXiv.2306.01116) Ôºà**2023.06.01**Ôºâ

<font color="gray">Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra-Aim√©e Cojocaru, Alessandro Cappelli, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-50-green)

---

[**Baselines for Identifying Watermarked Large Language Models**](https://doi.org/10.48550/arXiv.2305.18456) Ôºà**2023.05.29**Ôºâ

<font color="gray">Leonard Tang, Gavin Uberti, Tom Shlomi .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Undetectable Watermarks for Language Models**](https://doi.org/10.48550/arXiv.2306.09194) Ôºà**2023.05.25**Ôºâ

<font color="gray">Miranda Christ, S. Gunn, Or Zamir .  - „ÄêIACR Cryptology ePrint Archive„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective**](https://arxiv.org/abs/2305.15408) Ôºà**2023.05.24**Ôºâ

<font color="gray">Guhao Feng, Yuntian Gu, Bohang Zhang, Haotian Ye, Di He, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-26-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/guyuntian/CoT_benchmark)

---

[**Peek Across: Improving Multi-Document Modeling via Cross-Document Question-Answering**](https://arxiv.org/abs/2305.15387) Ôºà**2023.05.24**Ôºâ

<font color="gray">Avi Caciularu, Matthew E. Peters, Jacob Goldberger, Ido Dagan, Arman Cohan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/aviclu/peekacross)

---

[**Context-Aware Transformer Pre-Training for Answer Sentence Selection**](https://arxiv.org/abs/2305.15358) Ôºà**2023.05.24**Ôºâ

<font color="gray">Luca Di Liello, Siddhant Garg, Alessandro Moschitti </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**Gorilla: Large Language Model Connected with Massive APIs**](https://arxiv.org/abs/2305.15334) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shishir G. Patil, Tianjun Zhang, Xin Wang, Joseph E. Gonzalez </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-124-red)  [![](https://img.shields.io/badge/Github%20Stars-8.1k-blue)](https://github.com/ShishirPatil/gorilla)

---

[**Visual Programming for Text-to-Image Generation and Evaluation**](https://arxiv.org/abs/2305.15328) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jaemin Cho, Abhay Zala, Mohit Bansal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-15-red)

---

[**Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model**](https://arxiv.org/abs/2305.15265) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zirui Liu, Guanchu Wang, Shaochen Zhong, Zhaozhuo Xu, Daochen Zha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LMs with a Voice: Spoken Language Modeling beyond Speech Tokens**](https://arxiv.org/abs/2305.15255) Ôºà**2023.05.24**Ôºâ

<font color="gray">Eliya Nachmani, Alon Levkovitch, Julian Salazar, Chulayutsh Asawaroengchai, Soroosh Mariooryad, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)

---

[**Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator**](https://arxiv.org/abs/2305.15099) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ziwei He, Meng Yang, Minwei Feng, Jingcheng Yin, Xinbing Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/lumia-group/fouriertransformer)

---

[**CSTS: Conditional Semantic Textual Similarity**](https://arxiv.org/abs/2305.15093) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ameet Deshpande, Carlos E. Jimenez, Howard Chen, Vishvak S. Murahari, Victoria Graf, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-23-blue)](https://github.com/princeton-nlp/c-sts)

---

[**STAR: Boosting Low-Resource Event Extraction by Structure-to-Text Data Generation with Large Language Models**](https://arxiv.org/abs/2305.15090) Ôºà**2023.05.24**Ôºâ

<font color="gray">Mingyu Derek Ma, Xiaoxuan Wang, Po-Nien Kung, P. Jeffrey Brantingham, Nanyun Peng, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)

---

[**Contrastive Learning of Sentence Embeddings from Scratch**](https://arxiv.org/abs/2305.15077) Ôºà**2023.05.24**Ôºâ

<font color="gray">Junlei Zhang, Zhenzhong Lan, Junxian He </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-15-blue)](https://github.com/sjtu-lit/syncse)

---

[**Meta-Learning Online Adaptation of Language Models**](https://arxiv.org/abs/2305.15076) Ôºà**2023.05.24**Ôºâ

<font color="gray">Nathan J. Hu, Eric Mitchell, Christopher D. Manning, Chelsea Finn </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Who Wrote this Code? Watermarking for Code Generation**](https://arxiv.org/abs/2305.15060) Ôºà**2023.05.24**Ôºâ

<font color="gray">Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering**](https://arxiv.org/abs/2305.15056) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiajie Zhang, Shulin Cao, Tingjia Zhang, Xin Lv, Jiaxin Shi, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)

---

[**Understanding Arithmetic Reasoning in Language Models using Causal Mediation Analysis**](https://arxiv.org/abs/2305.15054) Ôºà**2023.05.24**Ôºâ

<font color="gray">Alessandro Stolfo, Yonatan Belinkov, Mrinmaya Sachan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Active Learning for Natural Language Generation**](https://arxiv.org/abs/2305.15040) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yotam Perlitz, Ariel Gera, Michal Shmueli-Scheuer, Dafna Sheinwald, Noam Slonim, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**SmartTrim: Adaptive Tokens and Parameters Pruning for Efficient Vision-Language Models**](https://arxiv.org/abs/2305.15033) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zekun Wang, Jingchang Chen, Wangchunshu Zhou, Ming Liu, Bing Qin </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**How to Distill your BERT: An Empirical Study on the Impact of Weight Initialisation and Distillation Objectives**](https://arxiv.org/abs/2305.15032) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xinpeng Wang, Leonie Weissweiler, Hinrich Schutze, Barbara Plank </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/mainlp/how-to-distill-your-bert)

---

[**ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification**](https://arxiv.org/abs/2305.15024) Ôºà**2023.05.24**Ôºâ

<font color="gray">Biao Zhao, Weiqiang Jin, Javier Del Ser, Guang Yang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-15-red)  [![](https://img.shields.io/badge/Github%20Stars-27-blue)](https://github.com/albert-jin/agricultural_textual_classification_chatgpt)

---

[**Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models**](https://arxiv.org/abs/2305.15023) Ôºà**2023.05.24**Ôºâ

<font color="gray">Gen Luo, Yiyi Zhou, Tianhe Ren, Shengxin Chen, Xiaoshuai Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-37-red)  [![](https://img.shields.io/badge/Github%20Stars-328-blue)](https://github.com/luogen1996/lavin)

---

[**Unlocking Temporal Question Answering for Large Language Models Using Code Execution**](https://arxiv.org/abs/2305.15014) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xingxuan Li, Liying Cheng, Qingyu Tan, Hwee Tou Ng, Shafiq Joty, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/damo-nlp-sg/mvcr)

---

[**Bactrian-X : A Multilingual Replicable Instruction-Following Model with Low-Rank Adaptation**](https://arxiv.org/abs/2305.15011) Ôºà**2023.05.24**Ôºâ

<font color="gray">Haonan Li, Fajri Koto, Minghao Wu, Alham Fikri Aji, Timothy Baldwin </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)  [![](https://img.shields.io/badge/Github%20Stars-70-blue)](https://github.com/mbzuai-nlp/bactrian-x)

---

[**Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism and Synonymous Substitution**](https://arxiv.org/abs/2305.15010) Ôºà**2023.05.24**Ôºâ

<font color="gray">Hongbo Zhang, Xiang Wan, Benyou Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/stevenzhb/bioplm_injectingknowledge)

---

[**LLMDet: A Large Language Models Detection Tool**](https://arxiv.org/abs/2305.15004) Ôºà**2023.05.24**Ôºâ

<font color="gray">Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng, Tat-Seng Chua </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/trustedllm/llmdet)

---

[**The Art of SOCRATIC QUESTIONING: Zero-shot Multimodal Reasoning with Recursive Thinking and Self-Questioning**](https://arxiv.org/abs/2305.14999) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu, Di Jin, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Reasoning with Language Model is Planning with World Model**](https://arxiv.org/abs/2305.14992) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-51-red)  [![](https://img.shields.io/badge/Github%20Stars-51-blue)](https://github.com/Ber666/RAP)

---

[**Large Language Models are Effective Table-to-Text Generators, Evaluators, and Feedback Providers**](https://arxiv.org/abs/2305.14987) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/yilunzhao/llm-t2t)

---

[**Improving Factuality of Abstractive Summarization without Sacrificing Summary Quality**](https://arxiv.org/abs/2305.14981) Ôºà**2023.05.24**Ôºâ

<font color="gray">Tanay Dixit, Fei Wang, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/tanay2001/efactsum)

---

[**OverPrompt: Enhancing ChatGPT Capabilities through an Efficient In-Context Learning Approach**](https://arxiv.org/abs/2305.14973) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiazheng Li, Runcong Zhao, Yulan He, Lin Gui </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**MMNet: Multi-Mask Network for Referring Image Segmentation**](https://arxiv.org/abs/2305.14969) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yichen Yan, Xingjian He, Wenxuan Wan, Jing Liu </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks**](https://arxiv.org/abs/2305.14965) Ôºà**2023.05.24**Ôºâ

<font color="gray">Abhinav Rao, Sachin Vashistha, Atharva Naik, Somak Aditya, Monojit Choudhury </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Editing Commonsense Knowledge in GPT**](https://arxiv.org/abs/2305.14956) Ôºà**2023.05.24**Ôºâ

<font color="gray">Anshita Gupta, Debanjan Mondal, Akshay Krishna Sheshadri, Wenlong Zhao, Xiang Lorraine Li, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low Resource Languages**](https://arxiv.org/abs/2305.14949) Ôºà**2023.05.24**Ôºâ

<font color="gray">Qi Gou, Zehua Xia, Wen-Hau Du </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Trade-Offs Between Fairness and Privacy in Language Modeling**](https://arxiv.org/abs/2305.14936) Ôºà**2023.05.24**Ôºâ

<font color="gray">Cleo Matzken, Steffen Eger, Ivan Habernal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Frugal Prompting for Dialog Models**](https://arxiv.org/abs/2305.14919) Ôºà**2023.05.24**Ôºâ

<font color="gray">Bishal Santra, Sakya Basak, Abhinandan De, Manish Gupta, Pawan Goyal </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**In-Context Demonstration Selection with Cross Entropy Difference**](https://arxiv.org/abs/2305.14726) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**A Causal View of Entity Bias in (Large) Language Models**](https://arxiv.org/abs/2305.14695) Ôºà**2023.05.24**Ôºâ

<font color="gray">Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models**](https://arxiv.org/abs/2305.14323) Ôºà**2023.05.23**Ôºâ

<font color="gray">Z. Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne Xin Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/rucaibox/chatcot)

---

[**Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning**](https://arxiv.org/abs/2305.12295) Ôºà**2023.05.20**Ôºâ

<font color="gray">Liangming Pan, Alon Albalak, Xinyi Wang, William Yang Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-22-red)  [![](https://img.shields.io/badge/Github%20Stars-68-blue)](https://github.com/teacherpeterpan/logic-llm)

---

[**LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4**](https://arxiv.org/abs/2305.12147) Ôºà**2023.05.20**Ôºâ

<font color="gray">Hanmeng Liu, Zhiyang Teng, Leyang Cui, Chaoli Zhang, Qiji Zhou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-33-blue)](https://github.com/csitfun/logicot)

---

[**SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs**](https://doi.org/10.48550/arXiv.2305.11461) Ôºà**2023.05.19**Ôºâ

<font color="gray">IokTong Lei, ZhiDong Deng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought**](https://doi.org/10.48550/arXiv.2305.11499) Ôºà**2023.05.19**Ôºâ

<font color="gray">Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning**](https://doi.org/10.48550/arXiv.2305.11383) Ôºà**2023.05.19**Ôºâ

<font color="gray">Po-Nien Kung, Nanyun Peng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**AutoTrial: Prompting Language Models for Clinical Trial Design**](https://doi.org/10.48550/arXiv.2305.11366) Ôºà**2023.05.19**Ôºâ

<font color="gray">Zifeng Wang, Cao Xiao, Jimeng Sun .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Efficient Prompting via Dynamic In-Context Learning**](https://doi.org/10.48550/arXiv.2305.11170) Ôºà**2023.05.18**Ôºâ

<font color="gray">Wangchunshu Zhou, Yuchen Jiang, Ryan Cotterell, Mrinmaya Sachan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Emergent and Predictable Memorization in Large Language Models**](https://arxiv.org/abs/2304.11158) Ôºà**2023.04.21**Ôºâ

<font color="gray">Stella Rose Biderman, Usvsn Sai Prashanth, Lintang Sutawika, Hailey Schoelkopf, Quentin G. Anthony, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-25-red)  [![](https://img.shields.io/badge/Github%20Stars-6.0k-blue)](https://github.com/eleutherai/gpt-neox)

---

[**SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks**](https://doi.org/10.48550/arXiv.2303.00733) Ôºà**2023.03.01**Ôºâ

<font color="gray">Kai-Wei Chang, Yu-Kai Wang, Hua Shen, Iu-thing Kang, W. Tseng, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis**](https://doi.org/10.48550/arXiv.2303.00815) Ôºà**2023.03.01**Ôºâ

<font color="gray">Jingli Shi, Weihua Li, Quan-wei Bai, Yi Yang, Jianhua Jiang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**EvoPrompting: Language Models for Code-Level Neural Architecture Search**](https://doi.org/10.48550/arXiv.2302.14838) Ôºà**2023.02.28**Ôºâ

<font color="gray">Angelica Chen, David Dohan, David R. So .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models**](https://doi.org/10.48550/arXiv.2302.12173) Ôºà**2023.02.23**Ôºâ

<font color="gray">Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, C. Endres, Thorsten Holz, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales**](https://doi.org/10.48550/arXiv.2302.08961) Ôºà**2023.02.17**Ôºâ

<font color="gray">M. Ruskov .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LabelPrompt: Effective Prompt-based Learning for Relation Classification**](https://doi.org/10.48550/arXiv.2302.08068) Ôºà**2023.02.16**Ôºâ

<font color="gray">W. Zhang, Xiaoning Song, Zhenhua Feng, Tianyang Xu, Xiaojun Wu .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition**](https://doi.org/10.48550/arXiv.2302.08102) Ôºà**2023.02.16**Ôºâ

<font color="gray">Minsu Kim, Hyungil Kim, Y. Ro .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Prompting for Multimodal Hateful Meme Classification**](https://doi.org/10.48550/arXiv.2302.04156) Ôºà**2023.02.08**Ôºâ

<font color="gray">Rui Cao, R. Lee, Wen-Haw Chong, Jing Jiang .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Toxicity Detection with Generative Prompt-based Inference**](https://doi.org/10.48550/arXiv.2205.12390) Ôºà**2022.05.24**Ôºâ

<font color="gray">Yau-Shian Wang, Y. Chang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**Learning to Transfer Prompts for Text Generation**](https://doi.org/10.48550/arXiv.2205.01543) Ôºà**2022.05.03**Ôºâ

<font color="gray">Junyi Li, Tianyi Tang, J. Nie, Ji-rong Wen, Wayne Xin Zhao .  - „ÄêNorth American Chapter of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-11-green)  [![](https://img.shields.io/badge/Github%20Stars-24-blue)](https://github.com/rucaibox/transfer-prompts-for-text-generation)

---

[**RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction**](https://doi.org/10.48550/arXiv.2203.09101) Ôºà**2022.03.17**Ôºâ

<font color="gray">Yew Ken Chia, Lidong Bing, Soujanya Poria, Luo Si .  - „ÄêFindings„Äë</font>

![](https://img.shields.io/badge/Citations-15-green)  [![](https://img.shields.io/badge/Github%20Stars-109-blue)](https://github.com/declare-lab/relationprompt)

---

[**QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition**](https://doi.org/10.48550/arXiv.2203.01543) Ôºà**2022.03.03**Ôºâ

<font color="gray">Andy T. Liu, Wei Xiao, Henghui Zhu, Dejiao Zhang, Shang-Wen Li, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-58-blue)](https://github.com/dayyass/QaNER)

---

[**PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts**](https://doi.org/10.18653/v1/2022.acl-demo.9) Ôºà**2022.02.02**Ôºâ

<font color="gray">Stephen H. Bach, Victor Sanh, Zheng Xin Yong, Albert Webson, Colin Raffel, etc .  - „ÄêAnnual Meeting of the Association for Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-54-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-108-red)  [![](https://img.shields.io/badge/Github%20Stars-2.1k-blue)](https://github.com/bigscience-workshop/promptsource)

---

[**Few-Shot Bot: Prompt-Based Learning for Dialogue Systems**](https://arxiv.org/abs/2110.08118) Ôºà**2021.10.15**Ôºâ

<font color="gray">Andrea Madotto, Zhaojiang Lin, Genta Indra Winata, Pascale Fung .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-24-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-69-red)  [![](https://img.shields.io/badge/Github%20Stars-708-blue)](https://github.com/tunib-ai/parallelformers)

---

[**SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based Sentiment Analysis**](https://arxiv.org/abs/2109.08306) Ôºà**2021.09.17**Ôºâ

<font color="gray">Chengxi Li, Feiyu Gao, Jiajun Bu, Lu Xu, Xiang Chen, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-20-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-61-red)

---

[**LightNER: A Lightweight Tuning Paradigm for Low-resource NER via Pluggable Prompting**](https://arxiv.org/abs/2109.00720) Ôºà**2021.08.31**Ôºâ

<font color="gray">Xiang Chen, Lei Li, Shumin Deng, Chuanqi Tan, Changliang Xu, etc .  - „ÄêInternational Conference on Computational Linguistics„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-30-red)

---

[**Program Synthesis with Large Language Models**](https://arxiv.org/abs/2108.07732) Ôºà**2021.08.16**Ôºâ

<font color="gray">Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, H. Michalewski, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-175-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-180-red)

---

[**Evaluating Large Language Models Trained on Code**](https://arxiv.org/abs/2107.03374) Ôºà**2021.07.07**Ôºâ

<font color="gray">Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-612-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-673-red)  [![](https://img.shields.io/badge/Github%20Stars-770-blue)](https://github.com/openai/human-eval)

---

[**KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction**](https://doi.org/10.1145/3485447.3511998) Ôºà**2021.04.15**Ôºâ

<font color="gray">Xiang Chen, Ningyu Zhang, Ningyu Zhang, Xin Xie, Shumin Deng, etc .  - „ÄêThe Web Conference„Äë</font>

![](https://img.shields.io/badge/Citations-86-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-179-red)  [![](https://img.shields.io/badge/Github%20Stars-164-blue)](https://github.com/zjunlp/KnowPrompt)

---

[**Language Models as Knowledge Bases?**](https://doi.org/10.18653/v1/D19-1250) Ôºà**2019.09.01**Ôºâ

<font color="gray">Fabio Petroni, Tim Rockt√§schel, Patrick Lewis, A. Bakhtin, Yuxiang Wu, etc .  - „ÄêConference on Empirical Methods in Natural Language Processing„Äë</font>

![](https://img.shields.io/badge/Citations-1038-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1.2k-red)  [![](https://img.shields.io/badge/Github%20Stars-1.1k-blue)](https://github.com/facebookresearch/LAMA)

---

[**AdaPrompt: Adaptive Prompt-based Finetuning for Relation Extraction**](https://api.semanticscholar.org/2404aecd866cfa15fee6ada095667980a63c4172) 

<font color="gray">Xiang Chen, Xin Xie, Ningyu Zhang, Jiahuan Yan, Shumin Deng, etc </font>

![](https://img.shields.io/badge/Citations-31-green)


</div>

# CONTINUE...