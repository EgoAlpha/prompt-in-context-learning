# üìÑ Survey

## Paper List

<div style="line-height:0.2em;">


[**Structural Ambiguity and its Disambiguation in Language Model Based Parsers: the Case of Dutch Clause Relativization**](https://arxiv.org/abs/2305.14917) Ôºà**2023.05.24**Ôºâ

<font color="gray">Gijs Wijnholds, Michael Moortgat </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Utility-Probability Duality of Neural Networks**](https://arxiv.org/abs/2305.14859) Ôºà**2023.05.24**Ôºâ

<font color="gray">Huang Bojun, Fei Yuan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Diffusion Models in NLP: A Survey**](https://arxiv.org/abs/2305.14671) Ôºà**2023.05.24**Ôºâ

<font color="gray">Hao Zou, Zae Myung Kim, Dongyeop Kang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language Models**](https://arxiv.org/abs/2305.14610) Ôºà**2023.05.24**Ôºâ

<font color="gray">Bryan Li, Chris Callison-Burch </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective**](https://arxiv.org/abs/2305.15408) Ôºà**2023.05.24**Ôºâ

<font color="gray">Guhao Feng, Yuntian Gu, Bohang Zhang, Haotian Ye, Di He, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Unit-based Speech-to-Speech Translation Without Parallel Data**](https://arxiv.org/abs/2305.15405) Ôºà**2023.05.24**Ôºâ

<font color="gray">Anuj Diwan, Anirudh Srinivasan, David F. Harwath, Eunsol Choi </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**A Neural Space-Time Representation for Text-to-Image Personalization**](https://arxiv.org/abs/2305.15391) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yuval Alaluf, Elad Richardson, Gal Metzer, Daniel Cohen-Or </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-11-blue)](https://github.com/NeuralTextualInversion/NeTI)

---

[**Breaking the Curse of Quality Saturation with User-Centric Ranking**](https://arxiv.org/abs/2305.15333) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zhuokai Zhao, Yang Yang, Wenyu Wang, Chihuang Liu, Yu Shi, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Visual Programming for Text-to-Image Generation and Evaluation**](https://arxiv.org/abs/2305.15328) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jaemin Cho, Abhay Zala, Mohit Bansal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Towards Foundation Models for Relational Databases [Vision Paper]**](https://arxiv.org/abs/2305.15321) Ôºà**2023.05.24**Ôºâ

<font color="gray">Liane Vogel, Benjamin Hilprecht, Carsten Binnig </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Training on Thin Air: Improve Image Classification with Generated Data**](https://arxiv.org/abs/2305.15316) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yongchao Zhou, Hshmat Sahak, Jimmy Ba </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/yongchao97/diffusion_inversion)

---

[**ViTMatte: Boosting Image Matting with Pretrained Plain Vision Transformers**](https://arxiv.org/abs/2305.15272) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jingfeng Yao, Xinggang Wang, Shusheng Yang, Baoyuan Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)  [![](https://img.shields.io/badge/Github%20Stars-13-blue)](https://github.com/hustvl/ViTMatte)

---

[**Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model**](https://arxiv.org/abs/2305.15265) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zirui Liu, Guanchu Wang, Shaochen Zhong, Zhaozhuo Xu, Daochen Zha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LMs with a Voice: Spoken Language Modeling beyond Speech Tokens**](https://arxiv.org/abs/2305.15255) Ôºà**2023.05.24**Ôºâ

<font color="gray">Eliya Nachmani, Alon Levkovitch, Julian Salazar, Chulayutsh Asawaroengchai, Soroosh Mariooryad, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Delving Deeper into Data Scaling in Masked Image Modeling**](https://arxiv.org/abs/2305.15248) Ôºà**2023.05.24**Ôºâ

<font color="gray">Cheng-Ze Lu, Xiaojie Jin, Qibin Hou, Jun Hao Liew, Ming-Ming Cheng, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Neural Summarization of Electronic Health Records**](https://arxiv.org/abs/2305.15222) Ôºà**2023.05.24**Ôºâ

<font color="gray">Koyena Pal, Seyed Ali Bahrainian, Laura Y. Mercurio, Carsten Eickhoff </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion Models**](https://arxiv.org/abs/2305.15194) Ôºà**2023.05.24**Ôºâ

<font color="gray">Sungnyun Kim, Junsoo Lee, Kibeom Hong, Daesik Kim, Namhyuk Ahn </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**Pre-training Multi-party Dialogue Models with Latent Discourse Inference**](https://arxiv.org/abs/2305.15175) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yiyang Li, Xinting Huang, Wei Bi, Hai Zhao </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Topic-Guided Self-Introduction Generation for Social Media Users**](https://arxiv.org/abs/2305.15138) Ôºà**2023.05.24**Ôºâ

<font color="gray">Chunpu Xu, Jing Li, Pijian Li, Min Yang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator**](https://arxiv.org/abs/2305.15099) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ziwei He, Meng Yang, Minwei Feng, Jingcheng Yin, Xinbing Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**CSTS: Conditional Semantic Textual Similarity**](https://arxiv.org/abs/2305.15093) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ameet Deshpande, Carlos E. Jimenez, Howard Chen, Vishvak S. Murahari, Victoria Graf, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**STAR: Boosting Low-Resource Event Extraction by Structure-to-Text Data Generation with Large Language Models**](https://arxiv.org/abs/2305.15090) Ôºà**2023.05.24**Ôºâ

<font color="gray">Mingyu Derek Ma, Xiaoxuan Wang, Po-Nien Kung, P. Jeffrey Brantingham, Nanyun Peng, etc </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Contrastive Learning of Sentence Embeddings from Scratch**](https://arxiv.org/abs/2305.15077) Ôºà**2023.05.24**Ôºâ

<font color="gray">Junlei Zhang, Zhenzhong Lan, Junxian He </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Meta-Learning Online Adaptation of Language Models**](https://arxiv.org/abs/2305.15076) Ôºà**2023.05.24**Ôºâ

<font color="gray">Nathan J. Hu, Eric Mitchell, Christopher D. Manning, Chelsea Finn </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Who Wrote this Code? Watermarking for Code Generation**](https://arxiv.org/abs/2305.15060) Ôºà**2023.05.24**Ôºâ

<font color="gray">Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning**](https://arxiv.org/abs/2305.15065) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ximing Lu, Faeze Brahman, Peter West, Jaehun Jang, Khyathi Chandu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering**](https://arxiv.org/abs/2305.15056) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiajie Zhang, Shulin Cao, Tingjia Zhang, Xin Lv, Jiaxin Shi, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Understanding Arithmetic Reasoning in Language Models using Causal Mediation Analysis**](https://arxiv.org/abs/2305.15054) Ôºà**2023.05.24**Ôºâ

<font color="gray">Alessandro Stolfo, Yonatan Belinkov, Mrinmaya Sachan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ranger: A Toolkit for Effect-Size Based Multi-Task Evaluation**](https://arxiv.org/abs/2305.15048) Ôºà**2023.05.24**Ôºâ

<font color="gray">Mete Sertkan, Sophia Althammer, Sebastian Hofstatter </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ghostbuster: Detecting Text Ghostwritten by Large Language Models**](https://arxiv.org/abs/2305.15047) Ôºà**2023.05.24**Ôºâ

<font color="gray">Vivek Verma, Eve Fleisig, Nicholas Tomlin, Dan Klein </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/vivek3141/ghostbuster)

---

[**Generating Faithful Synthetic Data with Large Language Models: A Case Study in Computational Social Science**](https://arxiv.org/abs/2305.15041) Ôºà**2023.05.24**Ôºâ

<font color="gray">Veniamin Veselovsky, Manoel Horta Ribeiro, Akhil Arora, Martin Josifoski, Ashton Anderson, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Active Learning for Natural Language Generation**](https://arxiv.org/abs/2305.15040) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yotam Perlitz, Ariel Gera, Michal Shmueli-Scheuer, Dafna Sheinwald, Noam Slonim, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SmartTrim: Adaptive Tokens and Parameters Pruning for Efficient Vision-Language Models**](https://arxiv.org/abs/2305.15033) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zekun Wang, Jingchang Chen, Wangchunshu Zhou, Ming Liu, Bing Qin </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**How to Distill your BERT: An Empirical Study on the Impact of Weight Initialisation and Distillation Objectives**](https://arxiv.org/abs/2305.15032) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xinpeng Wang, Leonie Weissweiler, Hinrich Schutze, Barbara Plank </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/mainlp/how-to-distill-your-bert)

---

[**Dior-CVAE: Diffusion Priors in Variational Dialog Generation**](https://arxiv.org/abs/2305.15025) Ôºà**2023.05.24**Ôºâ

<font color="gray">Tianyu Yang, Thy Thy Tran, Iryna Gurevych </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification**](https://arxiv.org/abs/2305.15024) Ôºà**2023.05.24**Ôºâ

<font color="gray">Biao Zhao, Weiqiang Jin, Javier Del Ser, Guang Yang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models**](https://arxiv.org/abs/2305.15023) Ôºà**2023.05.24**Ôºâ

<font color="gray">Gen Luo, Yiyi Zhou, Tianhe Ren, Shengxin Chen, Xiaoshuai Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Unlocking Temporal Question Answering for Large Language Models Using Code Execution**](https://arxiv.org/abs/2305.15014) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xingxuan Li, Liying Cheng, Qingyu Tan, Hwee Tou Ng, Shafiq Joty, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/damo-nlp-sg/mvcr)

---

[**Bactrian-X : A Multilingual Replicable Instruction-Following Model with Low-Rank Adaptation**](https://arxiv.org/abs/2305.15011) Ôºà**2023.05.24**Ôºâ

<font color="gray">Haonan Li, Fajri Koto, Minghao Wu, Alham Fikri Aji, Timothy Baldwin </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-50-blue)](https://github.com/mbzuai-nlp/bactrian-x)

---

[**Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism and Synonymous Substitution**](https://arxiv.org/abs/2305.15010) Ôºà**2023.05.24**Ôºâ

<font color="gray">Hongbo Zhang, Xiang Wan, Benyou Wang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The Art of SOCRATIC QUESTIONING: Zero-shot Multimodal Reasoning with Recursive Thinking and Self-Questioning**](https://arxiv.org/abs/2305.14999) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu, Di Jin, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Reasoning with Language Model is Planning with World Model**](https://arxiv.org/abs/2305.14992) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)

---

[**MuLER: Detailed and Scalable Reference-based Evaluation**](https://arxiv.org/abs/2305.14991) Ôºà**2023.05.24**Ôºâ

<font color="gray">Taelin Karidi, Leshem Choshen, Gal Patel, Omri Abend </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Models are Effective Table-to-Text Generators, Evaluators, and Feedback Providers**](https://arxiv.org/abs/2305.14987) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/yilunzhao/llm-t2t)

---

[**Improving Factuality of Abstractive Summarization without Sacrificing Summary Quality**](https://arxiv.org/abs/2305.14981) Ôºà**2023.05.24**Ôºâ

<font color="gray">Tanay Dixit, Fei Wang, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MMNet: Multi-Mask Network for Referring Image Segmentation**](https://arxiv.org/abs/2305.14969) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yichen Yan, Xingjian He, Wenxuan Wan, Jing Liu </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks**](https://arxiv.org/abs/2305.14965) Ôºà**2023.05.24**Ôºâ

<font color="gray">Abhinav Rao, Sachin Vashistha, Atharva Naik, Somak Aditya, Monojit Choudhury </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Editing Commonsense Knowledge in GPT**](https://arxiv.org/abs/2305.14956) Ôºà**2023.05.24**Ôºâ

<font color="gray">Anshita Gupta, Debanjan Mondal, Akshay Krishna Sheshadri, Wenlong Zhao, Xiang Lorraine Li, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low Resource Languages**](https://arxiv.org/abs/2305.14949) Ôºà**2023.05.24**Ôºâ

<font color="gray">Qi Gou, Zehua Xia, Wen-Hau Du </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Trade-Offs Between Fairness and Privacy in Language Modeling**](https://arxiv.org/abs/2305.14936) Ôºà**2023.05.24**Ôºâ

<font color="gray">Cleo Matzken, Steffen Eger, Ivan Habernal </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning**](https://arxiv.org/abs/2305.14909) Ôºà**2023.05.24**Ôºâ

<font color="gray">L. Guan, Karthik Valmeekam, Sarath Sreedharan, Subbarao Kambhampati </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection**](https://arxiv.org/abs/2305.14902) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**PIVOINE: Instruction Tuning for Open-world Information Extraction**](https://arxiv.org/abs/2305.14898) Ôºà**2023.05.24**Ôºâ

<font color="gray">Keming Lu, Xiaoman Pan, Kaiqiang Song, Hongming Zhang, Dong Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/lukeming-tsinghua/instruction-tuning-for-open-world-ie)

---

[**Text encoders are performance bottlenecks in contrastive vision-language models**](https://arxiv.org/abs/2305.14897) Ôºà**2023.05.24**Ôºâ

<font color="gray">Amita Kamath, Jack Hessel, Kai-Wei Chang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**HARD: Hard Augmentations for Robust Distillation**](https://arxiv.org/abs/2305.14890) Ôºà**2023.05.24**Ôºâ

<font color="gray">Arne F. Nix, Max F. Burg, Fabian H Sinz </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Privacy Implications of Retrieval-Based Language Models**](https://arxiv.org/abs/2305.14888) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yangsibo Huang, Samyak Gupta, Zexuan Zhong, Kai Li, Danqi Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/princeton-sysml/knnlm_privacy)

---

[**Interpretable by Design Visual Question Answering**](https://arxiv.org/abs/2305.14882) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xingyu Fu, Ben Zhou, Sihao Chen, Mark Yatskar, D. Roth </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Leveraging GPT-4 for Automatic Translation Post-Editing**](https://arxiv.org/abs/2305.14878) Ôºà**2023.05.24**Ôºâ

<font color="gray">Vikas Raunak, Amr Sharaf, Hany Hassan Awadallah, Arul Menezes </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering**](https://arxiv.org/abs/2305.14869) Ôºà**2023.05.24**Ôºâ

<font color="gray">Weiqi Wang, Tianqing Fang, Wenxuan Ding, Baixuan Xu, Xin Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/hkust-knowcomp/car)

---

[**Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers**](https://arxiv.org/abs/2305.14858) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zixuan Jiang, Jiaqi Gu, Hanqing Zhu, D. Pan </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/zixuanjiang/pre-rmsnorm-transformer)

---

[**Towards Few-shot Entity Recognition in Document Images: A Graph Neural Network Approach Robust to Image Manipulation**](https://arxiv.org/abs/2305.14828) Ôºà**2023.05.24**Ôºâ

<font color="gray">Prashant Krishnan, Zilong Wang, Yangkun Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Machine Reading Comprehension using Case-based Reasoning**](https://arxiv.org/abs/2305.14815) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dung Thai, Dhruv Agarwal, Mudit Chaudhary, R. Das, M. Zaheer, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification**](https://arxiv.org/abs/2305.14794) Ôºà**2023.05.24**Ôºâ

<font color="gray">Chengyu Dong, Zihan Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Text Conditional Alt-Text Generation for Twitter Images**](https://arxiv.org/abs/2305.14779) Ôºà**2023.05.24**Ôºâ

<font color="gray">Nikita Srivatsan, Sofia Samaniego, Omar Florez, Taylor Berg-Kirkpatrick </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**A Controllable QA-based Framework for Decontextualization**](https://arxiv.org/abs/2305.14772) Ôºà**2023.05.24**Ôºâ

<font color="gray">Benjamin Newman, Luca Soldaini, Raymond Fok, Arman Cohan, Kyle Lo </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SSD-2: Scaling and Inference-time Fusion of Diffusion Language Models**](https://arxiv.org/abs/2305.14771) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov, Marjan Ghazvininejad </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning**](https://arxiv.org/abs/2305.14761) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, Shafiq Joty </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ChatFace: Chat-Guided Real Face Editing via Diffusion Latent Space Manipulation**](https://arxiv.org/abs/2305.14742) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dongxu Yue, Qin Guo, Munan Ning, Jiaxi Cui, Yuesheng Zhu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**Trusting Your Evidence: Hallucinate Less with Context-aware Decoding**](https://arxiv.org/abs/2305.14739) Ôºà**2023.05.24**Ôºâ

<font color="gray">Weijia Shi, Xiaochuang Han, M. Lewis, Yulia Tsvetkov, Luke Zettlemoyer, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**GlobalBench: A Benchmark for Global Progress in Natural Language Processing**](https://arxiv.org/abs/2305.14716) Ôºà**2023.05.24**Ôºâ

<font color="gray">Y. Song, Catherine Cui, Simran Khanuja, Pengfei Liu, FAHIM FAISAL, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The student becomes the master: Matching GPT3 on Scientific Factual Error Correction**](https://arxiv.org/abs/2305.14707) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dhananjay Ashok, Atharva Kulkarni, Hai Pham, Barnab'as P'oczos </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**PruMUX: Augmenting Data Multiplexing with Model Compression**](https://arxiv.org/abs/2305.14706) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yushan Su, Vishvak S. Murahari, Karthik Narasimhan, Kai Li </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Flan-MoE: Scaling Instruction-Finetuned Language Models with Sparse Mixture of Experts**](https://arxiv.org/abs/2305.14705) Ôºà**2023.05.24**Ôºâ

<font color="gray">Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to Rank**](https://arxiv.org/abs/2305.14696) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dheeraj Mekala, Adithya Samavedhi, Chengyu Dong, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval**](https://arxiv.org/abs/2305.14685) Ôºà**2023.05.24**Ôºâ

<font color="gray">S. Yu, Chenghao Fan, Chenyan Xiong, David Jin, Zhiyuan Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Emergent inabilities? Inverse scaling over the course of pretraining**](https://arxiv.org/abs/2305.14681) Ôºà**2023.05.24**Ôºâ

<font color="gray">James A. Michaelov, B. Bergen </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Optimal Linear Subspace Search: Learning to Construct Fast and High-Quality Schedulers for Diffusion Models**](https://arxiv.org/abs/2305.14677) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zhongjie Duan, Chengyu Wang, Cen Chen, Jun Huang, Weining Qian </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**InteractiveIE: Towards Assessing the Strength of Human-AI Collaboration in Improving the Performance of Information Extraction**](https://arxiv.org/abs/2305.14659) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ishani Mondal, Michelle Yuan, N Anandhavelu, Aparna Garimella, Francis Ferraro, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**A Joint Time-frequency Domain Transformer for Multivariate Time Series Forecasting**](https://arxiv.org/abs/2305.14649) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yushu Chen, Shengzhuo Liu, Jinzhe Yang, Hao Jing, Wenlai Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Meta-review Generation with Checklist-guided Iterative Introspection**](https://arxiv.org/abs/2305.14647) Ôºà**2023.05.24**Ôºâ

<font color="gray">Qi Zeng, Mankeerat S. Sidhu, Hou Pong Chan, Lu Wang, Heng Ji </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Reinforcement Learning finetuned Vision-Code Transformer for UI-to-Code Generation**](https://arxiv.org/abs/2305.14637) Ôºà**2023.05.24**Ôºâ

<font color="gray">Davit Soselia, Khalid Saifullah, Tianyi Zhou </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**KNN-LM Does Not Improve Open-ended Text Generation**](https://arxiv.org/abs/2305.14625) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shufan Wang, Yixiao Song, Andrew Drozdov, Aparna Garimella, Varun Manjunatha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**COMET-M: Reasoning about Multiple Events in Complex Sentences**](https://arxiv.org/abs/2305.14617) Ôºà**2023.05.24**Ôºâ

<font color="gray">Sahithya Ravi, Raymond Ng, Vered Shwartz </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations**](https://arxiv.org/abs/2305.14599) Ôºà**2023.05.24**Ôºâ

<font color="gray">James Y. Huang, Wenlin Yao, Kaiqiang Song, Hongming Zhang, Muhao Chen, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers**](https://arxiv.org/abs/2305.14591) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ke Zhang, Danqing Wang, Jingtao Xia, William Yang Wang, Lei Li </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**RE$^2$: Region-Aware Relation Extraction from Visually Rich Documents**](https://arxiv.org/abs/2305.14590) Ôºà**2023.05.24**Ôºâ

<font color="gray">Pritika Ramu, Sijia Wang, Lalla Mouatadid, Joy Rimchala, Lifu Huang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution**](https://arxiv.org/abs/2305.15357) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yiyang Ma, Huan Yang, Wenhan Yang, Jianlong Fu, Jiaying Liu </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**How to Solve Few-Shot Abusive Content Detection Using the Data We Actually Have**](https://arxiv.org/abs/2305.14081) Ôºà**2023.05.23**Ôºâ

<font color="gray">Viktor Hangya, Alexander Fraser </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Language Models with Rationality**](https://arxiv.org/abs/2305.14250) Ôºà**2023.05.23**Ôºâ

<font color="gray">Nora Kassner, Oyvind Tafjord, Ashish Sabharwal, Kyle Richardson, Hinrich Sch√ºtze, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**A Trip Towards Fairness: Bias and De-Biasing in Large Language Models**](https://arxiv.org/abs/2305.13862) Ôºà**2023.05.23**Ôºâ

<font color="gray">Leonardo Ranaldi, Elena Sofia Ruzzetti, Davide Venditti, Dario Onorati, Fabio Massimo Zanzotto </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Question Answering as Programming for Solving Time-Sensitive Questions**](https://arxiv.org/abs/2305.14221) Ôºà**2023.05.23**Ôºâ

<font color="gray">Xinyu Zhu, Cheng Yang, Bei Chen, Siheng Li, Jian-Guang Lou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-303-blue)](https://github.com/microsoft/ContextualSP)

---

[**Better Zero-Shot Reasoning with Self-Adaptive Prompting**](https://arxiv.org/abs/2305.14106) Ôºà**2023.05.23**Ôºâ

<font color="gray">Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan O. Arik, Tomas Pfister </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Improving Language Models via Plug-and-Play Retrieval Feedback**](https://arxiv.org/abs/2305.14002) Ôºà**2023.05.23**Ôºâ

<font color="gray">Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, Ashish Sabharwal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**PaD: Program-aided Distillation Specializes Large Models in Reasoning**](https://arxiv.org/abs/2305.13888) Ôºà**2023.05.23**Ôºâ

<font color="gray">Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xingwei Long, Bowen Zhou </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Aligning Large Language Models through Synthetic Feedback**](https://arxiv.org/abs/2305.13735) Ôºà**2023.05.23**Ôºâ

<font color="gray">Sungdong Kim, Sanghwan Bae, Jamin Shin, Soyoung Kang, Donghyun Kwak, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large Language Models**](https://arxiv.org/abs/2305.13718) Ôºà**2023.05.23**Ôºâ

<font color="gray">Fangkai Jiao, Zhiyang Teng, Shafiq Joty, Bosheng Ding, Aixin Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?**](https://arxiv.org/abs/2305.14578) Ôºà**2023.05.23**Ôºâ

<font color="gray">Margarita Bugueno, Gerard de Melo </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Parameter-Efficient Language Model Tuning with Active Learning in Low-Resource Settings**](https://arxiv.org/abs/2305.14576) Ôºà**2023.05.23**Ôºâ

<font color="gray">Josip Juki'c, Jan vSnajder </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**FOCUS: Effective Embedding Initialization for Specializing Pretrained Multilingual Models on a Single Language**](https://arxiv.org/abs/2305.14481) Ôºà**2023.05.23**Ôºâ

<font color="gray">Konstantin Dobler, Gerard de Melo </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/konstantinjdobler/focus)

---

[**Control of a simulated MRI scanner with deep reinforcement learning**](https://arxiv.org/abs/2305.13979) Ôºà**2023.05.23**Ôºâ

<font color="gray">Simon Walker-Samuel </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MemeCap: A Dataset for Captioning and Interpreting Memes**](https://arxiv.org/abs/2305.13703) Ôºà**2023.05.23**Ôºâ

<font color="gray">EunJeong Hwang, Vered Shwartz </font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/eujhwang/meme-cap)

---

[**Difference-Masking: Choosing What to Mask in Continued Pretraining**](https://arxiv.org/abs/2305.14577) Ôºà**2023.05.23**Ôºâ

<font color="gray">Alex Wilf, Syeda Nahida Akter, Leena Mathur, Paul Pu Liang, Sheryl Mathew, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**From Characters to Words: Hierarchical Pre-trained Language Model for Open-vocabulary Language Understanding**](https://arxiv.org/abs/2305.14571) Ôºà**2023.05.23**Ôºâ

<font color="gray">Li Sun, Florian Luisier, Kayhan Batmanghelich, Dinei Florencio, Cha Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Exploring Semantic Variations in GAN Latent Spaces via Matrix Factorization**](https://arxiv.org/abs/2305.14551) Ôºà**2023.05.23**Ôºâ

<font color="gray">Andrey Palaev, Rustam A. Lukmanov, Adil Hamid Khan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Extracting Shopping Interest-Related Product Types from the Web**](https://arxiv.org/abs/2305.14549) Ôºà**2023.05.23**Ôºâ

<font color="gray">Yinghao Li, Colin Lockard, Prashant Shiralkar, Chao Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Eliminating Spurious Correlations from Pre-trained Models via Data Mixing**](https://arxiv.org/abs/2305.14521) Ôºà**2023.05.23**Ôºâ

<font color="gray">Yihao Xue, Ali Payani, Yu Yang, Baharan Mirzasoleiman </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders**](https://arxiv.org/abs/2305.14499) Ôºà**2023.05.23**Ôºâ

<font color="gray">Livio Baldini Soares, Daniel Gillick, Jeremy R. Cole, Tom Kwiatkowski </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ConGraT: Self-Supervised Contrastive Pretraining for Joint Graph and Text Embeddings**](https://arxiv.org/abs/2305.14321) Ôºà**2023.05.23**Ôºâ

<font color="gray">William Brannon, Suyash Fulay, Hang Jiang, Wonjune Kang, Brandon Roy, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/wwbrannon/congrat)

---

[**Linear Cross-Lingual Mapping of Sentence Embeddings**](https://arxiv.org/abs/2305.14256) Ôºà**2023.05.23**Ôºâ

<font color="gray">Oleg V. Vasilyev, Fumika Isono, John Bohannon </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Multi-Granularity Prompts for Topic Shift Detection in Dialogue**](https://arxiv.org/abs/2305.14006) Ôºà**2023.05.23**Ôºâ

<font color="gray">Jiangyi Lin, Yaxin Fan, Xiaomin Chu, Peifeng Li, Qiaoming Zhu </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding**](https://arxiv.org/abs/2305.14232) Ôºà**2023.05.23**Ôºâ

<font color="gray">Yu Zhang, Hao Cheng, Zhihong Shen, Xiaodong Liu, Yejiang Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ManiTweet: A New Benchmark for Identifying Manipulation of News on Social Media**](https://arxiv.org/abs/2305.14225) Ôºà**2023.05.23**Ôºâ

<font color="gray">Kung-Hsiang Huang, Hou Pong Chan, Kathleen McKeown, Heng Ji </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Revealing User Familiarity Bias in Task-Oriented Dialogue via Interactive Evaluation**](https://arxiv.org/abs/2305.13857) Ôºà**2023.05.23**Ôºâ

<font color="gray">Takyoung Kim, Jamin Shin, Young-Ho Kim, Sanghwan Bae, Sungdong Kim </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Asking Clarification Questions for Information Seeking on Task-Oriented Dialogues**](https://arxiv.org/abs/2305.13690) Ôºà**2023.05.23**Ôºâ

<font color="gray">Yue Feng, Hossein A. Rahmani, Aldo Lipani, Emine Yilmaz </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Error Detection for Text-to-SQL Semantic Parsing**](https://arxiv.org/abs/2305.13683) Ôºà**2023.05.23**Ôºâ

<font color="gray">Shijie Chen, Zi-Yuan Chen, Huan Sun, Yu Su </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**UNIMO-3: Multi-granularity Interaction for Vision-Language Representation Learning**](https://arxiv.org/abs/2305.13697) Ôºà**2023.05.23**Ôºâ

<font color="gray">Hao Yang, Can Gao, Hao L'iu, Xinyan Xiao, Yanyan Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment**](https://arxiv.org/abs/2305.13669) Ôºà**2023.05.23**Ôºâ

<font color="gray">Shuo Zhang, Liangming Pan, Junzhou Zhao, William Yang Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models**](https://arxiv.org/abs/2305.13655) Ôºà**2023.05.23**Ôºâ

<font color="gray">Long Lian, Boyi Li, Adam Yala, Trevor Darrell </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**EDIS: Entity-Driven Image Search over Multimodal Web Content**](https://arxiv.org/abs/2305.13631) Ôºà**2023.05.23**Ôºâ

<font color="gray">Siqi Liu, Weixi Feng, Wenhu Chen, William Yang Wang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ViT-TTS: Visual Text-to-Speech with Scalable Diffusion Transformer**](https://doi.org/10.48550/arXiv.2305.12708) Ôºà**2023.05.22**Ôºâ

<font color="gray">Huadai Liu, Rongjie Huang, Xuan Lin, Wenqiang Xu, Maozong Zheng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules**](https://arxiv.org/abs/2305.13406) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yanchen Liu, William Held, Diyi Yang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Knowledge-Retrieval Task-Oriented Dialog Systems with Semi-Supervision**](https://arxiv.org/abs/2305.13199) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yucheng Cai, Hong Liu, Zhijian Ou, Y. Huang, Junlan Feng </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Sentence Representations via Gaussian Embedding**](https://arxiv.org/abs/2305.12990) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shohei Yoda, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MacLaSa: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space**](https://arxiv.org/abs/2305.12785) Ôºà**2023.05.22**Ôºâ

<font color="gray">Hanxing Ding, Liang Pang, Z. Wei, Huawei Shen, Xueqi Cheng, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Keeping Up with the Language Models: Robustness-Bias Interplay in NLI Data and Models**](https://arxiv.org/abs/2305.12620) Ôºà**2023.05.22**Ôºâ

<font color="gray">Ioana Baldini, Chhavi Yadav, Payel Das, K. Varshney </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Flover: A Temporal Fusion Framework for Efficient Autoregressive Model Parallel Inference**](https://arxiv.org/abs/2305.13484) Ôºà**2023.05.22**Ôºâ

<font color="gray">Jinghan Yao, Nawras Alnaasan, Tian Chen, A. Shafi, Hari Subramoni, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/yjhmitweb/flover)

---

[**To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis**](https://arxiv.org/abs/2305.13230) Ôºà**2023.05.22**Ôºâ

<font color="gray">Fuzhao Xue, Yao Fu, Wangchunshu Zhou, Zangwei Zheng, Yang You </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A Preliminary Study on Writing Assistance**](https://arxiv.org/abs/2305.13225) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yue Zhang, Leyang Cui, Deng Cai, Xinting Huang, Tao Fang, etc </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**InheritSumm: A General, Versatile and Compact Summarizer by Distilling from GPT**](https://arxiv.org/abs/2305.13083) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yichong Xu, Ruochen Xu, Dan Iter, Yang Liu, Shuo Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Making Language Models Better Tool Learners with Execution Feedback**](https://arxiv.org/abs/2305.13068) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shuofei Qiao, Honghao Gui, Huajun Chen, Ningyu Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**GPT-SW3: An Autoregressive Language Model for the Nordic Languages**](https://arxiv.org/abs/2305.12987) Ôºà**2023.05.22**Ôºâ

<font color="gray">Ariel Ekgren, Amaru Cuba Gyllensten, F. Stollenwerk, Joey Ohman, Tim Isbister, etc </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination**](https://arxiv.org/abs/2305.12945) Ôºà**2023.05.22**Ôºâ

<font color="gray">Dongfang Li, Jindi Yu, Baotian Hu, Zhenran Xu, Min Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/hitsz-tmg/explaincpe)

---

[**Design a Delicious Lunchbox in Style**](https://arxiv.org/abs/2305.14522) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yutong Zhou </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Interpreting Transformer's Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT**](https://arxiv.org/abs/2305.13417) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shahar Katz, Yonatan Belinkov </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/shacharkz/visualizing-the-information-flow-of-gpt)

---

[**Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation**](https://arxiv.org/abs/2305.14386) Ôºà**2023.05.22**Ôºâ

<font color="gray">Zhenwen Liang, Wenhao Yu, Tanmay Rajpurohit, Peter Clark, Xiangliang Zhang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Connecting Multi-modal Contrastive Representations**](https://arxiv.org/abs/2305.14381) Ôºà**2023.05.22**Ôºâ

<font color="gray">Zehan Wang, Yang Zhao, Xize Cheng, Haifeng Huang, Jiageng Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Finding the Pillars of Strength for Multi-Head Attention**](https://arxiv.org/abs/2305.14380) Ôºà**2023.05.22**Ôºâ

<font color="gray">Jinjie Ni, Rui Mao, Zonglin Yang, Han Lei, E. Cambria </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Improving Classifier Robustness through Active Generation of Pairwise Counterfactuals**](https://arxiv.org/abs/2305.13535) Ôºà**2023.05.22**Ôºâ

<font color="gray">Ananth Balashankar, Xuezhi Wang, Yao Qin, Ben Packer, Nithum Thain, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance**](https://arxiv.org/abs/2305.13395) Ôºà**2023.05.22**Ôºâ

<font color="gray">Karel D'Oosterlinck, Franccois Remy, Johannes Deleu, Thomas Demeester, Chris Develder, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/kareldo/biodex)

---

[**If at First You Don't Succeed, Try, Try Again: Faithful Diffusion-based Text-to-Image Generation by Selection**](https://arxiv.org/abs/2305.13308) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shyamgopal Karthik, Karsten Roth, Massimiliano Mancini, Zeynep Akata </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Training Diffusion Models with Reinforcement Learning**](https://arxiv.org/abs/2305.13301) Ôºà**2023.05.22**Ôºâ

<font color="gray">Kevin Black, Michael Janner, Yilun Du, Ilya Kostrikov, S. Levine </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-22-red)

---

[**SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables**](https://arxiv.org/abs/2305.13186) Ôºà**2023.05.22**Ôºâ

<font color="gray">Xinyuan Lu, Liangming Pan, Qian Liu, Preslav Nakov, Min-Yen Kan </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/xinyuanlu00/scitab)

---

[**Lion: Adversarial Distillation of Closed-Source Large Language Model**](https://arxiv.org/abs/2305.12870) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yuxin Jiang, Chunkit Chan, Mingyang Chen, Wei Wang </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)  [![](https://img.shields.io/badge/Github%20Stars-16-blue)](https://github.com/yjiangcm/lion)

---

[**Interactive Data Synthesis for Systematic Vision Adaptation via LLMs-AIGCs Collaboration**](https://arxiv.org/abs/2305.12799) Ôºà**2023.05.22**Ôºâ

<font color="gray">Qifan Yu, Juncheng Li, Wentao Ye, Siliang Tang, Yueting Zhuang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-49-blue)](https://github.com/yuqifan1117/labal-anything-pipeline)

---

[**Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation**](https://arxiv.org/abs/2305.12786) Ôºà**2023.05.22**Ôºâ

<font color="gray">Wen Lai, Alexandra Chronopoulou, Alexander M. Fraser </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**This Prompt is Measuring: Evaluating Bias Evaluation in Language Models**](https://arxiv.org/abs/2305.12757) Ôºà**2023.05.22**Ôºâ

<font color="gray">Seraphina Goldfarb-Tarrant, Eddie L. Ungless, Esma Balkir, Su Lin Blodgett </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**G3Detector: General GPT-Generated Text Detector**](https://arxiv.org/abs/2305.12680) Ôºà**2023.05.22**Ôºâ

<font color="gray">Haolan Zhan, Xuanli He, Qiongkai Xu, Yuxiang Wu, Pontus Stenetorp </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Infor-Coef: Information Bottleneck-based Dynamic Token Downsampling for Compact and Efficient language model**](https://arxiv.org/abs/2305.12458) Ôºà**2023.05.21**Ôºâ

<font color="gray">Wenxin Tan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text**](https://arxiv.org/abs/2305.12599) Ôºà**2023.05.21**Ôºâ

<font color="gray">Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/strong-ai-lab/logical-equivalence-driven-amr-data-augmentation-for-representation-learning)

---

[**Retrieving Texts based on Abstract Descriptions**](https://arxiv.org/abs/2305.12517) Ôºà**2023.05.21**Ôºâ

<font color="gray">Shauli Ravfogel, Valentina Pyatkin, Amir D. N. Cohen, Avshalom Manevich, Yoav Goldberg </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Pruning Pre-trained Language Models with Principled Importance and Self-regularization**](https://arxiv.org/abs/2305.12394) Ôºà**2023.05.21**Ôºâ

<font color="gray">Siyu Ren, Kenny Q. Zhu </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/drsy/pins)

---

[**Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers**](https://arxiv.org/abs/2305.12567) Ôºà**2023.05.21**Ôºâ

<font color="gray">Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/gonglinyuan/metro_t0)

---

[**A Dual-level Detection Method for Video Copy Detection**](https://arxiv.org/abs/2305.12361) Ôºà**2023.05.21**Ôºâ

<font color="gray">Tianyi Wang, Feipeng Ma, Zhenhua Liu, Fengyun Rao </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/feipengma6/vsc22-submission)

---

[**Integer or Floating Point? New Outlooks for Low-Bit Quantization on Large Language Models**](https://arxiv.org/abs/2305.12356) Ôºà**2023.05.21**Ôºâ

<font color="gray">Yijia Zhang, Lingran Zhao, Shijie Cao, Wenqiang Wang, Ting Cao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**IR Models and the COVID-19 Pandemic: A Comparative Study of Performance and Challenges (preprint)**](https://arxiv.org/abs/2305.12528) Ôºà**2023.05.21**Ôºâ

<font color="gray">Moksh Shukla, Niti Jain, Shubham Gupta </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Communication Efficient Federated Learning for Multilingual Neural Machine Translation with Adapter**](https://arxiv.org/abs/2305.12449) Ôºà**2023.05.21**Ôºâ

<font color="gray">Yi Liu, Xiaohan Bi, Lei Li, Sishuo Chen, Wenkai Yang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/lancopku/fedmnmt)

---

[**WOT-Class: Weakly Supervised Open-world Text Classification**](https://arxiv.org/abs/2305.12401) Ôºà**2023.05.21**Ôºâ

<font color="gray">Tianle Wang, Zihan Wang, Weitang Liu, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**DreamWaltz: Make a Scene with Complex 3D Animatable Avatars**](https://arxiv.org/abs/2305.12529) Ôºà**2023.05.21**Ôºâ

<font color="gray">Yukun Huang, Jianan Wang, Ailing Zeng, Heng Cao, Xianbiao Qi, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs**](https://arxiv.org/abs/2305.12191) Ôºà**2023.05.20**Ôºâ

<font color="gray">Yatin Nandwani, Vineet Kumar, Dinesh Raghu, Sachindra Joshi, L. Lastras </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer**](https://arxiv.org/abs/2305.12077) Ôºà**2023.05.20**Ôºâ

<font color="gray">Kaige Xie, Tong Yu, Haoliang Wang, Junda Wu, Handong Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Collaborative Development of NLP models**](https://arxiv.org/abs/2305.12219) Ôºà**2023.05.20**Ôºâ

<font color="gray">Fereshte Khani, Marco Tulio Ribeiro </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Accurate Knowledge Distillation with n-best Reranking**](https://arxiv.org/abs/2305.12057) Ôºà**2023.05.20**Ôºâ

<font color="gray">Hendra Setiawan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Joint Foundation Model Caching and Inference of Generative AI Services for Edge Intelligence**](https://arxiv.org/abs/2305.12130) Ôºà**2023.05.20**Ôºâ

<font color="gray">Minrui Xu, D. Niyato, Hongliang Zhang, Jiawen Kang, Zehui Xiong, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DiffCap: Exploring Continuous Diffusion on Image Captioning**](https://arxiv.org/abs/2305.12144) Ôºà**2023.05.20**Ôºâ

<font color="gray">Yufeng He, Zefan Cai, Xu Gan, Baobao Chang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/arealgoodname/diffcap)

---

[**Towards Accurate Image Coding: Improved Autoregressive Image Generation with Dynamic Vector Quantization**](https://doi.org/10.48550/arXiv.2305.11718) Ôºà**2023.05.19**Ôºâ

<font color="gray">Mengqi Huang, Zhendong Mao, Zhuowei Chen, Yongdong Zhang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/crossmodalgroup/dynamicvectorquantization)

---

[**Late-Constraint Diffusion Guidance for Controllable Image Synthesis**](https://doi.org/10.48550/arXiv.2305.11520) Ôºà**2023.05.19**Ôºâ

<font color="gray">Chang Liu, Dong Liu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/AlonzoLeeeooo/LCDG)

---

[**BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases**](https://arxiv.org/abs/2305.12018) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xin Liu, Muhammad Khalifa, Lu Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/launchnlp/bolt)

---

[**STOAT: Structured Data to Analytical Text With Controls**](https://doi.org/10.48550/arXiv.2305.11826) Ôºà**2023.05.19**Ôºâ

<font color="gray">Deepanway Ghosal, Preksha Nema, A. Raghuveer .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Decouple knowledge from paramters for plug-and-play language modeling**](https://doi.org/10.48550/arXiv.2305.11564) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xin Cheng, Yankai Lin, Xiuying Chen, Dongyan Zhao, Rui Yan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/hannibal046/pluglm)

---

[**Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona**](https://doi.org/10.48550/arXiv.2305.11482) Ôºà**2023.05.19**Ôºâ

<font color="gray">Yihong Tang, Bo Wang, Miao Fang, Dongming Zhao, Kun Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/toyhom/clv)

---

[**Self-QA: Unsupervised Knowledge Guided Language Model Alignment**](https://arxiv.org/abs/2305.11952) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xuanyu Zhang, Qing Yang </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions**](https://doi.org/10.48550/arXiv.2305.11460) Ôºà**2023.05.19**Ôºâ

<font color="gray">Shiyao Ding, Takayuki Ito .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LLM Itself Can Read and Generate CXR Images**](https://doi.org/10.48550/arXiv.2305.11490) Ôºà**2023.05.19**Ôºâ

<font color="gray">Suhyeon Lee, Won Jun Kim, Jong-Chul Ye .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/hyn2028/llm-cxr)

---

[**Post Hoc Explanations of Language Models Can Improve Language Models**](https://doi.org/10.48550/arXiv.2305.11426) Ôºà**2023.05.19**Ôºâ

<font color="gray">Satyapriya, Krishna, Jiaqi Ma, Dylan Slack, Asma Ghandeharioun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models**](https://doi.org/10.48550/arXiv.2305.11414) Ôºà**2023.05.19**Ôºâ

<font color="gray">Sixing Yu, J. P. Mu√±oz, A. Jannesari .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning**](https://doi.org/10.48550/arXiv.2305.11383) Ôºà**2023.05.19**Ôºâ

<font color="gray">Po-Nien Kung, Nanyun Peng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding**](https://arxiv.org/abs/2305.12031) Ôºà**2023.05.19**Ôºâ

<font color="gray">Augustin Toma, Patrick R. Lawler, Jimmy Ba, Rahul G. Krishnan, Barry B. Rubin, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)  [![](https://img.shields.io/badge/Github%20Stars-19-blue)](https://github.com/bowang-lab/clinical-camel)

---

[**Complex Claim Verification with Evidence Retrieved in the Wild**](https://doi.org/10.48550/arXiv.2305.11859) Ôºà**2023.05.19**Ôºâ

<font color="gray">Jifan Chen, Grace Kim, Aniruddh Sriram, G. Durrett, Eunsol Choi .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Enhancing Vision-Language Pre-Training with Jointly Learned Questioner and Dense Captioner**](https://doi.org/10.48550/arXiv.2305.11769) Ôºà**2023.05.19**Ôºâ

<font color="gray">Zikang Liu, Sihan Chen, Longteng Guo, Handong Li, Xingjian He, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Plug-and-Play Medical Dialogue System**](https://doi.org/10.48550/arXiv.2305.11508) Ôºà**2023.05.19**Ôºâ

<font color="gray">Chengfeng Dou, Zhi Jin, Wenping Jiao, Haiyan Zhao, Zhenwei Tao, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics**](https://doi.org/10.48550/arXiv.2305.11806) Ôºà**2023.05.19**Ôºâ

<font color="gray">Ricardo Rei, Nuno M. Guerreiro, Marcos Vin√≠cius Treviso, Lu√≠sa Coheur, A. Lavie, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-246-blue)](https://github.com/Unbabel/COMET)

---

[**ReSeTOX: Re-learning attention weights for toxicity mitigation in machine translation**](https://doi.org/10.48550/arXiv.2305.11761) Ôºà**2023.05.19**Ôºâ

<font color="gray">Javier Garc'ia Gilabert, Carlos Escolano, M. Costa-juss√† .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation**](https://doi.org/10.48550/arXiv.2305.11746) Ôºà**2023.05.19**Ôºâ

<font color="gray">David Dale, Elena Voita, Janice Lam, Prangthip Hansanti, Christophe Ropers, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability**](https://doi.org/10.48550/arXiv.2305.11707) Ôºà**2023.05.19**Ôºâ

<font color="gray">Mario Giulianelli, Joris Baan, Wilker Aziz, Raquel Fern'andez, Barbara Plank .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/dmg-illc/nlg-uncertainty-probes)

---

[**Attributable and Scalable Opinion Summarization**](https://doi.org/10.48550/arXiv.2305.11603) Ôºà**2023.05.19**Ôºâ

<font color="gray">Tom Hosking, Hao Tang, Mirella Lapata .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/tomhosking/hercules)

---

[**Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens**](https://doi.org/10.48550/arXiv.2305.11550) Ôºà**2023.05.19**Ôºâ

<font color="gray">David Stap, Vlad Niculae, C. Monz .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**VideoFactory: Swap Attention in Spatiotemporal Diffusions for Text-to-Video Generation**](https://doi.org/10.48550/arXiv.2305.10874) Ôºà**2023.05.18**Ôºâ

<font color="gray">Wenjing Wang, Huan Yang, Zixi Tuo, Huiguo He, Junchen Zhu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**LDM3D: Latent Diffusion Model for 3D**](https://doi.org/10.48550/arXiv.2305.10853) Ôºà**2023.05.18**Ôºâ

<font color="gray">Gabriela Ben Melech Stan, Diana Wofk, Scottie Fox, Alex Redden, Will Saxton, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Catch-Up Distillation: You Only Need to Train Once for Accelerating Sampling**](https://doi.org/10.48550/arXiv.2305.10769) Ôºà**2023.05.18**Ôºâ

<font color="gray">Shitong Shao, Xu Dai, Shouyi Yin, Lujun Li, Huanran Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Zero-Day Backdoor Attack against Text-to-Image Diffusion Models via Personalization**](https://doi.org/10.48550/arXiv.2305.10701) Ôºà**2023.05.18**Ôºâ

<font color="gray">Yihao Huang, Qing Guo, Felix Juefei-Xu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Democratized Diffusion Language Model**](https://doi.org/10.48550/arXiv.2305.10818) Ôºà**2023.05.18**Ôºâ

<font color="gray">Nikita Balagansky, Daniil Gavrilov .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation**](https://doi.org/10.48550/arXiv.2305.11130) Ôºà**2023.05.18**Ôºâ

<font color="gray">Junkai Zhou, Liang Pang, Huawei Shen, Xueqi Cheng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Learning In-context Learning for Named Entity Recognition**](https://doi.org/10.48550/arXiv.2305.11038) Ôºà**2023.05.18**Ôºâ

<font color="gray">Jiawei Chen, Yaojie Lu, Hongyu Lin, Jie Lou, Wei Jia, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ahead-of-Time P-Tuning**](https://doi.org/10.48550/arXiv.2305.10835) Ôºà**2023.05.18**Ôºâ

<font color="gray">Daniil Gavrilov, Nikita Balagansky .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**How does the task complexity of masked pretraining objectives affect downstream performance?**](https://doi.org/10.48550/arXiv.2305.10992) Ôºà**2023.05.18**Ôºâ

<font color="gray">Atsuki Yamaguchi, Hiroaki Ozaki, Terufumi Morishita, Gaku Morio, Yasuhiro Sogawa .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings**](https://doi.org/10.48550/arXiv.2305.10786) Ôºà**2023.05.18**Ôºâ

<font color="gray">Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Chong Deng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**ReGen: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval**](https://doi.org/10.48550/arXiv.2305.10703) Ôºà**2023.05.18**Ôºâ

<font color="gray">Yue Yu, Yuchen Zhuang, Rongzhi Zhang, Yu Meng, Jiaming Shen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/yueyu1030/ReGen)

---

[**LIMA: Less Is More for Alignment**](https://doi.org/10.48550/arXiv.2305.11206) Ôºà**2023.05.18**Ôºâ

<font color="gray">Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**The Web Can Be Your Oyster for Improving Large Language Models**](https://doi.org/10.48550/arXiv.2305.10998) Ôºà**2023.05.18**Ôºâ

<font color="gray">Junyi Li, Tianyi Tang, Wayne Xin Zhao, Jingyuan Wang, J. Nie, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Support for Stock Trend Prediction Using Transformers and Sentiment Analysis**](https://arxiv.org/abs/2305.14368) Ôºà**2023.05.18**Ôºâ

<font color="gray">Harsimrat Kaeley, Ye Qiao, Nader Bagherzadeh </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities**](https://doi.org/10.48550/arXiv.2305.11172) Ôºà**2023.05.18**Ôºâ

<font color="gray">Peng Wang, Shijie Wang, Junyang Lin, Shuai Bai, Xiaohuan Zhou, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-296-blue)](https://github.com/OFA-Sys/ONE-PEACE)

---

[**TOME: A Two-stage Approach for Model-based Retrieval**](https://doi.org/10.48550/arXiv.2305.11161) Ôºà**2023.05.18**Ôºâ

<font color="gray">Ruiyang Ren, Wayne Xin Zhao, J. Liu, Huaqin Wu, Ji-rong Wen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild**](https://doi.org/10.48550/arXiv.2305.11147) Ôºà**2023.05.18**Ôºâ

<font color="gray">Can Qin, Shu Zhang, Ning Yu, Yihao Feng, Xinyi Yang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**LLMScore: Unveiling the Power of Large Language Models in Text-to-Image Synthesis Evaluation**](https://doi.org/10.48550/arXiv.2305.11116) Ôºà**2023.05.18**Ôºâ

<font color="gray">Yujie Lu, Xianjun Yang, Xiujun Li, X. Wang, William Yang Wang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-57-blue)](https://github.com/yujielu10/llmscore)

---

[**Generalized Planning in PDDL Domains with Pretrained Large Language Models**](https://doi.org/10.48550/arXiv.2305.11014) Ôºà**2023.05.18**Ôºâ

<font color="gray">Tom Silver, Soham Dan, Kavitha Srinivas, J. Tenenbaum, L. Kaelbling, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/tomsilver/llm-genplan)

---

[**Discriminative Diffusion Models as Few-shot Vision and Language Learners**](https://doi.org/10.48550/arXiv.2305.10722) Ôºà**2023.05.18**Ôºâ

<font color="gray">Xuehai He, Weixi Feng, Tsu-Jui Fu, Varun Jampani, Arjun Reddy Akula, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Comparing Biases and the Impact of Multilingual Training across Multiple Languages**](https://doi.org/10.48550/arXiv.2305.11242) Ôºà**2023.05.18**Ôºâ

<font color="gray">Sharon Levy, Neha Ann John, Ling Liu, Yogarshi Vyas, Jie Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Paxion: Patching Action Knowledge in Video-Language Foundation Models**](https://doi.org/10.48550/arXiv.2305.10683) Ôºà**2023.05.18**Ôºâ

<font color="gray">Zhenhailong Wang, Ansel Blume, Sha Li, Genglin Liu, Jaemin Cho, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/mikewangwzhl/paxion)

---

[**Vision-Language Pre-training with Object Contrastive Learning for 3D Scene Understanding**](https://doi.org/10.48550/arXiv.2305.10714) Ôºà**2023.05.18**Ôºâ

<font color="gray">Zhang Tao, Su He, D. Tao, Bin Chen, Zhi Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Listen, Think, and Understand**](https://doi.org/10.48550/arXiv.2305.10790) Ôºà**2023.05.18**Ôºâ

<font color="gray">Yuan Gong, Hongyin Luo, Alexander H. Liu, Leonid Karlinsky, James Glass .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-56-blue)](https://github.com/YuanGongND/ltu)

---

[**Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning**](https://doi.org/10.48550/arXiv.2305.10613) Ôºà**2023.05.17**Ôºâ

<font color="gray">Dong-Ho Lee, Kian Ahrabian, Woojeong Jin, Fred Morstatter, J. Pujara .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**When Gradient Descent Meets Derivative-Free Optimization: A Match Made in Black-Box Scenario**](https://doi.org/10.48550/arXiv.2305.10013) Ôºà**2023.05.17**Ôºâ

<font color="gray">Chengcheng Han, Liqing Cui, Renyu Zhu, J. Wang, Nuo Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SLiC-HF: Sequence Likelihood Calibration with Human Feedback**](https://doi.org/10.48550/arXiv.2305.10425) Ôºà**2023.05.17**Ôºâ

<font color="gray">Yao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**LeTI: Learning to Generate from Textual Interactions**](https://doi.org/10.48550/arXiv.2305.10314) Ôºà**2023.05.17**Ôºâ

<font color="gray">Xingyao Wang, Hao Peng, Reyhaneh Jabbarvand, Heng Ji .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-44-blue)](https://github.com/xingyaoww/leti)

---

[**M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models**](https://doi.org/10.48550/arXiv.2305.10263) Ôºà**2023.05.17**Ôºâ

<font color="gray">Chuang Liu, Renren Jin, Yuqi Ren, Linhao Yu, Tianyu Dong, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-22-blue)](https://github.com/tjunlp-lab/m3ke)

---

[**Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model**](https://doi.org/10.48550/arXiv.2305.10163) Ôºà**2023.05.17**Ôºâ

<font color="gray">Jiageng Wu, X. Wu, Zhaopeng Qiu, Minghui Li, Yefeng Zheng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Can Language Models Solve Graph Problems in Natural Language?**](https://doi.org/10.48550/arXiv.2305.10037) Ôºà**2023.05.17**Ôºâ

<font color="gray">Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang Han, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/arthur-heng/nlgraph)

---

[**Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling**](https://doi.org/10.48550/arXiv.2305.09993) Ôºà**2023.05.17**Ôºâ

<font color="gray">Weijia Xu, Andrzej Banburski-Fahey, N. Jojic .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**IMAD: IMage-Augmented multi-modal Dialogue**](https://arxiv.org/abs/2305.10512) Ôºà**2023.05.17**Ôºâ

<font color="gray">Moskvoretskii Viktor, Frolov Anton, Kuznetsov Denis </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Incorporating Attribution Importance for Improving Faithfulness Metrics**](https://doi.org/10.48550/arXiv.2305.10496) Ôºà**2023.05.17**Ôºâ

<font color="gray">Zhixue Zhao, Nikolaos Aletras .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/casszhao/softfaith)

---

[**Sequence-to-Sequence Pre-training with Unified Modality Masking for Visual Document Understanding**](https://doi.org/10.48550/arXiv.2305.10448) Ôºà**2023.05.16**Ôºâ

<font color="gray">ShuWei Feng, Tianyang Zhan, Zhanming Jie, Trung Quoc Luong, Xiaoran Jin .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Learning the Visualness of Text Using Large Vision-Language Models**](https://doi.org/10.48550/arXiv.2305.10434) Ôºà**2023.05.11**Ôºâ

<font color="gray">Gaurav Verma, Ryan A. Rossi, Chris Tensmeyer, Jiuxiang Gu, A. Nenkova .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SPSQL: Step-by-step Parsing Based Framework for Text-to-SQL Generation**](https://doi.org/10.48550/arXiv.2305.11061) Ôºà**2023.05.10**Ôºâ

<font color="gray">Ran Shen, Gang Sun, Hao Shen, Yiling Li, Liangfeng Jin, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Prompt Engineering for Healthcare: Methodologies and Applications**](https://doi.org/10.48550/arXiv.2304.14670) Ôºà**2023.04.28**Ôºâ

<font color="gray">Jiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Chong Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond**](https://arxiv.org/abs/2304.13712) Ôºà**2023.04.26**Ôºâ

<font color="gray">Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-186-red)  [![](https://img.shields.io/badge/Github%20Stars-4.5k-blue)](https://github.com/mooler0410/llmspracticalguide)

---

[**A Survey of Large Language Models**](https://arxiv.org/abs/2303.18223) Ôºà**2023.03.31**Ôºâ



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-480-red)  [![](https://img.shields.io/badge/Github%20Stars-2.0k-blue)](https://github.com/rucaibox/llmsurvey)

---

[**Augmented Language Models: a Survey**](https://doi.org/10.48550/arXiv.2302.07842) Ôºà**2023.02.15**Ôºâ

<font color="gray">Gr√©goire Mialon, Roberto Dess√¨, M. Lomeli, Christoforos Nalmpantis, Ramakanth Pasunuru, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**A Survey for In-context Learning**](https://doi.org/10.48550/arXiv.2301.00234) Ôºà**2022.12.31**Ôºâ

<font color="gray">Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Reasoning in Large Language Models: A Survey**](https://doi.org/10.48550/arXiv.2212.10403) Ôºà**2022.12.20**Ôºâ

<font color="gray">Jie Huang, K. Chang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-296-blue)](https://github.com/jeffhj/lm-reasoning)

---

[**Reasoning with Language Model Prompting: A Survey**](https://doi.org/10.48550/arXiv.2212.09597) Ôºà**2022.12.19**Ôºâ

<font color="gray">Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-375-blue)](https://github.com/zjunlp/Prompt4ReasoningPapers)

---

[**Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**](https://doi.org/10.1145/3560815) Ôºà**2021.07.28**Ôºâ

<font color="gray">Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, etc .  - „ÄêACM Computing Surveys„Äë</font>

![](https://img.shields.io/badge/Citations-462-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1.6k-red)  [![](https://img.shields.io/badge/Github%20Stars-201-blue)](https://github.com/mingkaid/rl-prompt)

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---

---


</div>

# CONTINUE...