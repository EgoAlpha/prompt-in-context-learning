# üìÑ Survey

## Paper List

<div style="line-height:0.2em;">


[**Motion meets Attention: Video Motion Prompts**](https://arxiv.org/abs/2407.03179) Ôºà**2024.07.03**Ôºâ

<font color="gray">Qixiang Chen, Lei Wang, Piotr Koniusz, Tom Gedeon </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards a Personal Health Large Language Model**](https://arxiv.org/abs/2406.06474) Ôºà**2024.06.10**Ôºâ

<font color="gray">J. Cosentino, Anastasiya Belyaeva, Xin Liu, N. Furlotte, Zhun Yang, etc </font>

![](https://img.shields.io/badge/Citations-2-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning**](https://arxiv.org/abs/2406.06469) Ôºà**2024.06.10**Ôºâ

<font color="gray">Joongwon Kim, Bhargavi Paranjape, Tushar Khot, Hanna Hajishirzi </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-228-blue)](https://github.com/agent-husky/husky-v1)

---

[**Towards Lifelong Learning of Large Language Models: A Survey**](https://arxiv.org/abs/2406.06391) Ôºà**2024.06.10**Ôºâ

<font color="gray">Junhao Zheng, Shengjie Qiu, Chengming Shi, Qianli Ma </font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**Towards Semantic Equivalence of Tokenization in Multimodal LLM**](https://arxiv.org/abs/2406.05127) Ôºà**2024.06.07**Ôºâ

<font color="gray">Shengqiong Wu, Hao Fei, Xiangtai Li, Jiayi Ji, Hanwang Zhang, etc </font>

![](https://img.shields.io/badge/Citations-4-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**LLMs Meet Multimodal Generation and Editing: A Survey**](https://doi.org/10.48550/arXiv.2405.19334) Ôºà**2024.05.29**Ôºâ

<font color="gray">Yin-Yin He, Zhaoyang Liu, Jingye Chen, Zeyue Tian, Hongyu Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-206-blue)](https://github.com/yingqinghe/awesome-llms-meet-multimodal-generation)

---

[**Tool Learning with Large Language Models: A Survey**](https://doi.org/10.48550/arXiv.2405.17935) Ôºà**2024.05.28**Ôºâ

<font color="gray">Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-106-blue)](https://github.com/quchangle1/llm-tool-survey)

---

[**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**](https://doi.org/10.48550/arXiv.2405.10255) Ôºà**2024.05.16**Ôºâ

<font color="gray">Xianzheng Ma, Yash Bhalgat, Brandon Smart, Shuai Chen, Xinghui Li, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-833-blue)](https://github.com/activevisionlab/awesome-llm-3d)

---

[**Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach**](https://doi.org/10.48550/arXiv.2404.15993) Ôºà**2024.04.24**Ôºâ

<font color="gray">Linyu Liu, Yu Pan, Xiaocheng Li, Guanting Chen .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**A Survey on the Memory Mechanism of Large Language Model based Agents**](https://doi.org/10.48550/arXiv.2404.13501) Ôºà**2024.04.21**Ôºâ

<font color="gray">Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)  [![](https://img.shields.io/badge/Github%20Stars-79-blue)](https://github.com/nuster1128/llm_agent_memory_survey)

---

[**The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey**](https://doi.org/10.48550/arXiv.2404.11584) Ôºà**2024.04.17**Ôºâ

<font color="gray">Tula Masterman, Sandi Besen, Mason Sawtell, Alex Chao .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**CausalBench: A Comprehensive Benchmark for Causal Learning Capability of Large Language Models**](https://doi.org/10.48550/arXiv.2404.06349) Ôºà**2024.04.09**Ôºâ

<font color="gray">Yu Zhou, Xingyu Wu, Beichen Huang, Jibin Wu, Liang Feng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**AI-Tutoring in Software Engineering Education: Experiences with Large Language Models in Programming Assessments**](https://doi.org/10.1145/3639474.3640061) Ôºà**2024.04.03**Ôºâ

<font color="gray">Eduard Frankford, Clemens Sauerwein, Patrick Bassner, Stephan Krusche, Ruth Breu .  - „Äê2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**A Survey on Large Language Model-Based Game Agents**](https://doi.org/10.48550/arXiv.2404.02039) Ôºà**2024.04.02**Ôºâ

<font color="gray">Sihao Hu, Tiansheng Huang, Fatih Ilhan, S. Tekin, Gaowen Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-140-blue)](https://github.com/git-disl/awesome-llm-game-agent-papers)

---

[**Large Language Models for Education: A Survey and Outlook**](https://doi.org/10.48550/arXiv.2403.18105) Ôºà**2024.03.26**Ôºâ

<font color="gray">Shen Wang, Tianlong Xu, Hang Li, Chaoli Zhang, Joleen Liang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-9-green)

---

[**The Ethics of ChatGPT in Medicine and Healthcare: A Systematic Review on Large Language Models (LLMs)**](https://arxiv.org/abs/2403.14473) Ôºà**2024.03.21**Ôºâ

<font color="gray">Joschka Haltaufderheide, R. Ranisch </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey**](https://arxiv.org/abs/2403.14608) Ôºà**2024.03.21**Ôºâ

<font color="gray">Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, Sai Qian Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-62-red)

---

[**ChatGPT Alternative Solutions: Large Language Models Survey**](https://doi.org/10.5121/csit.2024.140514) Ôºà**2024.03.16**Ôºâ

<font color="gray">H. Alipour, Nick Pendar, Kohinoor Roy .  - „ÄêNetworks, Blockchain and Internet of Things„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MM1: Methods, Analysis&Insights from Multimodal LLM Pre-training**](https://arxiv.org/abs/2403.09611) Ôºà**2024.03.14**Ôºâ

<font color="gray">Brandon McKinzie, Zhe Gan, J. Fauconnier, Sam Dodge, Bowen Zhang, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-230-red)

---

[**Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey**](https://arxiv.org/abs/2403.09606) Ôºà**2024.03.14**Ôºâ

<font color="gray">Xiaoyu Liu, Paiheng Xu, Junda Wu, Jiaxin Yuan, Yifan Yang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-21-red)

---

[**Model Parallelism on Distributed Infrastructure: A Literature Review from Theory to LLM Case-Studies**](https://arxiv.org/abs/2403.03699) Ôºà**2024.03.06**Ôºâ

<font color="gray">Felix Brakel, Uraz Odyurt, A. Varbanescu </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)

---

[**Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation**](https://arxiv.org/abs/2403.02951) Ôºà**2024.03.05**Ôºâ

<font color="gray">Bin Zhang, Yuxiao Ye, Guoqing Du, Xiaoru Hu, Zhishuai Li, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-26-red)

---

[**A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods**](https://arxiv.org/abs/2403.02901) Ôºà**2024.03.05**Ôºâ

<font color="gray">Hanlei Jin, Yang Zhang, Dan Meng, Jun Wang, Jinghua Tan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-34-red)

---

[**Large Language Models for Data Annotation: A Survey**](https://arxiv.org/abs/2402.13446) Ôºà**2024.02.21**Ôºâ

<font color="gray">Zhen Tan, Alimohammad Beigi, Song Wang, Ruocheng Guo, Amrita Bhattacharjee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-62-red)  [![](https://img.shields.io/badge/Github%20Stars-189-blue)](https://github.com/zhen-tan-dmml/llm4annotation)

---

[**A Survey on Knowledge Distillation of Large Language Models**](https://arxiv.org/abs/2402.13116) Ôºà**2024.02.20**Ôºâ

<font color="gray">Xiaohan Xu, Ming Li, Chongyang Tao, Tao Shen, Reynold Cheng, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-99-red)  [![](https://img.shields.io/badge/Github%20Stars-379-blue)](https://github.com/tebmer/awesome-knowledge-distillation-of-llms)

---

[**Investigating Cultural Alignment of Large Language Models**](https://arxiv.org/abs/2402.13231) Ôºà**2024.02.20**Ôºâ

<font color="gray">Badr AlKhamissi, Muhammad N. ElNokrashy, Mai AlKhamissi, Mona Diab </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/bkhmsi/cultural-trends)

---

[**MM-LLMs: Recent Advances in MultiModal Large Language Models**](https://doi.org/10.48550/arXiv.2401.13601) Ôºà**2024.01.24**Ôºâ

<font color="gray">Duzhen Zhang, Yahan Yu, Chenxing Li, Jiahua Dong, Dan Su, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Machine Translation with Large Language Models: Prompt Engineering for Persian, English, and Russian Directions**](https://doi.org/10.48550/arXiv.2401.08429) Ôºà**2024.01.16**Ôºâ

<font color="gray">Nooshin Pourkamali, Shler Ebrahim Sharifi .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives**](https://doi.org/10.48550/arXiv.2312.11970) Ôºà**2023.12.19**Ôºâ

<font color="gray">Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)

---

[**Retrieval-Augmented Generation for Large Language Models: A Survey**](https://arxiv.org/abs/2312.10997) Ôºà**2023.12.18**Ôºâ

<font color="gray">Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-774-red)  [![](https://img.shields.io/badge/Github%20Stars-1.5k-blue)](https://github.com/tongji-kgllm/rag-survey)

---

[**ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models**](https://doi.org/10.54254/2755-2721/21/20231153) Ôºà**2023.10.23**Ôºâ

<font color="gray">Zehao Wen, Rabih Younes .  - „ÄêApplied and Computational Engineering„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)

---

[**Retrieval-augmented Generation to Improve Math Question-Answering: Trade-offs Between Groundedness and Human Preference**](https://doi.org/10.48550/arXiv.2310.03184) Ôºà**2023.10.04**Ôºâ

<font color="gray">Zachary Levonian, Chenglu Li, Wangda Zhu, Anoushka Gade, Owen Henkel, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/digitalharborfoundation/rag-for-math-qa)

---

[**A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future**](https://doi.org/10.48550/arXiv.2309.15402) Ôºà**2023.09.27**Ôºâ

<font color="gray">Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**The Rise and Potential of Large Language Model Based Agents: A Survey**](https://doi.org/10.48550/arXiv.2309.07864) Ôºà**2023.09.14**Ôºâ

<font color="gray">Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-5.7k-blue)](https://github.com/woooodyy/llm-agent-paper-list)

---

[**Textbooks Are All You Need II: phi-1.5 technical report**](https://doi.org/10.48550/arXiv.2309.05463) Ôºà**2023.09.11**Ôºâ

<font color="gray">Yuan-Fang Li, S√©bastien Bubeck, Ronen Eldan, Allison Del Giorno, Suriya Gunasekar, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-6-green)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/knowlab/bi-weekly-paper-presentation)

---

[**Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models**](https://doi.org/10.48550/arXiv.2309.01219) Ôºà**2023.09.03**Ôºâ

<font color="gray">Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-8-green)  [![](https://img.shields.io/badge/Github%20Stars-854-blue)](https://github.com/hillzhang1999/llm-hallucination-survey)

---

[**Point-Bind&Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following**](https://arxiv.org/abs/2309.00615) Ôºà**2023.09.01**Ôºâ

<font color="gray">Ziyu Guo, Renrui Zhang, Xiangyang Zhu, Yiwen Tang, Xianzheng Ma, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-44-red)  [![](https://img.shields.io/badge/Github%20Stars-382-blue)](https://github.com/ziyuguo99/point-bind_point-llm)

---

[**Large language models in medicine: the potentials and pitfalls**](https://arxiv.org/abs/2309.00087) Ôºà**2023.08.31**Ôºâ

<font color="gray">J. Omiye, Haiwen Gui, Shawheen J. Rezaei, James Zou, Roxana Daneshjou </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Graph Models: A Perspective**](https://doi.org/10.48550/arXiv.2308.14522) Ôºà**2023.08.28**Ôºâ

<font color="gray">Ziwei Zhang, Haoyang Li, Zeyang Zhang, Yi Qin, Xin Wang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**A Survey on Large Language Model based Autonomous Agents**](https://doi.org/10.48550/arXiv.2308.11432) Ôºà**2023.08.22**Ôºâ

<font color="gray">Lei Wang, Chengbang Ma, Xueyang Feng, Zeyu Zhang, Hao-ran Yang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-13-green)  [![](https://img.shields.io/badge/Github%20Stars-2.4k-blue)](https://github.com/paitesanshi/llm-agent-survey)

---

[**Instruction Tuning for Large Language Models: A Survey**](https://doi.org/10.48550/arXiv.2308.10792) Ôºà**2023.08.21**Ôºâ

<font color="gray">Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-115-blue)](https://github.com/xiaoya-li/instruction-tuning-survey)

---

[**Scientific discovery in the age of artificial intelligence**](https://doi.org/10.1038/s41586-023-06221-2) Ôºà**2023.08.01**Ôºâ

<font color="gray">Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, etc .  - „ÄêNature„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-745-red)

---

[**Foundational Models Defining a New Era in Vision: A Survey and Outlook**](https://doi.org/10.48550/arXiv.2307.13721) Ôºà**2023.07.25**Ôºâ

<font color="gray">Muhammad Awais, Muzammal Naseer, Salman Siddique Khan, R. Anwer, Hisham Cholakkal, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  [![](https://img.shields.io/badge/Github%20Stars-431-blue)](https://github.com/awaisrauf/awesome-cv-foundational-models)

---

[**Foundational Models Defining a New Era in Vision: A Survey and Outlook**](https://arxiv.org/abs/2307.13721) Ôºà**2023.07.25**Ôºâ

<font color="gray">Muhammad Awais, Muzammal Naseer, Salman Siddique Khan, R. Anwer, Hisham Cholakkal, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-125-red)  [![](https://img.shields.io/badge/Github%20Stars-431-blue)](https://github.com/awaisrauf/awesome-cv-foundational-models)

---

[**Challenges and Applications of Large Language Models**](https://doi.org/10.48550/arXiv.2307.10169) Ôºà**2023.07.19**Ôºâ

<font color="gray">Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators**](https://doi.org/10.1145/3571884.3604316) Ôºà**2023.07.08**Ôºâ

<font color="gray">Andreas Liesenfeld, Alianda Lopez, Mark Dingemanse .  - „ÄêInternational Conference on Conversational User Interfaces„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-73-red)  [![](https://img.shields.io/badge/Github%20Stars-78-blue)](https://github.com/opening-up-chatgpt/opening-up-chatgpt.github.io)

---

[**A Survey on Evaluation of Large Language Models**](https://doi.org/10.48550/arXiv.2307.03109) Ôºà**2023.07.06**Ôºâ

<font color="gray">Yu-Chu Chang, Xu Wang, Jindong Wang, Yuanyi Wu, Kaijie Zhu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-1.3k-blue)](https://github.com/mlgroupjlu/llm-eval-survey)

---

[**A Survey on Evaluation of Large Language Models**](https://doi.org/10.48550/arXiv.2307.03109) Ôºà**2023.07.06**Ôºâ

<font color="gray">Yu-Chu Chang, Xu Wang, Jindong Wang, Yuanyi Wu, Kaijie Zhu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-25-green)  [![](https://img.shields.io/badge/Github%20Stars-1.3k-blue)](https://github.com/mlgroupjlu/llm-eval-survey)

---

[**A Survey on Multimodal Large Language Models**](https://doi.org/10.48550/arXiv.2306.13549) Ôºà**2023.06.23**Ôºâ

<font color="gray">Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)  [![](https://img.shields.io/badge/Github%20Stars-10.4k-blue)](https://github.com/bradyfu/awesome-multimodal-large-language-models)

---

[**Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health**](https://doi.org/10.48550/arXiv.2306.10070) Ôºà**2023.06.15**Ôºâ

<font color="gray">Shubo Tian, Qiao Jin, Lana Yeganova, Po-Ting Lai, Qingqing Zhu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**A Survey of Vision-Language Pre-training from the Lens of Multimodal Machine Translation**](https://doi.org/10.48550/arXiv.2306.07198) Ôºà**2023.06.12**Ôºâ

<font color="gray">Jeremy Gwinnup, Kevin Duh .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**How Can Recommender Systems Benefit from Large Language Models: A Survey**](https://doi.org/10.48550/arXiv.2306.05817) Ôºà**2023.06.09**Ôºâ

<font color="gray">Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-14-green)  [![](https://img.shields.io/badge/Github%20Stars-828-blue)](https://github.com/chiangel/awesome-llm-for-recsys)

---

[**Harnessing Large Language Models in Nursing Care Planning: Opportunities, Challenges, and Ethical Considerations**](https://doi.org/10.7759/cureus.40542) Ôºà**2023.06.01**Ôºâ

<font color="gray">A. Nashwan, Ahmad A. Abujaber .  - „ÄêCureus„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-25-red)

---

[**Structural Ambiguity and its Disambiguation in Language Model Based Parsers: the Case of Dutch Clause Relativization**](https://arxiv.org/abs/2305.14917) Ôºà**2023.05.24**Ôºâ

<font color="gray">Gijs Wijnholds, Michael Moortgat </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective**](https://arxiv.org/abs/2305.15408) Ôºà**2023.05.24**Ôºâ

<font color="gray">Guhao Feng, Yuntian Gu, Bohang Zhang, Haotian Ye, Di He, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-54-red)

---

[**Unit-based Speech-to-Speech Translation Without Parallel Data**](https://arxiv.org/abs/2305.15405) Ôºà**2023.05.24**Ôºâ

<font color="gray">Anuj Diwan, Anirudh Srinivasan, David F. Harwath, Eunsol Choi </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**A Neural Space-Time Representation for Text-to-Image Personalization**](https://arxiv.org/abs/2305.15391) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yuval Alaluf, Elad Richardson, Gal Metzer, Daniel Cohen-Or </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-24-red)  [![](https://img.shields.io/badge/Github%20Stars-160-blue)](https://github.com/NeuralTextualInversion/NeTI)

---

[**Visual Programming for Text-to-Image Generation and Evaluation**](https://arxiv.org/abs/2305.15328) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jaemin Cho, Abhay Zala, Mohit Bansal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-28-red)

---

[**Towards Foundation Models for Relational Databases [Vision Paper]**](https://arxiv.org/abs/2305.15321) Ôºà**2023.05.24**Ôºâ

<font color="gray">Liane Vogel, Benjamin Hilprecht, Carsten Binnig </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)

---

[**ViTMatte: Boosting Image Matting with Pretrained Plain Vision Transformers**](https://arxiv.org/abs/2305.15272) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jingfeng Yao, Xinggang Wang, Shusheng Yang, Baoyuan Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)  [![](https://img.shields.io/badge/Github%20Stars-284-blue)](https://github.com/hustvl/ViTMatte)

---

[**Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model**](https://arxiv.org/abs/2305.15265) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zirui Liu, Guanchu Wang, Shaochen Zhong, Zhaozhuo Xu, Daochen Zha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4-blue)](https://github.com/zirui-ray-liu/wtacrs)

---

[**LMs with a Voice: Spoken Language Modeling beyond Speech Tokens**](https://arxiv.org/abs/2305.15255) Ôºà**2023.05.24**Ôºâ

<font color="gray">Eliya Nachmani, Alon Levkovitch, Julian Salazar, Chulayutsh Asawaroengchai, Soroosh Mariooryad, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)

---

[**DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion Models**](https://arxiv.org/abs/2305.15194) Ôºà**2023.05.24**Ôºâ

<font color="gray">Sungnyun Kim, Junsoo Lee, Kibeom Hong, Daesik Kim, Namhyuk Ahn </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-15-red)  [![](https://img.shields.io/badge/Github%20Stars-41-blue)](https://github.com/sungnyun/diffblender)

---

[**Pre-training Multi-party Dialogue Models with Latent Discourse Inference**](https://arxiv.org/abs/2305.15175) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yiyang Li, Xinting Huang, Wei Bi, Hai Zhao </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/ericlee8/mpd_emvi)

---

[**Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator**](https://arxiv.org/abs/2305.15099) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ziwei He, Meng Yang, Minwei Feng, Jingcheng Yin, Xinbing Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-19-red)  [![](https://img.shields.io/badge/Github%20Stars-25-blue)](https://github.com/lumia-group/fouriertransformer)

---

[**CSTS: Conditional Semantic Textual Similarity**](https://arxiv.org/abs/2305.15093) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ameet Deshpande, Carlos E. Jimenez, Howard Chen, Vishvak S. Murahari, Victoria Graf, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-22-red)

---

[**STAR: Boosting Low-Resource Event Extraction by Structure-to-Text Data Generation with Large Language Models**](https://arxiv.org/abs/2305.15090) Ôºà**2023.05.24**Ôºâ

<font color="gray">Mingyu Derek Ma, Xiaoxuan Wang, Po-Nien Kung, P. Jeffrey Brantingham, Nanyun Peng, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)

---

[**Contrastive Learning of Sentence Embeddings from Scratch**](https://arxiv.org/abs/2305.15077) Ôºà**2023.05.24**Ôºâ

<font color="gray">Junlei Zhang, Zhenzhong Lan, Junxian He </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)  [![](https://img.shields.io/badge/Github%20Stars-33-blue)](https://github.com/hkust-nlp/syncse)

---

[**Meta-Learning Online Adaptation of Language Models**](https://arxiv.org/abs/2305.15076) Ôºà**2023.05.24**Ôºâ

<font color="gray">Nathan J. Hu, Eric Mitchell, Christopher D. Manning, Chelsea Finn </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-25-red)  [![](https://img.shields.io/badge/Github%20Stars-21-blue)](https://github.com/nathanhu0/CaMeLS)

---

[**Who Wrote this Code? Watermarking for Code Generation**](https://arxiv.org/abs/2305.15060) Ôºà**2023.05.24**Ôºâ

<font color="gray">Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)  [![](https://img.shields.io/badge/Github%20Stars-17-blue)](https://github.com/hongcheki/sweet-watermark)

---

[**Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering**](https://arxiv.org/abs/2305.15056) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jiajie Zhang, Shulin Cao, Tingjia Zhang, Xin Lv, Jiaxin Shi, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-17-red)

---

[**Understanding Arithmetic Reasoning in Language Models using Causal Mediation Analysis**](https://arxiv.org/abs/2305.15054) Ôºà**2023.05.24**Ôºâ

<font color="gray">Alessandro Stolfo, Yonatan Belinkov, Mrinmaya Sachan </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)

---

[**Ranger: A Toolkit for Effect-Size Based Multi-Task Evaluation**](https://arxiv.org/abs/2305.15048) Ôºà**2023.05.24**Ôºâ

<font color="gray">Mete Sertkan, Sophia Althammer, Sebastian Hofstatter </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/metesertkan/ranger)

---

[**Ghostbuster: Detecting Text Ghostwritten by Large Language Models**](https://arxiv.org/abs/2305.15047) Ôºà**2023.05.24**Ôºâ

<font color="gray">Vivek Verma, Eve Fleisig, Nicholas Tomlin, Dan Klein </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-19-red)  [![](https://img.shields.io/badge/Github%20Stars-123-blue)](https://github.com/vivek3141/ghostbuster)

---

[**Generating Faithful Synthetic Data with Large Language Models: A Case Study in Computational Social Science**](https://arxiv.org/abs/2305.15041) Ôºà**2023.05.24**Ôºâ

<font color="gray">Veniamin Veselovsky, Manoel Horta Ribeiro, Akhil Arora, Martin Josifoski, Ashton Anderson, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-21-red)

---

[**Active Learning for Natural Language Generation**](https://arxiv.org/abs/2305.15040) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yotam Perlitz, Ariel Gera, Michal Shmueli-Scheuer, Dafna Sheinwald, Noam Slonim, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-11-red)

---

[**SmartTrim: Adaptive Tokens and Parameters Pruning for Efficient Vision-Language Models**](https://arxiv.org/abs/2305.15033) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zekun Wang, Jingchang Chen, Wangchunshu Zhou, Ming Liu, Bing Qin </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**How to Distill your BERT: An Empirical Study on the Impact of Weight Initialisation and Distillation Objectives**](https://arxiv.org/abs/2305.15032) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xinpeng Wang, Leonie Weissweiler, Hinrich Schutze, Barbara Plank </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-9-blue)](https://github.com/mainlp/how-to-distill-your-bert)

---

[**ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification**](https://arxiv.org/abs/2305.15024) Ôºà**2023.05.24**Ôºâ

<font color="gray">Biao Zhao, Weiqiang Jin, Javier Del Ser, Guang Yang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-93-red)  [![](https://img.shields.io/badge/Github%20Stars-38-blue)](https://github.com/albert-jin/agricultural_textual_classification_chatgpt)

---

[**Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models**](https://arxiv.org/abs/2305.15023) Ôºà**2023.05.24**Ôºâ

<font color="gray">Gen Luo, Yiyi Zhou, Tianhe Ren, Shengxin Chen, Xiaoshuai Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-63-red)  [![](https://img.shields.io/badge/Github%20Stars-491-blue)](https://github.com/luogen1996/lavin)

---

[**Unlocking Temporal Question Answering for Large Language Models Using Code Execution**](https://arxiv.org/abs/2305.15014) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xingxuan Li, Liying Cheng, Qingyu Tan, Hwee Tou Ng, Shafiq Joty, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/damo-nlp-sg/mvcr)

---

[**Bactrian-X : A Multilingual Replicable Instruction-Following Model with Low-Rank Adaptation**](https://arxiv.org/abs/2305.15011) Ôºà**2023.05.24**Ôºâ

<font color="gray">Haonan Li, Fajri Koto, Minghao Wu, Alham Fikri Aji, Timothy Baldwin </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism and Synonymous Substitution**](https://arxiv.org/abs/2305.15010) Ôºà**2023.05.24**Ôºâ

<font color="gray">Hongbo Zhang, Xiang Wan, Benyou Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1-red)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/stevenzhb/bioplm_injectingknowledge)

---

[**The Art of SOCRATIC QUESTIONING: Zero-shot Multimodal Reasoning with Recursive Thinking and Self-Questioning**](https://arxiv.org/abs/2305.14999) Ôºà**2023.05.24**Ôºâ

<font color="gray">Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu, Di Jin, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)

---

[**Reasoning with Language Model is Planning with World Model**](https://arxiv.org/abs/2305.14992) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-149-red)  [![](https://img.shields.io/badge/Github%20Stars-965-blue)](https://github.com/ber666/llm-reasoners)

---

[**MuLER: Detailed and Scalable Reference-based Evaluation**](https://arxiv.org/abs/2305.14991) Ôºà**2023.05.24**Ôºâ

<font color="gray">Taelin Karidi, Leshem Choshen, Gal Patel, Omri Abend </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Large Language Models are Effective Table-to-Text Generators, Evaluators, and Feedback Providers**](https://arxiv.org/abs/2305.14987) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru Tang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)

---

[**Improving Factuality of Abstractive Summarization without Sacrificing Summary Quality**](https://arxiv.org/abs/2305.14981) Ôºà**2023.05.24**Ôºâ

<font color="gray">Tanay Dixit, Fei Wang, Muhao Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-15-red)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/tanay2001/efactsum)

---

[**MMNet: Multi-Mask Network for Referring Image Segmentation**](https://arxiv.org/abs/2305.14969) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yichen Yan, Xingjian He, Wenxuan Wan, Jing Liu </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks**](https://arxiv.org/abs/2305.14965) Ôºà**2023.05.24**Ôºâ

<font color="gray">Abhinav Rao, Sachin Vashistha, Atharva Naik, Somak Aditya, Monojit Choudhury </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**Editing Commonsense Knowledge in GPT**](https://arxiv.org/abs/2305.14956) Ôºà**2023.05.24**Ôºâ

<font color="gray">Anshita Gupta, Debanjan Mondal, Akshay Krishna Sheshadri, Wenlong Zhao, Xiang Lorraine Li, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)

---

[**Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low Resource Languages**](https://arxiv.org/abs/2305.14949) Ôºà**2023.05.24**Ôºâ

<font color="gray">Qi Gou, Zehua Xia, Wen-Hau Du </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Trade-Offs Between Fairness and Privacy in Language Modeling**](https://arxiv.org/abs/2305.14936) Ôºà**2023.05.24**Ôºâ

<font color="gray">Cleo Matzken, Steffen Eger, Ivan Habernal </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)  [![](https://img.shields.io/badge/Github%20Stars-1-blue)](https://github.com/cleolotta/fair-and-private-lm)

---

[**Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning**](https://arxiv.org/abs/2305.14909) Ôºà**2023.05.24**Ôºâ

<font color="gray">L. Guan, Karthik Valmeekam, Sarath Sreedharan, Subbarao Kambhampati </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-43-red)

---

[**M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection**](https://arxiv.org/abs/2305.14902) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-65-blue)](https://github.com/mbzuai-nlp/semeval2024-task8)

---

[**PIVOINE: Instruction Tuning for Open-world Information Extraction**](https://arxiv.org/abs/2305.14898) Ôºà**2023.05.24**Ôºâ

<font color="gray">Keming Lu, Xiaoman Pan, Kaiqiang Song, Hongming Zhang, Dong Yu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)  [![](https://img.shields.io/badge/Github%20Stars-20-blue)](https://github.com/lukeming-tsinghua/instruction-tuning-for-open-world-ie)

---

[**Text encoders are performance bottlenecks in contrastive vision-language models**](https://arxiv.org/abs/2305.14897) Ôºà**2023.05.24**Ôºâ

<font color="gray">Amita Kamath, Jack Hessel, Kai-Wei Chang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**HARD: Hard Augmentations for Robust Distillation**](https://arxiv.org/abs/2305.14890) Ôºà**2023.05.24**Ôºâ

<font color="gray">Arne F. Nix, Max F. Burg, Fabian H Sinz </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Privacy Implications of Retrieval-Based Language Models**](https://arxiv.org/abs/2305.14888) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yangsibo Huang, Samyak Gupta, Zexuan Zhong, Kai Li, Danqi Chen </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-34-blue)](https://github.com/princeton-sysml/knnlm_privacy)

---

[**Interpretable by Design Visual Question Answering**](https://arxiv.org/abs/2305.14882) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xingyu Fu, Ben Zhou, Sihao Chen, Mark Yatskar, D. Roth </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**Leveraging GPT-4 for Automatic Translation Post-Editing**](https://arxiv.org/abs/2305.14878) Ôºà**2023.05.24**Ôºâ

<font color="gray">Vikas Raunak, Amr Sharaf, Hany Hassan Awadallah, Arul Menezes </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-26-red)

---

[**CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering**](https://arxiv.org/abs/2305.14869) Ôºà**2023.05.24**Ôºâ

<font color="gray">Weiqi Wang, Tianqing Fang, Wenxuan Ding, Baixuan Xu, Xin Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)  [![](https://img.shields.io/badge/Github%20Stars-7-blue)](https://github.com/hkust-knowcomp/car)

---

[**Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers**](https://arxiv.org/abs/2305.14858) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zixuan Jiang, Jiaqi Gu, Hanqing Zhu, D. Pan </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-18-blue)](https://github.com/zixuanjiang/pre-rmsnorm-transformer)

---

[**Towards Few-shot Entity Recognition in Document Images: A Graph Neural Network Approach Robust to Image Manipulation**](https://arxiv.org/abs/2305.14828) Ôºà**2023.05.24**Ôºâ

<font color="gray">Prashant Krishnan, Zilong Wang, Yangkun Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)

---

[**Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification**](https://arxiv.org/abs/2305.14794) Ôºà**2023.05.24**Ôºâ

<font color="gray">Chengyu Dong, Zihan Wang, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Text Conditional Alt-Text Generation for Twitter Images**](https://arxiv.org/abs/2305.14779) Ôºà**2023.05.24**Ôºâ

<font color="gray">Nikita Srivatsan, Sofia Samaniego, Omar Florez, Taylor Berg-Kirkpatrick </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**A Controllable QA-based Framework for Decontextualization**](https://arxiv.org/abs/2305.14772) Ôºà**2023.05.24**Ôºâ

<font color="gray">Benjamin Newman, Luca Soldaini, Raymond Fok, Arman Cohan, Kyle Lo </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)

---

[**SSD-2: Scaling and Inference-time Fusion of Diffusion Language Models**](https://arxiv.org/abs/2305.14771) Ôºà**2023.05.24**Ôºâ

<font color="gray">Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov, Marjan Ghazvininejad </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning**](https://arxiv.org/abs/2305.14761) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, Shafiq Joty </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-21-red)  [![](https://img.shields.io/badge/Github%20Stars-53-blue)](https://github.com/vis-nlp/unichart)

---

[**ChatFace: Chat-Guided Real Face Editing via Diffusion Latent Space Manipulation**](https://arxiv.org/abs/2305.14742) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dongxu Yue, Qin Guo, Munan Ning, Jiaxi Cui, Yuesheng Zhu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)

---

[**Trusting Your Evidence: Hallucinate Less with Context-aware Decoding**](https://arxiv.org/abs/2305.14739) Ôºà**2023.05.24**Ôºâ

<font color="gray">Weijia Shi, Xiaochuang Han, M. Lewis, Yulia Tsvetkov, Luke Zettlemoyer, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-52-red)

---

[**GlobalBench: A Benchmark for Global Progress in Natural Language Processing**](https://arxiv.org/abs/2305.14716) Ôºà**2023.05.24**Ôºâ

<font color="gray">Y. Song, Catherine Cui, Simran Khanuja, Pengfei Liu, FAHIM FAISAL, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)

---

[**The student becomes the master: Matching GPT3 on Scientific Factual Error Correction**](https://arxiv.org/abs/2305.14707) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dhananjay Ashok, Atharva Kulkarni, Hai Pham, Barnab'as P'oczos </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**PruMUX: Augmenting Data Multiplexing with Model Compression**](https://arxiv.org/abs/2305.14706) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yushan Su, Vishvak S. Murahari, Karthik Narasimhan, Kai Li </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/yushansu/prumux)

---

[**Flan-MoE: Scaling Instruction-Finetuned Language Models with Sparse Mixture of Experts**](https://arxiv.org/abs/2305.14705) Ôºà**2023.05.24**Ôºâ

<font color="gray">Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-90-red)

---

[**SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to Rank**](https://arxiv.org/abs/2305.14696) Ôºà**2023.05.24**Ôºâ

<font color="gray">Dheeraj Mekala, Adithya Samavedhi, Chengyu Dong, Jingbo Shang </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval**](https://arxiv.org/abs/2305.14685) Ôºà**2023.05.24**Ôºâ

<font color="gray">S. Yu, Chenghao Fan, Chenyan Xiong, David Jin, Zhiyuan Liu, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/openmatch/fit5)

---

[**Emergent inabilities? Inverse scaling over the course of pretraining**](https://arxiv.org/abs/2305.14681) Ôºà**2023.05.24**Ôºâ

<font color="gray">James A. Michaelov, B. Bergen </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Optimal Linear Subspace Search: Learning to Construct Fast and High-Quality Schedulers for Diffusion Models**](https://arxiv.org/abs/2305.14677) Ôºà**2023.05.24**Ôºâ

<font color="gray">Zhongjie Duan, Chengyu Wang, Cen Chen, Jun Huang, Weining Qian </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2.0k-blue)](https://github.com/alibaba/EasyNLP/tree/master/diffusion/olss_scheduler)

---

[**InteractiveIE: Towards Assessing the Strength of Human-AI Collaboration in Improving the Performance of Information Extraction**](https://arxiv.org/abs/2305.14659) Ôºà**2023.05.24**Ôºâ

<font color="gray">Ishani Mondal, Michelle Yuan, N Anandhavelu, Aparna Garimella, Francis Ferraro, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2-red)

---

[**A Joint Time-frequency Domain Transformer for Multivariate Time Series Forecasting**](https://arxiv.org/abs/2305.14649) Ôºà**2023.05.24**Ôºâ

<font color="gray">Yushu Chen, Shengzhuo Liu, Jinzhe Yang, Hao Jing, Wenlai Zhao, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/rationalspark/jtft)

---

[**Meta-review Generation with Checklist-guided Iterative Introspection**](https://arxiv.org/abs/2305.14647) Ôºà**2023.05.24**Ôºâ

<font color="gray">Qi Zeng, Mankeerat S. Sidhu, Hou Pong Chan, Lu Wang, Heng Ji </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Reinforcement Learning finetuned Vision-Code Transformer for UI-to-Code Generation**](https://arxiv.org/abs/2305.14637) Ôºà**2023.05.24**Ôºâ

<font color="gray">Davit Soselia, Khalid Saifullah, Tianyi Zhou </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-4-red)

---

[**KNN-LM Does Not Improve Open-ended Text Generation**](https://arxiv.org/abs/2305.14625) Ôºà**2023.05.24**Ôºâ

<font color="gray">Shufan Wang, Yixiao Song, Andrew Drozdov, Aparna Garimella, Varun Manjunatha, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**Language Models with Rationality**](https://arxiv.org/abs/2305.14250) Ôºà**2023.05.23**Ôºâ

<font color="gray">Nora Kassner, Oyvind Tafjord, Ashish Sabharwal, Kyle Richardson, Hinrich Sch√ºtze, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)

---

[**Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?**](https://arxiv.org/abs/2305.14578) Ôºà**2023.05.23**Ôºâ

<font color="gray">Margarita Bugueno, Gerard de Melo </font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/buguemar/grtc_gnns)

---

[**A Trip Towards Fairness: Bias and De-Biasing in Large Language Models**](https://arxiv.org/abs/2305.13862) Ôºà**2023.05.23**Ôºâ

<font color="gray">Leonardo Ranaldi, Elena Sofia Ruzzetti, Davide Venditti, Dario Onorati, Fabio Massimo Zanzotto </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)

---

[**Question Answering as Programming for Solving Time-Sensitive Questions**](https://arxiv.org/abs/2305.14221) Ôºà**2023.05.23**Ôºâ

<font color="gray">Xinyu Zhu, Cheng Yang, Bei Chen, Siheng Li, Jian-Guang Lou, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/tianhongzxy/qaap)

---

[**PaD: Program-aided Distillation Specializes Large Models in Reasoning**](https://arxiv.org/abs/2305.13888) Ôºà**2023.05.23**Ôºâ

<font color="gray">Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xingwei Long, Bowen Zhou </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)

---

[**Aligning Large Language Models through Synthetic Feedback**](https://arxiv.org/abs/2305.13735) Ôºà**2023.05.23**Ôºâ

<font color="gray">Sungdong Kim, Sanghwan Bae, Jamin Shin, Soyoung Kang, Donghyun Kwak, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-38-red)  [![](https://img.shields.io/badge/Github%20Stars-22-blue)](https://github.com/naver-ai/almost)

---

[**LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large Language Models**](https://arxiv.org/abs/2305.13718) Ôºà**2023.05.23**Ôºâ

<font color="gray">Fangkai Jiao, Zhiyang Teng, Shafiq Joty, Bosheng Ding, Aixin Sun, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**ViT-TTS: Visual Text-to-Speech with Scalable Diffusion Transformer**](https://doi.org/10.48550/arXiv.2305.12708) Ôºà**2023.05.22**Ôºâ

<font color="gray">Huadai Liu, Rongjie Huang, Xuan Lin, Wenqiang Xu, Maozong Zheng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules**](https://arxiv.org/abs/2305.13406) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yanchen Liu, William Held, Diyi Yang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/salt-nlp/dada)

---

[**Knowledge-Retrieval Task-Oriented Dialog Systems with Semi-Supervision**](https://arxiv.org/abs/2305.13199) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yucheng Cai, Hong Liu, Zhijian Ou, Y. Huang, Junlan Feng </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/thu-spmi/jsa-krtod)

---

[**Sentence Representations via Gaussian Embedding**](https://arxiv.org/abs/2305.12990) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shohei Yoda, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**MacLaSa: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space**](https://arxiv.org/abs/2305.12785) Ôºà**2023.05.22**Ôºâ

<font color="gray">Hanxing Ding, Liang Pang, Z. Wei, Huawei Shen, Xueqi Cheng, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-7-red)  [![](https://img.shields.io/badge/Github%20Stars-6-blue)](https://github.com/trustedllm/maclasa)

---

[**Keeping Up with the Language Models: Robustness-Bias Interplay in NLI Data and Models**](https://arxiv.org/abs/2305.12620) Ôºà**2023.05.22**Ôºâ

<font color="gray">Ioana Baldini, Chhavi Yadav, Payel Das, K. Varshney </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis**](https://arxiv.org/abs/2305.13230) Ôºà**2023.05.22**Ôºâ

<font color="gray">Fuzhao Xue, Yao Fu, Wangchunshu Zhou, Zangwei Zheng, Yang You </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-56-red)

---

[**Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A Preliminary Study on Writing Assistance**](https://arxiv.org/abs/2305.13225) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yue Zhang, Leyang Cui, Deng Cai, Xinting Huang, Tao Fang, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-16-red)

---

[**InheritSumm: A General, Versatile and Compact Summarizer by Distilling from GPT**](https://arxiv.org/abs/2305.13083) Ôºà**2023.05.22**Ôºâ

<font color="gray">Yichong Xu, Ruochen Xu, Dan Iter, Yang Liu, Shuo Wang, etc </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Making Language Models Better Tool Learners with Execution Feedback**](https://arxiv.org/abs/2305.13068) Ôºà**2023.05.22**Ôºâ

<font color="gray">Shuofei Qiao, Honghao Gui, Huajun Chen, Ningyu Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)  [![](https://img.shields.io/badge/Github%20Stars-32-blue)](https://github.com/zjunlp/trice)

---

[**GPT-SW3: An Autoregressive Language Model for the Nordic Languages**](https://arxiv.org/abs/2305.12987) Ôºà**2023.05.22**Ôºâ

<font color="gray">Ariel Ekgren, Amaru Cuba Gyllensten, F. Stollenwerk, Joey Ohman, Tim Isbister, etc </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-6-red)

---

[**ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination**](https://arxiv.org/abs/2305.12945) Ôºà**2023.05.22**Ôºâ

<font color="gray">Dongfang Li, Jindi Yu, Baotian Hu, Zhenran Xu, Min Zhang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-8-red)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/hitsz-tmg/explaincpe)

---

[**Infor-Coef: Information Bottleneck-based Dynamic Token Downsampling for Compact and Efficient language model**](https://arxiv.org/abs/2305.12458) Ôºà**2023.05.21**Ôºâ

<font color="gray">Wenxin Tan </font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text**](https://arxiv.org/abs/2305.12599) Ôºà**2023.05.21**Ôºâ

<font color="gray">Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-3-red)

---

[**Retrieving Texts based on Abstract Descriptions**](https://arxiv.org/abs/2305.12517) Ôºà**2023.05.21**Ôºâ

<font color="gray">Shauli Ravfogel, Valentina Pyatkin, Amir D. N. Cohen, Avshalom Manevich, Yoav Goldberg </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-14-red)

---

[**Pruning Pre-trained Language Models with Principled Importance and Self-regularization**](https://arxiv.org/abs/2305.12394) Ôºà**2023.05.21**Ôºâ

<font color="gray">Siyu Ren, Kenny Q. Zhu </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-10-red)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/drsy/pins)

---

[**Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers**](https://arxiv.org/abs/2305.12567) Ôºà**2023.05.21**Ôºâ

<font color="gray">Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-12-red)  [![](https://img.shields.io/badge/Github%20Stars-20-blue)](https://github.com/gonglinyuan/metro_t0)

---

[**Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs**](https://arxiv.org/abs/2305.12191) Ôºà**2023.05.20**Ôºâ

<font color="gray">Yatin Nandwani, Vineet Kumar, Dinesh Raghu, Sachindra Joshi, L. Lastras </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-5-red)  [![](https://img.shields.io/badge/Github%20Stars-5-blue)](https://github.com/ynandwan/pmi-faith)

---

[**Towards Accurate Image Coding: Improved Autoregressive Image Generation with Dynamic Vector Quantization**](https://doi.org/10.48550/arXiv.2305.11718) Ôºà**2023.05.19**Ôºâ

<font color="gray">Mengqi Huang, Zhendong Mao, Zhuowei Chen, Yongdong Zhang .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-121-blue)](https://github.com/crossmodalgroup/dynamicvectorquantization)

---

[**Late-Constraint Diffusion Guidance for Controllable Image Synthesis**](https://doi.org/10.48550/arXiv.2305.11520) Ôºà**2023.05.19**Ôºâ

<font color="gray">Chang Liu, Dong Liu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Self-QA: Unsupervised Knowledge Guided Language Model Alignment**](https://arxiv.org/abs/2305.11952) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xuanyu Zhang, Qing Yang </font>

![](https://img.shields.io/badge/Citations-1-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-13-red)  [![](https://img.shields.io/badge/Github%20Stars-930-blue)](https://github.com/duxiaoman-di/xuanyuan)

---

[**Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions**](https://doi.org/10.48550/arXiv.2305.11460) Ôºà**2023.05.19**Ôºâ

<font color="gray">Shiyao Ding, Takayuki Ito .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases**](https://arxiv.org/abs/2305.12018) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xin Liu, Muhammad Khalifa, Lu Wang </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-9-red)  [![](https://img.shields.io/badge/Github%20Stars-14-blue)](https://github.com/launchnlp/bolt)

---

[**STOAT: Structured Data to Analytical Text With Controls**](https://doi.org/10.48550/arXiv.2305.11826) Ôºà**2023.05.19**Ôºâ

<font color="gray">Deepanway Ghosal, Preksha Nema, A. Raghuveer .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Decouple knowledge from paramters for plug-and-play language modeling**](https://doi.org/10.48550/arXiv.2305.11564) Ôºà**2023.05.19**Ôºâ

<font color="gray">Xin Cheng, Yankai Lin, Xiuying Chen, Dongyan Zhao, Rui Yan .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona**](https://doi.org/10.48550/arXiv.2305.11482) Ôºà**2023.05.19**Ôºâ

<font color="gray">Yihong Tang, Bo Wang, Miao Fang, Dongming Zhao, Kun Huang, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-8-blue)](https://github.com/toyhom/clv)

---

[**LLM Itself Can Read and Generate CXR Images**](https://doi.org/10.48550/arXiv.2305.11490) Ôºà**2023.05.19**Ôºâ

<font color="gray">Suhyeon Lee, Won Jun Kim, Jong-Chul Ye .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Post Hoc Explanations of Language Models Can Improve Language Models**](https://doi.org/10.48550/arXiv.2305.11426) Ôºà**2023.05.19**Ôºâ

<font color="gray">Satyapriya, Krishna, Jiaqi Ma, Dylan Slack, Asma Ghandeharioun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models**](https://doi.org/10.48550/arXiv.2305.11414) Ôºà**2023.05.19**Ôºâ

<font color="gray">Sixing Yu, J. P. Mu√±oz, A. Jannesari .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning**](https://doi.org/10.48550/arXiv.2305.11383) Ôºà**2023.05.19**Ôºâ

<font color="gray">Po-Nien Kung, Nanyun Peng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Democratized Diffusion Language Model**](https://doi.org/10.48550/arXiv.2305.10818) Ôºà**2023.05.18**Ôºâ

<font color="gray">Nikita Balagansky, Daniil Gavrilov .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**VideoFactory: Swap Attention in Spatiotemporal Diffusions for Text-to-Video Generation**](https://doi.org/10.48550/arXiv.2305.10874) Ôºà**2023.05.18**Ôºâ

<font color="gray">Wenjing Wang, Huan Yang, Zixi Tuo, Huiguo He, Junchen Zhu, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-1-green)

---

[**LDM3D: Latent Diffusion Model for 3D**](https://doi.org/10.48550/arXiv.2305.10853) Ôºà**2023.05.18**Ôºâ

<font color="gray">Gabriela Ben Melech Stan, Diana Wofk, Scottie Fox, Alex Redden, Will Saxton, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-4.3k-blue)](https://github.com/intel-isl/MiDaS)

---

[**Catch-Up Distillation: You Only Need to Train Once for Accelerating Sampling**](https://doi.org/10.48550/arXiv.2305.10769) Ôºà**2023.05.18**Ôºâ

<font color="gray">Shitong Shao, Xu Dai, Shouyi Yin, Lujun Li, Huanran Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-3-blue)](https://github.com/shaoshitong/Catch-Up-Distillation)

---

[**Ahead-of-Time P-Tuning**](https://doi.org/10.48550/arXiv.2305.10835) Ôºà**2023.05.18**Ôºâ

<font color="gray">Daniil Gavrilov, Nikita Balagansky .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Zero-Day Backdoor Attack against Text-to-Image Diffusion Models via Personalization**](https://doi.org/10.48550/arXiv.2305.10701) Ôºà**2023.05.18**Ôºâ

<font color="gray">Yihao Huang, Qing Guo, Felix Juefei-Xu .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation**](https://doi.org/10.48550/arXiv.2305.11130) Ôºà**2023.05.18**Ôºâ

<font color="gray">Junkai Zhou, Liang Pang, Huawei Shen, Xueqi Cheng .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/934865517zjk/simoap)

---

[**How does the task complexity of masked pretraining objectives affect downstream performance?**](https://doi.org/10.48550/arXiv.2305.10992) Ôºà**2023.05.18**Ôºâ

<font color="gray">Atsuki Yamaguchi, Hiroaki Ozaki, Terufumi Morishita, Gaku Morio, Yasuhiro Sogawa .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-2-blue)](https://github.com/hitachi-nlp/mlm-probe-acl2023)

---

[**Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings**](https://doi.org/10.48550/arXiv.2305.10786) Ôºà**2023.05.18**Ôºâ

<font color="gray">Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Chong Deng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-97-blue)](https://github.com/alibaba-damo-academy/spokennlp)

---

[**ReGen: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval**](https://doi.org/10.48550/arXiv.2305.10703) Ôºà**2023.05.18**Ôºâ

<font color="gray">Yue Yu, Yuchen Zhuang, Rongzhi Zhang, Yu Meng, Jiaming Shen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-18-blue)](https://github.com/yueyu1030/ReGen)

---

[**LIMA: Less Is More for Alignment**](https://doi.org/10.48550/arXiv.2305.11206) Ôºà**2023.05.18**Ôºâ

<font color="gray">Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)  [![](https://img.shields.io/badge/Github%20Stars-2.6k-blue)](https://github.com/alpha-vllm/llama2-accessory)

---

[**The Web Can Be Your Oyster for Improving Large Language Models**](https://doi.org/10.48550/arXiv.2305.10998) Ôºà**2023.05.18**Ôºâ

<font color="gray">Junyi Li, Tianyi Tang, Wayne Xin Zhao, Jingyuan Wang, J. Nie, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-10-blue)](https://github.com/rucaibox/uniweb)

---

[**TOME: A Two-stage Approach for Model-based Retrieval**](https://doi.org/10.48550/arXiv.2305.11161) Ôºà**2023.05.18**Ôºâ

<font color="gray">Ruiyang Ren, Wayne Xin Zhao, J. Liu, Huaqin Wu, Ji-rong Wen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**When Gradient Descent Meets Derivative-Free Optimization: A Match Made in Black-Box Scenario**](https://doi.org/10.48550/arXiv.2305.10013) Ôºà**2023.05.17**Ôºâ

<font color="gray">Chengcheng Han, Liqing Cui, Renyu Zhu, J. Wang, Nuo Chen, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**SLiC-HF: Sequence Likelihood Calibration with Human Feedback**](https://doi.org/10.48550/arXiv.2305.10425) Ôºà**2023.05.17**Ôºâ

<font color="gray">Yao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-2-green)

---

[**LeTI: Learning to Generate from Textual Interactions**](https://doi.org/10.48550/arXiv.2305.10314) Ôºà**2023.05.17**Ôºâ

<font color="gray">Xingyao Wang, Hao Peng, Reyhaneh Jabbarvand, Heng Ji .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-61-blue)](https://github.com/xingyaoww/leti)

---

[**M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models**](https://doi.org/10.48550/arXiv.2305.10263) Ôºà**2023.05.17**Ôºâ

<font color="gray">Chuang Liu, Renren Jin, Yuqi Ren, Linhao Yu, Tianyu Dong, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)  [![](https://img.shields.io/badge/Github%20Stars-90-blue)](https://github.com/tjunlp-lab/m3ke)

---

[**Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling**](https://doi.org/10.48550/arXiv.2305.09993) Ôºà**2023.05.17**Ôºâ

<font color="gray">Weijia Xu, Andrzej Banburski-Fahey, N. Jojic .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Prompt Engineering for Healthcare: Methodologies and Applications**](https://doi.org/10.48550/arXiv.2304.14670) Ôºà**2023.04.28**Ôºâ

<font color="gray">Jiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Chong Ma, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond**](https://arxiv.org/abs/2304.13712) Ôºà**2023.04.26**Ôºâ

<font color="gray">Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, etc </font>

![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-562-red)  [![](https://img.shields.io/badge/Github%20Stars-9.0k-blue)](https://github.com/mooler0410/llmspracticalguide)

---

[**A Survey of Large Language Models**](https://arxiv.org/abs/2303.18223) Ôºà**2023.03.31**Ôºâ



![](https://img.shields.io/badge/Citations-0-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-1.9k-red)

---

[**On the Creativity of Large Language Models**](https://doi.org/10.48550/arXiv.2304.00008) Ôºà**2023.03.27**Ôºâ

<font color="gray">Giorgio Franceschelli, Mirco Musolesi .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-3-green)

---

[**Augmented Language Models: a Survey**](https://doi.org/10.48550/arXiv.2302.07842) Ôºà**2023.02.15**Ôºâ

<font color="gray">Gr√©goire Mialon, Roberto Dess√¨, M. Lomeli, Christoforos Nalmpantis, Ramakanth Pasunuru, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-4-green)

---

[**A Survey for In-context Learning**](https://doi.org/10.48550/arXiv.2301.00234) Ôºà**2022.12.31**Ôºâ

<font color="gray">Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-0-green)

---

[**Towards Reasoning in Large Language Models: A Survey**](https://doi.org/10.48550/arXiv.2212.10403) Ôºà**2022.12.20**Ôºâ

<font color="gray">Jie Huang, K. Chang .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-5-green)  [![](https://img.shields.io/badge/Github%20Stars-510-blue)](https://github.com/jeffhj/lm-reasoning)

---

[**Reasoning with Language Model Prompting: A Survey**](https://doi.org/10.48550/arXiv.2212.09597) Ôºà**2022.12.19**Ôºâ

<font color="gray">Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, etc .  - „ÄêArXiv„Äë</font>

![](https://img.shields.io/badge/Citations-7-green)  [![](https://img.shields.io/badge/Github%20Stars-826-blue)](https://github.com/zjunlp/Prompt4ReasoningPapers)

---

[**Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**](https://doi.org/10.1145/3560815) Ôºà**2021.07.28**Ôºâ

<font color="gray">Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, etc .  - „ÄêACM Computing Surveys„Äë</font>

![](https://img.shields.io/badge/Citations-462-green)  ![](https://img.shields.io/badge/Mendeley%20Readers-2.2k-red)  [![](https://img.shields.io/badge/Github%20Stars-376-blue)](https://github.com/pfliu-nlp/NLPedia-Pretrain)

---

[**Aligning Large Language Models with Human: A Survey**](https://doi.org/10.48550/arXiv.2307.12966) 

<font color="gray">Yufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xingshan Zeng, etc .  - „ÄêarXiv.org„Äë</font>

![](https://img.shields.io/badge/Citations-18-green)  [![](https://img.shields.io/badge/Github%20Stars-637-blue)](https://github.com/garyyufei/alignllmhumansurvey)


</div>

# CONTINUE...