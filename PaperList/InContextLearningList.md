# 📄 In-context Learning

## Paper List

[**Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning**](https://doi.org/10.48550/arXiv.2301.11916) 👨‍🎓Xinyi Wang,Wanrong Zhu,William Yang Wang 2023 ![](https://img.shields.io/badge/pub-2023--01--27-green)![](https://img.shields.io/badge/cite-1-red)

[**OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization**](https://doi.org/10.48550/arXiv.2212.12017) 👨‍🎓S. Iyer,Xiaojuan Lin,Ramakanth Pasunuru,Todor Mihaylov,Daniel Simig,Ping Yu etc 2022 ![](https://img.shields.io/badge/pub-2022--12--22-green)![](https://img.shields.io/badge/cite-9-red)

[**Prompt-Augmented Linear Probing: Scaling Beyond The Limit of Few-shot In-Context Learners**](https://doi.org/10.48550/arXiv.2212.10873) 👨‍🎓Hyunsoo Cho,Hyuhng Joon Kim,Junyeob Kim,Sang-Woo Lee,Sang-goo Lee,Kang Min Yoo etc 2022 ![](https://img.shields.io/badge/pub-2022--12--21-green)![](https://img.shields.io/badge/cite-2-red)

[**Self-adaptive In-context Learning**](https://doi.org/10.48550/arXiv.2212.10375) 👨‍🎓Zhiyong Wu,Yaoxiang Wang,Jiacheng Ye,Lingpeng Kong 2022 ![](https://img.shields.io/badge/pub-2022--12--20-green)![](https://img.shields.io/badge/cite-2-red)

[**Is GPT-3 a Good Data Annotator?**](https://doi.org/10.48550/arXiv.2212.10450) 👨‍🎓Bosheng Ding,Chengwei Qin,Linlin Liu,Lidong Bing,Shafiq R. Joty,Boyang Li etc 2022 ![](https://img.shields.io/badge/pub-2022--12--20-green)![](https://img.shields.io/badge/cite-2-red)

[**Reasoning with Language Model Prompting: A Survey**](https://doi.org/10.48550/arXiv.2212.09597) 👨‍🎓Shuofei Qiao,Yixin Ou,Ningyu Zhang,Xiang Chen,Yunzhi Yao,Shumin Deng etc 2022 ![](https://img.shields.io/badge/pub-2022--12--19-green)![](https://img.shields.io/badge/cite-7-red)

[**Structured Prompting: Scaling In-Context Learning to 1, 000 Examples**](https://doi.org/10.48550/arXiv.2212.06713) 👨‍🎓Y. Hao,Yutao Sun,Li Dong,Zhixiong Han,Yuxian Gu,Furu Wei etc 2022 ![](https://img.shields.io/badge/pub-2022--12--13-green)![](https://img.shields.io/badge/cite-2-red)

[**Complementary Explanations for Effective In-Context Learning**](https://doi.org/10.48550/arXiv.2211.13892) 👨‍🎓Xi Ye,Srini Iyer,Asli Celikyilmaz,V. Stoyanov,Greg Durrett,Ramakanth Pasunuru etc 2022 ![](https://img.shields.io/badge/pub-2022--11--25-green)![](https://img.shields.io/badge/cite-5-red)

[**Active Example Selection for In-Context Learning**](https://doi.org/10.48550/arXiv.2211.04486) 👨‍🎓Yiming Zhang,Shi Feng,Chenhao Tan 2022 ![](https://img.shields.io/badge/pub-2022--11--08-green)![](https://img.shields.io/badge/cite-6-red)

[**Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning**](https://doi.org/10.48550/arXiv.2211.03044) 👨‍🎓Yu Meng,Martin Michalski,Jiaxin Huang,Yu Zhang,T. Abdelzaher,Jiawei Han etc 2022 ![](https://img.shields.io/badge/pub-2022--11--06-green)![](https://img.shields.io/badge/cite-2-red)

[**Large Language Models Are Human-Level Prompt Engineers**](https://doi.org/10.48550/arXiv.2211.01910) 👨‍🎓Yongchao Zhou,Andrei Ioan Muresanu,Ziwen Han,Keiran Paster,Silviu Pitis,Harris Chan etc 2022 ![](https://img.shields.io/badge/pub-2022--11--03-green)![](https://img.shields.io/badge/cite-19-red)

[**ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback**](https://doi.org/10.48550/arXiv.2210.12329) 👨‍🎓Jiacheng Ye,Jiahui Gao,Jiangtao Feng,Zhiyong Wu,Tao Yu,Lingpeng Kong etc 2022 ![](https://img.shields.io/badge/pub-2022--10--22-green)![](https://img.shields.io/badge/cite-3-red)

[**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**](https://doi.org/10.48550/arXiv.2210.09261) 👨‍🎓Mirac Suzgun,Nathan Scales,Nathanael Scharli,Sebastian Gehrmann,Yi Tay,Hyung Won Chung etc 2022 ![](https://img.shields.io/badge/pub-2022--10--17-green)![](https://img.shields.io/badge/cite-27-red)

[**Prompting GPT-3 To Be Reliable**](https://doi.org/10.48550/arXiv.2210.09150) 👨‍🎓Chenglei Si,Zhe Gan,Zhengyuan Yang,Shuohang Wang,Jianfeng Wang,Jordan L. Boyd-Graber etc 2022 ![](https://img.shields.io/badge/pub-2022--10--17-green)![](https://img.shields.io/badge/cite-9-red)

[**Automatic Chain of Thought Prompting in Large Language Models**](https://doi.org/10.48550/arXiv.2210.03493) 👨‍🎓Zhuosheng Zhang,Aston Zhang,Mu Li,Alexander J. Smola 2022 ![](https://img.shields.io/badge/pub-2022--10--07-green)![](https://img.shields.io/badge/cite-21-red)

[**Language Models are Multilingual Chain-of-Thought Reasoners**](https://doi.org/10.48550/arXiv.2210.03057) 👨‍🎓Freda Shi,Mirac Suzgun,Markus Freitag,Xuezhi Wang,Suraj Srivats,Soroush Vosoughi etc 2022 ![](https://img.shields.io/badge/pub-2022--10--06-green)![](https://img.shields.io/badge/cite-19-red)

[**Complexity-Based Prompting for Multi-Step Reasoning**](https://doi.org/10.48550/arXiv.2210.00720) 👨‍🎓Yao Fu,Hao-Chun Peng,Ashish Sabharwal,Peter Clark,Tushar Khot 2022 ![](https://img.shields.io/badge/pub-2022--10--03-green)![](https://img.shields.io/badge/cite-17-red)

[**In-context Learning and Induction Heads**](https://doi.org/10.48550/arXiv.2209.11895) 👨‍🎓Catherine Olsson,Nelson Elhage,Neel Nanda,Nicholas Joseph,Nova DasSarma,T. Henighan etc 2022 ![](https://img.shields.io/badge/pub-2022--09--24-green)![](https://img.shields.io/badge/cite-32-red)

[**On the Relation between Sensitivity and Accuracy in In-context Learning**](https://doi.org/10.48550/arXiv.2209.07661) 👨‍🎓Yanda Chen,Chen Zhao,Zhou Yu,K. McKeown,He He 2022 ![](https://img.shields.io/badge/pub-2022--09--16-green)![](https://img.shields.io/badge/cite-8-red)

[**Selective Annotation Makes Language Models Better Few-Shot Learners**](https://doi.org/10.48550/arXiv.2209.01975) 👨‍🎓Hongjin Su,Jungo Kasai,Chen Henry Wu,Weijia Shi,Tianlu Wang,Jiayi Xin etc 2022 ![](https://img.shields.io/badge/pub-2022--09--05-green)![](https://img.shields.io/badge/cite-20-red)

[**What Can Transformers Learn In-Context? A Case Study of Simple Function Classes**](https://doi.org/10.48550/arXiv.2208.01066) 👨‍🎓Shivam Garg,Dimitris Tsipras,Percy Liang,G. Valiant 2022 ![](https://img.shields.io/badge/pub-2022--08--01-green)![](https://img.shields.io/badge/cite-24-red)

[**Rationale-Augmented Ensembles in Language Models**](https://doi.org/10.48550/arXiv.2207.00747) 👨‍🎓Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou etc 2022 ![](https://img.shields.io/badge/pub-2022--07--02-green)![](https://img.shields.io/badge/cite-25-red)

[**Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator**](https://doi.org/10.48550/arXiv.2206.08082) 👨‍🎓Hyuhng Joon Kim,Hyunsoo Cho,Junyeob Kim,Taeuk Kim,Kang Min Yoo,Sang-goo Lee etc 2022 ![](https://img.shields.io/badge/pub-2022--06--16-green)![](https://img.shields.io/badge/cite-1-red)

[**Emergent Abilities of Large Language Models**](https://doi.org/10.48550/arXiv.2206.07682) 👨‍🎓Jason Wei,Yi Tay,Rishi Bommasani,Colin Raffel,Barret Zoph,Sebastian Borgeaud etc 2022 ![](https://img.shields.io/badge/pub-2022--06--15-green)![](https://img.shields.io/badge/cite-142-red)

[**RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning**](https://doi.org/10.48550/arXiv.2205.12548) 👨‍🎓Mingkai Deng,Jianyu Wang,Cheng-Ping Hsieh,Yihan Wang,Han Guo,Tianmin Shu etc 2022 ![](https://img.shields.io/badge/pub-2022--05--25-green)![](https://img.shields.io/badge/cite-25-red)

[**Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations**](https://doi.org/10.48550/arXiv.2205.12685) 👨‍🎓Junyeob Kim,Hyuhng Joon Kim,Hyunsoo Cho,Hwiyeol Jo,Sang-Woo Lee,Sang-goo Lee etc 2022 ![](https://img.shields.io/badge/pub-2022--05--25-green)![](https://img.shields.io/badge/cite-11-red)

[**Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations**](https://doi.org/10.48550/arXiv.2205.11822) 👨‍🎓Jaehun Jung,Lianhui Qin,S. Welleck,Faeze Brahman,Chandra Bhagavatula,Ronan Le Bras etc 2022 ![](https://img.shields.io/badge/pub-2022--05--24-green)![](https://img.shields.io/badge/cite-25-red)

[**Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing**](https://doi.org/10.48550/arXiv.2205.12253) 👨‍🎓Linlu Qiu,Peter Shaw,Panupong Pasupat,Tianze Shi,Jonathan Herzig,Emily Pitler etc 2022 ![](https://img.shields.io/badge/pub-2022--05--24-green)![](https://img.shields.io/badge/cite-10-red)

[**Large Language Models are Zero-Shot Reasoners**](https://arxiv.org/abs/2302.135402205.11916) 👨‍🎓Takeshi Kojima,S. Gu,Machel Reid,Yutaka Matsuo,Yusuke Iwasawa 2022 ![](https://img.shields.io/badge/pub-2022--05--24-green)![](https://img.shields.io/badge/cite-176-red)

[**Instruction Induction: From Few Examples to Natural Language Task Descriptions**](https://doi.org/10.48550/arXiv.2205.10782) 👨‍🎓Or Honovich,Uri Shaham,Samuel R. Bowman,Omer Levy 2022 ![](https://img.shields.io/badge/pub-2022--05--22-green)![](https://img.shields.io/badge/cite-8-red)

[**Prototypical Calibration for Few-shot Learning of Language Models**](https://doi.org/10.48550/arXiv.2205.10183) 👨‍🎓Zhixiong Han,Y. Hao,Li Dong,Yutao Sun,Furu Wei 2022 ![](https://img.shields.io/badge/pub-2022--05--20-green)![](https://img.shields.io/badge/cite-4-red)

[**Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning**](https://doi.org/10.48550/arXiv.2205.05638) 👨‍🎓Haokun Liu,Derek Tam,Mohammed Muqeeth,Jay Mohta,Tenghao Huang,Mohit Bansal etc 2022 ![](https://img.shields.io/badge/pub-2022--05--11-green)![](https://img.shields.io/badge/cite-55-red)

[**The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning**](https://arxiv.org/abs/2302.135402205.03401) 👨‍🎓Xi Ye,Greg Durrett 2022 ![](https://img.shields.io/badge/pub-2022--05--06-green)![](https://img.shields.io/badge/cite-9-red)

[**Improving In-Context Few-Shot Learning via Self-Supervised Training**](https://doi.org/10.48550/arXiv.2205.01703) 👨‍🎓Mingda Chen,Jingfei Du,Ramakanth Pasunuru,Todor Mihaylov,Srini Iyer,V. Stoyanov etc 2022 ![](https://img.shields.io/badge/pub-2022--05--03-green)![](https://img.shields.io/badge/cite-5-red)

[**OPT: Open Pre-trained Transformer Language Models**](https://arxiv.org/abs/2302.135402205.01068) 👨‍🎓Susan Zhang,Stephen Roller,Naman Goyal,Mikel Artetxe,Moya Chen,Shuohui Chen etc 2022 ![](https://img.shields.io/badge/pub-2022--05--02-green)![](https://img.shields.io/badge/cite-296-red)

[**On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model**](https://doi.org/10.48550/arXiv.2204.13509) 👨‍🎓Seongjin Shin,Sang-Woo Lee,Hwijeen Ahn,Sungdong Kim,Hyoungseok Kim,Boseop Kim etc 2022 ![](https://img.shields.io/badge/pub-2022--04--28-green)![](https://img.shields.io/badge/cite-13-red)

[**PaLM: Scaling Language Modeling with Pathways**](https://arxiv.org/abs/2302.135402204.02311) 👨‍🎓Aakanksha Chowdhery,Sharan Narang,Jacob Devlin,Maarten Bosma,Gaurav Mishra,Adam Roberts etc 2022 ![](https://img.shields.io/badge/pub-2022--04--05-green)![](https://img.shields.io/badge/cite-596-red)

[**Can language models learn from explanations in context?**](https://doi.org/10.48550/arXiv.2204.02329) 👨‍🎓Andrew Kyle Lampinen,I. Dasgupta,Stephanie C. Y. Chan,Kory Matthewson,Michael Henry Tessler,Antonia Creswell etc 2022 ![](https://img.shields.io/badge/pub-2022--04--05-green)![](https://img.shields.io/badge/cite-60-red)

[**Prompt-free and Efficient Few-shot Learning with Language Models**](https://doi.org/10.48550/arXiv.2204.01172) 👨‍🎓Rabeeh Karimi Mahabadi,Luke Zettlemoyer,J. Henderson,Marzieh Saeidi,Lambert Mathias,V. Stoyanov etc 2022 ![](https://img.shields.io/badge/pub-2022--04--03-green)![](https://img.shields.io/badge/cite-20-red)

[**Self-Consistency Improves Chain of Thought Reasoning in Language Models**](https://doi.org/10.48550/arXiv.2203.11171) 👨‍🎓Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou etc 2022 ![](https://img.shields.io/badge/pub-2022--03--21-green)![](https://img.shields.io/badge/cite-126-red)

[**Iteratively Prompt Pre-trained Language Models for Chain of Thought**](https://arxiv.org/abs/2302.135402203.08383) 👨‍🎓Boshi Wang,Xiang Deng,Huan Sun 2022 ![](https://img.shields.io/badge/pub-2022--03--16-green)![](https://img.shields.io/badge/cite-5-red)

[**GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models**](https://doi.org/10.48550/arXiv.2203.07281) 👨‍🎓Archiki Prasad,Peter Hase,Xiang Zhou,Mohit Bansal 2022 ![](https://img.shields.io/badge/pub-2022--03--14-green)![](https://img.shields.io/badge/cite-23-red)

[**Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?**](https://arxiv.org/abs/2302.135402202.12837) 👨‍🎓Sewon Min,Xinxi Lyu,Ari Holtzman,Mikel Artetxe,M. Lewis,Hannaneh Hajishirzi etc 2022 ![](https://img.shields.io/badge/pub-2022--02--25-green)![](https://img.shields.io/badge/cite-121-red)

[**AdaPrompt: Adaptive Model Training for Prompt-based NLP**](https://arxiv.org/abs/2302.135402202.04824) 👨‍🎓Yulong Chen,Yang Liu,Li Dong,Shuohang Wang,Chenguang Zhu,Michael Zeng etc 2022 ![](https://img.shields.io/badge/pub-2022--02--10-green)![](https://img.shields.io/badge/cite-11-red)

[**PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts**](https://doi.org/10.18653/v1/2022.acl-demo.9) 👨‍🎓Stephen H. Bach,Victor Sanh,Zheng Xin Yong,Albert Webson,Colin Raffel,Nihal V. Nayak etc 2022 ![](https://img.shields.io/badge/pub-2022--02--02-green)![](https://img.shields.io/badge/cite-53-red)

[**Co-training Improves Prompt-based Learning for Large Language Models**](https://arxiv.org/abs/2302.135402202.00828) 👨‍🎓Hunter Lang,Monica Agrawal,Yoon Kim,D. Sontag 2022 ![](https://img.shields.io/badge/pub-2022--02--02-green)![](https://img.shields.io/badge/cite-8-red)

[**Chain of Thought Prompting Elicits Reasoning in Large Language Models**](https://arxiv.org/abs/2302.135402201.11903) 👨‍🎓Jason Wei,Xuezhi Wang,Dale Schuurmans,Maarten Bosma,E. Chi,Quoc Le etc 2022 ![](https://img.shields.io/badge/pub-2022--01--28-green)![](https://img.shields.io/badge/cite-368-red)

[**Black-box Prompt Learning for Pre-trained Language Models**](https://arxiv.org/abs/2302.135402201.08531) 👨‍🎓Shizhe Diao,Xuechun Li,Yong Lin,Zhichao Huang,Xiao Zhou,Tong Zhang etc 2022 ![](https://img.shields.io/badge/pub-2022--01--21-green)![](https://img.shields.io/badge/cite-17-red)

[**UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models**](https://arxiv.org/abs/2302.135402201.05966) 👨‍🎓Tianbao Xie,Chen Henry Wu,Peng Shi,Ruiqi Zhong,Torsten Scholak,Michihiro Yasunaga etc 2022 ![](https://img.shields.io/badge/pub-2022--01--16-green)![](https://img.shields.io/badge/cite-96-red)

[**Learning To Retrieve Prompts for In-Context Learning**](https://doi.org/10.18653/v1/2022.naacl-main.191) 👨‍🎓Ohad Rubin,Jonathan Herzig,Jonathan Berant 2021 ![](https://img.shields.io/badge/pub-2021--12--16-green)![](https://img.shields.io/badge/cite-80-red)

[**Few-Shot Semantic Parsing with Language Models Trained on Code**](https://doi.org/10.18653/v1/2022.naacl-main.396) 👨‍🎓Richard Shin,Benjamin Van Durme 2021 ![](https://img.shields.io/badge/pub-2021--12--16-green)![](https://img.shields.io/badge/cite-19-red)

[**Scaling Language Models: Methods, Analysis & Insights from Training Gopher**](https://arxiv.org/abs/2302.135402112.11446) 👨‍🎓Jack W. Rae,Sebastian Borgeaud,Trevor Cai,Katie Millican,Jordan Hoffmann,Francis Song etc 2021 ![](https://img.shields.io/badge/pub-2021--12--08-green)![](https://img.shields.io/badge/cite-300-red)

[**True Few-Shot Learning with Prompts—A Real-World Perspective**](https://doi.org/10.1162/tacl_a_00485) 👨‍🎓Timo Schick,Hinrich Schütze 2021 ![](https://img.shields.io/badge/pub-2021--11--26-green)![](https://img.shields.io/badge/cite-14-red)

[**An Explanation of In-context Learning as Implicit Bayesian Inference**](https://arxiv.org/abs/2302.135402111.02080) 👨‍🎓Sang Michael Xie,Aditi Raghunathan,Percy Liang,Tengyu Ma 2021 ![](https://img.shields.io/badge/pub-2021--11--03-green)![](https://img.shields.io/badge/cite-52-red)

[**MetaICL: Learning to Learn In Context**](https://doi.org/10.18653/v1/2022.naacl-main.201) 👨‍🎓Sewon Min,M. Lewis,Luke Zettlemoyer,Hannaneh Hajishirzi 2021 ![](https://img.shields.io/badge/pub-2021--10--29-green)![](https://img.shields.io/badge/cite-80-red)

[**Meta-learning via Language Model In-context Tuning**](https://doi.org/10.18653/v1/2022.acl-long.53) 👨‍🎓Yanda Chen,Ruiqi Zhong,Sheng Zha,G. Karypis,He He 2021 ![](https://img.shields.io/badge/pub-2021--10--15-green)![](https://img.shields.io/badge/cite-31-red)

[**Few-Shot Bot: Prompt-Based Learning for Dialogue Systems**](https://arxiv.org/abs/2302.135402110.08118) 👨‍🎓Andrea Madotto,Zhaojiang Lin,Genta Indra Winata,Pascale Fung 2021 ![](https://img.shields.io/badge/pub-2021--10--15-green)![](https://img.shields.io/badge/cite-24-red)

[**Coherence boosting: When your pretrained language model is not paying enough attention**](https://doi.org/10.18653/v1/2022.acl-long.565) 👨‍🎓Nikolay Malkin,Zhen Wang,N. Jojic 2021 ![](https://img.shields.io/badge/pub-2021--10--15-green)![](https://img.shields.io/badge/cite-4-red)

[**Reframing Instructional Prompts to GPTk’s Language**](https://doi.org/10.18653/v1/2022.findings-acl.50) 👨‍🎓Swaroop Mishra,Daniel Khashabi,Chitta Baral,Yejin Choi,Hannaneh Hajishirzi 2021 ![](https://img.shields.io/badge/pub-2021--09--16-green)![](https://img.shields.io/badge/cite-55-red)

[**Finetuned Language Models Are Zero-Shot Learners**](https://arxiv.org/abs/2302.135402109.01652) 👨‍🎓Jason Wei,Maarten Bosma,Vincent Zhao,Kelvin Guu,A. Yu,Brian Lester etc 2021 ![](https://img.shields.io/badge/pub-2021--09--03-green)![](https://img.shields.io/badge/cite-369-red)

[**Do Prompt-Based Models Really Understand the Meaning of Their Prompts?**](https://doi.org/10.18653/v1/2022.naacl-main.167) 👨‍🎓Albert Webson,Ellie Pavlick 2021 ![](https://img.shields.io/badge/pub-2021--09--02-green)![](https://img.shields.io/badge/cite-66-red)

[**Noisy Channel Language Model Prompting for Few-Shot Text Classification**](https://doi.org/10.18653/v1/2022.acl-long.365) 👨‍🎓Sewon Min,Michael Lewis,Hannaneh Hajishirzi,Luke Zettlemoyer 2021 ![](https://img.shields.io/badge/pub-2021--08--09-green)![](https://img.shields.io/badge/cite-69-red)

[**Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**](https://doi.org/10.1145/3560815) 👨‍🎓Pengfei Liu,Weizhe Yuan,Jinlan Fu,Zhengbao Jiang,Hiroaki Hayashi,Graham Neubig etc 2021 ![](https://img.shields.io/badge/pub-2021--07--28-green)![](https://img.shields.io/badge/cite-429-red)

[**Evaluating Large Language Models Trained on Code**](https://arxiv.org/abs/2302.135402107.03374) 👨‍🎓Mark Chen,Jerry Tworek,Heewoo Jun,Qiming Yuan,Henrique Ponde,Jared Kaplan etc 2021 ![](https://img.shields.io/badge/pub-2021--07--07-green)![](https://img.shields.io/badge/cite-594-red)

[**Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models**](https://doi.org/10.18653/v1/2022.findings-acl.222) 👨‍🎓Robert L Logan IV,Ivana Balavzevi'c,Eric Wallace,Fabio Petroni,Sameer Singh,Sebastian Riedel etc 2021 ![](https://img.shields.io/badge/pub-2021--06--24-green)![](https://img.shields.io/badge/cite-70-red)

[**True Few-Shot Learning with Language Models**](https://arxiv.org/abs/2302.135402105.11447) 👨‍🎓Ethan Perez,Douwe Kiela,Kyunghyun Cho 2021 ![](https://img.shields.io/badge/pub-2021--05--24-green)![](https://img.shields.io/badge/cite-148-red)

[**The Power of Scale for Parameter-Efficient Prompt Tuning**](https://doi.org/10.18653/v1/2021.emnlp-main.243) 👨‍🎓Brian Lester,Rami Al-Rfou,Noah Constant 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-675-red)

[**Constrained Language Models Yield Few-Shot Semantic Parsers**](https://doi.org/10.18653/v1/2021.emnlp-main.608) 👨‍🎓Richard Shin,C. H. Lin,Sam Thomson,Charles C. Chen,Subhro Roy,Emmanouil Antonios Platanios etc 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-79-red)

[**Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity**](https://doi.org/10.18653/v1/2022.acl-long.556) 👨‍🎓Yao Lu,Max Bartolo,Alastair Moore,S. Riedel,Pontus Stenetorp 2021 ![](https://img.shields.io/badge/pub-2021--04--18-green)![](https://img.shields.io/badge/cite-165-red)

[**Surface Form Competition: Why the Highest Probability Answer Isn’t Always Right**](https://doi.org/10.18653/v1/2021.emnlp-main.564) 👨‍🎓Ari Holtzman,Peter West,Vered Schwartz,Yejin Choi,Luke Zettlemoyer 2021 ![](https://img.shields.io/badge/pub-2021--04--16-green)![](https://img.shields.io/badge/cite-73-red)

[**GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow**](https://doi.org/10.5281/ZENODO.5297715) 👨‍🎓Sid Black,Leo Gao,Phil Wang,Connor Leahy,Stella Rose Biderman 2021 ![](https://img.shields.io/badge/pub-2021--03--21-green)![](https://img.shields.io/badge/cite-198-red)

[**Calibrate Before Use: Improving Few-Shot Performance of Language Models**](https://arxiv.org/abs/2302.135402102.09690) 👨‍🎓Tony Zhao,Eric Wallace,Shi Feng,D. Klein,Sameer Singh 2021 ![](https://img.shields.io/badge/pub-2021--02--19-green)![](https://img.shields.io/badge/cite-277-red)

[**What Makes Good In-Context Examples for GPT-3?**](https://doi.org/10.18653/v1/2022.deelio-1.10) 👨‍🎓Jiachang Liu,Dinghan Shen,Yizhe Zhang,Bill Dolan,L. Carin,Weizhu Chen etc 2021 ![](https://img.shields.io/badge/pub-2021--01--17-green)![](https://img.shields.io/badge/cite-163-red)

[**Making Pre-trained Language Models Better Few-shot Learners**](https://doi.org/10.18653/v1/2021.acl-long.295) 👨‍🎓Tianyu Gao,Adam Fisch,Danqi Chen 2021 ![](https://img.shields.io/badge/pub-2021--01--01-green)![](https://img.shields.io/badge/cite-635-red)

[**The Pile: An 800GB Dataset of Diverse Text for Language Modeling**](https://arxiv.org/abs/2302.135402101.00027) 👨‍🎓Leo Gao,Stella Rose Biderman,Sid Black,Laurence Golding,Travis Hoppe,Charles Foster etc 2020 ![](https://img.shields.io/badge/pub-2020--12--31-green)![](https://img.shields.io/badge/cite-328-red)

[**Language Models are Few-Shot Learners**](https://arxiv.org/abs/2302.135402005.14165) 👨‍🎓Tom B. Brown,Benjamin Mann,Nick Ryder,Melanie Subbiah,J. Kaplan,Prafulla Dhariwal etc 2020 ![](https://img.shields.io/badge/pub-2020--05--28-green)![](https://img.shields.io/badge/cite-8351-red)

[**ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators**](https://arxiv.org/abs/2302.135402003.10555) 👨‍🎓Kevin Clark,Minh-Thang Luong,Quoc V. Le,Christopher D. Manning 2020 ![](https://img.shields.io/badge/pub-2020--03--23-green)![](https://img.shields.io/badge/cite-1846-red)

[**Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference**](https://doi.org/10.18653/v1/2021.eacl-main.20) 👨‍🎓Timo Schick,Hinrich Schütze 2020 ![](https://img.shields.io/badge/pub-2020--01--21-green)![](https://img.shields.io/badge/cite-579-red)

[**Momentum Contrast for Unsupervised Visual Representation Learning**](https://doi.org/10.1109/cvpr42600.2020.00975) 👨‍🎓Kaiming He,Haoqi Fan,Yuxin Wu,Saining Xie,Ross B. Girshick 2019 ![](https://img.shields.io/badge/pub-2019--11--13-green)![](https://img.shields.io/badge/cite-5429-red)

[**BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension**](https://doi.org/10.18653/v1/2020.acl-main.703) 👨‍🎓M. Lewis,Yinhan Liu,Naman Goyal,Marjan Ghazvininejad,Abdelrahman Mohamed,Omer Levy etc 2019 ![](https://img.shields.io/badge/pub-2019--10--29-green)![](https://img.shields.io/badge/cite-4052-red)

[**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**](https://arxiv.org/abs/2302.135401910.10683) 👨‍🎓Colin Raffel,Noam M. Shazeer,Adam Roberts,Katherine Lee,Sharan Narang,Michael Matena etc 2019 ![](https://img.shields.io/badge/pub-2019--10--23-green)![](https://img.shields.io/badge/cite-6286-red)

[**HuggingFace's Transformers: State-of-the-art Natural Language Processing**](https://arxiv.org/abs/2302.135401910.03771) 👨‍🎓Thomas Wolf,Lysandre Debut,Victor Sanh,Julien Chaumond,Clement Delangue,Anthony Moi etc 2019 ![](https://img.shields.io/badge/pub-2019--10--09-green)![](https://img.shields.io/badge/cite-3513-red)

[**Transformers: State-of-the-Art Natural Language Processing**](https://doi.org/10.18653/v1/2020.emnlp-demos.6) 👨‍🎓Thomas Wolf,Lysandre Debut,Victor Sanh,Julien Chaumond,Clement Delangue,Anthony Moi etc 2019 ![](https://img.shields.io/badge/pub-2019--10--09-green)![](https://img.shields.io/badge/cite-3941-red)

[**ALBERT: A Lite BERT for Self-supervised Learning of Language Representations**](https://arxiv.org/abs/2302.135401909.11942) 👨‍🎓Zhenzhong Lan,Mingda Chen,Sebastian Goodman,Kevin Gimpel,Piyush Sharma,Radu Soricut etc 2019 ![](https://img.shields.io/badge/pub-2019--09--26-green)![](https://img.shields.io/badge/cite-3711-red)

[**RoBERTa: A Robustly Optimized BERT Pretraining Approach**](https://arxiv.org/abs/2302.135401907.11692) 👨‍🎓Yinhan Liu,Myle Ott,Naman Goyal,Jingfei Du,Mandar Joshi,Danqi Chen etc 2019 ![](https://img.shields.io/badge/pub-2019--07--26-green)![](https://img.shields.io/badge/cite-10930-red)

[**BERTScore: Evaluating Text Generation with BERT**](https://arxiv.org/abs/2302.135401904.09675) 👨‍🎓Tianyi Zhang,Varsha Kishore,Felix Wu,Kilian Q. Weinberger,Yoav Artzi 2019 ![](https://img.shields.io/badge/pub-2019--04--21-green)![](https://img.shields.io/badge/cite-1634-red)

[**BioBERT: a pre-trained biomedical language representation model for biomedical text mining**](https://doi.org/10.1093/bioinformatics/btz682) 👨‍🎓Jinhyuk Lee,Wonjin Yoon,Sungdong Kim,Donghyeon Kim,Sunkyu Kim,Chan Ho So etc 2019 ![](https://img.shields.io/badge/pub-2019--01--25-green)![](https://img.shields.io/badge/cite-2743-red)

[**Representation Learning with Contrastive Predictive Coding**](https://arxiv.org/abs/2302.135401807.03748) 👨‍🎓Aäron van den Oord,Yazhe Li,Oriol Vinyals 2018 ![](https://img.shields.io/badge/pub-2018--07--10-green)![](https://img.shields.io/badge/cite-4597-red)

[**Know What You Don’t Know: Unanswerable Questions for SQuAD**](https://doi.org/10.18653/v1/P18-2124) 👨‍🎓Pranav Rajpurkar,Robin Jia,Percy Liang 2018 ![](https://img.shields.io/badge/pub-2018--06--11-green)![](https://img.shields.io/badge/cite-1718-red)

[**GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding**](https://doi.org/10.18653/v1/W18-5446) 👨‍🎓Alex Wang,Amanpreet Singh,Julian Michael,Felix Hill,Omer Levy,Samuel R. Bowman etc 2018 ![](https://img.shields.io/badge/pub-2018--04--20-green)![](https://img.shields.io/badge/cite-3499-red)

[**UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction**](https://arxiv.org/abs/2302.135401802.03426) 👨‍🎓Leland McInnes,John Healy 2018 ![](https://img.shields.io/badge/pub-2018--02--09-green)![](https://img.shields.io/badge/cite-5118-red)

[**Decoupled Weight Decay Regularization**](https://api.semanticscholar.org/d07284a6811f1b2745d91bdb06b040b57f226882) 👨‍🎓I. Loshchilov,F. Hutter 2017 ![](https://img.shields.io/badge/pub-2017--11--14-green)![](https://img.shields.io/badge/cite-6264-red)

[**On Calibration of Modern Neural Networks**](https://arxiv.org/abs/2302.135401706.04599) 👨‍🎓Chuan Guo,Geoff Pleiss,Yu Sun,Kilian Q. Weinberger 2017 ![](https://img.shields.io/badge/pub-2017--06--14-green)![](https://img.shields.io/badge/cite-3066-red)

[**Attention is All you Need**](https://arxiv.org/abs/2302.135401706.03762) 👨‍🎓Ashish Vaswani,Noam M. Shazeer,Niki Parmar,Jakob Uszkoreit,Llion Jones,Aidan N. Gomez etc 2017 ![](https://img.shields.io/badge/pub-2017--06--12-green)![](https://img.shields.io/badge/cite-51971-red)

[**Curiosity-Driven Exploration by Self-Supervised Prediction**](https://doi.org/10.1109/CVPRW.2017.70) 👨‍🎓Deepak Pathak,Pulkit Agrawal,Alexei A. Efros,Trevor Darrell 2017 ![](https://img.shields.io/badge/pub-2017--05--15-green)![](https://img.shields.io/badge/cite-1672-red)

[**A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference**](https://doi.org/10.18653/v1/N18-1101) 👨‍🎓Adina Williams,Nikita Nangia,Samuel R. Bowman 2017 ![](https://img.shields.io/badge/pub-2017--04--18-green)![](https://img.shields.io/badge/cite-2610-red)

[**Understanding Black-box Predictions via Influence Functions**](https://arxiv.org/abs/2302.135401703.04730) 👨‍🎓Pang Wei Koh,Percy Liang 2017 ![](https://img.shields.io/badge/pub-2017--03--14-green)![](https://img.shields.io/badge/cite-1811-red)

[**Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks**](https://arxiv.org/abs/2302.135401703.03400) 👨‍🎓Chelsea Finn,P. Abbeel,S. Levine 2017 ![](https://img.shields.io/badge/pub-2017--03--09-green)![](https://img.shields.io/badge/cite-7087-red)

[**Axiomatic Attribution for Deep Networks**](https://arxiv.org/abs/2302.135401703.01365) 👨‍🎓Mukund Sundararajan,Ankur Taly,Qiqi Yan 2017 ![](https://img.shields.io/badge/pub-2017--03--04-green)![](https://img.shields.io/badge/cite-3082-red)

[**Billion-Scale Similarity Search with GPUs**](https://doi.org/10.1109/tbdata.2019.2921572) 👨‍🎓Jeff Johnson,Matthijs Douze,H. Jégou 2017 ![](https://img.shields.io/badge/pub-2017--02--28-green)![](https://img.shields.io/badge/cite-1725-red)

[**Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles**](https://arxiv.org/abs/2302.135401612.01474) 👨‍🎓Balaji Lakshminarayanan,A. Pritzel,C. Blundell 2016 ![](https://img.shields.io/badge/pub-2016--12--05-green)![](https://img.shields.io/badge/cite-3175-red)

[**Understanding deep learning requires rethinking generalization**](https://arxiv.org/abs/2302.135401611.03530) 👨‍🎓Chiyuan Zhang,Samy Bengio,Moritz Hardt,B. Recht,Oriol Vinyals 2016 ![](https://img.shields.io/badge/pub-2016--11--04-green)![](https://img.shields.io/badge/cite-3936-red)

[**Optimization as a Model for Few-Shot Learning**](https://api.semanticscholar.org/29c887794eed2ca9462638ff853e6fe1ab91d5d8) 👨‍🎓S. Ravi,H. Larochelle 2016 ![](https://img.shields.io/badge/pub-2016--11--04-green)![](https://img.shields.io/badge/cite-2567-red)

[**A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks**](https://arxiv.org/abs/2302.135401610.02136) 👨‍🎓Dan Hendrycks,Kevin Gimpel 2016 ![](https://img.shields.io/badge/pub-2016--10--07-green)![](https://img.shields.io/badge/cite-1788-red)

[**SQuAD: 100,000+ Questions for Machine Comprehension of Text**](https://doi.org/10.18653/v1/D16-1264) 👨‍🎓Pranav Rajpurkar,Jian Zhang,Konstantin Lopyrev,Percy Liang 2016 ![](https://img.shields.io/badge/pub-2016--06--16-green)![](https://img.shields.io/badge/cite-5197-red)

[**Matching Networks for One Shot Learning**](https://arxiv.org/abs/2302.135401606.04080) 👨‍🎓Oriol Vinyals,C. Blundell,T. Lillicrap,K. Kavukcuoglu,Daan Wierstra 2016 ![](https://img.shields.io/badge/pub-2016--06--13-green)![](https://img.shields.io/badge/cite-4816-red)

[**“Why Should I Trust You?”: Explaining the Predictions of Any Classifier**](https://doi.org/10.1145/2939672.2939778) 👨‍🎓Marco Tulio Ribeiro,Sameer Singh,Carlos Guestrin 2016 ![](https://img.shields.io/badge/pub-2016--02--16-green)![](https://img.shields.io/badge/cite-9632-red)

[**Deep Residual Learning for Image Recognition**](https://doi.org/10.1109/cvpr.2016.90) 👨‍🎓Kaiming He,X. Zhang,Shaoqing Ren,Jian Sun 2015 ![](https://img.shields.io/badge/pub-2015--12--10-green)![](https://img.shields.io/badge/cite-122183-red)

[**Character-level Convolutional Networks for Text Classification**](https://arxiv.org/abs/2302.135401509.01626) 👨‍🎓Xiang Zhang,J. Zhao,Yann LeCun 2015 ![](https://img.shields.io/badge/pub-2015--09--04-green)![](https://img.shields.io/badge/cite-4160-red)

[**A large annotated corpus for learning natural language inference**](https://doi.org/10.18653/v1/D15-1075) 👨‍🎓Samuel R. Bowman,Gabor Angeli,Christopher Potts,Christopher D. Manning 2015 ![](https://img.shields.io/badge/pub-2015--08--21-green)![](https://img.shields.io/badge/cite-2999-red)

[**ActivityNet: A large-scale video benchmark for human activity understanding**](https://doi.org/10.1109/CVPR.2015.7298698) 👨‍🎓Fabian Caba Heilbron,Victor Escorcia,Bernard Ghanem,Juan Carlos Niebles 2015 ![](https://img.shields.io/badge/pub-2015--06--07-green)![](https://img.shields.io/badge/cite-1612-red)

[**Adam: A Method for Stochastic Optimization**](https://arxiv.org/abs/2302.135401412.6980) 👨‍🎓Diederik P. Kingma,Jimmy Ba 2014 ![](https://img.shields.io/badge/pub-2014--12--22-green)![](https://img.shields.io/badge/cite-110816-red)

[**Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps**](https://arxiv.org/abs/2302.135401312.6034) 👨‍🎓K. Simonyan,A. Vedaldi,Andrew Zisserman 2013 ![](https://img.shields.io/badge/pub-2013--12--20-green)![](https://img.shields.io/badge/cite-5229-red)

[**Playing Atari with Deep Reinforcement Learning**](https://arxiv.org/abs/2302.135401312.5602) 👨‍🎓Volodymyr Mnih,K. Kavukcuoglu,David Silver,A. Graves,Ioannis Antonoglou,Daan Wierstra etc 2013 ![](https://img.shields.io/badge/pub-2013--12--19-green)![](https://img.shields.io/badge/cite-8414-red)

[**Hidden factors and hidden topics: understanding rating dimensions with review text**](https://doi.org/10.1145/2507157.2507163) 👨‍🎓Julian McAuley,J. Leskovec 2013 ![](https://img.shields.io/badge/pub-2013--10--12-green)![](https://img.shields.io/badge/cite-1517-red)

[**Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank**](https://api.semanticscholar.org/687bac2d3320083eb4530bf18bb8f8f721477600) 👨‍🎓R. Socher,Alex Perelygin,Jean Wu,Jason Chuang,Christopher D. Manning,A. Ng etc 2013 ![](https://img.shields.io/badge/pub-2013--10--01-green)![](https://img.shields.io/badge/cite-6124-red)

[**Efficient Estimation of Word Representations in Vector Space**](https://arxiv.org/abs/2302.135401301.3781) 👨‍🎓Tomas Mikolov,Kai Chen,G. Corrado,J. Dean 2013 ![](https://img.shields.io/badge/pub-2013--01--16-green)![](https://img.shields.io/badge/cite-25157-red)

[**The NumPy Array: A Structure for Efficient Numerical Computation**](https://doi.org/10.1109/MCSE.2011.37) 👨‍🎓S. Walt,S. Colbert,G. Varoquaux 2011 ![](https://img.shields.io/badge/pub-2011--02--07-green)![](https://img.shields.io/badge/cite-6594-red)

[**Steven Bird, Ewan Klein and Edward Loper: Natural Language Processing with Python, Analyzing Text with the Natural Language Toolkit**](https://doi.org/10.1007/s10579-010-9124-x) 👨‍🎓Wiebke Wagner 2010 ![](https://img.shields.io/badge/pub-2010--12--01-green)![](https://img.shields.io/badge/cite-1724-red)

[**Why Does Unsupervised Pre-training Help Deep Learning?**](https://doi.org/10.5555/1756006.1756025) 👨‍🎓D. Erhan,Aaron C. Courville,Yoshua Bengio,Pascal Vincent 2010 ![](https://img.shields.io/badge/pub-2010--03--01-green)![](https://img.shields.io/badge/cite-2072-red)

[**The Probabilistic Relevance Framework: BM25 and Beyond**](https://doi.org/10.1561/1500000019) 👨‍🎓S. Robertson,H. Zaragoza 2009 ![](https://img.shields.io/badge/pub-2009--04--01-green)![](https://img.shields.io/badge/cite-1854-red)

[**Learning to rank for information retrieval**](https://doi.org/10.1007/978-3-642-14267-3) 👨‍🎓Tie-Yan Liu 2009 ![](https://img.shields.io/badge/pub-2009--03--01-green)![](https://img.shields.io/badge/cite-2730-red)

[**The PASCAL Recognising Textual Entailment Challenge**](https://doi.org/10.1007/11736790_9) 👨‍🎓Ido Dagan,Oren Glickman,B. Magnini 2007 ![](https://img.shields.io/badge/pub-2007--06--28-green)![](https://img.shields.io/badge/cite-1948-red)

[**Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales**](https://doi.org/10.3115/1219840.1219855) 👨‍🎓B. Pang,Lillian Lee 2005 ![](https://img.shields.io/badge/pub-2005--06--17-green)![](https://img.shields.io/badge/cite-2509-red)

[**A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts**](https://doi.org/10.3115/1218955.1218990) 👨‍🎓B. Pang,Lillian Lee 2004 ![](https://img.shields.io/badge/pub-2004--07--21-green)![](https://img.shields.io/badge/cite-3765-red)

[**Latent Dirichlet Allocation**](https://doi.org/10.1016/B978-0-12-411519-4.00006-9) 👨‍🎓D. Blei,A. Ng,Michael I. Jordan 2001 ![](https://img.shields.io/badge/pub-2001--01--03-green)![](https://img.shields.io/badge/cite-33642-red)

[**Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping**](https://api.semanticscholar.org/94066dc12fe31e96af7557838159bde598cb4f10) 👨‍🎓A. Ng,D. Harada,Stuart J. Russell 1999 ![](https://img.shields.io/badge/pub-1999--06--27-green)![](https://img.shields.io/badge/cite-1797-red)

[**OPTICS: ordering points to identify the clustering structure**](https://doi.org/10.1145/304182.304187) 👨‍🎓M. Ankerst,M. Breunig,H. Kriegel,J. Sander 1999 ![](https://img.shields.io/badge/pub-1999--06--01-green)![](https://img.shields.io/badge/cite-3993-red)

[**An Introduction to Variational Methods for Graphical Models**](https://doi.org/10.1023/A:1007665907178) 👨‍🎓Michael I. Jordan,Zoubin Ghahramani,T. Jaakkola,L. Saul 1999 ![](https://img.shields.io/badge/pub-1999--02--01-green)![](https://img.shields.io/badge/cite-4039-red)

[**Long Short-Term Memory**](https://doi.org/10.1162/neco.1997.9.8.1735) 👨‍🎓S. Hochreiter,J. Schmidhuber 1997 ![](https://img.shields.io/badge/pub-1997--11--01-green)![](https://img.shields.io/badge/cite-61441-red)

[**Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory.**](https://doi.org/10.1037/0033-295X.102.3.419) 👨‍🎓James L. McClelland,B. McNaughton,R. O’Reilly 1995 ![](https://img.shields.io/badge/pub-1995--07--01-green)![](https://img.shields.io/badge/cite-4614-red)

[**Memory and the hippocampus: a synthesis from findings with rats, monkeys, and humans.**](https://doi.org/10.1037/0033-295X.99.2.195) 👨‍🎓L. Squire 1992 ![](https://img.shields.io/badge/pub-1992--03--30-green)![](https://img.shields.io/badge/cite-5284-red)

[**Learning internal representations by error propagation**](https://doi.org/10.1016/B978-1-4832-1446-7.50035-2) 👨‍🎓D. Rumelhart,Geoffrey E. Hinton,Ronald J. Williams 1986 ![](https://img.shields.io/badge/pub-1986--01--03-green)![](https://img.shields.io/badge/cite-20072-red)

[**Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper**](https://doi.org/10.1111/J.2517-6161.1977.TB01600.X) 👨‍🎓A. Dempster,N. Laird,D. Rubin 1977 ![](https://img.shields.io/badge/pub-1977--09--01-green)![](https://img.shields.io/badge/cite-50347-red)

[**Monte Carlo Sampling Methods Using Markov Chains and Their Applications**](https://doi.org/10.1093/BIOMET/57.1.97) 👨‍🎓W. K. Hastings 1970 ![](https://img.shields.io/badge/pub-1970--04--01-green)![](https://img.shields.io/badge/cite-14415-red)

[**Statistical Inference for Probabilistic Functions of Finite State Markov Chains**](https://doi.org/10.1214/AOMS/1177699147) 👨‍🎓L. Baum,T. Petrie 1966 ![](https://img.shields.io/badge/pub-1966--12--01-green)![](https://img.shields.io/badge/cite-2906-red)

[**A Markovian Decision Process**](https://doi.org/10.1512/IUMJ.1957.6.56038) 👨‍🎓R. Bellman 1957 ![](https://img.shields.io/badge/pub-1957--04--18-green)![](https://img.shields.io/badge/cite-2103-red)

[**Equation of state calculations by fast computing machines**](https://doi.org/10.1063/1.1699114) 👨‍🎓N. Metropolis,A. W. Rosenbluth,M. Rosenbluth,A. H. Teller,E. Teller 1953 ![](https://img.shields.io/badge/pub-1953--06--01-green)![](https://img.shields.io/badge/cite-33689-red)

[**DBpedia - A large-scale, multilingual knowledge base extracted from Wikipedia**](https://doi.org/10.3233/SW-140134) 👨‍🎓Jens Lehmann,Robert Isele,Max Jakob,Anja Jentzsch,D. Kontokostas,Pablo N. Mendes etc 2015 ![](https://img.shields.io/badge/cite-2645-red)

[**Probabilistic Outputs for Support vector Machines and Comparisons to Regularized Likelihood Methods**](https://api.semanticscholar.org/384bb3944abe9441dcd2cede5e7cd7353e9ee5f7) 👨‍🎓J. Platt 1999 ![](https://img.shields.io/badge/cite-5501-red)

[**Speech and language processing - an introduction to natural language processing, computational linguistics, and speech recognition**](https://api.semanticscholar.org/b54bcfca3fddc26b8889739a247a25e445818149) 👨‍🎓Dan Jurafsky,James H. Martin 2000 ![](https://img.shields.io/badge/cite-3977-red)

[**Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond**](https://doi.org/10.1109/tnn.2005.848998) 👨‍🎓A. Atiya 2005 ![](https://img.shields.io/badge/cite-8566-red)

[**Stochastic Neighbor Embedding**](https://api.semanticscholar.org/14d46c6396837986bb4b9a14024cb64797b8c6c0) 👨‍🎓Geoffrey E. Hinton,S. Roweis 2002 ![](https://img.shields.io/badge/cite-1601-red)

[**SMOTE: Synthetic Minority Over-sampling Technique**](https://doi.org/10.1613/jair.953) 👨‍🎓N. Chawla,K. Bowyer,L. Hall,W. Kegelmeyer 2002 ![](https://img.shields.io/badge/cite-17180-red)

[**Improving Language Understanding by Generative Pre-Training**](https://api.semanticscholar.org/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035) 👨‍🎓Alec Radford,Karthik Narasimhan 2018 ![](https://img.shields.io/badge/cite-4775-red)

[**The use of MMR, diversity-based reranking for reordering documents and producing summaries**](https://doi.org/10.1145/290941.291025) 👨‍🎓J. Carbonell,Jade Goldstein-Stewart 1998 ![](https://img.shields.io/badge/cite-2508-red)

[**Human behavior and the principle of least effort**](https://doi.org/10.1037/h0052803) 👨‍🎓G. Zipf 1949 ![](https://img.shields.io/badge/cite-7346-red)

[**Language Models are Unsupervised Multitask Learners**](https://api.semanticscholar.org/9405cc0d6169988371b2755e573cc28650d14dfe) 👨‍🎓Alec Radford,Jeff Wu,Rewon Child,D. Luan,Dario Amodei,Ilya Sutskever etc 2019 ![](https://img.shields.io/badge/cite-8849-red)

[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://doi.org/10.18653/v1/N19-1423) 👨‍🎓Jacob Devlin,Ming-Wei Chang,Kenton Lee,Kristina Toutanova 2019 ![](https://img.shields.io/badge/cite-47696-red)

[**Active Learning Literature Survey**](https://api.semanticscholar.org/818826f356444f3daa3447755bf63f171f39ec47) 👨‍🎓Burr Settles 2009 ![](https://img.shields.io/badge/cite-5213-red)

[**of the Association for Computational Linguistics:**](https://doi.org/10.1016/b0-08-044854-2/05234-2) 👨‍🎓Vladimir Meza Ruiz,Rashmi Gangadharaiah,Maria Leonor Pacheco,Danqi Chen,Ryan Cotterell 2001 ![](https://img.shields.io/badge/cite-4067-red)

# CONTINUE...
